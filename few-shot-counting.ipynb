{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of HW6_Q2_final",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8x5HFdKa2NF"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxEGCblRPqze",
        "outputId": "ef93e5d2-1c24-4404-c097-222d14e86365"
      },
      "source": [
        "!git clone https://github.com/cvlab-stonybrook/LearningToCountEverything"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'LearningToCountEverything'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 64 (delta 17), reused 17 (delta 17), pack-reused 43\u001b[K\n",
            "Unpacking objects: 100% (64/64), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZy-lCYARvqM"
      },
      "source": [
        "# Setup "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izdqTiGfRH8c",
        "outputId": "457ad468-9765-4919-95bc-1242b7af6dad"
      },
      "source": [
        "%cd LearningToCountEverything/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LearningToCountEverything\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M71bcZ92UIkP",
        "outputId": "fcbf0634-6f59-43df-f7a3-bd3567b5ba72"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/    learn2countEverything.png  orange_box_ex.txt  README.md  train.py\n",
            "demo.py  model.py                   orange.jpg         test.py    utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpUP696M8vb5",
        "outputId": "48b20aad-b781-4fc5-fcc1-9077a8c22c72"
      },
      "source": [
        "%cd data/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LearningToCountEverything/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyJ3r4ej1ZH3",
        "outputId": "de263b49-8591-4a40-fc28-5c811984c43b"
      },
      "source": [
        "# upload images_384_VarV2 and mask_images\n",
        "!unzip images_384_VarV2.zip\n",
        "!unzip mask_images.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  inflating: mask_images/2029_anno.png  \n",
            "  inflating: mask_images/595_anno.png  \n",
            "  inflating: mask_images/5667_anno.png  \n",
            "  inflating: mask_images/3674_anno.png  \n",
            "  inflating: mask_images/587_anno.png  \n",
            "  inflating: mask_images/49_anno.png  \n",
            "  inflating: mask_images/2894_anno.png  \n",
            "  inflating: mask_images/5033_anno.png  \n",
            "  inflating: mask_images/7698_anno.png  \n",
            "  inflating: mask_images/345_anno.png  \n",
            "  inflating: mask_images/5921_anno.png  \n",
            "  inflating: mask_images/3883_anno.png  \n",
            "  inflating: mask_images/4469_anno.png  \n",
            "  inflating: mask_images/5082_anno.png  \n",
            "  inflating: mask_images/6902_anno.png  \n",
            "  inflating: mask_images/6400_anno.png  \n",
            "  inflating: mask_images/5257_anno.png  \n",
            "  inflating: mask_images/3247_anno.png  \n",
            "  inflating: mask_images/4038_anno.png  \n",
            "  inflating: mask_images/200_anno.png  \n",
            "  inflating: mask_images/7547_anno.png  \n",
            "  inflating: mask_images/2272_anno.png  \n",
            "  inflating: mask_images/5936_anno.png  \n",
            "  inflating: mask_images/5261_anno.png  \n",
            "  inflating: mask_images/5719_anno.png  \n",
            "  inflating: mask_images/3199_anno.png  \n",
            "  inflating: mask_images/5859_anno.png  \n",
            "  inflating: mask_images/6210_anno.png  \n",
            "  inflating: mask_images/6868_anno.png  \n",
            "  inflating: mask_images/6734_anno.png  \n",
            "  inflating: mask_images/4093_anno.png  \n",
            "  inflating: mask_images/2103_anno.png  \n",
            "  inflating: mask_images/6758_anno.png  \n",
            "  inflating: mask_images/2764_anno.png  \n",
            "  inflating: mask_images/2328_anno.png  \n",
            "  inflating: mask_images/7596_anno.png  \n",
            "  inflating: mask_images/4108_anno.png  \n",
            "  inflating: mask_images/3835_anno.png  \n",
            "  inflating: mask_images/4330_anno.png  \n",
            "  inflating: mask_images/5693_anno.png  \n",
            "  inflating: mask_images/6433_anno.png  \n",
            "  inflating: mask_images/756_anno.png  \n",
            "  inflating: mask_images/319_anno.png  \n",
            "  inflating: mask_images/779_anno.png  \n",
            "  inflating: mask_images/4568_anno.png  \n",
            "  inflating: mask_images/562_anno.png  \n",
            "  inflating: mask_images/6157_anno.png  \n",
            "  inflating: mask_images/3399_anno.png  \n",
            "  inflating: mask_images/3815_anno.png  \n",
            "  inflating: mask_images/6737_anno.png  \n",
            "  inflating: mask_images/6724_anno.png  \n",
            "  inflating: mask_images/2715_anno.png  \n",
            "  inflating: mask_images/5543_anno.png  \n",
            "  inflating: mask_images/4718_anno.png  \n",
            "  inflating: mask_images/357_anno.png  \n",
            "  inflating: mask_images/6112_anno.png  \n",
            "  inflating: mask_images/3939_anno.png  \n",
            "  inflating: mask_images/6200_anno.png  \n",
            "  inflating: mask_images/290_anno.png  \n",
            " extracting: mask_images/4214_anno.png  \n",
            "  inflating: mask_images/6147_anno.png  \n",
            "  inflating: mask_images/6671_anno.png  \n",
            "  inflating: mask_images/2989_anno.png  \n",
            "  inflating: mask_images/4036_anno.png  \n",
            "  inflating: mask_images/4048_anno.png  \n",
            "  inflating: mask_images/2795_anno.png  \n",
            "  inflating: mask_images/6542_anno.png  \n",
            "  inflating: mask_images/6616_anno.png  \n",
            "  inflating: mask_images/2189_anno.png  \n",
            "  inflating: mask_images/6500_anno.png  \n",
            "  inflating: mask_images/7221_anno.png  \n",
            "  inflating: mask_images/555_anno.png  \n",
            "  inflating: mask_images/3762_anno.png  \n",
            "  inflating: mask_images/7045_anno.png  \n",
            "  inflating: mask_images/4359_anno.png  \n",
            "  inflating: mask_images/6063_anno.png  \n",
            "  inflating: mask_images/2822_anno.png  \n",
            "  inflating: mask_images/6815_anno.png  \n",
            "  inflating: mask_images/4463_anno.png  \n",
            "  inflating: mask_images/2037_anno.png  \n",
            "  inflating: mask_images/6992_anno.png  \n",
            "  inflating: mask_images/7145_anno.png  \n",
            "  inflating: mask_images/6641_anno.png  \n",
            "  inflating: mask_images/3229_anno.png  \n",
            "  inflating: mask_images/3206_anno.png  \n",
            "  inflating: mask_images/3122_anno.png  \n",
            "  inflating: mask_images/3428_anno.png  \n",
            "  inflating: mask_images/3235_anno.png  \n",
            "  inflating: mask_images/4208_anno.png  \n",
            "  inflating: mask_images/1972_anno.png  \n",
            "  inflating: mask_images/3521_anno.png  \n",
            "  inflating: mask_images/7512_anno.png  \n",
            "  inflating: mask_images/6196_anno.png  \n",
            "  inflating: mask_images/5038_anno.png  \n",
            "  inflating: mask_images/2431_anno.png  \n",
            "  inflating: mask_images/7710_anno.png  \n",
            "  inflating: mask_images/3684_anno.png  \n",
            "  inflating: mask_images/6551_anno.png  \n",
            "  inflating: mask_images/7305_anno.png  \n",
            "  inflating: mask_images/2064_anno.png  \n",
            "  inflating: mask_images/5161_anno.png  \n",
            "  inflating: mask_images/7638_anno.png  \n",
            "  inflating: mask_images/6044_anno.png  \n",
            "  inflating: mask_images/3502_anno.png  \n",
            "  inflating: mask_images/7620_anno.png  \n",
            "  inflating: mask_images/2927_anno.png  \n",
            "  inflating: mask_images/7670_anno.png  \n",
            "  inflating: mask_images/6709_anno.png  \n",
            "  inflating: mask_images/6572_anno.png  \n",
            "  inflating: mask_images/4441_anno.png  \n",
            "  inflating: mask_images/1971_anno.png  \n",
            "  inflating: mask_images/5517_anno.png  \n",
            "  inflating: mask_images/2298_anno.png  \n",
            "  inflating: mask_images/7146_anno.png  \n",
            "  inflating: mask_images/7104_anno.png  \n",
            "  inflating: mask_images/3653_anno.png  \n",
            "  inflating: mask_images/670_anno.png  \n",
            "  inflating: mask_images/5962_anno.png  \n",
            "  inflating: mask_images/4989_anno.png  \n",
            "  inflating: mask_images/5113_anno.png  \n",
            "  inflating: mask_images/6621_anno.png  \n",
            " extracting: mask_images/783_anno.png  \n",
            "  inflating: mask_images/3504_anno.png  \n",
            "  inflating: mask_images/3309_anno.png  \n",
            "  inflating: mask_images/6901_anno.png  \n",
            "  inflating: mask_images/7158_anno.png  \n",
            "  inflating: mask_images/7152_anno.png  \n",
            "  inflating: mask_images/5176_anno.png  \n",
            "  inflating: mask_images/7605_anno.png  \n",
            "  inflating: mask_images/4686_anno.png  \n",
            "  inflating: mask_images/63_anno.png  \n",
            "  inflating: mask_images/269_anno.png  \n",
            "  inflating: mask_images/3900_anno.png  \n",
            "  inflating: mask_images/5748_anno.png  \n",
            "  inflating: mask_images/7357_anno.png  \n",
            "  inflating: mask_images/2570_anno.png  \n",
            "  inflating: mask_images/3543_anno.png  \n",
            "  inflating: mask_images/2467_anno.png  \n",
            "  inflating: mask_images/2121_anno.png  \n",
            "  inflating: mask_images/4010_anno.png  \n",
            "  inflating: mask_images/2215_anno.png  \n",
            "  inflating: mask_images/4034_anno.png  \n",
            "  inflating: mask_images/4253_anno.png  \n",
            "  inflating: mask_images/581_anno.png  \n",
            "  inflating: mask_images/52_anno.png  \n",
            "  inflating: mask_images/5894_anno.png  \n",
            "  inflating: mask_images/4572_anno.png  \n",
            "  inflating: mask_images/2829_anno.png  \n",
            "  inflating: mask_images/5227_anno.png  \n",
            "  inflating: mask_images/1456_anno.png  \n",
            "  inflating: mask_images/651_anno.png  \n",
            "  inflating: mask_images/7525_anno.png  \n",
            "  inflating: mask_images/3950_anno.png  \n",
            "  inflating: mask_images/890_anno.png  \n",
            "  inflating: mask_images/3089_anno.png  \n",
            "  inflating: mask_images/2719_anno.png  \n",
            "  inflating: mask_images/644_anno.png  \n",
            "  inflating: mask_images/6229_anno.png  \n",
            "  inflating: mask_images/6622_anno.png  \n",
            "  inflating: mask_images/6717_anno.png  \n",
            "  inflating: mask_images/2697_anno.png  \n",
            "  inflating: mask_images/4662_anno.png  \n",
            "  inflating: mask_images/5347_anno.png  \n",
            "  inflating: mask_images/294_anno.png  \n",
            "  inflating: mask_images/5565_anno.png  \n",
            "  inflating: mask_images/2260_anno.png  \n",
            "  inflating: mask_images/5238_anno.png  \n",
            "  inflating: mask_images/3937_anno.png  \n",
            "  inflating: mask_images/7194_anno.png  \n",
            "  inflating: mask_images/3596_anno.png  \n",
            "  inflating: mask_images/4802_anno.png  \n",
            "  inflating: mask_images/3549_anno.png  \n",
            "  inflating: mask_images/4206_anno.png  \n",
            "  inflating: mask_images/7069_anno.png  \n",
            "  inflating: mask_images/5774_anno.png  \n",
            "  inflating: mask_images/2679_anno.png  \n",
            "  inflating: mask_images/5060_anno.png  \n",
            "  inflating: mask_images/5255_anno.png  \n",
            "  inflating: mask_images/7671_anno.png  \n",
            "  inflating: mask_images/6834_anno.png  \n",
            "  inflating: mask_images/3461_anno.png  \n",
            "  inflating: mask_images/833_anno.png  \n",
            "  inflating: mask_images/7212_anno.png  \n",
            "  inflating: mask_images/4089_anno.png  \n",
            "  inflating: mask_images/3614_anno.png  \n",
            "  inflating: mask_images/2983_anno.png  \n",
            "  inflating: mask_images/2317_anno.png  \n",
            "  inflating: mask_images/485_anno.png  \n",
            "  inflating: mask_images/3403_anno.png  \n",
            "  inflating: mask_images/6328_anno.png  \n",
            "  inflating: mask_images/2899_anno.png  \n",
            "  inflating: mask_images/3373_anno.png  \n",
            "  inflating: mask_images/7392_anno.png  \n",
            "  inflating: mask_images/6140_anno.png  \n",
            "  inflating: mask_images/5710_anno.png  \n",
            "  inflating: mask_images/6176_anno.png  \n",
            "  inflating: mask_images/7574_anno.png  \n",
            "  inflating: mask_images/420_anno.png  \n",
            "  inflating: mask_images/7701_anno.png  \n",
            "  inflating: mask_images/358_anno.png  \n",
            "  inflating: mask_images/1625_anno.png  \n",
            "  inflating: mask_images/7704_anno.png  \n",
            "  inflating: mask_images/6302_anno.png  \n",
            "  inflating: mask_images/4306_anno.png  \n",
            "  inflating: mask_images/1636_anno.png  \n",
            "  inflating: mask_images/4349_anno.png  \n",
            "  inflating: mask_images/6429_anno.png  \n",
            "  inflating: mask_images/7038_anno.png  \n",
            "  inflating: mask_images/6957_anno.png  \n",
            "  inflating: mask_images/7402_anno.png  \n",
            "  inflating: mask_images/3984_anno.png  \n",
            "  inflating: mask_images/4562_anno.png  \n",
            "  inflating: mask_images/6666_anno.png  \n",
            "  inflating: mask_images/7618_anno.png  \n",
            "  inflating: mask_images/7227_anno.png  \n",
            "  inflating: mask_images/6384_anno.png  \n",
            "  inflating: mask_images/6723_anno.png  \n",
            "  inflating: mask_images/4002_anno.png  \n",
            "  inflating: mask_images/5353_anno.png  \n",
            "  inflating: mask_images/3820_anno.png  \n",
            "  inflating: mask_images/4900_anno.png  \n",
            "  inflating: mask_images/4040_anno.png  \n",
            "  inflating: mask_images/3382_anno.png  \n",
            "  inflating: mask_images/941_anno.png  \n",
            "  inflating: mask_images/3097_anno.png  \n",
            "  inflating: mask_images/4512_anno.png  \n",
            "  inflating: mask_images/5138_anno.png  \n",
            "  inflating: mask_images/7262_anno.png  \n",
            "  inflating: mask_images/5701_anno.png  \n",
            "  inflating: mask_images/5467_anno.png  \n",
            "  inflating: mask_images/5904_anno.png  \n",
            "  inflating: mask_images/4601_anno.png  \n",
            "  inflating: mask_images/6048_anno.png  \n",
            "  inflating: mask_images/5641_anno.png  \n",
            "  inflating: mask_images/349_anno.png  \n",
            "  inflating: mask_images/4210_anno.png  \n",
            "  inflating: mask_images/6873_anno.png  \n",
            "  inflating: mask_images/5272_anno.png  \n",
            "  inflating: mask_images/7466_anno.png  \n",
            "  inflating: mask_images/4658_anno.png  \n",
            "  inflating: mask_images/2536_anno.png  \n",
            "  inflating: mask_images/5463_anno.png  \n",
            "  inflating: mask_images/3341_anno.png  \n",
            "  inflating: mask_images/3538_anno.png  \n",
            "  inflating: mask_images/5017_anno.png  \n",
            "  inflating: mask_images/219_anno.png  \n",
            "  inflating: mask_images/4137_anno.png  \n",
            "  inflating: mask_images/5893_anno.png  \n",
            "  inflating: mask_images/6562_anno.png  \n",
            "  inflating: mask_images/7378_anno.png  \n",
            "  inflating: mask_images/3620_anno.png  \n",
            "  inflating: mask_images/759_anno.png  \n",
            "  inflating: mask_images/4530_anno.png  \n",
            "  inflating: mask_images/3265_anno.png  \n",
            "  inflating: mask_images/4256_anno.png  \n",
            "  inflating: mask_images/1983_anno.png  \n",
            "  inflating: mask_images/469_anno.png  \n",
            "  inflating: mask_images/5798_anno.png  \n",
            "  inflating: mask_images/3556_anno.png  \n",
            "  inflating: mask_images/5545_anno.png  \n",
            "  inflating: mask_images/497_anno.png  \n",
            "  inflating: mask_images/3884_anno.png  \n",
            "  inflating: mask_images/2659_anno.png  \n",
            "  inflating: mask_images/3802_anno.png  \n",
            "  inflating: mask_images/4437_anno.png  \n",
            "  inflating: mask_images/6438_anno.png  \n",
            "  inflating: mask_images/5625_anno.png  \n",
            "  inflating: mask_images/34_anno.png  \n",
            "  inflating: mask_images/5012_anno.png  \n",
            "  inflating: mask_images/5413_anno.png  \n",
            "  inflating: mask_images/3706_anno.png  \n",
            "  inflating: mask_images/5030_anno.png  \n",
            "  inflating: mask_images/6778_anno.png  \n",
            "  inflating: mask_images/2437_anno.png  \n",
            "  inflating: mask_images/7118_anno.png  \n",
            "  inflating: mask_images/3686_anno.png  \n",
            "  inflating: mask_images/5430_anno.png  \n",
            "  inflating: mask_images/84_anno.png  \n",
            "  inflating: mask_images/5554_anno.png  \n",
            "  inflating: mask_images/7022_anno.png  \n",
            "  inflating: mask_images/5995_anno.png  \n",
            "  inflating: mask_images/3592_anno.png  \n",
            "  inflating: mask_images/758_anno.png  \n",
            "  inflating: mask_images/5706_anno.png  \n",
            "  inflating: mask_images/3014_anno.png  \n",
            "  inflating: mask_images/6388_anno.png  \n",
            "  inflating: mask_images/7107_anno.png  \n",
            "  inflating: mask_images/5496_anno.png  \n",
            "  inflating: mask_images/6993_anno.png  \n",
            "  inflating: mask_images/9_anno.png  \n",
            "  inflating: mask_images/7542_anno.png  \n",
            "  inflating: mask_images/429_anno.png  \n",
            "  inflating: mask_images/6389_anno.png  \n",
            "  inflating: mask_images/4564_anno.png  \n",
            "  inflating: mask_images/7414_anno.png  \n",
            "  inflating: mask_images/2900_anno.png  \n",
            "  inflating: mask_images/2095_anno.png  \n",
            "  inflating: mask_images/6504_anno.png  \n",
            "  inflating: mask_images/2411_anno.png  \n",
            "  inflating: mask_images/6488_anno.png  \n",
            "  inflating: mask_images/2020_anno.png  \n",
            "  inflating: mask_images/5519_anno.png  \n",
            "  inflating: mask_images/6867_anno.png  \n",
            "  inflating: mask_images/4085_anno.png  \n",
            "  inflating: mask_images/4555_anno.png  \n",
            "  inflating: mask_images/6235_anno.png  \n",
            "  inflating: mask_images/6864_anno.png  \n",
            "  inflating: mask_images/3761_anno.png  \n",
            "  inflating: mask_images/2803_anno.png  \n",
            "  inflating: mask_images/6114_anno.png  \n",
            "  inflating: mask_images/3982_anno.png  \n",
            "  inflating: mask_images/1106_anno.png  \n",
            "  inflating: mask_images/3190_anno.png  \n",
            "  inflating: mask_images/7442_anno.png  \n",
            "  inflating: mask_images/190_anno.png  \n",
            "  inflating: mask_images/2716_anno.png  \n",
            "  inflating: mask_images/7209_anno.png  \n",
            "  inflating: mask_images/6194_anno.png  \n",
            "  inflating: mask_images/6072_anno.png  \n",
            "  inflating: mask_images/4890_anno.png  \n",
            "  inflating: mask_images/6706_anno.png  \n",
            "  inflating: mask_images/4094_anno.png  \n",
            " extracting: mask_images/1863_anno.png  \n",
            "  inflating: mask_images/3811_anno.png  \n",
            "  inflating: mask_images/6610_anno.png  \n",
            "  inflating: mask_images/7630_anno.png  \n",
            "  inflating: mask_images/5483_anno.png  \n",
            "  inflating: mask_images/24_anno.png  \n",
            "  inflating: mask_images/885_anno.png  \n",
            "  inflating: mask_images/5732_anno.png  \n",
            "  inflating: mask_images/5516_anno.png  \n",
            "  inflating: mask_images/4557_anno.png  \n",
            "  inflating: mask_images/2902_anno.png  \n",
            "  inflating: mask_images/6223_anno.png  \n",
            "  inflating: mask_images/7137_anno.png  \n",
            "  inflating: mask_images/5036_anno.png  \n",
            "  inflating: mask_images/3983_anno.png  \n",
            "  inflating: mask_images/3445_anno.png  \n",
            "  inflating: mask_images/2500_anno.png  \n",
            "  inflating: mask_images/3405_anno.png  \n",
            "  inflating: mask_images/7086_anno.png  \n",
            "  inflating: mask_images/7575_anno.png  \n",
            "  inflating: mask_images/5382_anno.png  \n",
            "  inflating: mask_images/2247_anno.png  \n",
            "  inflating: mask_images/3065_anno.png  \n",
            "  inflating: mask_images/3916_anno.png  \n",
            "  inflating: mask_images/5403_anno.png  \n",
            "  inflating: mask_images/6541_anno.png  \n",
            "  inflating: mask_images/7359_anno.png  \n",
            "  inflating: mask_images/747_anno.png  \n",
            "  inflating: mask_images/2486_anno.png  \n",
            "  inflating: mask_images/6192_anno.png  \n",
            "  inflating: mask_images/825_anno.png  \n",
            "  inflating: mask_images/5080_anno.png  \n",
            "  inflating: mask_images/5851_anno.png  \n",
            "  inflating: mask_images/3718_anno.png  \n",
            "  inflating: mask_images/3391_anno.png  \n",
            "  inflating: mask_images/5351_anno.png  \n",
            "  inflating: mask_images/5972_anno.png  \n",
            "  inflating: mask_images/6658_anno.png  \n",
            "  inflating: mask_images/6552_anno.png  \n",
            "  inflating: mask_images/5731_anno.png  \n",
            "  inflating: mask_images/1943_anno.png  \n",
            "  inflating: mask_images/6481_anno.png  \n",
            "  inflating: mask_images/6708_anno.png  \n",
            "  inflating: mask_images/3701_anno.png  \n",
            "  inflating: mask_images/7376_anno.png  \n",
            "  inflating: mask_images/2004_anno.png  \n",
            "  inflating: mask_images/5507_anno.png  \n",
            "  inflating: mask_images/686_anno.png  \n",
            "  inflating: mask_images/7552_anno.png  \n",
            "  inflating: mask_images/2805_anno.png  \n",
            "  inflating: mask_images/59_anno.png  \n",
            "  inflating: mask_images/5185_anno.png  \n",
            "  inflating: mask_images/6960_anno.png  \n",
            "  inflating: mask_images/7454_anno.png  \n",
            "  inflating: mask_images/4104_anno.png  \n",
            "  inflating: mask_images/6332_anno.png  \n",
            "  inflating: mask_images/3090_anno.png  \n",
            "  inflating: mask_images/7373_anno.png  \n",
            "  inflating: mask_images/4785_anno.png  \n",
            "  inflating: mask_images/5172_anno.png  \n",
            "  inflating: mask_images/693_anno.png  \n",
            "  inflating: mask_images/567_anno.png  \n",
            "  inflating: mask_images/7365_anno.png  \n",
            "  inflating: mask_images/3426_anno.png  \n",
            "  inflating: mask_images/2881_anno.png  \n",
            "  inflating: mask_images/3783_anno.png  \n",
            "  inflating: mask_images/742_anno.png  \n",
            "  inflating: mask_images/7468_anno.png  \n",
            "  inflating: mask_images/3278_anno.png  \n",
            "  inflating: mask_images/7204_anno.png  \n",
            "  inflating: mask_images/331_anno.png  \n",
            "  inflating: mask_images/6188_anno.png  \n",
            "  inflating: mask_images/5664_anno.png  \n",
            "  inflating: mask_images/3525_anno.png  \n",
            "  inflating: mask_images/4803_anno.png  \n",
            "  inflating: mask_images/4327_anno.png  \n",
            "  inflating: mask_images/3271_anno.png  \n",
            "  inflating: mask_images/7544_anno.png  \n",
            "  inflating: mask_images/5281_anno.png  \n",
            "  inflating: mask_images/795_anno.png  \n",
            "  inflating: mask_images/6774_anno.png  \n",
            "  inflating: mask_images/6143_anno.png  \n",
            "  inflating: mask_images/1955_anno.png  \n",
            "  inflating: mask_images/2766_anno.png  \n",
            "  inflating: mask_images/3965_anno.png  \n",
            "  inflating: mask_images/6458_anno.png  \n",
            "  inflating: mask_images/838_anno.png  \n",
            "  inflating: mask_images/7381_anno.png  \n",
            "  inflating: mask_images/488_anno.png  \n",
            "  inflating: mask_images/1984_anno.png  \n",
            "  inflating: mask_images/3456_anno.png  \n",
            "  inflating: mask_images/2207_anno.png  \n",
            "  inflating: mask_images/6771_anno.png  \n",
            "  inflating: mask_images/7607_anno.png  \n",
            "  inflating: mask_images/730_anno.png  \n",
            "  inflating: mask_images/6093_anno.png  \n",
            "  inflating: mask_images/5968_anno.png  \n",
            "  inflating: mask_images/4026_anno.png  \n",
            "  inflating: mask_images/5191_anno.png  \n",
            "  inflating: mask_images/3431_anno.png  \n",
            "  inflating: mask_images/5342_anno.png  \n",
            "  inflating: mask_images/6369_anno.png  \n",
            "  inflating: mask_images/2140_anno.png  \n",
            "  inflating: mask_images/5872_anno.png  \n",
            "  inflating: mask_images/6591_anno.png  \n",
            "  inflating: mask_images/5997_anno.png  \n",
            "  inflating: mask_images/3473_anno.png  \n",
            "  inflating: mask_images/2530_anno.png  \n",
            "  inflating: mask_images/3813_anno.png  \n",
            "  inflating: mask_images/878_anno.png  \n",
            "  inflating: mask_images/5296_anno.png  \n",
            "  inflating: mask_images/2871_anno.png  \n",
            "  inflating: mask_images/3844_anno.png  \n",
            "  inflating: mask_images/782_anno.png  \n",
            "  inflating: mask_images/3569_anno.png  \n",
            "  inflating: mask_images/2786_anno.png  \n",
            "  inflating: mask_images/4983_anno.png  \n",
            "  inflating: mask_images/6408_anno.png  \n",
            "  inflating: mask_images/871_anno.png  \n",
            "  inflating: mask_images/6580_anno.png  \n",
            "  inflating: mask_images/4251_anno.png  \n",
            "  inflating: mask_images/5450_anno.png  \n",
            "  inflating: mask_images/3250_anno.png  \n",
            "  inflating: mask_images/6603_anno.png  \n",
            "  inflating: mask_images/6277_anno.png  \n",
            "  inflating: mask_images/2069_anno.png  \n",
            "  inflating: mask_images/6145_anno.png  \n",
            "  inflating: mask_images/6446_anno.png  \n",
            "  inflating: mask_images/4165_anno.png  \n",
            "  inflating: mask_images/4976_anno.png  \n",
            "  inflating: mask_images/205_anno.png  \n",
            "  inflating: mask_images/5784_anno.png  \n",
            "  inflating: mask_images/5025_anno.png  \n",
            "  inflating: mask_images/3298_anno.png  \n",
            "  inflating: mask_images/4246_anno.png  \n",
            "  inflating: mask_images/5290_anno.png  \n",
            "  inflating: mask_images/5718_anno.png  \n",
            " extracting: mask_images/5096_anno.png  \n",
            "  inflating: mask_images/3657_anno.png  \n",
            "  inflating: mask_images/5322_anno.png  \n",
            "  inflating: mask_images/7500_anno.png  \n",
            "  inflating: mask_images/2361_anno.png  \n",
            "  inflating: mask_images/442_anno.png  \n",
            "  inflating: mask_images/513_anno.png  \n",
            "  inflating: mask_images/3969_anno.png  \n",
            "  inflating: mask_images/4249_anno.png  \n",
            "  inflating: mask_images/4864_anno.png  \n",
            "  inflating: mask_images/949_anno.png  \n",
            "  inflating: mask_images/4035_anno.png  \n",
            "  inflating: mask_images/3413_anno.png  \n",
            "  inflating: mask_images/2631_anno.png  \n",
            "  inflating: mask_images/2487_anno.png  \n",
            "  inflating: mask_images/4934_anno.png  \n",
            "  inflating: mask_images/7127_anno.png  \n",
            "  inflating: mask_images/493_anno.png  \n",
            "  inflating: mask_images/7071_anno.png  \n",
            "  inflating: mask_images/4615_anno.png  \n",
            "  inflating: mask_images/5327_anno.png  \n",
            "  inflating: mask_images/6914_anno.png  \n",
            "  inflating: mask_images/6178_anno.png  \n",
            "  inflating: mask_images/3854_anno.png  \n",
            "  inflating: mask_images/732_anno.png  \n",
            "  inflating: mask_images/3791_anno.png  \n",
            "  inflating: mask_images/4877_anno.png  \n",
            "  inflating: mask_images/2235_anno.png  \n",
            "  inflating: mask_images/3385_anno.png  \n",
            "  inflating: mask_images/5053_anno.png  \n",
            "  inflating: mask_images/4133_anno.png  \n",
            "  inflating: mask_images/7062_anno.png  \n",
            "  inflating: mask_images/65_anno.png  \n",
            "  inflating: mask_images/5552_anno.png  \n",
            "  inflating: mask_images/5093_anno.png  \n",
            "  inflating: mask_images/2152_anno.png  \n",
            "  inflating: mask_images/2416_anno.png  \n",
            "  inflating: mask_images/3191_anno.png  \n",
            "  inflating: mask_images/549_anno.png  \n",
            "  inflating: mask_images/2159_anno.png  \n",
            "  inflating: mask_images/2111_anno.png  \n",
            "  inflating: mask_images/5307_anno.png  \n",
            "  inflating: mask_images/5201_anno.png  \n",
            "  inflating: mask_images/4497_anno.png  \n",
            "  inflating: mask_images/3801_anno.png  \n",
            "  inflating: mask_images/4793_anno.png  \n",
            "  inflating: mask_images/2541_anno.png  \n",
            "  inflating: mask_images/3594_anno.png  \n",
            "  inflating: mask_images/7138_anno.png  \n",
            "  inflating: mask_images/6821_anno.png  \n",
            "  inflating: mask_images/5827_anno.png  \n",
            "  inflating: mask_images/7664_anno.png  \n",
            "  inflating: mask_images/7506_anno.png  \n",
            "  inflating: mask_images/2979_anno.png  \n",
            "  inflating: mask_images/7000_anno.png  \n",
            "  inflating: mask_images/6891_anno.png  \n",
            "  inflating: mask_images/3287_anno.png  \n",
            "  inflating: mask_images/3631_anno.png  \n",
            "  inflating: mask_images/807_anno.png  \n",
            "  inflating: mask_images/3765_anno.png  \n",
            "  inflating: mask_images/6162_anno.png  \n",
            "  inflating: mask_images/6625_anno.png  \n",
            "  inflating: mask_images/79_anno.png  \n",
            "  inflating: mask_images/3430_anno.png  \n",
            "  inflating: mask_images/4261_anno.png  \n",
            "  inflating: mask_images/5551_anno.png  \n",
            "  inflating: mask_images/4222_anno.png  \n",
            "  inflating: mask_images/6803_anno.png  \n",
            "  inflating: mask_images/2117_anno.png  \n",
            "  inflating: mask_images/6314_anno.png  \n",
            "  inflating: mask_images/674_anno.png  \n",
            "  inflating: mask_images/3333_anno.png  \n",
            "  inflating: mask_images/4314_anno.png  \n",
            "  inflating: mask_images/6646_anno.png  \n",
            "  inflating: mask_images/6286_anno.png  \n",
            "  inflating: mask_images/4672_anno.png  \n",
            "  inflating: mask_images/736_anno.png  \n",
            "  inflating: mask_images/3931_anno.png  \n",
            "  inflating: mask_images/1123_anno.png  \n",
            "  inflating: mask_images/3241_anno.png  \n",
            "  inflating: mask_images/267_anno.png  \n",
            "  inflating: mask_images/7207_anno.png  \n",
            "  inflating: mask_images/7451_anno.png  \n",
            "  inflating: mask_images/3307_anno.png  \n",
            "  inflating: mask_images/6569_anno.png  \n",
            "  inflating: mask_images/3508_anno.png  \n",
            "  inflating: mask_images/3225_anno.png  \n",
            "  inflating: mask_images/6313_anno.png  \n",
            "  inflating: mask_images/7093_anno.png  \n",
            "  inflating: mask_images/5365_anno.png  \n",
            "  inflating: mask_images/1884_anno.png  \n",
            "  inflating: mask_images/6264_anno.png  \n",
            "  inflating: mask_images/3766_anno.png  \n",
            "  inflating: mask_images/340_anno.png  \n",
            "  inflating: mask_images/5291_anno.png  \n",
            "  inflating: mask_images/7087_anno.png  \n",
            "  inflating: mask_images/6013_anno.png  \n",
            "  inflating: mask_images/2139_anno.png  \n",
            "  inflating: mask_images/3554_anno.png  \n",
            "  inflating: mask_images/4598_anno.png  \n",
            "  inflating: mask_images/5438_anno.png  \n",
            "  inflating: mask_images/6826_anno.png  \n",
            "  inflating: mask_images/2444_anno.png  \n",
            "  inflating: mask_images/6909_anno.png  \n",
            "  inflating: mask_images/558_anno.png  \n",
            "  inflating: mask_images/502_anno.png  \n",
            "  inflating: mask_images/4748_anno.png  \n",
            "  inflating: mask_images/805_anno.png  \n",
            "  inflating: mask_images/3398_anno.png  \n",
            "  inflating: mask_images/280_anno.png  \n",
            "  inflating: mask_images/2449_anno.png  \n",
            "  inflating: mask_images/7422_anno.png  \n",
            "  inflating: mask_images/7385_anno.png  \n",
            "  inflating: mask_images/3989_anno.png  \n",
            "  inflating: mask_images/7099_anno.png  \n",
            "  inflating: mask_images/3330_anno.png  \n",
            "  inflating: mask_images/3604_anno.png  \n",
            "  inflating: mask_images/5344_anno.png  \n",
            "  inflating: mask_images/7261_anno.png  \n",
            "  inflating: mask_images/7459_anno.png  \n",
            "  inflating: mask_images/4003_anno.png  \n",
            "  inflating: mask_images/518_anno.png  \n",
            "  inflating: mask_images/6731_anno.png  \n",
            "  inflating: mask_images/6402_anno.png  \n",
            "  inflating: mask_images/4078_anno.png  \n",
            "  inflating: mask_images/7418_anno.png  \n",
            "  inflating: mask_images/7064_anno.png  \n",
            "  inflating: mask_images/3236_anno.png  \n",
            "  inflating: mask_images/2356_anno.png  \n",
            "  inflating: mask_images/6797_anno.png  \n",
            "  inflating: mask_images/7449_anno.png  \n",
            "  inflating: mask_images/5616_anno.png  \n",
            "  inflating: mask_images/7614_anno.png  \n",
            "  inflating: mask_images/3615_anno.png  \n",
            "  inflating: mask_images/638_anno.png  \n",
            "  inflating: mask_images/4052_anno.png  \n",
            "  inflating: mask_images/4708_anno.png  \n",
            "  inflating: mask_images/3262_anno.png  \n",
            "  inflating: mask_images/5637_anno.png  \n",
            "  inflating: mask_images/2624_anno.png  \n",
            "  inflating: mask_images/6831_anno.png  \n",
            "  inflating: mask_images/4790_anno.png  \n",
            "  inflating: mask_images/7343_anno.png  \n",
            "  inflating: mask_images/6792_anno.png  \n",
            "  inflating: mask_images/4584_anno.png  \n",
            "  inflating: mask_images/2828_anno.png  \n",
            "  inflating: mask_images/5349_anno.png  \n",
            "  inflating: mask_images/6000_anno.png  \n",
            "  inflating: mask_images/4209_anno.png  \n",
            "  inflating: mask_images/3347_anno.png  \n",
            "  inflating: mask_images/3166_anno.png  \n",
            "  inflating: mask_images/4980_anno.png  \n",
            "  inflating: mask_images/2463_anno.png  \n",
            "  inflating: mask_images/7075_anno.png  \n",
            "  inflating: mask_images/7015_anno.png  \n",
            "  inflating: mask_images/7533_anno.png  \n",
            "  inflating: mask_images/5278_anno.png  \n",
            "  inflating: mask_images/6191_anno.png  \n",
            "  inflating: mask_images/3251_anno.png  \n",
            "  inflating: mask_images/4896_anno.png  \n",
            "  inflating: mask_images/5875_anno.png  \n",
            "  inflating: mask_images/6728_anno.png  \n",
            "  inflating: mask_images/1961_anno.png  \n",
            "  inflating: mask_images/7129_anno.png  \n",
            "  inflating: mask_images/2481_anno.png  \n",
            "  inflating: mask_images/4813_anno.png  \n",
            "  inflating: mask_images/1958_anno.png  \n",
            "  inflating: mask_images/4373_anno.png  \n",
            "  inflating: mask_images/7351_anno.png  \n",
            "  inflating: mask_images/217_anno.png  \n",
            "  inflating: mask_images/3025_anno.png  \n",
            "  inflating: mask_images/3834_anno.png  \n",
            "  inflating: mask_images/5763_anno.png  \n",
            "  inflating: mask_images/642_anno.png  \n",
            "  inflating: mask_images/4616_anno.png  \n",
            "  inflating: mask_images/6022_anno.png  \n",
            "  inflating: mask_images/5700_anno.png  \n",
            "  inflating: mask_images/2728_anno.png  \n",
            "  inflating: mask_images/6161_anno.png  \n",
            "  inflating: mask_images/2596_anno.png  \n",
            "  inflating: mask_images/7114_anno.png  \n",
            "  inflating: mask_images/5499_anno.png  \n",
            "  inflating: mask_images/2842_anno.png  \n",
            "  inflating: mask_images/6180_anno.png  \n",
            "  inflating: mask_images/4370_anno.png  \n",
            "  inflating: mask_images/3726_anno.png  \n",
            "  inflating: mask_images/797_anno.png  \n",
            "  inflating: mask_images/4403_anno.png  \n",
            "  inflating: mask_images/3850_anno.png  \n",
            "  inflating: mask_images/4452_anno.png  \n",
            "  inflating: mask_images/3379_anno.png  \n",
            "  inflating: mask_images/4699_anno.png  \n",
            "  inflating: mask_images/3550_anno.png  \n",
            "  inflating: mask_images/2357_anno.png  \n",
            "  inflating: mask_images/4086_anno.png  \n",
            "  inflating: mask_images/1899_anno.png  \n",
            "  inflating: mask_images/6390_anno.png  \n",
            "  inflating: mask_images/3007_anno.png  \n",
            "  inflating: mask_images/6156_anno.png  \n",
            "  inflating: mask_images/4874_anno.png  \n",
            "  inflating: mask_images/2729_anno.png  \n",
            "  inflating: mask_images/7023_anno.png  \n",
            "  inflating: mask_images/4220_anno.png  \n",
            "  inflating: mask_images/4098_anno.png  \n",
            "  inflating: mask_images/5982_anno.png  \n",
            "  inflating: mask_images/7151_anno.png  \n",
            "  inflating: mask_images/5775_anno.png  \n",
            "  inflating: mask_images/3576_anno.png  \n",
            "  inflating: mask_images/6693_anno.png  \n",
            "  inflating: mask_images/5323_anno.png  \n",
            "  inflating: mask_images/2614_anno.png  \n",
            "  inflating: mask_images/5390_anno.png  \n",
            "  inflating: mask_images/6365_anno.png  \n",
            "  inflating: mask_images/744_anno.png  \n",
            "  inflating: mask_images/2378_anno.png  \n",
            "  inflating: mask_images/5606_anno.png  \n",
            "  inflating: mask_images/4238_anno.png  \n",
            "  inflating: mask_images/4487_anno.png  \n",
            "  inflating: mask_images/3650_anno.png  \n",
            "  inflating: mask_images/5061_anno.png  \n",
            "  inflating: mask_images/231_anno.png  \n",
            "  inflating: mask_images/5772_anno.png  \n",
            "  inflating: mask_images/2816_anno.png  \n",
            "  inflating: mask_images/2598_anno.png  \n",
            "  inflating: mask_images/4272_anno.png  \n",
            "  inflating: mask_images/4612_anno.png  \n",
            "  inflating: mask_images/3205_anno.png  \n",
            "  inflating: mask_images/3383_anno.png  \n",
            "  inflating: mask_images/5181_anno.png  \n",
            "  inflating: mask_images/3156_anno.png  \n",
            "  inflating: mask_images/4287_anno.png  \n",
            "  inflating: mask_images/685_anno.png  \n",
            "  inflating: mask_images/2233_anno.png  \n",
            "  inflating: mask_images/4953_anno.png  \n",
            "  inflating: mask_images/5632_anno.png  \n",
            "  inflating: mask_images/6611_anno.png  \n",
            "  inflating: mask_images/5034_anno.png  \n",
            "  inflating: mask_images/520_anno.png  \n",
            "  inflating: mask_images/255_anno.png  \n",
            "  inflating: mask_images/3742_anno.png  \n",
            "  inflating: mask_images/6756_anno.png  \n",
            "  inflating: mask_images/7668_anno.png  \n",
            "  inflating: mask_images/2404_anno.png  \n",
            "  inflating: mask_images/3818_anno.png  \n",
            "  inflating: mask_images/1976_anno.png  \n",
            "  inflating: mask_images/3905_anno.png  \n",
            "  inflating: mask_images/2698_anno.png  \n",
            "  inflating: mask_images/7160_anno.png  \n",
            "  inflating: mask_images/576_anno.png  \n",
            "  inflating: mask_images/3991_anno.png  \n",
            "  inflating: mask_images/234_anno.png  \n",
            "  inflating: mask_images/4789_anno.png  \n",
            "  inflating: mask_images/3637_anno.png  \n",
            "  inflating: mask_images/5279_anno.png  \n",
            "  inflating: mask_images/395_anno.png  \n",
            "  inflating: mask_images/2924_anno.png  \n",
            "  inflating: mask_images/2018_anno.png  \n",
            "  inflating: mask_images/7179_anno.png  \n",
            "  inflating: mask_images/5926_anno.png  \n",
            "  inflating: mask_images/3730_anno.png  \n",
            "  inflating: mask_images/757_anno.png  \n",
            "  inflating: mask_images/6966_anno.png  \n",
            "  inflating: mask_images/3595_anno.png  \n",
            "  inflating: mask_images/2136_anno.png  \n",
            "  inflating: mask_images/4221_anno.png  \n",
            "  inflating: mask_images/6996_anno.png  \n",
            "  inflating: mask_images/2494_anno.png  \n",
            "  inflating: mask_images/1867_anno.png  \n",
            "  inflating: mask_images/5956_anno.png  \n",
            "  inflating: mask_images/4480_anno.png  \n",
            "  inflating: mask_images/1950_anno.png  \n",
            "  inflating: mask_images/7550_anno.png  \n",
            "  inflating: mask_images/1949_anno.png  \n",
            "  inflating: mask_images/6806_anno.png  \n",
            "  inflating: mask_images/4643_anno.png  \n",
            "  inflating: mask_images/645_anno.png  \n",
            "  inflating: mask_images/5830_anno.png  \n",
            "  inflating: mask_images/42_anno.png  \n",
            "  inflating: mask_images/21_anno.png  \n",
            "  inflating: mask_images/4657_anno.png  \n",
            "  inflating: mask_images/6318_anno.png  \n",
            "  inflating: mask_images/6958_anno.png  \n",
            "  inflating: mask_images/7228_anno.png  \n",
            "  inflating: mask_images/7684_anno.png  \n",
            "  inflating: mask_images/3608_anno.png  \n",
            "  inflating: mask_images/2762_anno.png  \n",
            "  inflating: mask_images/5747_anno.png  \n",
            "  inflating: mask_images/2854_anno.png  \n",
            "  inflating: mask_images/6290_anno.png  \n",
            "  inflating: mask_images/5971_anno.png  \n",
            "  inflating: mask_images/7105_anno.png  \n",
            "  inflating: mask_images/5981_anno.png  \n",
            "  inflating: mask_images/6466_anno.png  \n",
            "  inflating: mask_images/6638_anno.png  \n",
            "  inflating: mask_images/4009_anno.png  \n",
            "  inflating: mask_images/3873_anno.png  \n",
            "  inflating: mask_images/3135_anno.png  \n",
            "  inflating: mask_images/482_anno.png  \n",
            "  inflating: mask_images/2591_anno.png  \n",
            "  inflating: mask_images/5898_anno.png  \n",
            "  inflating: mask_images/7040_anno.png  \n",
            " extracting: mask_images/4057_anno.png  \n",
            "  inflating: mask_images/5840_anno.png  \n",
            "  inflating: mask_images/2930_anno.png  \n",
            "  inflating: mask_images/3491_anno.png  \n",
            "  inflating: mask_images/3688_anno.png  \n",
            "  inflating: mask_images/3572_anno.png  \n",
            "  inflating: mask_images/3685_anno.png  \n",
            "  inflating: mask_images/6915_anno.png  \n",
            "  inflating: mask_images/6285_anno.png  \n",
            "  inflating: mask_images/5297_anno.png  \n",
            "  inflating: mask_images/7623_anno.png  \n",
            "  inflating: mask_images/2650_anno.png  \n",
            "  inflating: mask_images/6605_anno.png  \n",
            "  inflating: mask_images/3833_anno.png  \n",
            "  inflating: mask_images/3563_anno.png  \n",
            "  inflating: mask_images/4895_anno.png  \n",
            "  inflating: mask_images/2694_anno.png  \n",
            "  inflating: mask_images/3774_anno.png  \n",
            "  inflating: mask_images/5816_anno.png  \n",
            "  inflating: mask_images/4241_anno.png  \n",
            " extracting: mask_images/4593_anno.png  \n",
            "  inflating: mask_images/2198_anno.png  \n",
            "  inflating: mask_images/7136_anno.png  \n",
            "  inflating: mask_images/2949_anno.png  \n",
            "  inflating: mask_images/3709_anno.png  \n",
            "  inflating: mask_images/2017_anno.png  \n",
            "  inflating: mask_images/4342_anno.png  \n",
            "  inflating: mask_images/4379_anno.png  \n",
            "  inflating: mask_images/4343_anno.png  \n",
            "  inflating: mask_images/6366_anno.png  \n",
            "  inflating: mask_images/5217_anno.png  \n",
            "  inflating: mask_images/4498_anno.png  \n",
            "  inflating: mask_images/682_anno.png  \n",
            "  inflating: mask_images/5326_anno.png  \n",
            "  inflating: mask_images/6271_anno.png  \n",
            "  inflating: mask_images/4275_anno.png  \n",
            "  inflating: mask_images/1772_anno.png  \n",
            "  inflating: mask_images/3420_anno.png  \n",
            "  inflating: mask_images/3270_anno.png  \n",
            "  inflating: mask_images/27_anno.png  \n",
            "  inflating: mask_images/6599_anno.png  \n",
            "  inflating: mask_images/2194_anno.png  \n",
            "  inflating: mask_images/7096_anno.png  \n",
            "  inflating: mask_images/3054_anno.png  \n",
            "  inflating: mask_images/72_anno.png  \n",
            "  inflating: mask_images/310_anno.png  \n",
            "  inflating: mask_images/7174_anno.png  \n",
            "  inflating: mask_images/6890_anno.png  \n",
            "  inflating: mask_images/2038_anno.png  \n",
            "  inflating: mask_images/803_anno.png  \n",
            "  inflating: mask_images/5269_anno.png  \n",
            "  inflating: mask_images/579_anno.png  \n",
            "  inflating: mask_images/4442_anno.png  \n",
            "  inflating: mask_images/6423_anno.png  \n",
            "  inflating: mask_images/6059_anno.png  \n",
            "  inflating: mask_images/2665_anno.png  \n",
            "  inflating: mask_images/4112_anno.png  \n",
            "  inflating: mask_images/2628_anno.png  \n",
            "  inflating: mask_images/3257_anno.png  \n",
            "  inflating: mask_images/5716_anno.png  \n",
            "  inflating: mask_images/3846_anno.png  \n",
            "  inflating: mask_images/5400_anno.png  \n",
            "  inflating: mask_images/6387_anno.png  \n",
            "  inflating: mask_images/6435_anno.png  \n",
            "  inflating: mask_images/4360_anno.png  \n",
            "  inflating: mask_images/2001_anno.png  \n",
            "  inflating: mask_images/7306_anno.png  \n",
            "  inflating: mask_images/7496_anno.png  \n",
            "  inflating: mask_images/6195_anno.png  \n",
            "  inflating: mask_images/633_anno.png  \n",
            "  inflating: mask_images/2497_anno.png  \n",
            "  inflating: mask_images/4245_anno.png  \n",
            "  inflating: mask_images/7518_anno.png  \n",
            "  inflating: mask_images/6814_anno.png  \n",
            "  inflating: mask_images/7510_anno.png  \n",
            "  inflating: mask_images/6757_anno.png  \n",
            "  inflating: mask_images/636_anno.png  \n",
            "  inflating: mask_images/864_anno.png  \n",
            "  inflating: mask_images/6250_anno.png  \n",
            "  inflating: mask_images/5561_anno.png  \n",
            "  inflating: mask_images/2546_anno.png  \n",
            "  inflating: mask_images/7186_anno.png  \n",
            "  inflating: mask_images/7334_anno.png  \n",
            "  inflating: mask_images/5004_anno.png  \n",
            "  inflating: mask_images/504_anno.png  \n",
            "  inflating: mask_images/2145_anno.png  \n",
            "  inflating: mask_images/6729_anno.png  \n",
            "  inflating: mask_images/5795_anno.png  \n",
            "  inflating: mask_images/3895_anno.png  \n",
            "  inflating: mask_images/7276_anno.png  \n",
            "  inflating: mask_images/4376_anno.png  \n",
            "  inflating: mask_images/3402_anno.png  \n",
            "  inflating: mask_images/5124_anno.png  \n",
            "  inflating: mask_images/3661_anno.png  \n",
            "  inflating: mask_images/5407_anno.png  \n",
            "  inflating: mask_images/578_anno.png  \n",
            " extracting: mask_images/6136_anno.png  \n",
            "  inflating: mask_images/5602_anno.png  \n",
            "  inflating: mask_images/809_anno.png  \n",
            "  inflating: mask_images/6461_anno.png  \n",
            "  inflating: mask_images/6716_anno.png  \n",
            "  inflating: mask_images/7238_anno.png  \n",
            "  inflating: mask_images/2130_anno.png  \n",
            "  inflating: mask_images/4339_anno.png  \n",
            "  inflating: mask_images/6704_anno.png  \n",
            "  inflating: mask_images/4861_anno.png  \n",
            "  inflating: mask_images/2462_anno.png  \n",
            "  inflating: mask_images/2611_anno.png  \n",
            "  inflating: mask_images/5066_anno.png  \n",
            "  inflating: mask_images/3847_anno.png  \n",
            "  inflating: mask_images/5107_anno.png  \n",
            "  inflating: mask_images/5579_anno.png  \n",
            "  inflating: mask_images/6707_anno.png  \n",
            "  inflating: mask_images/2203_anno.png  \n",
            "  inflating: mask_images/6800_anno.png  \n",
            "  inflating: mask_images/3101_anno.png  \n",
            "  inflating: mask_images/7067_anno.png  \n",
            "  inflating: mask_images/806_anno.png  \n",
            "  inflating: mask_images/7386_anno.png  \n",
            "  inflating: mask_images/7453_anno.png  \n",
            "  inflating: mask_images/6053_anno.png  \n",
            "  inflating: mask_images/2195_anno.png  \n",
            "  inflating: mask_images/3086_anno.png  \n",
            "  inflating: mask_images/2088_anno.png  \n",
            "  inflating: mask_images/6910_anno.png  \n",
            "  inflating: mask_images/3149_anno.png  \n",
            "  inflating: mask_images/4333_anno.png  \n",
            "  inflating: mask_images/3084_anno.png  \n",
            "  inflating: mask_images/6322_anno.png  \n",
            "  inflating: mask_images/6887_anno.png  \n",
            "  inflating: mask_images/584_anno.png  \n",
            "  inflating: mask_images/6794_anno.png  \n",
            "  inflating: mask_images/4965_anno.png  \n",
            "  inflating: mask_images/3360_anno.png  \n",
            "  inflating: mask_images/7530_anno.png  \n",
            "  inflating: mask_images/3327_anno.png  \n",
            "  inflating: mask_images/5568_anno.png  \n",
            "  inflating: mask_images/5338_anno.png  \n",
            "  inflating: mask_images/6780_anno.png  \n",
            "  inflating: mask_images/710_anno.png  \n",
            "  inflating: mask_images/4199_anno.png  \n",
            "  inflating: mask_images/5271_anno.png  \n",
            "  inflating: mask_images/6497_anno.png  \n",
            "  inflating: mask_images/3230_anno.png  \n",
            "  inflating: mask_images/3434_anno.png  \n",
            "  inflating: mask_images/3066_anno.png  \n",
            "  inflating: mask_images/7172_anno.png  \n",
            "  inflating: mask_images/2557_anno.png  \n",
            "  inflating: mask_images/6686_anno.png  \n",
            "  inflating: mask_images/439_anno.png  \n",
            "  inflating: mask_images/2757_anno.png  \n",
            "  inflating: mask_images/5488_anno.png  \n",
            "  inflating: mask_images/3825_anno.png  \n",
            "  inflating: mask_images/4912_anno.png  \n",
            "  inflating: mask_images/5940_anno.png  \n",
            "  inflating: mask_images/3793_anno.png  \n",
            "  inflating: mask_images/5752_anno.png  \n",
            "  inflating: mask_images/4933_anno.png  \n",
            "  inflating: mask_images/4335_anno.png  \n",
            "  inflating: mask_images/7177_anno.png  \n",
            "  inflating: mask_images/7030_anno.png  \n",
            "  inflating: mask_images/2630_anno.png  \n",
            "  inflating: mask_images/6951_anno.png  \n",
            "  inflating: mask_images/3176_anno.png  \n",
            "  inflating: mask_images/5443_anno.png  \n",
            "  inflating: mask_images/4041_anno.png  \n",
            "  inflating: mask_images/2470_anno.png  \n",
            "  inflating: mask_images/6198_anno.png  \n",
            "  inflating: mask_images/6106_anno.png  \n",
            "  inflating: mask_images/4622_anno.png  \n",
            "  inflating: mask_images/249_anno.png  \n",
            "  inflating: mask_images/7610_anno.png  \n",
            "  inflating: mask_images/4677_anno.png  \n",
            "  inflating: mask_images/2835_anno.png  \n",
            "  inflating: mask_images/5604_anno.png  \n",
            "  inflating: mask_images/507_anno.png  \n",
            "  inflating: mask_images/1901_anno.png  \n",
            "  inflating: mask_images/3974_anno.png  \n",
            "  inflating: mask_images/1889_anno.png  \n",
            "  inflating: mask_images/862_anno.png  \n",
            "  inflating: mask_images/325_anno.png  \n",
            "  inflating: mask_images/3806_anno.png  \n",
            "  inflating: mask_images/643_anno.png  \n",
            "  inflating: mask_images/7629_anno.png  \n",
            "  inflating: mask_images/3281_anno.png  \n",
            "  inflating: mask_images/6534_anno.png  \n",
            "  inflating: mask_images/1915_anno.png  \n",
            "  inflating: mask_images/6246_anno.png  \n",
            "  inflating: mask_images/6344_anno.png  \n",
            "  inflating: mask_images/4073_anno.png  \n",
            "  inflating: mask_images/920_anno.png  \n",
            "  inflating: mask_images/5852_anno.png  \n",
            "  inflating: mask_images/5896_anno.png  \n",
            "  inflating: mask_images/5933_anno.png  \n",
            "  inflating: mask_images/3621_anno.png  \n",
            "  inflating: mask_images/4939_anno.png  \n",
            "  inflating: mask_images/417_anno.png  \n",
            "  inflating: mask_images/297_anno.png  \n",
            "  inflating: mask_images/6804_anno.png  \n",
            "  inflating: mask_images/728_anno.png  \n",
            "  inflating: mask_images/4787_anno.png  \n",
            "  inflating: mask_images/4080_anno.png  \n",
            "  inflating: mask_images/763_anno.png  \n",
            "  inflating: mask_images/6303_anno.png  \n",
            "  inflating: mask_images/4193_anno.png  \n",
            "  inflating: mask_images/3866_anno.png  \n",
            "  inflating: mask_images/1886_anno.png  \n",
            "  inflating: mask_images/4559_anno.png  \n",
            "  inflating: mask_images/5508_anno.png  \n",
            "  inflating: mask_images/2782_anno.png  \n",
            "  inflating: mask_images/4702_anno.png  \n",
            "  inflating: mask_images/6639_anno.png  \n",
            "  inflating: mask_images/7344_anno.png  \n",
            "  inflating: mask_images/7341_anno.png  \n",
            "  inflating: mask_images/7319_anno.png  \n",
            "  inflating: mask_images/5771_anno.png  \n",
            "  inflating: mask_images/6009_anno.png  \n",
            "  inflating: mask_images/5330_anno.png  \n",
            "  inflating: mask_images/2068_anno.png  \n",
            "  inflating: mask_images/4145_anno.png  \n",
            "  inflating: mask_images/804_anno.png  \n",
            "  inflating: mask_images/6418_anno.png  \n",
            "  inflating: mask_images/5489_anno.png  \n",
            "  inflating: mask_images/4849_anno.png  \n",
            "  inflating: mask_images/4134_anno.png  \n",
            "  inflating: mask_images/1966_anno.png  \n",
            "  inflating: mask_images/445_anno.png  \n",
            "  inflating: mask_images/5745_anno.png  \n",
            "  inflating: mask_images/4058_anno.png  \n",
            "  inflating: mask_images/7622_anno.png  \n",
            "  inflating: mask_images/3180_anno.png  \n",
            "  inflating: mask_images/5845_anno.png  \n",
            "  inflating: mask_images/344_anno.png  \n",
            "  inflating: mask_images/5538_anno.png  \n",
            "  inflating: mask_images/4670_anno.png  \n",
            "  inflating: mask_images/7222_anno.png  \n",
            " extracting: mask_images/2091_anno.png  \n",
            "  inflating: mask_images/5245_anno.png  \n",
            "  inflating: mask_images/2910_anno.png  \n",
            "  inflating: mask_images/7219_anno.png  \n",
            "  inflating: mask_images/313_anno.png  \n",
            "  inflating: mask_images/910_anno.png  \n",
            "  inflating: mask_images/4115_anno.png  \n",
            "  inflating: mask_images/3636_anno.png  \n",
            "  inflating: mask_images/4729_anno.png  \n",
            "  inflating: mask_images/639_anno.png  \n",
            "  inflating: mask_images/2262_anno.png  \n",
            "  inflating: mask_images/3561_anno.png  \n",
            "  inflating: mask_images/7103_anno.png  \n",
            "  inflating: mask_images/4765_anno.png  \n",
            "  inflating: mask_images/5162_anno.png  \n",
            "  inflating: mask_images/5864_anno.png  \n",
            "  inflating: mask_images/4845_anno.png  \n",
            "  inflating: mask_images/948_anno.png  \n",
            "  inflating: mask_images/3580_anno.png  \n",
            "  inflating: mask_images/4485_anno.png  \n",
            "  inflating: mask_images/3992_anno.png  \n",
            "  inflating: mask_images/6986_anno.png  \n",
            "  inflating: mask_images/702_anno.png  \n",
            "  inflating: mask_images/2240_anno.png  \n",
            "  inflating: mask_images/2330_anno.png  \n",
            "  inflating: mask_images/4468_anno.png  \n",
            "  inflating: mask_images/483_anno.png  \n",
            "  inflating: mask_images/7433_anno.png  \n",
            "  inflating: mask_images/5098_anno.png  \n",
            "  inflating: mask_images/4841_anno.png  \n",
            " extracting: mask_images/5064_anno.png  \n",
            "  inflating: mask_images/6690_anno.png  \n",
            "  inflating: mask_images/3911_anno.png  \n",
            "  inflating: mask_images/4365_anno.png  \n",
            "  inflating: mask_images/5214_anno.png  \n",
            "  inflating: mask_images/4837_anno.png  \n",
            "  inflating: mask_images/3401_anno.png  \n",
            "  inflating: mask_images/4095_anno.png  \n",
            "  inflating: mask_images/3438_anno.png  \n",
            "  inflating: mask_images/5126_anno.png  \n",
            "  inflating: mask_images/6598_anno.png  \n",
            "  inflating: mask_images/5221_anno.png  \n",
            "  inflating: mask_images/4732_anno.png  \n",
            "  inflating: mask_images/2181_anno.png  \n",
            "  inflating: mask_images/6247_anno.png  \n",
            "  inflating: mask_images/7266_anno.png  \n",
            "  inflating: mask_images/6490_anno.png  \n",
            "  inflating: mask_images/7054_anno.png  \n",
            "  inflating: mask_images/2153_anno.png  \n",
            "  inflating: mask_images/5969_anno.png  \n",
            "  inflating: mask_images/68_anno.png  \n",
            "  inflating: mask_images/5601_anno.png  \n",
            "  inflating: mask_images/7141_anno.png  \n",
            "  inflating: mask_images/7235_anno.png  \n",
            "  inflating: mask_images/6046_anno.png  \n",
            "  inflating: mask_images/2966_anno.png  \n",
            "  inflating: mask_images/5987_anno.png  \n",
            "  inflating: mask_images/4889_anno.png  \n",
            "  inflating: mask_images/5539_anno.png  \n",
            "  inflating: mask_images/3964_anno.png  \n",
            "  inflating: mask_images/6576_anno.png  \n",
            "  inflating: mask_images/3586_anno.png  \n",
            "  inflating: mask_images/5857_anno.png  \n",
            "  inflating: mask_images/6614_anno.png  \n",
            "  inflating: mask_images/7669_anno.png  \n",
            "  inflating: mask_images/7051_anno.png  \n",
            "  inflating: mask_images/1994_anno.png  \n",
            "  inflating: mask_images/5660_anno.png  \n",
            "  inflating: mask_images/628_anno.png  \n",
            "  inflating: mask_images/4998_anno.png  \n",
            "  inflating: mask_images/6289_anno.png  \n",
            "  inflating: mask_images/6035_anno.png  \n",
            "  inflating: mask_images/3173_anno.png  \n",
            "  inflating: mask_images/6976_anno.png  \n",
            "  inflating: mask_images/3980_anno.png  \n",
            "  inflating: mask_images/6404_anno.png  \n",
            "  inflating: mask_images/2445_anno.png  \n",
            "  inflating: mask_images/6456_anno.png  \n",
            "  inflating: mask_images/2636_anno.png  \n",
            "  inflating: mask_images/5678_anno.png  \n",
            "  inflating: mask_images/762_anno.png  \n",
            "  inflating: mask_images/5991_anno.png  \n",
            "  inflating: mask_images/3787_anno.png  \n",
            "  inflating: mask_images/2722_anno.png  \n",
            "  inflating: mask_images/3665_anno.png  \n",
            "  inflating: mask_images/5219_anno.png  \n",
            "  inflating: mask_images/3792_anno.png  \n",
            "  inflating: mask_images/6895_anno.png  \n",
            "  inflating: mask_images/6852_anno.png  \n",
            "  inflating: mask_images/7409_anno.png  \n",
            "  inflating: mask_images/253_anno.png  \n",
            "  inflating: mask_images/826_anno.png  \n",
            "  inflating: mask_images/2984_anno.png  \n",
            "  inflating: mask_images/4087_anno.png  \n",
            "  inflating: mask_images/4332_anno.png  \n",
            "  inflating: mask_images/3719_anno.png  \n",
            "  inflating: mask_images/3628_anno.png  \n",
            "  inflating: mask_images/5031_anno.png  \n",
            "  inflating: mask_images/6657_anno.png  \n",
            "  inflating: mask_images/5368_anno.png  \n",
            "  inflating: mask_images/4271_anno.png  \n",
            "  inflating: mask_images/5335_anno.png  \n",
            "  inflating: mask_images/5425_anno.png  \n",
            "  inflating: mask_images/7192_anno.png  \n",
            "  inflating: mask_images/5329_anno.png  \n",
            "  inflating: mask_images/2958_anno.png  \n",
            "  inflating: mask_images/5009_anno.png  \n",
            "  inflating: mask_images/7609_anno.png  \n",
            "  inflating: mask_images/2815_anno.png  \n",
            "  inflating: mask_images/2514_anno.png  \n",
            "  inflating: mask_images/6142_anno.png  \n",
            "  inflating: mask_images/7591_anno.png  \n",
            "  inflating: mask_images/4346_anno.png  \n",
            "  inflating: mask_images/2559_anno.png  \n",
            "  inflating: mask_images/3165_anno.png  \n",
            "  inflating: mask_images/2740_anno.png  \n",
            "  inflating: mask_images/6018_anno.png  \n",
            "  inflating: mask_images/2210_anno.png  \n",
            "  inflating: mask_images/5805_anno.png  \n",
            "  inflating: mask_images/5393_anno.png  \n",
            "  inflating: mask_images/5536_anno.png  \n",
            "  inflating: mask_images/6422_anno.png  \n",
            "  inflating: mask_images/6850_anno.png  \n",
            "  inflating: mask_images/5196_anno.png  \n",
            "  inflating: mask_images/6095_anno.png  \n",
            "  inflating: mask_images/5882_anno.png  \n",
            "  inflating: mask_images/2280_anno.png  \n",
            "  inflating: mask_images/7258_anno.png  \n",
            "  inflating: mask_images/3797_anno.png  \n",
            "  inflating: mask_images/561_anno.png  \n",
            "  inflating: mask_images/3680_anno.png  \n",
            "  inflating: mask_images/3227_anno.png  \n",
            "  inflating: mask_images/4678_anno.png  \n",
            "  inflating: mask_images/5614_anno.png  \n",
            "  inflating: mask_images/303_anno.png  \n",
            "  inflating: mask_images/7428_anno.png  \n",
            "  inflating: mask_images/2353_anno.png  \n",
            "  inflating: mask_images/3299_anno.png  \n",
            "  inflating: mask_images/5821_anno.png  \n",
            "  inflating: mask_images/4259_anno.png  \n",
            "  inflating: mask_images/2261_anno.png  \n",
            "  inflating: mask_images/3095_anno.png  \n",
            "  inflating: mask_images/5260_anno.png  \n",
            "  inflating: mask_images/3319_anno.png  \n",
            "  inflating: mask_images/2584_anno.png  \n",
            "  inflating: mask_images/1053_anno.png  \n",
            "  inflating: mask_images/6627_anno.png  \n",
            "  inflating: mask_images/4932_anno.png  \n",
            "  inflating: mask_images/534_anno.png  \n",
            "  inflating: mask_images/4978_anno.png  \n",
            "  inflating: mask_images/7580_anno.png  \n",
            "  inflating: mask_images/5977_anno.png  \n",
            "  inflating: mask_images/250_anno.png  \n",
            "  inflating: mask_images/3605_anno.png  \n",
            "  inflating: mask_images/2010_anno.png  \n",
            "  inflating: mask_images/3198_anno.png  \n",
            "  inflating: mask_images/4952_anno.png  \n",
            "  inflating: mask_images/3326_anno.png  \n",
            "  inflating: mask_images/6453_anno.png  \n",
            "  inflating: mask_images/640_anno.png  \n",
            "  inflating: mask_images/7126_anno.png  \n",
            "  inflating: mask_images/919_anno.png  \n",
            "  inflating: mask_images/4037_anno.png  \n",
            "  inflating: mask_images/6496_anno.png  \n",
            "  inflating: mask_images/5846_anno.png  \n",
            "  inflating: mask_images/5990_anno.png  \n",
            "  inflating: mask_images/4394_anno.png  \n",
            "  inflating: mask_images/4207_anno.png  \n",
            "  inflating: mask_images/7539_anno.png  \n",
            "  inflating: mask_images/7521_anno.png  \n",
            "  inflating: mask_images/432_anno.png  \n",
            "  inflating: mask_images/966_anno.png  \n",
            "  inflating: mask_images/2127_anno.png  \n",
            "  inflating: mask_images/7279_anno.png  \n",
            "  inflating: mask_images/4366_anno.png  \n",
            "  inflating: mask_images/6777_anno.png  \n",
            "  inflating: mask_images/7001_anno.png  \n",
            "  inflating: mask_images/5948_anno.png  \n",
            "  inflating: mask_images/5866_anno.png  \n",
            "  inflating: mask_images/6494_anno.png  \n",
            "  inflating: mask_images/6575_anno.png  \n",
            "  inflating: mask_images/2879_anno.png  \n",
            "  inflating: mask_images/6851_anno.png  \n",
            "  inflating: mask_images/2206_anno.png  \n",
            "  inflating: mask_images/2602_anno.png  \n",
            "  inflating: mask_images/4524_anno.png  \n",
            "  inflating: mask_images/2301_anno.png  \n",
            "  inflating: mask_images/5756_anno.png  \n",
            "  inflating: mask_images/3683_anno.png  \n",
            "  inflating: mask_images/2151_anno.png  \n",
            "  inflating: mask_images/5076_anno.png  \n",
            "  inflating: mask_images/850_anno.png  \n",
            "  inflating: mask_images/4580_anno.png  \n",
            "  inflating: mask_images/5792_anno.png  \n",
            "  inflating: mask_images/4539_anno.png  \n",
            "  inflating: mask_images/6153_anno.png  \n",
            "  inflating: mask_images/7053_anno.png  \n",
            "  inflating: mask_images/5839_anno.png  \n",
            "  inflating: mask_images/7189_anno.png  \n",
            "  inflating: mask_images/437_anno.png  \n",
            "  inflating: mask_images/6819_anno.png  \n",
            "  inflating: mask_images/7350_anno.png  \n",
            "  inflating: mask_images/2731_anno.png  \n",
            "  inflating: mask_images/3240_anno.png  \n",
            "  inflating: mask_images/4540_anno.png  \n",
            "  inflating: mask_images/3952_anno.png  \n",
            "  inflating: mask_images/3727_anno.png  \n",
            "  inflating: mask_images/2573_anno.png  \n",
            "  inflating: mask_images/6354_anno.png  \n",
            "  inflating: mask_images/5704_anno.png  \n",
            "  inflating: mask_images/5213_anno.png  \n",
            "  inflating: mask_images/5679_anno.png  \n",
            "  inflating: mask_images/7526_anno.png  \n",
            "  inflating: mask_images/222_anno.png  \n",
            " extracting: mask_images/5088_anno.png  \n",
            "  inflating: mask_images/4624_anno.png  \n",
            "  inflating: mask_images/2418_anno.png  \n",
            "  inflating: mask_images/4236_anno.png  \n",
            "  inflating: mask_images/3941_anno.png  \n",
            "  inflating: mask_images/5698_anno.png  \n",
            "  inflating: mask_images/2860_anno.png  \n",
            "  inflating: mask_images/7493_anno.png  \n",
            "  inflating: mask_images/4756_anno.png  \n",
            "  inflating: mask_images/2391_anno.png  \n",
            "  inflating: mask_images/4313_anno.png  \n",
            "  inflating: mask_images/6312_anno.png  \n",
            "  inflating: mask_images/6379_anno.png  \n",
            "  inflating: mask_images/7565_anno.png  \n",
            "  inflating: mask_images/5835_anno.png  \n",
            "  inflating: mask_images/3283_anno.png  \n",
            "  inflating: mask_images/3894_anno.png  \n",
            "  inflating: mask_images/635_anno.png  \n",
            "  inflating: mask_images/6578_anno.png  \n",
            "  inflating: mask_images/5055_anno.png  \n",
            "  inflating: mask_images/1050_anno.png  \n",
            "  inflating: mask_images/5643_anno.png  \n",
            "  inflating: mask_images/5018_anno.png  \n",
            "  inflating: mask_images/4741_anno.png  \n",
            "  inflating: mask_images/309_anno.png  \n",
            "  inflating: mask_images/7612_anno.png  \n",
            "  inflating: mask_images/3630_anno.png  \n",
            "  inflating: mask_images/5456_anno.png  \n",
            "  inflating: mask_images/6309_anno.png  \n",
            "  inflating: mask_images/2641_anno.png  \n",
            "  inflating: mask_images/780_anno.png  \n",
            "  inflating: mask_images/7456_anno.png  \n",
            "  inflating: mask_images/3100_anno.png  \n",
            "  inflating: mask_images/3689_anno.png  \n",
            "  inflating: mask_images/6601_anno.png  \n",
            "  inflating: mask_images/5527_anno.png  \n",
            "  inflating: mask_images/4988_anno.png  \n",
            "  inflating: mask_images/708_anno.png  \n",
            "  inflating: mask_images/5649_anno.png  \n",
            "  inflating: mask_images/26_anno.png  \n",
            "  inflating: mask_images/5174_anno.png  \n",
            "  inflating: mask_images/4113_anno.png  \n",
            "  inflating: mask_images/4853_anno.png  \n",
            "  inflating: mask_images/2741_anno.png  \n",
            "  inflating: mask_images/2506_anno.png  \n",
            "  inflating: mask_images/2113_anno.png  \n",
            "  inflating: mask_images/5803_anno.png  \n",
            "  inflating: mask_images/4946_anno.png  \n",
            "  inflating: mask_images/3711_anno.png  \n",
            "  inflating: mask_images/7289_anno.png  \n",
            "  inflating: mask_images/7509_anno.png  \n",
            "  inflating: mask_images/7534_anno.png  \n",
            "  inflating: mask_images/2003_anno.png  \n",
            "  inflating: mask_images/6561_anno.png  \n",
            "  inflating: mask_images/3651_anno.png  \n",
            "  inflating: mask_images/2174_anno.png  \n",
            "  inflating: mask_images/6104_anno.png  \n",
            "  inflating: mask_images/3784_anno.png  \n",
            "  inflating: mask_images/7411_anno.png  \n",
            "  inflating: mask_images/7112_anno.png  \n",
            "  inflating: mask_images/694_anno.png  \n",
            "  inflating: mask_images/4776_anno.png  \n",
            "  inflating: mask_images/6865_anno.png  \n",
            "  inflating: mask_images/7713_anno.png  \n",
            "  inflating: mask_images/7020_anno.png  \n",
            "  inflating: mask_images/4542_anno.png  \n",
            "  inflating: mask_images/3311_anno.png  \n",
            "  inflating: mask_images/7475_anno.png  \n",
            "  inflating: mask_images/7683_anno.png  \n",
            "  inflating: mask_images/7375_anno.png  \n",
            "  inflating: mask_images/6071_anno.png  \n",
            "  inflating: mask_images/7641_anno.png  \n",
            "  inflating: mask_images/4997_anno.png  \n",
            "  inflating: mask_images/5873_anno.png  \n",
            "  inflating: mask_images/6099_anno.png  \n",
            "  inflating: mask_images/7532_anno.png  \n",
            "  inflating: mask_images/3029_anno.png  \n",
            "  inflating: mask_images/196_anno.png  \n",
            "  inflating: mask_images/2985_anno.png  \n",
            "  inflating: mask_images/3539_anno.png  \n",
            "  inflating: mask_images/5319_anno.png  \n",
            "  inflating: mask_images/5900_anno.png  \n",
            "  inflating: mask_images/7314_anno.png  \n",
            "  inflating: mask_images/5658_anno.png  \n",
            "  inflating: mask_images/2746_anno.png  \n",
            "  inflating: mask_images/6386_anno.png  \n",
            "  inflating: mask_images/238_anno.png  \n",
            "  inflating: mask_images/7413_anno.png  \n",
            "  inflating: mask_images/6773_anno.png  \n",
            "  inflating: mask_images/4937_anno.png  \n",
            "  inflating: mask_images/6144_anno.png  \n",
            "  inflating: mask_images/6284_anno.png  \n",
            "  inflating: mask_images/6160_anno.png  \n",
            "  inflating: mask_images/2432_anno.png  \n",
            "  inflating: mask_images/515_anno.png  \n",
            "  inflating: mask_images/667_anno.png  \n",
            "  inflating: mask_images/6064_anno.png  \n",
            "  inflating: mask_images/5666_anno.png  \n",
            "  inflating: mask_images/7148_anno.png  \n",
            "  inflating: mask_images/775_anno.png  \n",
            "  inflating: mask_images/6324_anno.png  \n",
            "  inflating: mask_images/4817_anno.png  \n",
            "  inflating: mask_images/3867_anno.png  \n",
            "  inflating: mask_images/4809_anno.png  \n",
            "  inflating: mask_images/3603_anno.png  \n",
            "  inflating: mask_images/3736_anno.png  \n",
            "  inflating: mask_images/213_anno.png  \n",
            "  inflating: mask_images/5312_anno.png  \n",
            "  inflating: mask_images/4879_anno.png  \n",
            "  inflating: mask_images/3979_anno.png  \n",
            "  inflating: mask_images/5769_anno.png  \n",
            "  inflating: mask_images/706_anno.png  \n",
            "  inflating: mask_images/7504_anno.png  \n",
            "  inflating: mask_images/5958_anno.png  \n",
            "  inflating: mask_images/6582_anno.png  \n",
            "  inflating: mask_images/5239_anno.png  \n",
            "  inflating: mask_images/7257_anno.png  \n",
            "  inflating: mask_images/5929_anno.png  \n",
            "  inflating: mask_images/668_anno.png  \n",
            "  inflating: mask_images/5680_anno.png  \n",
            "  inflating: mask_images/4042_anno.png  \n",
            "  inflating: mask_images/36_anno.png  \n",
            "  inflating: mask_images/602_anno.png  \n",
            "  inflating: mask_images/3458_anno.png  \n",
            "  inflating: mask_images/6486_anno.png  \n",
            "  inflating: mask_images/5471_anno.png  \n",
            "  inflating: mask_images/6012_anno.png  \n",
            "  inflating: mask_images/6065_anno.png  \n",
            "  inflating: mask_images/5983_anno.png  \n",
            "  inflating: mask_images/7095_anno.png  \n",
            "  inflating: mask_images/7541_anno.png  \n",
            "  inflating: mask_images/5420_anno.png  \n",
            "  inflating: mask_images/7471_anno.png  \n",
            "  inflating: mask_images/7056_anno.png  \n",
            "  inflating: mask_images/6564_anno.png  \n",
            "  inflating: mask_images/5363_anno.png  \n",
            "  inflating: mask_images/5340_anno.png  \n",
            "  inflating: mask_images/551_anno.png  \n",
            "  inflating: mask_images/4122_anno.png  \n",
            "  inflating: mask_images/6585_anno.png  \n",
            "  inflating: mask_images/4621_anno.png  \n",
            "  inflating: mask_images/6654_anno.png  \n",
            "  inflating: mask_images/2447_anno.png  \n",
            "  inflating: mask_images/5523_anno.png  \n",
            "  inflating: mask_images/790_anno.png  \n",
            "  inflating: mask_images/6287_anno.png  \n",
            "  inflating: mask_images/2654_anno.png  \n",
            "  inflating: mask_images/3482_anno.png  \n",
            "  inflating: mask_images/7588_anno.png  \n",
            "  inflating: mask_images/2387_anno.png  \n",
            "  inflating: mask_images/5163_anno.png  \n",
            "  inflating: mask_images/4263_anno.png  \n",
            "  inflating: mask_images/678_anno.png  \n",
            "  inflating: mask_images/5822_anno.png  \n",
            "  inflating: mask_images/768_anno.png  \n",
            "  inflating: mask_images/590_anno.png  \n",
            "  inflating: mask_images/830_anno.png  \n",
            "  inflating: mask_images/4285_anno.png  \n",
            " extracting: mask_images/3264_anno.png  \n",
            "  inflating: mask_images/40_anno.png  \n",
            "  inflating: mask_images/5132_anno.png  \n",
            "  inflating: mask_images/6975_anno.png  \n",
            "  inflating: mask_images/5553_anno.png  \n",
            "  inflating: mask_images/2540_anno.png  \n",
            "  inflating: mask_images/7057_anno.png  \n",
            "  inflating: mask_images/6810_anno.png  \n",
            "  inflating: mask_images/4514_anno.png  \n",
            "  inflating: mask_images/3362_anno.png  \n",
            "  inflating: mask_images/6412_anno.png  \n",
            "  inflating: mask_images/5899_anno.png  \n",
            "  inflating: mask_images/6596_anno.png  \n",
            "  inflating: mask_images/6789_anno.png  \n",
            "  inflating: mask_images/5454_anno.png  \n",
            "  inflating: mask_images/272_anno.png  \n",
            "  inflating: mask_images/4964_anno.png  \n",
            "  inflating: mask_images/7366_anno.png  \n",
            "  inflating: mask_images/766_anno.png  \n",
            "  inflating: mask_images/2660_anno.png  \n",
            "  inflating: mask_images/4358_anno.png  \n",
            "  inflating: mask_images/7488_anno.png  \n",
            "  inflating: mask_images/5861_anno.png  \n",
            "  inflating: mask_images/194_anno.png  \n",
            "  inflating: mask_images/3812_anno.png  \n",
            "  inflating: mask_images/4633_anno.png  \n",
            "  inflating: mask_images/6416_anno.png  \n",
            "  inflating: mask_images/6676_anno.png  \n",
            "  inflating: mask_images/3400_anno.png  \n",
            "  inflating: mask_images/3116_anno.png  \n",
            "  inflating: mask_images/5455_anno.png  \n",
            "  inflating: mask_images/3645_anno.png  \n",
            "  inflating: mask_images/5452_anno.png  \n",
            "  inflating: mask_images/7282_anno.png  \n",
            "  inflating: mask_images/4739_anno.png  \n",
            "  inflating: mask_images/5918_anno.png  \n",
            "  inflating: mask_images/6540_anno.png  \n",
            "  inflating: mask_images/6448_anno.png  \n",
            "  inflating: mask_images/6981_anno.png  \n",
            "  inflating: mask_images/2104_anno.png  \n",
            "  inflating: mask_images/4878_anno.png  \n",
            "  inflating: mask_images/835_anno.png  \n",
            "  inflating: mask_images/3697_anno.png  \n",
            "  inflating: mask_images/754_anno.png  \n",
            "  inflating: mask_images/6442_anno.png  \n",
            "  inflating: mask_images/489_anno.png  \n",
            "  inflating: mask_images/915_anno.png  \n",
            "  inflating: mask_images/5385_anno.png  \n",
            "  inflating: mask_images/3114_anno.png  \n",
            "  inflating: mask_images/3708_anno.png  \n",
            "  inflating: mask_images/6659_anno.png  \n",
            "  inflating: mask_images/4862_anno.png  \n",
            "  inflating: mask_images/5994_anno.png  \n",
            "  inflating: mask_images/4923_anno.png  \n",
            "  inflating: mask_images/6051_anno.png  \n",
            "  inflating: mask_images/2897_anno.png  \n",
            "  inflating: mask_images/3275_anno.png  \n",
            " extracting: mask_images/6963_anno.png  \n",
            "  inflating: mask_images/3879_anno.png  \n",
            "  inflating: mask_images/3626_anno.png  \n",
            "  inflating: mask_images/2615_anno.png  \n",
            "  inflating: mask_images/5923_anno.png  \n",
            "  inflating: mask_images/3432_anno.png  \n",
            "  inflating: mask_images/6918_anno.png  \n",
            "  inflating: mask_images/2969_anno.png  \n",
            "  inflating: mask_images/7573_anno.png  \n",
            "  inflating: mask_images/2730_anno.png  \n",
            "  inflating: mask_images/289_anno.png  \n",
            "  inflating: mask_images/2696_anno.png  \n",
            "  inflating: mask_images/3067_anno.png  \n",
            "  inflating: mask_images/3546_anno.png  \n",
            "  inflating: mask_images/6370_anno.png  \n",
            "  inflating: mask_images/5094_anno.png  \n",
            "  inflating: mask_images/774_anno.png  \n",
            "  inflating: mask_images/6994_anno.png  \n",
            "  inflating: mask_images/972_anno.png  \n",
            "  inflating: mask_images/5367_anno.png  \n",
            "  inflating: mask_images/288_anno.png  \n",
            "  inflating: mask_images/6016_anno.png  \n",
            "  inflating: mask_images/929_anno.png  \n",
            "  inflating: mask_images/5906_anno.png  \n",
            "  inflating: mask_images/3476_anno.png  \n",
            "  inflating: mask_images/3223_anno.png  \n",
            "  inflating: mask_images/495_anno.png  \n",
            "  inflating: mask_images/1935_anno.png  \n",
            "  inflating: mask_images/3938_anno.png  \n",
            "  inflating: mask_images/4022_anno.png  \n",
            "  inflating: mask_images/7049_anno.png  \n",
            "  inflating: mask_images/4284_anno.png  \n",
            "  inflating: mask_images/3573_anno.png  \n",
            "  inflating: mask_images/665_anno.png  \n",
            "  inflating: mask_images/7157_anno.png  \n",
            "  inflating: mask_images/2289_anno.png  \n",
            "  inflating: mask_images/6067_anno.png  \n",
            "  inflating: mask_images/4951_anno.png  \n",
            "  inflating: mask_images/2916_anno.png  \n",
            "  inflating: mask_images/6741_anno.png  \n",
            "  inflating: mask_images/3320_anno.png  \n",
            "  inflating: mask_images/6356_anno.png  \n",
            "  inflating: mask_images/2428_anno.png  \n",
            "  inflating: mask_images/4866_anno.png  \n",
            "  inflating: mask_images/7633_anno.png  \n",
            "  inflating: mask_images/3305_anno.png  \n",
            "  inflating: mask_images/5528_anno.png  \n",
            "  inflating: mask_images/5682_anno.png  \n",
            "  inflating: mask_images/6173_anno.png  \n",
            "  inflating: mask_images/7676_anno.png  \n",
            "  inflating: mask_images/202_anno.png  \n",
            "  inflating: mask_images/4436_anno.png  \n",
            "  inflating: mask_images/306_anno.png  \n",
            "  inflating: mask_images/4014_anno.png  \n",
            "  inflating: mask_images/5119_anno.png  \n",
            "  inflating: mask_images/444_anno.png  \n",
            "  inflating: mask_images/4518_anno.png  \n",
            "  inflating: mask_images/5555_anno.png  \n",
            "  inflating: mask_images/1572_anno.png  \n",
            "  inflating: mask_images/4681_anno.png  \n",
            "  inflating: mask_images/2259_anno.png  \n",
            "  inflating: mask_images/5590_anno.png  \n",
            "  inflating: mask_images/1989_anno.png  \n",
            "  inflating: mask_images/5121_anno.png  \n",
            "  inflating: mask_images/1888_anno.png  \n",
            "  inflating: mask_images/597_anno.png  \n",
            "  inflating: mask_images/7083_anno.png  \n",
            "  inflating: mask_images/3622_anno.png  \n",
            "  inflating: mask_images/6330_anno.png  \n",
            "  inflating: mask_images/7511_anno.png  \n",
            "  inflating: mask_images/7522_anno.png  \n",
            "  inflating: mask_images/7284_anno.png  \n",
            "  inflating: mask_images/7342_anno.png  \n",
            "  inflating: mask_images/6637_anno.png  \n",
            "  inflating: mask_images/4743_anno.png  \n",
            "  inflating: mask_images/5836_anno.png  \n",
            "  inflating: mask_images/6260_anno.png  \n",
            "  inflating: mask_images/2453_anno.png  \n",
            "  inflating: mask_images/2107_anno.png  \n",
            "  inflating: mask_images/4281_anno.png  \n",
            "  inflating: mask_images/7431_anno.png  \n",
            "  inflating: mask_images/413_anno.png  \n",
            "  inflating: mask_images/5395_anno.png  \n",
            "  inflating: mask_images/7213_anno.png  \n",
            "  inflating: mask_images/4783_anno.png  \n",
            "  inflating: mask_images/6884_anno.png  \n",
            "  inflating: mask_images/3958_anno.png  \n",
            "  inflating: mask_images/3041_anno.png  \n",
            "  inflating: mask_images/5652_anno.png  \n",
            "  inflating: mask_images/4950_anno.png  \n",
            "  inflating: mask_images/5953_anno.png  \n",
            "  inflating: mask_images/3814_anno.png  \n",
            "  inflating: mask_images/4128_anno.png  \n",
            "  inflating: mask_images/4522_anno.png  \n",
            "  inflating: mask_images/6308_anno.png  \n",
            "  inflating: mask_images/3203_anno.png  \n",
            "  inflating: mask_images/6138_anno.png  \n",
            "  inflating: mask_images/6377_anno.png  \n",
            "  inflating: mask_images/3955_anno.png  \n",
            "  inflating: mask_images/4408_anno.png  \n",
            "  inflating: mask_images/6360_anno.png  \n",
            "  inflating: mask_images/2427_anno.png  \n",
            "  inflating: mask_images/2090_anno.png  \n",
            "  inflating: mask_images/5386_anno.png  \n",
            "  inflating: mask_images/6457_anno.png  \n",
            "  inflating: mask_images/1866_anno.png  \n",
            "  inflating: mask_images/6672_anno.png  \n",
            "  inflating: mask_images/5998_anno.png  \n",
            "  inflating: mask_images/737_anno.png  \n",
            "  inflating: mask_images/5457_anno.png  \n",
            "  inflating: mask_images/2419_anno.png  \n",
            "  inflating: mask_images/4927_anno.png  \n",
            "  inflating: mask_images/6292_anno.png  \n",
            "  inflating: mask_images/2101_anno.png  \n",
            "  inflating: mask_images/4660_anno.png  \n",
            "  inflating: mask_images/2834_anno.png  \n",
            "  inflating: mask_images/4851_anno.png  \n",
            "  inflating: mask_images/5028_anno.png  \n",
            "  inflating: mask_images/6529_anno.png  \n",
            "  inflating: mask_images/5262_anno.png  \n",
            "  inflating: mask_images/4269_anno.png  \n",
            "  inflating: mask_images/3738_anno.png  \n",
            "  inflating: mask_images/7018_anno.png  \n",
            "  inflating: mask_images/5620_anno.png  \n",
            "  inflating: mask_images/556_anno.png  \n",
            "  inflating: mask_images/5416_anno.png  \n",
            "  inflating: mask_images/6628_anno.png  \n",
            "  inflating: mask_images/2118_anno.png  \n",
            "  inflating: mask_images/4985_anno.png  \n",
            "  inflating: mask_images/4107_anno.png  \n",
            "  inflating: mask_images/7415_anno.png  \n",
            "  inflating: mask_images/2490_anno.png  \n",
            "  inflating: mask_images/6555_anno.png  \n",
            "  inflating: mask_images/4292_anno.png  \n",
            "  inflating: mask_images/4728_anno.png  \n",
            "  inflating: mask_images/5674_anno.png  \n",
            "  inflating: mask_images/2108_anno.png  \n",
            "  inflating: mask_images/7181_anno.png  \n",
            "  inflating: mask_images/6932_anno.png  \n",
            "  inflating: mask_images/7611_anno.png  \n",
            "  inflating: mask_images/5492_anno.png  \n",
            "  inflating: mask_images/4457_anno.png  \n",
            "  inflating: mask_images/3177_anno.png  \n",
            "  inflating: mask_images/3030_anno.png  \n",
            "  inflating: mask_images/4061_anno.png  \n",
            "  inflating: mask_images/4237_anno.png  \n",
            "  inflating: mask_images/3957_anno.png  \n",
            "  inflating: mask_images/3268_anno.png  \n",
            "  inflating: mask_images/5200_anno.png  \n",
            "  inflating: mask_images/4640_anno.png  \n",
            "  inflating: mask_images/2960_anno.png  \n",
            "  inflating: mask_images/2168_anno.png  \n",
            "  inflating: mask_images/7109_anno.png  \n",
            "  inflating: mask_images/6521_anno.png  \n",
            "  inflating: mask_images/6618_anno.png  \n",
            "  inflating: mask_images/5398_anno.png  \n",
            "  inflating: mask_images/50_anno.png  \n",
            "  inflating: mask_images/4606_anno.png  \n",
            "  inflating: mask_images/2726_anno.png  \n",
            "  inflating: mask_images/3917_anno.png  \n",
            "  inflating: mask_images/5885_anno.png  \n",
            "  inflating: mask_images/902_anno.png  \n",
            "  inflating: mask_images/6108_anno.png  \n",
            "  inflating: mask_images/3841_anno.png  \n",
            "  inflating: mask_images/575_anno.png  \n",
            "  inflating: mask_images/2605_anno.png  \n",
            "  inflating: mask_images/5582_anno.png  \n",
            "  inflating: mask_images/5714_anno.png  \n",
            "  inflating: mask_images/7660_anno.png  \n",
            "  inflating: mask_images/4810_anno.png  \n",
            "  inflating: mask_images/2417_anno.png  \n",
            "  inflating: mask_images/6548_anno.png  \n",
            "  inflating: mask_images/4387_anno.png  \n",
            "  inflating: mask_images/7441_anno.png  \n",
            "  inflating: mask_images/3509_anno.png  \n",
            "  inflating: mask_images/3703_anno.png  \n",
            "  inflating: mask_images/2794_anno.png  \n",
            "  inflating: mask_images/7582_anno.png  \n",
            "  inflating: mask_images/3186_anno.png  \n",
            "  inflating: mask_images/4405_anno.png  \n",
            "  inflating: mask_images/4384_anno.png  \n",
            "  inflating: mask_images/2256_anno.png  \n",
            "  inflating: mask_images/6254_anno.png  \n",
            "  inflating: mask_images/4102_anno.png  \n",
            "  inflating: mask_images/3346_anno.png  \n",
            "  inflating: mask_images/2644_anno.png  \n",
            "  inflating: mask_images/5168_anno.png  \n",
            "  inflating: mask_images/6854_anno.png  \n",
            "  inflating: mask_images/5171_anno.png  \n",
            "  inflating: mask_images/6316_anno.png  \n",
            "  inflating: mask_images/2166_anno.png  \n",
            "  inflating: mask_images/2282_anno.png  \n",
            "  inflating: mask_images/1894_anno.png  \n",
            "  inflating: mask_images/2830_anno.png  \n",
            "  inflating: mask_images/4372_anno.png  \n",
            "  inflating: mask_images/2477_anno.png  \n",
            "  inflating: mask_images/713_anno.png  \n",
            "  inflating: mask_images/4179_anno.png  \n",
            "  inflating: mask_images/3724_anno.png  \n",
            "  inflating: mask_images/536_anno.png  \n",
            "  inflating: mask_images/7474_anno.png  \n",
            "  inflating: mask_images/6092_anno.png  \n",
            "  inflating: mask_images/5547_anno.png  \n",
            "  inflating: mask_images/4265_anno.png  \n",
            "  inflating: mask_images/6503_anno.png  \n",
            "  inflating: mask_images/6543_anno.png  \n",
            "  inflating: mask_images/5051_anno.png  \n",
            "  inflating: mask_images/7101_anno.png  \n",
            "  inflating: mask_images/7619_anno.png  \n",
            "  inflating: mask_images/5640_anno.png  \n",
            "  inflating: mask_images/2553_anno.png  \n",
            "  inflating: mask_images/3889_anno.png  \n",
            "  inflating: mask_images/4500_anno.png  \n",
            "  inflating: mask_images/5417_anno.png  \n",
            "  inflating: mask_images/4599_anno.png  \n",
            "  inflating: mask_images/6082_anno.png  \n",
            "  inflating: mask_images/817_anno.png  \n",
            "  inflating: mask_images/3503_anno.png  \n",
            "  inflating: mask_images/6037_anno.png  \n",
            "  inflating: mask_images/6765_anno.png  \n",
            "  inflating: mask_images/637_anno.png  \n",
            "  inflating: mask_images/4151_anno.png  \n",
            "  inflating: mask_images/6944_anno.png  \n",
            "  inflating: mask_images/5182_anno.png  \n",
            "  inflating: mask_images/5493_anno.png  \n",
            "  inflating: mask_images/7273_anno.png  \n",
            "  inflating: mask_images/2943_anno.png  \n",
            "  inflating: mask_images/4779_anno.png  \n",
            "  inflating: mask_images/7465_anno.png  \n",
            "  inflating: mask_images/6535_anno.png  \n",
            "  inflating: mask_images/3196_anno.png  \n",
            "  inflating: mask_images/6268_anno.png  \n",
            "  inflating: mask_images/3898_anno.png  \n",
            "  inflating: mask_images/6362_anno.png  \n",
            "  inflating: mask_images/5333_anno.png  \n",
            " extracting: mask_images/3963_anno.png  \n",
            "  inflating: mask_images/5938_anno.png  \n",
            "  inflating: mask_images/98_anno.png  \n",
            "  inflating: mask_images/5210_anno.png  \n",
            "  inflating: mask_images/1921_anno.png  \n",
            "  inflating: mask_images/3381_anno.png  \n",
            "  inflating: mask_images/6424_anno.png  \n",
            "  inflating: mask_images/7240_anno.png  \n",
            "  inflating: mask_images/284_anno.png  \n",
            "  inflating: mask_images/6152_anno.png  \n",
            "  inflating: mask_images/226_anno.png  \n",
            "  inflating: mask_images/6823_anno.png  \n",
            "  inflating: mask_images/5283_anno.png  \n",
            "  inflating: mask_images/5474_anno.png  \n",
            "  inflating: mask_images/6159_anno.png  \n",
            "  inflating: mask_images/5188_anno.png  \n",
            "  inflating: mask_images/1872_anno.png  \n",
            "  inflating: mask_images/3828_anno.png  \n",
            "  inflating: mask_images/4590_anno.png  \n",
            "  inflating: mask_images/3542_anno.png  \n",
            "  inflating: mask_images/2081_anno.png  \n",
            "  inflating: mask_images/2141_anno.png  \n",
            "  inflating: mask_images/302_anno.png  \n",
            "  inflating: mask_images/4476_anno.png  \n",
            "  inflating: mask_images/6444_anno.png  \n",
            "  inflating: mask_images/1934_anno.png  \n",
            "  inflating: mask_images/6527_anno.png  \n",
            "  inflating: mask_images/3195_anno.png  \n",
            "  inflating: mask_images/6973_anno.png  \n",
            "  inflating: mask_images/3663_anno.png  \n",
            "  inflating: mask_images/4479_anno.png  \n",
            "  inflating: mask_images/2612_anno.png  \n",
            "  inflating: mask_images/2572_anno.png  \n",
            "  inflating: mask_images/5800_anno.png  \n",
            "  inflating: mask_images/5537_anno.png  \n",
            "  inflating: mask_images/2858_anno.png  \n",
            "  inflating: mask_images/6487_anno.png  \n",
            "  inflating: mask_images/2501_anno.png  \n",
            "  inflating: mask_images/7216_anno.png  \n",
            "  inflating: mask_images/5806_anno.png  \n",
            "  inflating: mask_images/3107_anno.png  \n",
            "  inflating: mask_images/5231_anno.png  \n",
            "  inflating: mask_images/1087_anno.png  \n",
            "  inflating: mask_images/6340_anno.png  \n",
            "  inflating: mask_images/4689_anno.png  \n",
            "  inflating: mask_images/505_anno.png  \n",
            "  inflating: mask_images/3152_anno.png  \n",
            "  inflating: mask_images/7026_anno.png  \n",
            "  inflating: mask_images/4545_anno.png  \n",
            "  inflating: mask_images/7659_anno.png  \n",
            "  inflating: mask_images/7508_anno.png  \n",
            "  inflating: mask_images/4970_anno.png  \n",
            "  inflating: mask_images/869_anno.png  \n",
            "  inflating: mask_images/2491_anno.png  \n",
            "  inflating: mask_images/1919_anno.png  \n",
            "  inflating: mask_images/7379_anno.png  \n",
            "  inflating: mask_images/5487_anno.png  \n",
            "  inflating: mask_images/4917_anno.png  \n",
            "  inflating: mask_images/7405_anno.png  \n",
            "  inflating: mask_images/5647_anno.png  \n",
            "  inflating: mask_images/6233_anno.png  \n",
            "  inflating: mask_images/4691_anno.png  \n",
            "  inflating: mask_images/2041_anno.png  \n",
            "  inflating: mask_images/6123_anno.png  \n",
            "  inflating: mask_images/4184_anno.png  \n",
            "  inflating: mask_images/6779_anno.png  \n",
            "  inflating: mask_images/6912_anno.png  \n",
            "  inflating: mask_images/5183_anno.png  \n",
            "  inflating: mask_images/5148_anno.png  \n",
            "  inflating: mask_images/4577_anno.png  \n",
            "  inflating: mask_images/4136_anno.png  \n",
            "  inflating: mask_images/5341_anno.png  \n",
            "  inflating: mask_images/5232_anno.png  \n",
            "  inflating: mask_images/4426_anno.png  \n",
            "  inflating: mask_images/3481_anno.png  \n",
            "  inflating: mask_images/5199_anno.png  \n",
            "  inflating: mask_images/1895_anno.png  \n",
            "  inflating: mask_images/2143_anno.png  \n",
            "  inflating: mask_images/517_anno.png  \n",
            "  inflating: mask_images/6998_anno.png  \n",
            "  inflating: mask_images/3306_anno.png  \n",
            "  inflating: mask_images/3520_anno.png  \n",
            "  inflating: mask_images/5711_anno.png  \n",
            "  inflating: mask_images/6008_anno.png  \n",
            "  inflating: mask_images/3412_anno.png  \n",
            "  inflating: mask_images/6396_anno.png  \n",
            "  inflating: mask_images/6315_anno.png  \n",
            "  inflating: mask_images/3785_anno.png  \n",
            "  inflating: mask_images/426_anno.png  \n",
            "  inflating: mask_images/3511_anno.png  \n",
            "  inflating: mask_images/405_anno.png  \n",
            "  inflating: mask_images/7436_anno.png  \n",
            "  inflating: mask_images/3896_anno.png  \n",
            "  inflating: mask_images/5558_anno.png  \n",
            "  inflating: mask_images/7006_anno.png  \n",
            "  inflating: mask_images/5133_anno.png  \n",
            "  inflating: mask_images/3574_anno.png  \n",
            "  inflating: mask_images/2273_anno.png  \n",
            "  inflating: mask_images/6280_anno.png  \n",
            "  inflating: mask_images/1920_anno.png  \n",
            "  inflating: mask_images/265_anno.png  \n",
            "  inflating: mask_images/725_anno.png  \n",
            "  inflating: mask_images/3702_anno.png  \n",
            "  inflating: mask_images/5963_anno.png  \n",
            "  inflating: mask_images/4676_anno.png  \n",
            "  inflating: mask_images/2047_anno.png  \n",
            "  inflating: mask_images/503_anno.png  \n",
            "  inflating: mask_images/4738_anno.png  \n",
            "  inflating: mask_images/7528_anno.png  \n",
            "  inflating: mask_images/7233_anno.png  \n",
            "  inflating: mask_images/7594_anno.png  \n",
            "  inflating: mask_images/4652_anno.png  \n",
            "  inflating: mask_images/4242_anno.png  \n",
            "  inflating: mask_images/3312_anno.png  \n",
            "  inflating: mask_images/6403_anno.png  \n",
            " extracting: mask_images/5540_anno.png  \n",
            "  inflating: mask_images/4688_anno.png  \n",
            "  inflating: mask_images/3729_anno.png  \n",
            "  inflating: mask_images/4628_anno.png  \n",
            "  inflating: mask_images/5825_anno.png  \n",
            "  inflating: mask_images/6334_anno.png  \n",
            "  inflating: mask_images/6098_anno.png  \n",
            "  inflating: mask_images/5762_anno.png  \n",
            "  inflating: mask_images/5796_anno.png  \n",
            "  inflating: mask_images/6682_anno.png  \n",
            "  inflating: mask_images/6720_anno.png  \n",
            "  inflating: mask_images/292_anno.png  \n",
            "  inflating: mask_images/2522_anno.png  \n",
            "  inflating: mask_images/7017_anno.png  \n",
            "  inflating: mask_images/5299_anno.png  \n",
            "  inflating: mask_images/5814_anno.png  \n",
            "  inflating: mask_images/4063_anno.png  \n",
            "  inflating: mask_images/786_anno.png  \n",
            "  inflating: mask_images/7201_anno.png  \n",
            "  inflating: mask_images/4618_anno.png  \n",
            "  inflating: mask_images/5509_anno.png  \n",
            "  inflating: mask_images/3993_anno.png  \n",
            "  inflating: mask_images/7048_anno.png  \n",
            "  inflating: mask_images/453_anno.png  \n",
            "  inflating: mask_images/334_anno.png  \n",
            "  inflating: mask_images/5145_anno.png  \n",
            "  inflating: mask_images/7529_anno.png  \n",
            "  inflating: mask_images/5194_anno.png  \n",
            "  inflating: mask_images/3970_anno.png  \n",
            "  inflating: mask_images/4881_anno.png  \n",
            "  inflating: mask_images/792_anno.png  \n",
            "  inflating: mask_images/6816_anno.png  \n",
            "  inflating: mask_images/3679_anno.png  \n",
            "  inflating: mask_images/4641_anno.png  \n",
            "  inflating: mask_images/3001_anno.png  \n",
            "  inflating: mask_images/3869_anno.png  \n",
            "  inflating: mask_images/6103_anno.png  \n",
            "  inflating: mask_images/6060_anno.png  \n",
            "  inflating: mask_images/834_anno.png  \n",
            "  inflating: mask_images/7657_anno.png  \n",
            "  inflating: mask_images/6483_anno.png  \n",
            "  inflating: mask_images/71_anno.png  \n",
            "  inflating: mask_images/6999_anno.png  \n",
            "  inflating: mask_images/399_anno.png  \n",
            "  inflating: mask_images/7198_anno.png  \n",
            "  inflating: mask_images/4303_anno.png  \n",
            "  inflating: mask_images/4460_anno.png  \n",
            "  inflating: mask_images/2826_anno.png  \n",
            "  inflating: mask_images/4578_anno.png  \n",
            "  inflating: mask_images/7644_anno.png  \n",
            "  inflating: mask_images/3853_anno.png  \n",
            "  inflating: mask_images/4205_anno.png  \n",
            "  inflating: mask_images/6883_anno.png  \n",
            "  inflating: mask_images/1967_anno.png  \n",
            "  inflating: mask_images/7686_anno.png  \n",
            "  inflating: mask_images/6117_anno.png  \n",
            "  inflating: mask_images/2499_anno.png  \n",
            "  inflating: mask_images/4885_anno.png  \n",
            "  inflating: mask_images/547_anno.png  \n",
            "  inflating: mask_images/5723_anno.png  \n",
            "  inflating: mask_images/3201_anno.png  \n",
            "  inflating: mask_images/6946_anno.png  \n",
            "  inflating: mask_images/959_anno.png  \n",
            "  inflating: mask_images/1328_anno.png  \n",
            "  inflating: mask_images/4682_anno.png  \n",
            "  inflating: mask_images/3466_anno.png  \n",
            "  inflating: mask_images/4820_anno.png  \n",
            "  inflating: mask_images/4168_anno.png  \n",
            "  inflating: mask_images/7625_anno.png  \n",
            "  inflating: mask_images/5396_anno.png  \n",
            "  inflating: mask_images/3224_anno.png  \n",
            "  inflating: mask_images/769_anno.png  \n",
            "  inflating: mask_images/4489_anno.png  \n",
            "  inflating: mask_images/5007_anno.png  \n",
            "  inflating: mask_images/7060_anno.png  \n",
            "  inflating: mask_images/4006_anno.png  \n",
            "  inflating: mask_images/5903_anno.png  \n",
            "  inflating: mask_images/6181_anno.png  \n",
            "  inflating: mask_images/5198_anno.png  \n",
            "  inflating: mask_images/7425_anno.png  \n",
            "  inflating: mask_images/3214_anno.png  \n",
            "  inflating: mask_images/3733_anno.png  \n",
            "  inflating: mask_images/411_anno.png  \n",
            "  inflating: mask_images/4465_anno.png  \n",
            "  inflating: mask_images/3741_anno.png  \n",
            "  inflating: mask_images/5503_anno.png  \n",
            "  inflating: mask_images/4619_anno.png  \n",
            "  inflating: mask_images/4139_anno.png  \n",
            "  inflating: mask_images/2543_anno.png  \n",
            "  inflating: mask_images/6524_anno.png  \n",
            "  inflating: mask_images/6337_anno.png  \n",
            "  inflating: mask_images/5729_anno.png  \n",
            "  inflating: mask_images/4579_anno.png  \n",
            "  inflating: mask_images/5878_anno.png  \n",
            "  inflating: mask_images/6743_anno.png  \n",
            "  inflating: mask_images/2400_anno.png  \n",
            "  inflating: mask_images/6784_anno.png  \n",
            "  inflating: mask_images/6701_anno.png  \n",
            "  inflating: mask_images/3123_anno.png  \n",
            "  inflating: mask_images/4382_anno.png  \n",
            "  inflating: mask_images/4868_anno.png  \n",
            "  inflating: mask_images/7263_anno.png  \n",
            "  inflating: mask_images/7613_anno.png  \n",
            "  inflating: mask_images/3799_anno.png  \n",
            "  inflating: mask_images/961_anno.png  \n",
            "  inflating: mask_images/2288_anno.png  \n",
            "  inflating: mask_images/5266_anno.png  \n",
            "  inflating: mask_images/6203_anno.png  \n",
            "  inflating: mask_images/2929_anno.png  \n",
            "  inflating: mask_images/6259_anno.png  \n",
            "  inflating: mask_images/6231_anno.png  \n",
            "  inflating: mask_images/4378_anno.png  \n",
            "  inflating: mask_images/7292_anno.png  \n",
            "  inflating: mask_images/5057_anno.png  \n",
            "  inflating: mask_images/853_anno.png  \n",
            "  inflating: mask_images/4961_anno.png  \n",
            "  inflating: mask_images/2226_anno.png  \n",
            "  inflating: mask_images/5482_anno.png  \n",
            "  inflating: mask_images/1458_anno.png  \n",
            "  inflating: mask_images/796_anno.png  \n",
            "  inflating: mask_images/4231_anno.png  \n",
            "  inflating: mask_images/4913_anno.png  \n",
            "  inflating: mask_images/4130_anno.png  \n",
            "  inflating: mask_images/6137_anno.png  \n",
            "  inflating: mask_images/283_anno.png  \n",
            "  inflating: mask_images/6121_anno.png  \n",
            "  inflating: mask_images/2208_anno.png  \n",
            "  inflating: mask_images/3646_anno.png  \n",
            "  inflating: mask_images/2906_anno.png  \n",
            "  inflating: mask_images/2155_anno.png  \n",
            "  inflating: mask_images/4794_anno.png  \n",
            "  inflating: mask_images/3129_anno.png  \n",
            "  inflating: mask_images/3808_anno.png  \n",
            "  inflating: mask_images/4888_anno.png  \n",
            "  inflating: mask_images/6931_anno.png  \n",
            "  inflating: mask_images/4111_anno.png  \n",
            "  inflating: mask_images/1939_anno.png  \n",
            "  inflating: mask_images/5426_anno.png  \n",
            "  inflating: mask_images/4635_anno.png  \n",
            "  inflating: mask_images/3770_anno.png  \n",
            "  inflating: mask_images/5592_anno.png  \n",
            "  inflating: mask_images/5744_anno.png  \n",
            "  inflating: mask_images/2252_anno.png  \n",
            "  inflating: mask_images/7183_anno.png  \n",
            "  inflating: mask_images/2073_anno.png  \n",
            "  inflating: mask_images/287_anno.png  \n",
            "  inflating: mask_images/3137_anno.png  \n",
            "  inflating: mask_images/7124_anno.png  \n",
            "  inflating: mask_images/342_anno.png  \n",
            "  inflating: mask_images/6842_anno.png  \n",
            "  inflating: mask_images/2982_anno.png  \n",
            "  inflating: mask_images/701_anno.png  \n",
            "  inflating: mask_images/1246_anno.png  \n",
            "  inflating: mask_images/4161_anno.png  \n",
            "  inflating: mask_images/3096_anno.png  \n",
            "  inflating: mask_images/2175_anno.png  \n",
            "  inflating: mask_images/7570_anno.png  \n",
            "  inflating: mask_images/385_anno.png  \n",
            "  inflating: mask_images/6057_anno.png  \n",
            "  inflating: mask_images/3652_anno.png  \n",
            "  inflating: mask_images/3078_anno.png  \n",
            "  inflating: mask_images/6080_anno.png  \n",
            "  inflating: mask_images/7621_anno.png  \n",
            "  inflating: mask_images/3342_anno.png  \n",
            "  inflating: mask_images/2884_anno.png  \n",
            "  inflating: mask_images/2980_anno.png  \n",
            "  inflating: mask_images/6371_anno.png  \n",
            "  inflating: mask_images/7599_anno.png  \n",
            "  inflating: mask_images/6929_anno.png  \n",
            "  inflating: mask_images/4013_anno.png  \n",
            "  inflating: mask_images/3138_anno.png  \n",
            "  inflating: mask_images/2751_anno.png  \n",
            "  inflating: mask_images/7122_anno.png  \n",
            "  inflating: mask_images/4773_anno.png  \n",
            "  inflating: mask_images/2662_anno.png  \n",
            "  inflating: mask_images/799_anno.png  \n",
            "  inflating: mask_images/3659_anno.png  \n",
            "  inflating: mask_images/4552_anno.png  \n",
            "  inflating: mask_images/6003_anno.png  \n",
            "  inflating: mask_images/7536_anno.png  \n",
            "  inflating: mask_images/4669_anno.png  \n",
            "  inflating: mask_images/2526_anno.png  \n",
            "  inflating: mask_images/5597_anno.png  \n",
            "  inflating: mask_images/5216_anno.png  \n",
            "  inflating: mask_images/7545_anno.png  \n",
            "  inflating: mask_images/2287_anno.png  \n",
            "  inflating: mask_images/891_anno.png  \n",
            "  inflating: mask_images/4705_anno.png  \n",
            "  inflating: mask_images/5596_anno.png  \n",
            "  inflating: mask_images/369_anno.png  \n",
            "  inflating: mask_images/3356_anno.png  \n",
            "  inflating: mask_images/7044_anno.png  \n",
            "  inflating: mask_images/7435_anno.png  \n",
            "  inflating: mask_images/4547_anno.png  \n",
            "  inflating: mask_images/5810_anno.png  \n",
            "  inflating: mask_images/4544_anno.png  \n",
            "  inflating: mask_images/7505_anno.png  \n",
            "  inflating: mask_images/2237_anno.png  \n",
            "  inflating: mask_images/4226_anno.png  \n",
            "  inflating: mask_images/5419_anno.png  \n",
            "  inflating: mask_images/359_anno.png  \n",
            "  inflating: mask_images/4082_anno.png  \n",
            "  inflating: mask_images/3392_anno.png  \n",
            "  inflating: mask_images/4157_anno.png  \n",
            "  inflating: mask_images/5880_anno.png  \n",
            "  inflating: mask_images/6985_anno.png  \n",
            "  inflating: mask_images/3494_anno.png  \n",
            "  inflating: mask_images/7046_anno.png  \n",
            "  inflating: mask_images/6339_anno.png  \n",
            "  inflating: mask_images/2942_anno.png  \n",
            "  inflating: mask_images/4019_anno.png  \n",
            "  inflating: mask_images/2012_anno.png  \n",
            "  inflating: mask_images/3470_anno.png  \n",
            "  inflating: mask_images/388_anno.png  \n",
            "  inflating: mask_images/4071_anno.png  \n",
            "  inflating: mask_images/2229_anno.png  \n",
            "  inflating: mask_images/7469_anno.png  \n",
            "  inflating: mask_images/4801_anno.png  \n",
            "  inflating: mask_images/6062_anno.png  \n",
            "  inflating: mask_images/712_anno.png  \n",
            "  inflating: mask_images/4594_anno.png  \n",
            "  inflating: mask_images/4850_anno.png  \n",
            "  inflating: mask_images/2619_anno.png  \n",
            "  inflating: mask_images/5697_anno.png  \n",
            "  inflating: mask_images/7253_anno.png  \n",
            "  inflating: mask_images/6068_anno.png  \n",
            "  inflating: mask_images/381_anno.png  \n",
            "  inflating: mask_images/7134_anno.png  \n",
            "  inflating: mask_images/3315_anno.png  \n",
            "  inflating: mask_images/5253_anno.png  \n",
            "  inflating: mask_images/7450_anno.png  \n",
            "  inflating: mask_images/5631_anno.png  \n",
            "  inflating: mask_images/7476_anno.png  \n",
            "  inflating: mask_images/4375_anno.png  \n",
            "  inflating: mask_images/650_anno.png  \n",
            "  inflating: mask_images/491_anno.png  \n",
            "  inflating: mask_images/703_anno.png  \n",
            "  inflating: mask_images/3153_anno.png  \n",
            "  inflating: mask_images/4416_anno.png  \n",
            "  inflating: mask_images/3995_anno.png  \n",
            "  inflating: mask_images/6679_anno.png  \n",
            "  inflating: mask_images/2903_anno.png  \n",
            "  inflating: mask_images/6588_anno.png  \n",
            "  inflating: mask_images/3424_anno.png  \n",
            "  inflating: mask_images/4558_anno.png  \n",
            "  inflating: mask_images/508_anno.png  \n",
            "  inflating: mask_images/4393_anno.png  \n",
            "  inflating: mask_images/7624_anno.png  \n",
            "  inflating: mask_images/5380_anno.png  \n",
            "  inflating: mask_images/6130_anno.png  \n",
            "  inflating: mask_images/1537_anno.png  \n",
            "  inflating: mask_images/3034_anno.png  \n",
            "  inflating: mask_images/5663_anno.png  \n",
            "  inflating: mask_images/1948_anno.png  \n",
            "  inflating: mask_images/823_anno.png  \n",
            "  inflating: mask_images/3913_anno.png  \n",
            "  inflating: mask_images/487_anno.png  \n",
            "  inflating: mask_images/4103_anno.png  \n",
            "  inflating: mask_images/6979_anno.png  \n",
            "  inflating: mask_images/4353_anno.png  \n",
            "  inflating: mask_images/6185_anno.png  \n",
            "  inflating: mask_images/3301_anno.png  \n",
            "  inflating: mask_images/4364_anno.png  \n",
            "  inflating: mask_images/7557_anno.png  \n",
            "  inflating: mask_images/5890_anno.png  \n",
            "  inflating: mask_images/7199_anno.png  \n",
            "  inflating: mask_images/1461_anno.png  \n",
            "  inflating: mask_images/4051_anno.png  \n",
            "  inflating: mask_images/5111_anno.png  \n",
            "  inflating: mask_images/6034_anno.png  \n",
            "  inflating: mask_images/2750_anno.png  \n",
            "  inflating: mask_images/2870_anno.png  \n",
            "  inflating: mask_images/6656_anno.png  \n",
            "  inflating: mask_images/6274_anno.png  \n",
            "  inflating: mask_images/3496_anno.png  \n",
            "  inflating: mask_images/6040_anno.png  \n",
            "  inflating: mask_images/2807_anno.png  \n",
            "  inflating: mask_images/5289_anno.png  \n",
            "  inflating: mask_images/6146_anno.png  \n",
            "  inflating: mask_images/904_anno.png  \n",
            "  inflating: mask_images/935_anno.png  \n",
            "  inflating: mask_images/7419_anno.png  \n",
            "  inflating: mask_images/5655_anno.png  \n",
            "  inflating: mask_images/2305_anno.png  \n",
            "  inflating: mask_images/3613_anno.png  \n",
            "  inflating: mask_images/498_anno.png  \n",
            "  inflating: mask_images/580_anno.png  \n",
            "  inflating: mask_images/5746_anno.png  \n",
            "  inflating: mask_images/6736_anno.png  \n",
            "  inflating: mask_images/2704_anno.png  \n",
            "  inflating: mask_images/7058_anno.png  \n",
            "  inflating: mask_images/3901_anno.png  \n",
            "  inflating: mask_images/7636_anno.png  \n",
            "  inflating: mask_images/6969_anno.png  \n",
            "  inflating: mask_images/4091_anno.png  \n",
            "  inflating: mask_images/6010_anno.png  \n",
            "  inflating: mask_images/378_anno.png  \n",
            "  inflating: mask_images/6608_anno.png  \n",
            "  inflating: mask_images/7464_anno.png  \n",
            "  inflating: mask_images/979_anno.png  \n",
            "  inflating: mask_images/3475_anno.png  \n",
            "  inflating: mask_images/7709_anno.png  \n",
            "  inflating: mask_images/4768_anno.png  \n",
            "  inflating: mask_images/3419_anno.png  \n",
            "  inflating: mask_images/764_anno.png  \n",
            "  inflating: mask_images/7267_anno.png  \n",
            "  inflating: mask_images/3213_anno.png  \n",
            "  inflating: mask_images/5909_anno.png  \n",
            "  inflating: mask_images/6691_anno.png  \n",
            "  inflating: mask_images/6955_anno.png  \n",
            "  inflating: mask_images/3378_anno.png  \n",
            "  inflating: mask_images/6732_anno.png  \n",
            "  inflating: mask_images/6995_anno.png  \n",
            "  inflating: mask_images/6663_anno.png  \n",
            "  inflating: mask_images/5022_anno.png  \n",
            "  inflating: mask_images/7042_anno.png  \n",
            "  inflating: mask_images/3303_anno.png  \n",
            "  inflating: mask_images/3571_anno.png  \n",
            "  inflating: mask_images/3506_anno.png  \n",
            "  inflating: mask_images/6832_anno.png  \n",
            "  inflating: mask_images/4294_anno.png  \n",
            "  inflating: mask_images/2420_anno.png  \n",
            "  inflating: mask_images/5548_anno.png  \n",
            "  inflating: mask_images/4935_anno.png  \n",
            "  inflating: mask_images/317_anno.png  \n",
            "  inflating: mask_images/85_anno.png  \n",
            "  inflating: mask_images/3258_anno.png  \n",
            "  inflating: mask_images/7074_anno.png  \n",
            "  inflating: mask_images/6359_anno.png  \n",
            "  inflating: mask_images/2742_anno.png  \n",
            "  inflating: mask_images/2478_anno.png  \n",
            "  inflating: mask_images/2673_anno.png  \n",
            "  inflating: mask_images/4830_anno.png  \n",
            "  inflating: mask_images/3953_anno.png  \n",
            "  inflating: mask_images/784_anno.png  \n",
            "  inflating: mask_images/963_anno.png  \n",
            "  inflating: mask_images/6531_anno.png  \n",
            "  inflating: mask_images/311_anno.png  \n",
            "  inflating: mask_images/2367_anno.png  \n",
            "  inflating: mask_images/4334_anno.png  \n",
            "  inflating: mask_images/5567_anno.png  \n",
            "  inflating: mask_images/484_anno.png  \n",
            "  inflating: mask_images/3872_anno.png  \n",
            "  inflating: mask_images/2688_anno.png  \n",
            "  inflating: mask_images/6205_anno.png  \n",
            "  inflating: mask_images/2832_anno.png  \n",
            "  inflating: mask_images/1462_anno.png  \n",
            "  inflating: mask_images/5352_anno.png  \n",
            "  inflating: mask_images/5402_anno.png  \n",
            "  inflating: mask_images/4818_anno.png  \n",
            "  inflating: mask_images/5336_anno.png  \n",
            "  inflating: mask_images/7440_anno.png  \n",
            "  inflating: mask_images/4039_anno.png  \n",
            "  inflating: mask_images/794_anno.png  \n",
            "  inflating: mask_images/5136_anno.png  \n",
            "  inflating: mask_images/4665_anno.png  \n",
            "  inflating: mask_images/2312_anno.png  \n",
            "  inflating: mask_images/3527_anno.png  \n",
            "  inflating: mask_images/3716_anno.png  \n",
            "  inflating: mask_images/3450_anno.png  \n",
            "  inflating: mask_images/2941_anno.png  \n",
            "  inflating: mask_images/4745_anno.png  \n",
            "  inflating: mask_images/5612_anno.png  \n",
            "  inflating: mask_images/6493_anno.png  \n",
            "  inflating: mask_images/6086_anno.png  \n",
            "  inflating: mask_images/456_anno.png  \n",
            "  inflating: mask_images/7578_anno.png  \n",
            "  inflating: mask_images/5072_anno.png  \n",
            "  inflating: mask_images/4110_anno.png  \n",
            "  inflating: mask_images/5967_anno.png  \n",
            "  inflating: mask_images/7236_anno.png  \n",
            "  inflating: mask_images/7538_anno.png  \n",
            "  inflating: mask_images/7566_anno.png  \n",
            "  inflating: mask_images/2423_anno.png  \n",
            "  inflating: mask_images/3768_anno.png  \n",
            "  inflating: mask_images/307_anno.png  \n",
            "  inflating: mask_images/4992_anno.png  \n",
            "  inflating: mask_images/7593_anno.png  \n",
            "  inflating: mask_images/240_anno.png  \n",
            "  inflating: mask_images/5485_anno.png  \n",
            "  inflating: mask_images/7714_anno.png  \n",
            "  inflating: mask_images/564_anno.png  \n",
            "  inflating: mask_images/3211_anno.png  \n",
            "  inflating: mask_images/7380_anno.png  \n",
            "  inflating: mask_images/2172_anno.png  \n",
            "  inflating: mask_images/3845_anno.png  \n",
            "  inflating: mask_images/3565_anno.png  \n",
            "  inflating: mask_images/2061_anno.png  \n",
            "  inflating: mask_images/681_anno.png  \n",
            "  inflating: mask_images/6532_anno.png  \n",
            "  inflating: mask_images/588_anno.png  \n",
            "  inflating: mask_images/6964_anno.png  \n",
            "  inflating: mask_images/3954_anno.png  \n",
            "  inflating: mask_images/6298_anno.png  \n",
            "  inflating: mask_images/7360_anno.png  \n",
            "  inflating: mask_images/6911_anno.png  \n",
            "  inflating: mask_images/4011_anno.png  \n",
            "  inflating: mask_images/6522_anno.png  \n",
            "  inflating: mask_images/7106_anno.png  \n",
            "  inflating: mask_images/6135_anno.png  \n",
            "  inflating: mask_images/2223_anno.png  \n",
            "  inflating: mask_images/48_anno.png  \n",
            "  inflating: mask_images/4746_anno.png  \n",
            "  inflating: mask_images/7482_anno.png  \n",
            "  inflating: mask_images/873_anno.png  \n",
            "  inflating: mask_images/1945_anno.png  \n",
            "  inflating: mask_images/3495_anno.png  \n",
            "  inflating: mask_images/3064_anno.png  \n",
            "  inflating: mask_images/2790_anno.png  \n",
            "  inflating: mask_images/3249_anno.png  \n",
            "  inflating: mask_images/5237_anno.png  \n",
            "  inflating: mask_images/6079_anno.png  \n",
            "  inflating: mask_images/4737_anno.png  \n",
            "  inflating: mask_images/5241_anno.png  \n",
            "  inflating: mask_images/2523_anno.png  \n",
            "  inflating: mask_images/6380_anno.png  \n",
            "  inflating: mask_images/6984_anno.png  \n",
            "  inflating: mask_images/5854_anno.png  \n",
            "  inflating: mask_images/5159_anno.png  \n",
            "  inflating: mask_images/4449_anno.png  \n",
            "  inflating: mask_images/4675_anno.png  \n",
            "  inflating: mask_images/4100_anno.png  \n",
            "  inflating: mask_images/4854_anno.png  \n",
            "  inflating: mask_images/6426_anno.png  \n",
            "  inflating: mask_images/6776_anno.png  \n",
            "  inflating: mask_images/5460_anno.png  \n",
            "  inflating: mask_images/4814_anno.png  \n",
            "  inflating: mask_images/3927_anno.png  \n",
            "  inflating: mask_images/3664_anno.png  \n",
            "  inflating: mask_images/5379_anno.png  \n",
            "  inflating: mask_images/605_anno.png  \n",
            "  inflating: mask_images/6879_anno.png  \n",
            "  inflating: mask_images/540_anno.png  \n",
            "  inflating: mask_images/7076_anno.png  \n",
            "  inflating: mask_images/2406_anno.png  \n",
            "  inflating: mask_images/6934_anno.png  \n",
            "  inflating: mask_images/5391_anno.png  \n",
            "  inflating: mask_images/4429_anno.png  \n",
            "  inflating: mask_images/2084_anno.png  \n",
            "  inflating: mask_images/3777_anno.png  \n",
            "  inflating: mask_images/6811_anno.png  \n",
            "  inflating: mask_images/5311_anno.png  \n",
            "  inflating: mask_images/2052_anno.png  \n",
            "  inflating: mask_images/6460_anno.png  \n",
            "  inflating: mask_images/324_anno.png  \n",
            "  inflating: mask_images/3175_anno.png  \n",
            "  inflating: mask_images/1864_anno.png  \n",
            "  inflating: mask_images/5369_anno.png  \n",
            "  inflating: mask_images/2225_anno.png  \n",
            "  inflating: mask_images/5713_anno.png  \n",
            "  inflating: mask_images/3910_anno.png  \n",
            "  inflating: mask_images/3239_anno.png  \n",
            "  inflating: mask_images/5881_anno.png  \n",
            "  inflating: mask_images/4451_anno.png  \n",
            "  inflating: mask_images/666_anno.png  \n",
            "  inflating: mask_images/4629_anno.png  \n",
            "  inflating: mask_images/229_anno.png  \n",
            "  inflating: mask_images/750_anno.png  \n",
            "  inflating: mask_images/23_anno.png  \n",
            "  inflating: mask_images/931_anno.png  \n",
            "  inflating: mask_images/6662_anno.png  \n",
            "  inflating: mask_images/6376_anno.png  \n",
            "  inflating: mask_images/7708_anno.png  \n",
            "  inflating: mask_images/2558_anno.png  \n",
            "  inflating: mask_images/658_anno.png  \n",
            "  inflating: mask_images/7651_anno.png  \n",
            "  inflating: mask_images/2176_anno.png  \n",
            "  inflating: mask_images/4957_anno.png  \n",
            "  inflating: mask_images/401_anno.png  \n",
            "  inflating: mask_images/3593_anno.png  \n",
            "  inflating: mask_images/6118_anno.png  \n",
            "  inflating: mask_images/2767_anno.png  \n",
            "  inflating: mask_images/7447_anno.png  \n",
            "  inflating: mask_images/5074_anno.png  \n",
            "  inflating: mask_images/573_anno.png  \n",
            "  inflating: mask_images/4926_anno.png  \n",
            "  inflating: mask_images/5605_anno.png  \n",
            "  inflating: mask_images/6990_anno.png  \n",
            "  inflating: mask_images/4348_anno.png  \n",
            "  inflating: mask_images/337_anno.png  \n",
            "  inflating: mask_images/4920_anno.png  \n",
            "  inflating: mask_images/5184_anno.png  \n",
            "  inflating: mask_images/2128_anno.png  \n",
            "  inflating: mask_images/4381_anno.png  \n",
            "  inflating: mask_images/2864_anno.png  \n",
            "  inflating: mask_images/4001_anno.png  \n",
            "  inflating: mask_images/4786_anno.png  \n",
            "  inflating: mask_images/3455_anno.png  \n",
            "  inflating: mask_images/5087_anno.png  \n",
            "  inflating: mask_images/3629_anno.png  \n",
            "  inflating: mask_images/91_anno.png  \n",
            "  inflating: mask_images/2511_anno.png  \n",
            "  inflating: mask_images/6563_anno.png  \n",
            "  inflating: mask_images/7438_anno.png  \n",
            "  inflating: mask_images/4119_anno.png  \n",
            "  inflating: mask_images/6089_anno.png  \n",
            "  inflating: mask_images/4431_anno.png  \n",
            "  inflating: mask_images/3256_anno.png  \n",
            "  inflating: mask_images/3390_anno.png  \n",
            "  inflating: mask_images/3131_anno.png  \n",
            "  inflating: mask_images/6212_anno.png  \n",
            "  inflating: mask_images/2700_anno.png  \n",
            "  inflating: mask_images/6208_anno.png  \n",
            "  inflating: mask_images/6511_anno.png  \n",
            "  inflating: mask_images/2621_anno.png  \n",
            "  inflating: mask_images/6326_anno.png  \n",
            "  inflating: mask_images/2601_anno.png  \n",
            "  inflating: mask_images/6897_anno.png  \n",
            "  inflating: mask_images/2996_anno.png  \n",
            "  inflating: mask_images/4191_anno.png  \n",
            "  inflating: mask_images/5381_anno.png  \n",
            "  inflating: mask_images/7420_anno.png  \n",
            "  inflating: mask_images/752_anno.png  \n",
            "  inflating: mask_images/3891_anno.png  \n",
            "  inflating: mask_images/2727_anno.png  \n",
            "  inflating: mask_images/2425_anno.png  \n",
            "  inflating: mask_images/3497_anno.png  \n",
            "  inflating: mask_images/2724_anno.png  \n",
            "  inflating: mask_images/5134_anno.png  \n",
            "  inflating: mask_images/2232_anno.png  \n",
            "  inflating: mask_images/3843_anno.png  \n",
            "  inflating: mask_images/6650_anno.png  \n",
            "  inflating: mask_images/6257_anno.png  \n",
            "  inflating: mask_images/4855_anno.png  \n",
            "  inflating: mask_images/3363_anno.png  \n",
            "  inflating: mask_images/5973_anno.png  \n",
            "  inflating: mask_images/6342_anno.png  \n",
            "  inflating: mask_images/4047_anno.png  \n",
            "  inflating: mask_images/4583_anno.png  \n",
            "  inflating: mask_images/7088_anno.png  \n",
            "  inflating: mask_images/2945_anno.png  \n",
            "  inflating: mask_images/4277_anno.png  \n",
            "  inflating: mask_images/4648_anno.png  \n",
            "  inflating: mask_images/2009_anno.png  \n",
            "  inflating: mask_images/5250_anno.png  \n",
            "  inflating: mask_images/7705_anno.png  \n",
            "  inflating: mask_images/918_anno.png  \n",
            "  inflating: mask_images/3705_anno.png  \n",
            "  inflating: mask_images/4815_anno.png  \n",
            "  inflating: mask_images/2878_anno.png  \n",
            "  inflating: mask_images/960_anno.png  \n",
            "  inflating: mask_images/4703_anno.png  \n",
            "  inflating: mask_images/7444_anno.png  \n",
            "  inflating: mask_images/4903_anno.png  \n",
            "  inflating: mask_images/2156_anno.png  \n",
            "  inflating: mask_images/5950_anno.png  \n",
            "  inflating: mask_images/6649_anno.png  \n",
            "  inflating: mask_images/3410_anno.png  \n",
            "  inflating: mask_images/4634_anno.png  \n",
            "  inflating: mask_images/1509_anno.png  \n",
            "  inflating: mask_images/4527_anno.png  \n",
            "  inflating: mask_images/5755_anno.png  \n",
            "  inflating: mask_images/5274_anno.png  \n",
            "  inflating: mask_images/526_anno.png  \n",
            "  inflating: mask_images/6175_anno.png  \n",
            "  inflating: mask_images/4488_anno.png  \n",
            "  inflating: mask_images/5192_anno.png  \n",
            "  inflating: mask_images/4812_anno.png  \n",
            "  inflating: mask_images/1306_anno.png  \n",
            "  inflating: mask_images/286_anno.png  \n",
            "  inflating: mask_images/5556_anno.png  \n",
            "  inflating: mask_images/3961_anno.png  \n",
            "  inflating: mask_images/4289_anno.png  \n",
            "  inflating: mask_images/868_anno.png  \n",
            "  inflating: mask_images/6807_anno.png  \n",
            "  inflating: mask_images/3109_anno.png  \n",
            "  inflating: mask_images/6643_anno.png  \n",
            "  inflating: mask_images/74_anno.png  \n",
            "  inflating: mask_images/7498_anno.png  \n",
            "  inflating: mask_images/3353_anno.png  \n",
            "  inflating: mask_images/5578_anno.png  \n",
            "  inflating: mask_images/4871_anno.png  \n",
            "  inflating: mask_images/2456_anno.png  \n",
            "  inflating: mask_images/3875_anno.png  \n",
            "  inflating: mask_images/4655_anno.png  \n",
            "  inflating: mask_images/4283_anno.png  \n",
            "  inflating: mask_images/7531_anno.png  \n",
            "  inflating: mask_images/5108_anno.png  \n",
            "  inflating: mask_images/3036_anno.png  \n",
            "  inflating: mask_images/341_anno.png  \n",
            "  inflating: mask_images/366_anno.png  \n",
            "  inflating: mask_images/7274_anno.png  \n",
            "  inflating: mask_images/3427_anno.png  \n",
            "  inflating: mask_images/3582_anno.png  \n",
            "  inflating: mask_images/4994_anno.png  \n",
            "  inflating: mask_images/6327_anno.png  \n",
            "  inflating: mask_images/842_anno.png  \n",
            "  inflating: mask_images/7024_anno.png  \n",
            "  inflating: mask_images/5491_anno.png  \n",
            "  inflating: mask_images/4200_anno.png  \n",
            "  inflating: mask_images/6822_anno.png  \n",
            "  inflating: mask_images/717_anno.png  \n",
            "  inflating: mask_images/3644_anno.png  \n",
            "  inflating: mask_images/5829_anno.png  \n",
            "  inflating: mask_images/7304_anno.png  \n",
            "  inflating: mask_images/943_anno.png  \n",
            "  inflating: mask_images/7400_anno.png  \n",
            "  inflating: mask_images/1965_anno.png  \n",
            "  inflating: mask_images/6903_anno.png  \n",
            "  inflating: mask_images/3134_anno.png  \n",
            "  inflating: mask_images/3365_anno.png  \n",
            "  inflating: mask_images/4549_anno.png  \n",
            "  inflating: mask_images/2932_anno.png  \n",
            "  inflating: mask_images/5513_anno.png  \n",
            "  inflating: mask_images/3893_anno.png  \n",
            "  inflating: mask_images/6279_anno.png  \n",
            "  inflating: mask_images/2244_anno.png  \n",
            "  inflating: mask_images/5480_anno.png  \n",
            "  inflating: mask_images/3779_anno.png  \n",
            "  inflating: mask_images/5743_anno.png  \n",
            "  inflating: mask_images/410_anno.png  \n",
            "  inflating: mask_images/4891_anno.png  \n",
            "  inflating: mask_images/4296_anno.png  \n",
            "  inflating: mask_images/4181_anno.png  \n",
            "  inflating: mask_images/7215_anno.png  \n",
            "  inflating: mask_images/4605_anno.png  \n",
            "  inflating: mask_images/7643_anno.png  \n",
            "  inflating: mask_images/836_anno.png  \n",
            "  inflating: mask_images/4755_anno.png  \n",
            "  inflating: mask_images/3457_anno.png  \n",
            "  inflating: mask_images/3715_anno.png  \n",
            "  inflating: mask_images/6492_anno.png  \n",
            "  inflating: mask_images/7232_anno.png  \n",
            "  inflating: mask_images/4067_anno.png  \n",
            "  inflating: mask_images/2275_anno.png  \n",
            "  inflating: mask_images/2892_anno.png  \n",
            "  inflating: mask_images/4827_anno.png  \n",
            "  inflating: mask_images/7576_anno.png  \n",
            "  inflating: mask_images/7223_anno.png  \n",
            "  inflating: mask_images/2717_anno.png  \n",
            "  inflating: mask_images/3851_anno.png  \n",
            "  inflating: mask_images/6760_anno.png  \n",
            "  inflating: mask_images/3723_anno.png  \n",
            "  inflating: mask_images/4144_anno.png  \n",
            "  inflating: mask_images/6310_anno.png  \n",
            "  inflating: mask_images/270_anno.png  \n",
            "  inflating: mask_images/3778_anno.png  \n",
            "  inflating: mask_images/6571_anno.png  \n",
            "  inflating: mask_images/6023_anno.png  \n",
            "  inflating: mask_images/6712_anno.png  \n",
            "  inflating: mask_images/832_anno.png  \n",
            "  inflating: mask_images/3023_anno.png  \n",
            "  inflating: mask_images/3368_anno.png  \n",
            " extracting: mask_images/5209_anno.png  \n",
            "  inflating: mask_images/6941_anno.png  \n",
            "  inflating: mask_images/2496_anno.png  \n",
            "  inflating: mask_images/2457_anno.png  \n",
            "  inflating: mask_images/6926_anno.png  \n",
            "  inflating: mask_images/4282_anno.png  \n",
            "  inflating: mask_images/2354_anno.png  \n",
            "  inflating: mask_images/7248_anno.png  \n",
            "  inflating: mask_images/4505_anno.png  \n",
            "  inflating: mask_images/470_anno.png  \n",
            "  inflating: mask_images/4_anno.png  \n",
            "  inflating: mask_images/4799_anno.png  \n",
            "  inflating: mask_images/5048_anno.png  \n",
            "  inflating: mask_images/6430_anno.png  \n",
            "  inflating: mask_images/7226_anno.png  \n",
            "  inflating: mask_images/5905_anno.png  \n",
            "  inflating: mask_images/3354_anno.png  \n",
            "  inflating: mask_images/6853_anno.png  \n",
            "  inflating: mask_images/923_anno.png  \n",
            "  inflating: mask_images/6812_anno.png  \n",
            "  inflating: mask_images/6311_anno.png  \n",
            "  inflating: mask_images/5952_anno.png  \n",
            "  inflating: mask_images/3960_anno.png  \n",
            "  inflating: mask_images/4797_anno.png  \n",
            "  inflating: mask_images/7387_anno.png  \n",
            "  inflating: mask_images/6405_anno.png  \n",
            "  inflating: mask_images/4153_anno.png  \n",
            "  inflating: mask_images/7116_anno.png  \n",
            "  inflating: mask_images/4529_anno.png  \n",
            "  inflating: mask_images/4316_anno.png  \n",
            "  inflating: mask_images/5301_anno.png  \n",
            "  inflating: mask_images/2028_anno.png  \n",
            "  inflating: mask_images/523_anno.png  \n",
            "  inflating: mask_images/4734_anno.png  \n",
            "  inflating: mask_images/6467_anno.png  \n",
            "  inflating: mask_images/5621_anno.png  \n",
            "  inflating: mask_images/6469_anno.png  \n",
            "  inflating: mask_images/7458_anno.png  \n",
            "  inflating: mask_images/7012_anno.png  \n",
            "  inflating: mask_images/6350_anno.png  \n",
            "  inflating: mask_images/5924_anno.png  \n",
            "  inflating: mask_images/3519_anno.png  \n",
            "  inflating: mask_images/7254_anno.png  \n",
            "  inflating: mask_images/2483_anno.png  \n",
            "  inflating: mask_images/7559_anno.png  \n",
            "  inflating: mask_images/5976_anno.png  \n",
            "  inflating: mask_images/5571_anno.png  \n",
            "  inflating: mask_images/3767_anno.png  \n",
            "  inflating: mask_images/2690_anno.png  \n",
            "  inflating: mask_images/3332_anno.png  \n",
            "  inflating: mask_images/4274_anno.png  \n",
            "  inflating: mask_images/4777_anno.png  \n",
            "  inflating: mask_images/995_anno.png  \n",
            "  inflating: mask_images/2867_anno.png  \n",
            "  inflating: mask_images/5920_anno.png  \n",
            "  inflating: mask_images/1931_anno.png  \n",
            "  inflating: mask_images/6038_anno.png  \n",
            "  inflating: mask_images/3627_anno.png  \n",
            "  inflating: mask_images/7507_anno.png  \n",
            "  inflating: mask_images/5324_anno.png  \n",
            "  inflating: mask_images/5306_anno.png  \n",
            "  inflating: mask_images/2264_anno.png  \n",
            "  inflating: mask_images/738_anno.png  \n",
            "  inflating: mask_images/4519_anno.png  \n",
            "  inflating: mask_images/6482_anno.png  \n",
            "  inflating: mask_images/7517_anno.png  \n",
            "  inflating: mask_images/7013_anno.png  \n",
            "  inflating: mask_images/4847_anno.png  \n",
            "  inflating: mask_images/6698_anno.png  \n",
            "  inflating: mask_images/634_anno.png  \n",
            "  inflating: mask_images/4174_anno.png  \n",
            "  inflating: mask_images/47_anno.png  \n",
            "  inflating: mask_images/583_anno.png  \n",
            "  inflating: mask_images/3077_anno.png  \n",
            "  inflating: mask_images/1917_anno.png  \n",
            "  inflating: mask_images/7389_anno.png  \n",
            "  inflating: mask_images/3447_anno.png  \n",
            "  inflating: mask_images/86_anno.png  \n",
            "  inflating: mask_images/4258_anno.png  \n",
            "  inflating: mask_images/3691_anno.png  \n",
            "  inflating: mask_images/2344_anno.png  \n",
            "  inflating: mask_images/215_anno.png  \n",
            "  inflating: mask_images/3335_anno.png  \n",
            "  inflating: mask_images/4706_anno.png  \n",
            "  inflating: mask_images/3966_anno.png  \n",
            "  inflating: mask_images/2744_anno.png  \n",
            "  inflating: mask_images/6439_anno.png  \n",
            "  inflating: mask_images/7486_anno.png  \n",
            "  inflating: mask_images/2058_anno.png  \n",
            "  inflating: mask_images/4243_anno.png  \n",
            "  inflating: mask_images/3372_anno.png  \n",
            " extracting: mask_images/5090_anno.png  \n",
            "  inflating: mask_images/7169_anno.png  \n",
            "  inflating: mask_images/187_anno.png  \n",
            "  inflating: mask_images/5572_anno.png  \n",
            "  inflating: mask_images/5302_anno.png  \n",
            "  inflating: mask_images/1890_anno.png  \n",
            "  inflating: mask_images/4054_anno.png  \n",
            "  inflating: mask_images/749_anno.png  \n",
            "  inflating: mask_images/2129_anno.png  \n",
            "  inflating: mask_images/2359_anno.png  \n",
            "  inflating: mask_images/277_anno.png  \n",
            "  inflating: mask_images/3566_anno.png  \n",
            "  inflating: mask_images/2355_anno.png  \n",
            "  inflating: mask_images/3171_anno.png  \n",
            "  inflating: mask_images/436_anno.png  \n",
            "  inflating: mask_images/4715_anno.png  \n",
            "  inflating: mask_images/2219_anno.png  \n",
            "  inflating: mask_images/5175_anno.png  \n",
            "  inflating: mask_images/5584_anno.png  \n",
            "  inflating: mask_images/6829_anno.png  \n",
            "  inflating: mask_images/6263_anno.png  \n",
            "  inflating: mask_images/3221_anno.png  \n",
            "  inflating: mask_images/6341_anno.png  \n",
            "  inflating: mask_images/887_anno.png  \n",
            "  inflating: mask_images/4029_anno.png  \n",
            "  inflating: mask_images/254_anno.png  \n",
            "  inflating: mask_images/3817_anno.png  \n",
            "  inflating: mask_images/4423_anno.png  \n",
            "  inflating: mask_images/3074_anno.png  \n",
            "  inflating: mask_images/5314_anno.png  \n",
            "  inflating: mask_images/5150_anno.png  \n",
            "  inflating: mask_images/5065_anno.png  \n",
            "  inflating: mask_images/5703_anno.png  \n",
            "  inflating: mask_images/7173_anno.png  \n",
            "  inflating: mask_images/4627_anno.png  \n",
            "  inflating: mask_images/4571_anno.png  \n",
            "  inflating: mask_images/211_anno.png  \n",
            "  inflating: mask_images/7592_anno.png  \n",
            "  inflating: mask_images/6722_anno.png  \n",
            "  inflating: mask_images/7288_anno.png  \n",
            "  inflating: mask_images/7703_anno.png  \n",
            "  inflating: mask_images/6374_anno.png  \n",
            "  inflating: mask_images/3936_anno.png  \n",
            "  inflating: mask_images/3505_anno.png  \n",
            "  inflating: mask_images/7225_anno.png  \n",
            "  inflating: mask_images/3771_anno.png  \n",
            "  inflating: mask_images/4758_anno.png  \n",
            "  inflating: mask_images/4180_anno.png  \n",
            "  inflating: mask_images/4581_anno.png  \n",
            "  inflating: mask_images/6202_anno.png  \n",
            "  inflating: mask_images/6017_anno.png  \n",
            "  inflating: mask_images/6109_anno.png  \n",
            "  inflating: mask_images/677_anno.png  \n",
            "  inflating: mask_images/926_anno.png  \n",
            "  inflating: mask_images/5211_anno.png  \n",
            "  inflating: mask_images/4227_anno.png  \n",
            "  inflating: mask_images/7658_anno.png  \n",
            "  inflating: mask_images/6395_anno.png  \n",
            "  inflating: mask_images/301_anno.png  \n",
            "  inflating: mask_images/755_anno.png  \n",
            "  inflating: mask_images/6101_anno.png  \n",
            "  inflating: mask_images/4162_anno.png  \n",
            "  inflating: mask_images/7140_anno.png  \n",
            "  inflating: mask_images/6484_anno.png  \n",
            "  inflating: mask_images/3752_anno.png  \n",
            "  inflating: mask_images/6207_anno.png  \n",
            "  inflating: mask_images/6665_anno.png  \n",
            "  inflating: mask_images/6856_anno.png  \n",
            "  inflating: mask_images/745_anno.png  \n",
            "  inflating: mask_images/984_anno.png  \n",
            "  inflating: mask_images/6820_anno.png  \n",
            "  inflating: mask_images/1913_anno.png  \n",
            " extracting: mask_images/2512_anno.png  \n",
            "  inflating: mask_images/820_anno.png  \n",
            "  inflating: mask_images/7230_anno.png  \n",
            "  inflating: mask_images/4390_anno.png  \n",
            "  inflating: mask_images/7066_anno.png  \n",
            "  inflating: mask_images/6304_anno.png  \n",
            "  inflating: mask_images/6219_anno.png  \n",
            "  inflating: mask_images/6528_anno.png  \n",
            "  inflating: mask_images/7367_anno.png  \n",
            "  inflating: mask_images/5947_anno.png  \n",
            "  inflating: mask_images/7427_anno.png  \n",
            "  inflating: mask_images/4435_anno.png  \n",
            "  inflating: mask_images/6434_anno.png  \n",
            "  inflating: mask_images/7125_anno.png  \n",
            "  inflating: mask_images/7354_anno.png  \n",
            "  inflating: mask_images/6477_anno.png  \n",
            "  inflating: mask_images/6567_anno.png  \n",
            "  inflating: mask_images/2044_anno.png  \n",
            "  inflating: mask_images/6714_anno.png  \n",
            "  inflating: mask_images/5603_anno.png  \n",
            "  inflating: mask_images/5677_anno.png  \n",
            "  inflating: mask_images/6906_anno.png  \n",
            "  inflating: mask_images/746_anno.png  \n",
            "  inflating: mask_images/4537_anno.png  \n",
            "  inflating: mask_images/5690_anno.png  \n",
            "  inflating: mask_images/5599_anno.png  \n",
            "  inflating: mask_images/5243_anno.png  \n",
            "  inflating: mask_images/375_anno.png  \n",
            "  inflating: mask_images/2705_anno.png  \n",
            "  inflating: mask_images/4981_anno.png  \n",
            "  inflating: mask_images/6171_anno.png  \n",
            "  inflating: mask_images/7318_anno.png  \n",
            "  inflating: mask_images/6179_anno.png  \n",
            "  inflating: mask_images/6991_anno.png  \n",
            "  inflating: mask_images/3529_anno.png  \n",
            "  inflating: mask_images/5445_anno.png  \n",
            "  inflating: mask_images/189_anno.png  \n",
            "  inflating: mask_images/5115_anno.png  \n",
            "  inflating: mask_images/6634_anno.png  \n",
            "  inflating: mask_images/6516_anno.png  \n",
            "  inflating: mask_images/7672_anno.png  \n",
            "  inflating: mask_images/3981_anno.png  \n",
            "  inflating: mask_images/2099_anno.png  \n",
            "  inflating: mask_images/2234_anno.png  \n",
            "  inflating: mask_images/4317_anno.png  \n",
            "  inflating: mask_images/7275_anno.png  \n",
            "  inflating: mask_images/6940_anno.png  \n",
            "  inflating: mask_images/3731_anno.png  \n",
            "  inflating: mask_images/2642_anno.png  \n",
            "  inflating: mask_images/2402_anno.png  \n",
            "  inflating: mask_images/361_anno.png  \n",
            "  inflating: mask_images/5925_anno.png  \n",
            "  inflating: mask_images/735_anno.png  \n",
            "  inflating: mask_images/897_anno.png  \n",
            "  inflating: mask_images/2070_anno.png  \n",
            "  inflating: mask_images/7470_anno.png  \n",
            "  inflating: mask_images/593_anno.png  \n",
            "  inflating: mask_images/3446_anno.png  \n",
            "  inflating: mask_images/5008_anno.png  \n",
            "  inflating: mask_images/7291_anno.png  \n",
            "  inflating: mask_images/6440_anno.png  \n",
            "  inflating: mask_images/7501_anno.png  \n",
            "  inflating: mask_images/6265_anno.png  \n",
            "  inflating: mask_images/3662_anno.png  \n",
            "  inflating: mask_images/209_anno.png  \n",
            "  inflating: mask_images/5046_anno.png  \n",
            "  inflating: mask_images/2880_anno.png  \n",
            "  inflating: mask_images/5361_anno.png  \n",
            "  inflating: mask_images/2743_anno.png  \n",
            "  inflating: mask_images/4066_anno.png  \n",
            "  inflating: mask_images/3151_anno.png  \n",
            "  inflating: mask_images/3516_anno.png  \n",
            "  inflating: mask_images/7264_anno.png  \n",
            "  inflating: mask_images/3747_anno.png  \n",
            "  inflating: mask_images/3700_anno.png  \n",
            "  inflating: mask_images/4693_anno.png  \n",
            "  inflating: mask_images/3772_anno.png  \n",
            "  inflating: mask_images/3263_anno.png  \n",
            "  inflating: mask_images/7259_anno.png  \n",
            "  inflating: mask_images/4290_anno.png  \n",
            "  inflating: mask_images/56_anno.png  \n",
            "  inflating: mask_images/3837_anno.png  \n",
            "  inflating: mask_images/2180_anno.png  \n",
            "  inflating: mask_images/3782_anno.png  \n",
            "  inflating: mask_images/6841_anno.png  \n",
            "  inflating: mask_images/6775_anno.png  \n",
            "  inflating: mask_images/7681_anno.png  \n",
            "  inflating: mask_images/6187_anno.png  \n",
            "  inflating: mask_images/7091_anno.png  \n",
            "  inflating: mask_images/5941_anno.png  \n",
            "  inflating: mask_images/1977_anno.png  \n",
            "  inflating: mask_images/197_anno.png  \n",
            "  inflating: mask_images/2440_anno.png  \n",
            "  inflating: mask_images/3798_anno.png  \n",
            "  inflating: mask_images/4828_anno.png  \n",
            "  inflating: mask_images/2373_anno.png  \n",
            "  inflating: mask_images/6537_anno.png  \n",
            "  inflating: mask_images/1924_anno.png  \n",
            "  inflating: mask_images/5788_anno.png  \n",
            "  inflating: mask_images/1900_anno.png  \n",
            "  inflating: mask_images/5202_anno.png  \n",
            "  inflating: mask_images/592_anno.png  \n",
            "  inflating: mask_images/7084_anno.png  \n",
            "  inflating: mask_images/5049_anno.png  \n",
            "  inflating: mask_images/1896_anno.png  \n",
            "  inflating: mask_images/3764_anno.png  \n",
            "  inflating: mask_images/7028_anno.png  \n",
            "  inflating: mask_images/7487_anno.png  \n",
            "  inflating: mask_images/5120_anno.png  \n",
            "  inflating: mask_images/4975_anno.png  \n",
            "  inflating: mask_images/4911_anno.png  \n",
            "  inflating: mask_images/6997_anno.png  \n",
            "  inflating: mask_images/53_anno.png  \n",
            "  inflating: mask_images/697_anno.png  \n",
            "  inflating: mask_images/3868_anno.png  \n",
            "  inflating: mask_images/6568_anno.png  \n",
            "  inflating: mask_images/705_anno.png  \n",
            "  inflating: mask_images/3120_anno.png  \n",
            "  inflating: mask_images/82_anno.png  \n",
            "  inflating: mask_images/3477_anno.png  \n",
            "  inflating: mask_images/3598_anno.png  \n",
            "  inflating: mask_images/5505_anno.png  \n",
            "  inflating: mask_images/4044_anno.png  \n",
            "  inflating: mask_images/5016_anno.png  \n",
            "  inflating: mask_images/4499_anno.png  \n",
            "  inflating: mask_images/1938_anno.png  \n",
            "  inflating: mask_images/6550_anno.png  \n",
            "  inflating: mask_images/6930_anno.png  \n",
            "  inflating: mask_images/3672_anno.png  \n",
            "  inflating: mask_images/4055_anno.png  \n",
            "  inflating: mask_images/264_anno.png  \n",
            "  inflating: mask_images/1947_anno.png  \n",
            "  inflating: mask_images/6113_anno.png  \n",
            "  inflating: mask_images/6939_anno.png  \n",
            "  inflating: mask_images/6351_anno.png  \n",
            "  inflating: mask_images/5989_anno.png  \n",
            "  inflating: mask_images/4724_anno.png  \n",
            "  inflating: mask_images/41_anno.png  \n",
            "  inflating: mask_images/7108_anno.png  \n",
            "  inflating: mask_images/4415_anno.png  \n",
            "  inflating: mask_images/542_anno.png  \n",
            "  inflating: mask_images/2213_anno.png  \n",
            "  inflating: mask_images/6602_anno.png  \n",
            "  inflating: mask_images/7707_anno.png  \n",
            "  inflating: mask_images/6781_anno.png  \n",
            "  inflating: mask_images/3012_anno.png  \n",
            "  inflating: mask_images/6539_anno.png  \n",
            "  inflating: mask_images/2245_anno.png  \n",
            "  inflating: mask_images/7243_anno.png  \n",
            "  inflating: mask_images/5808_anno.png  \n",
            "  inflating: mask_images/600_anno.png  \n",
            "  inflating: mask_images/2993_anno.png  \n",
            "  inflating: mask_images/3269_anno.png  \n",
            "  inflating: mask_images/3276_anno.png  \n",
            "  inflating: mask_images/552_anno.png  \n",
            "  inflating: mask_images/2793_anno.png  \n",
            "  inflating: mask_images/6565_anno.png  \n",
            "  inflating: mask_images/582_anno.png  \n",
            "  inflating: mask_images/4486_anno.png  \n",
            "  inflating: mask_images/5944_anno.png  \n",
            "  inflating: mask_images/4664_anno.png  \n",
            "  inflating: mask_images/4587_anno.png  \n",
            "  inflating: mask_images/4930_anno.png  \n",
            "  inflating: mask_images/731_anno.png  \n",
            "  inflating: mask_images/7070_anno.png  \n",
            "  inflating: mask_images/4159_anno.png  \n",
            "  inflating: mask_images/4560_anno.png  \n",
            "  inflating: mask_images/7178_anno.png  \n",
            "  inflating: mask_images/3832_anno.png  \n",
            "  inflating: mask_images/6301_anno.png  \n",
            "  inflating: mask_images/672_anno.png  \n",
            "  inflating: mask_images/4733_anno.png  \n",
            "  inflating: mask_images/3552_anno.png  \n",
            "  inflating: mask_images/3676_anno.png  \n",
            "  inflating: mask_images/7429_anno.png  \n",
            "  inflating: mask_images/6473_anno.png  \n",
            "  inflating: mask_images/5644_anno.png  \n",
            "  inflating: mask_images/3245_anno.png  \n",
            "  inflating: mask_images/4795_anno.png  \n",
            "  inflating: mask_images/2089_anno.png  \n",
            "  inflating: mask_images/2986_anno.png  \n",
            "  inflating: mask_images/7645_anno.png  \n",
            "  inflating: mask_images/5935_anno.png  \n",
            "  inflating: mask_images/3617_anno.png  \n",
            "  inflating: mask_images/6094_anno.png  \n",
            "  inflating: mask_images/83_anno.png  \n",
            "  inflating: mask_images/2987_anno.png  \n",
            "  inflating: mask_images/5760_anno.png  \n",
            "  inflating: mask_images/2990_anno.png  \n",
            "  inflating: mask_images/4775_anno.png  \n",
            "  inflating: mask_images/7335_anno.png  \n",
            "  inflating: mask_images/7296_anno.png  \n",
            "  inflating: mask_images/7692_anno.png  \n",
            "  inflating: mask_images/4032_anno.png  \n",
            "  inflating: mask_images/3750_anno.png  \n",
            "  inflating: mask_images/7694_anno.png  \n",
            "  inflating: mask_images/428_anno.png  \n",
            "  inflating: mask_images/7242_anno.png  \n",
            "  inflating: mask_images/6011_anno.png  \n",
            "  inflating: mask_images/6186_anno.png  \n",
            "  inflating: mask_images/4839_anno.png  \n",
            "  inflating: mask_images/4385_anno.png  \n",
            "  inflating: mask_images/77_anno.png  \n",
            "  inflating: mask_images/7055_anno.png  \n",
            "  inflating: mask_images/3794_anno.png  \n",
            "  inflating: mask_images/1902_anno.png  \n",
            "  inflating: mask_images/3956_anno.png  \n",
            "  inflating: mask_images/3570_anno.png  \n",
            "  inflating: mask_images/6796_anno.png  \n",
            "  inflating: mask_images/5524_anno.png  \n",
            "  inflating: mask_images/2918_anno.png  \n",
            "  inflating: mask_images/4396_anno.png  \n",
            "  inflating: mask_images/2956_anno.png  \n",
            "  inflating: mask_images/2509_anno.png  \n",
            "  inflating: mask_images/5427_anno.png  \n",
            "  inflating: mask_images/274_anno.png  \n",
            "  inflating: mask_images/5642_anno.png  \n",
            "  inflating: mask_images/5129_anno.png  \n",
            "  inflating: mask_images/3182_anno.png  \n",
            "  inflating: mask_images/4158_anno.png  \n",
            "  inflating: mask_images/2042_anno.png  \n",
            "  inflating: mask_images/698_anno.png  \n",
            "  inflating: mask_images/6954_anno.png  \n",
            "  inflating: mask_images/4312_anno.png  \n",
            "  inflating: mask_images/2347_anno.png  \n",
            "  inflating: mask_images/610_anno.png  \n",
            "  inflating: mask_images/6410_anno.png  \n",
            "  inflating: mask_images/851_anno.png  \n",
            "  inflating: mask_images/914_anno.png  \n",
            "  inflating: mask_images/2792_anno.png  \n",
            "  inflating: mask_images/195_anno.png  \n",
            "  inflating: mask_images/4709_anno.png  \n",
            "  inflating: mask_images/6421_anno.png  \n",
            "  inflating: mask_images/2686_anno.png  \n",
            "  inflating: mask_images/6133_anno.png  \n",
            "  inflating: mask_images/3024_anno.png  \n",
            "  inflating: mask_images/892_anno.png  \n",
            "  inflating: mask_images/3414_anno.png  \n",
            "  inflating: mask_images/5205_anno.png  \n",
            "  inflating: mask_images/2035_anno.png  \n",
            "  inflating: mask_images/2031_anno.png  \n",
            "  inflating: mask_images/3800_anno.png  \n",
            "  inflating: mask_images/6544_anno.png  \n",
            "  inflating: mask_images/3047_anno.png  \n",
            "  inflating: mask_images/5472_anno.png  \n",
            "  inflating: mask_images/2026_anno.png  \n",
            "  inflating: mask_images/4646_anno.png  \n",
            "  inflating: mask_images/3468_anno.png  \n",
            "  inflating: mask_images/7568_anno.png  \n",
            "  inflating: mask_images/7667_anno.png  \n",
            "  inflating: mask_images/6272_anno.png  \n",
            "  inflating: mask_images/2964_anno.png  \n",
            "  inflating: mask_images/5332_anno.png  \n",
            "  inflating: mask_images/5942_anno.png  \n",
            "  inflating: mask_images/4608_anno.png  \n",
            "  inflating: mask_images/408_anno.png  \n",
            "  inflating: mask_images/1391_anno.png  \n",
            "  inflating: mask_images/7632_anno.png  \n",
            "  inflating: mask_images/431_anno.png  \n",
            "  inflating: mask_images/6021_anno.png  \n",
            "  inflating: mask_images/3534_anno.png  \n",
            "  inflating: mask_images/4991_anno.png  \n",
            "  inflating: mask_images/4882_anno.png  \n",
            "  inflating: mask_images/7322_anno.png  \n",
            "  inflating: mask_images/4754_anno.png  \n",
            "  inflating: mask_images/4235_anno.png  \n",
            "  inflating: mask_images/689_anno.png  \n",
            "  inflating: mask_images/7503_anno.png  \n",
            "  inflating: mask_images/60_anno.png  \n",
            "  inflating: mask_images/3925_anno.png  \n",
            "  inflating: mask_images/3028_anno.png  \n",
            "  inflating: mask_images/1918_anno.png  \n",
            "  inflating: mask_images/1942_anno.png  \n",
            "  inflating: mask_images/5264_anno.png  \n",
            "  inflating: mask_images/4230_anno.png  \n",
            "  inflating: mask_images/3139_anno.png  \n",
            "  inflating: mask_images/4516_anno.png  \n",
            "  inflating: mask_images/5252_anno.png  \n",
            "  inflating: mask_images/4482_anno.png  \n",
            "  inflating: mask_images/6830_anno.png  \n",
            "  inflating: mask_images/4563_anno.png  \n",
            "  inflating: mask_images/55_anno.png  \n",
            "  inflating: mask_images/6721_anno.png  \n",
            "  inflating: mask_images/4511_anno.png  \n",
            "  inflating: mask_images/5661_anno.png  \n",
            "  inflating: mask_images/4194_anno.png  \n",
            "  inflating: mask_images/2412_anno.png  \n",
            "  inflating: mask_images/2415_anno.png  \n",
            "  inflating: mask_images/2177_anno.png  \n",
            "  inflating: mask_images/1957_anno.png  \n",
            "  inflating: mask_images/3144_anno.png  \n",
            "  inflating: mask_images/7663_anno.png  \n",
            "  inflating: mask_images/7195_anno.png  \n",
            "  inflating: mask_images/2529_anno.png  \n",
            "  inflating: mask_images/7080_anno.png  \n",
            "  inflating: mask_images/6282_anno.png  \n",
            "  inflating: mask_images/7123_anno.png  \n",
            "  inflating: mask_images/3740_anno.png  \n",
            "  inflating: mask_images/3903_anno.png  \n",
            "  inflating: mask_images/5954_anno.png  \n",
            "  inflating: mask_images/6420_anno.png  \n",
            "  inflating: mask_images/5916_anno.png  \n",
            "  inflating: mask_images/7408_anno.png  \n",
            "  inflating: mask_images/3671_anno.png  \n",
            "  inflating: mask_images/4844_anno.png  \n",
            "  inflating: mask_images/3163_anno.png  \n",
            "  inflating: mask_images/6015_anno.png  \n",
            "  inflating: mask_images/2701_anno.png  \n",
            "  inflating: mask_images/4796_anno.png  \n",
            "  inflating: mask_images/5544_anno.png  \n",
            "  inflating: mask_images/4477_anno.png  \n",
            "  inflating: mask_images/4798_anno.png  \n",
            "  inflating: mask_images/6074_anno.png  \n",
            "  inflating: mask_images/6645_anno.png  \n",
            "  inflating: mask_images/6898_anno.png  \n",
            "  inflating: mask_images/4357_anno.png  \n",
            "  inflating: mask_images/3246_anno.png  \n",
            "  inflating: mask_images/5300_anno.png  \n",
            "  inflating: mask_images/480_anno.png  \n",
            "  inflating: mask_images/3384_anno.png  \n",
            "  inflating: mask_images/3111_anno.png  \n",
            "  inflating: mask_images/5166_anno.png  \n",
            "  inflating: mask_images/2124_anno.png  \n",
            "  inflating: mask_images/7121_anno.png  \n",
            "  inflating: mask_images/632_anno.png  \n",
            "  inflating: mask_images/188_anno.png  \n",
            "  inflating: mask_images/5267_anno.png  \n",
            "  inflating: mask_images/6740_anno.png  \n",
            "  inflating: mask_images/896_anno.png  \n",
            "  inflating: mask_images/7339_anno.png  \n",
            "  inflating: mask_images/4218_anno.png  \n",
            "  inflating: mask_images/7345_anno.png  \n",
            "  inflating: mask_images/5860_anno.png  \n",
            "  inflating: mask_images/6419_anno.png  \n",
            "  inflating: mask_images/3093_anno.png  \n",
            "  inflating: mask_images/33_anno.png  \n",
            "  inflating: mask_images/3994_anno.png  \n",
            "  inflating: mask_images/776_anno.png  \n",
            "  inflating: mask_images/3492_anno.png  \n",
            "  inflating: mask_images/379_anno.png  \n",
            "  inflating: mask_images/7642_anno.png  \n",
            "  inflating: mask_images/5917_anno.png  \n",
            "  inflating: mask_images/6988_anno.png  \n",
            "  inflating: mask_images/5024_anno.png  \n",
            "  inflating: mask_images/2092_anno.png  \n",
            "  inflating: mask_images/6077_anno.png  \n",
            "  inflating: mask_images/6805_anno.png  \n",
            "  inflating: mask_images/3279_anno.png  \n",
            "  inflating: mask_images/4182_anno.png  \n",
            "  inflating: mask_images/6885_anno.png  \n",
            "  inflating: mask_images/7361_anno.png  \n",
            "  inflating: mask_images/6306_anno.png  \n",
            "  inflating: mask_images/599_anno.png  \n",
            "  inflating: mask_images/7571_anno.png  \n",
            "  inflating: mask_images/6767_anno.png  \n",
            "  inflating: mask_images/4521_anno.png  \n",
            "  inflating: mask_images/2953_anno.png  \n",
            " extracting: mask_images/5315_anno.png  \n",
            "  inflating: mask_images/2676_anno.png  \n",
            "  inflating: mask_images/7113_anno.png  \n",
            "  inflating: mask_images/5891_anno.png  \n",
            "  inflating: mask_images/4767_anno.png  \n",
            "  inflating: mask_images/5343_anno.png  \n",
            "  inflating: mask_images/2110_anno.png  \n",
            "  inflating: mask_images/4938_anno.png  \n",
            "  inflating: mask_images/5550_anno.png  \n",
            "  inflating: mask_images/7654_anno.png  \n",
            "  inflating: mask_images/3119_anno.png  \n",
            "  inflating: mask_images/2702_anno.png  \n",
            "  inflating: mask_images/6849_anno.png  \n",
            "  inflating: mask_images/4727_anno.png  \n",
            "  inflating: mask_images/6058_anno.png  \n",
            "  inflating: mask_images/6061_anno.png  \n",
            "  inflating: mask_images/6399_anno.png  \n",
            "  inflating: mask_images/7560_anno.png  \n",
            "  inflating: mask_images/7073_anno.png  \n",
            "  inflating: mask_images/6480_anno.png  \n",
            "  inflating: mask_images/7516_anno.png  \n",
            "  inflating: mask_images/846_anno.png  \n",
            "  inflating: mask_images/1455_anno.png  \n",
            "  inflating: mask_images/4262_anno.png  \n",
            "  inflating: mask_images/5531_anno.png  \n",
            "  inflating: mask_images/3648_anno.png  \n",
            "  inflating: mask_images/975_anno.png  \n",
            "  inflating: mask_images/964_anno.png  \n",
            "  inflating: mask_images/2474_anno.png  \n",
            "  inflating: mask_images/7246_anno.png  \n",
            "  inflating: mask_images/7117_anno.png  \n",
            "  inflating: mask_images/7626_anno.png  \n",
            "  inflating: mask_images/5887_anno.png  \n",
            "  inflating: mask_images/2238_anno.png  \n",
            "  inflating: mask_images/5458_anno.png  \n",
            "  inflating: mask_images/4596_anno.png  \n",
            "  inflating: mask_images/5560_anno.png  \n",
            "  inflating: mask_images/2482_anno.png  \n",
            "  inflating: mask_images/3568_anno.png  \n",
            "  inflating: mask_images/7399_anno.png  \n",
            "  inflating: mask_images/4620_anno.png  \n",
            "  inflating: mask_images/894_anno.png  \n",
            "  inflating: mask_images/977_anno.png  \n",
            "  inflating: mask_images/5249_anno.png  \n",
            "  inflating: mask_images/5892_anno.png  \n",
            "  inflating: mask_images/6119_anno.png  \n",
            "  inflating: mask_images/3675_anno.png  \n",
            "  inflating: mask_images/4049_anno.png  \n",
            "  inflating: mask_images/2013_anno.png  \n",
            "  inflating: mask_images/4244_anno.png  \n",
            "  inflating: mask_images/5247_anno.png  \n",
            "  inflating: mask_images/4967_anno.png  \n",
            "  inflating: mask_images/6297_anno.png  \n",
            "  inflating: mask_images/4548_anno.png  \n",
            "  inflating: mask_images/5884_anno.png  \n",
            "  inflating: mask_images/4389_anno.png  \n",
            "  inflating: mask_images/6677_anno.png  \n",
            "  inflating: mask_images/4474_anno.png  \n",
            "  inflating: mask_images/5433_anno.png  \n",
            "  inflating: mask_images/459_anno.png  \n",
            "  inflating: mask_images/7079_anno.png  \n",
            "  inflating: mask_images/7142_anno.png  \n",
            "  inflating: mask_images/457_anno.png  \n",
            "  inflating: mask_images/5761_anno.png  \n",
            "  inflating: mask_images/1981_anno.png  \n",
            "  inflating: mask_images/3943_anno.png  \n",
            "  inflating: mask_images/3132_anno.png  \n",
            "  inflating: mask_images/5781_anno.png  \n",
            "  inflating: mask_images/7353_anno.png  \n",
            "  inflating: mask_images/4585_anno.png  \n",
            "  inflating: mask_images/5984_anno.png  \n",
            "  inflating: mask_images/5153_anno.png  \n",
            "  inflating: mask_images/475_anno.png  \n",
            "  inflating: mask_images/5273_anno.png  \n",
            "  inflating: mask_images/4124_anno.png  \n",
            "  inflating: mask_images/4617_anno.png  \n",
            "  inflating: mask_images/2709_anno.png  \n",
            "  inflating: mask_images/5766_anno.png  \n",
            "  inflating: mask_images/44_anno.png  \n",
            "  inflating: mask_images/7627_anno.png  \n",
            "  inflating: mask_images/2771_anno.png  \n",
            "  inflating: mask_images/4647_anno.png  \n",
            "  inflating: mask_images/6120_anno.png  \n",
            "  inflating: mask_images/6305_anno.png  \n",
            "  inflating: mask_images/4806_anno.png  \n",
            "  inflating: mask_images/6933_anno.png  \n",
            "  inflating: mask_images/525_anno.png  \n",
            "  inflating: mask_images/4045_anno.png  \n",
            "  inflating: mask_images/409_anno.png  \n",
            "  inflating: mask_images/5128_anno.png  \n",
            "  inflating: mask_images/1467_anno.png  \n",
            "  inflating: mask_images/6518_anno.png  \n",
            "  inflating: mask_images/4065_anno.png  \n",
            "  inflating: mask_images/988_anno.png  \n",
            "  inflating: mask_images/5116_anno.png  \n",
            "  inflating: mask_images/7617_anno.png  \n",
            "  inflating: mask_images/6744_anno.png  \n",
            "  inflating: mask_images/6291_anno.png  \n",
            "  inflating: mask_images/3154_anno.png  \n",
            "  inflating: mask_images/7646_anno.png  \n",
            "  inflating: mask_images/5375_anno.png  \n",
            "  inflating: mask_images/3824_anno.png  \n",
            "  inflating: mask_images/3862_anno.png  \n",
            "  inflating: mask_images/6502_anno.png  \n",
            "  inflating: mask_images/4613_anno.png  \n",
            "  inflating: mask_images/840_anno.png  \n",
            "  inflating: mask_images/2699_anno.png  \n",
            "  inflating: mask_images/4666_anno.png  \n",
            "  inflating: mask_images/5915_anno.png  \n",
            "  inflating: mask_images/741_anno.png  \n",
            "  inflating: mask_images/4792_anno.png  \n",
            "  inflating: mask_images/3296_anno.png  \n",
            "  inflating: mask_images/3739_anno.png  \n",
            "  inflating: mask_images/7317_anno.png  \n",
            "  inflating: mask_images/2952_anno.png  \n",
            "  inflating: mask_images/2585_anno.png  \n",
            "  inflating: mask_images/4192_anno.png  \n",
            "  inflating: mask_images/7309_anno.png  \n",
            "  inflating: mask_images/2059_anno.png  \n",
            "  inflating: mask_images/4483_anno.png  \n",
            "  inflating: mask_images/4326_anno.png  \n",
            "  inflating: mask_images/7197_anno.png  \n",
            "  inflating: mask_images/6626_anno.png  \n",
            "  inflating: mask_images/849_anno.png  \n",
            "  inflating: mask_images/7293_anno.png  \n",
            "  inflating: mask_images/2515_anno.png  \n",
            "  inflating: mask_images/999_anno.png  \n",
            "  inflating: mask_images/227_anno.png  \n",
            "  inflating: mask_images/6069_anno.png  \n",
            "  inflating: mask_images/3118_anno.png  \n",
            "  inflating: mask_images/4554_anno.png  \n",
            "  inflating: mask_images/6642_anno.png  \n",
            "  inflating: mask_images/4979_anno.png  \n",
            "  inflating: mask_images/2323_anno.png  \n",
            "  inflating: mask_images/7009_anno.png  \n",
            "  inflating: mask_images/5848_anno.png  \n",
            "  inflating: mask_images/7391_anno.png  \n",
            "  inflating: mask_images/4698_anno.png  \n",
            "  inflating: mask_images/7224_anno.png  \n",
            "  inflating: mask_images/2191_anno.png  \n",
            "  inflating: mask_images/7036_anno.png  \n",
            "  inflating: mask_images/5684_anno.png  \n",
            "  inflating: mask_images/2939_anno.png  \n",
            "  inflating: mask_images/2535_anno.png  \n",
            "  inflating: mask_images/3202_anno.png  \n",
            "  inflating: mask_images/4368_anno.png  \n",
            "  inflating: mask_images/2869_anno.png  \n",
            "  inflating: mask_images/2775_anno.png  \n",
            "  inflating: mask_images/5160_anno.png  \n",
            "  inflating: mask_images/2802_anno.png  \n",
            "  inflating: mask_images/69_anno.png  \n",
            "  inflating: mask_images/5955_anno.png  \n",
            "  inflating: mask_images/5518_anno.png  \n",
            "  inflating: mask_images/7287_anno.png  \n",
            "  inflating: mask_images/3704_anno.png  \n",
            "  inflating: mask_images/6871_anno.png  \n",
            "  inflating: mask_images/5879_anno.png  \n",
            "  inflating: mask_images/6961_anno.png  \n",
            "  inflating: mask_images/3681_anno.png  \n",
            "  inflating: mask_images/7606_anno.png  \n",
            "  inflating: mask_images/2928_anno.png  \n",
            "  inflating: mask_images/4367_anno.png  \n",
            "  inflating: mask_images/3788_anno.png  \n",
            "  inflating: mask_images/3216_anno.png  \n",
            "  inflating: mask_images/546_anno.png  \n",
            "  inflating: mask_images/6790_anno.png  \n",
            "  inflating: mask_images/7595_anno.png  \n",
            "  inflating: mask_images/2086_anno.png  \n",
            "  inflating: mask_images/4674_anno.png  \n",
            "  inflating: mask_images/424_anno.png  \n",
            "  inflating: mask_images/7567_anno.png  \n",
            "  inflating: mask_images/6925_anno.png  \n",
            "  inflating: mask_images/7555_anno.png  \n",
            "  inflating: mask_images/5943_anno.png  \n",
            "  inflating: mask_images/4288_anno.png  \n",
            "  inflating: mask_images/2667_anno.png  \n",
            "  inflating: mask_images/5607_anno.png  \n",
            "  inflating: mask_images/5741_anno.png  \n",
            "  inflating: mask_images/5423_anno.png  \n",
            "  inflating: mask_images/3359_anno.png  \n",
            " extracting: mask_images/5533_anno.png  \n",
            "  inflating: mask_images/4418_anno.png  \n",
            "  inflating: mask_images/4720_anno.png  \n",
            "  inflating: mask_images/7492_anno.png  \n",
            "  inflating: mask_images/801_anno.png  \n",
            "  inflating: mask_images/6261_anno.png  \n",
            "  inflating: mask_images/7205_anno.png  \n",
            "  inflating: mask_images/6870_anno.png  \n",
            "  inflating: mask_images/6347_anno.png  \n",
            "  inflating: mask_images/6738_anno.png  \n",
            "  inflating: mask_images/2369_anno.png  \n",
            "  inflating: mask_images/2787_anno.png  \n",
            "  inflating: mask_images/2550_anno.png  \n",
            "  inflating: mask_images/3471_anno.png  \n",
            "  inflating: mask_images/2670_anno.png  \n",
            "  inflating: mask_images/6670_anno.png  \n",
            "  inflating: mask_images/4742_anno.png  \n",
            "  inflating: mask_images/3656_anno.png  \n",
            "  inflating: mask_images/6349_anno.png  \n",
            "  inflating: mask_images/3421_anno.png  \n",
            "  inflating: mask_images/3083_anno.png  \n",
            "  inflating: mask_images/911_anno.png  \n",
            "  inflating: mask_images/5079_anno.png  \n",
            "  inflating: mask_images/4945_anno.png  \n",
            "  inflating: mask_images/2875_anno.png  \n",
            "  inflating: mask_images/4406_anno.png  \n",
            "  inflating: mask_images/2554_anno.png  \n",
            "  inflating: mask_images/4402_anno.png  \n",
            "  inflating: mask_images/3288_anno.png  \n",
            "  inflating: mask_images/2954_anno.png  \n",
            "  inflating: mask_images/4918_anno.png  \n",
            "  inflating: mask_images/3168_anno.png  \n",
            "  inflating: mask_images/3632_anno.png  \n",
            "  inflating: mask_images/7241_anno.png  \n",
            "  inflating: mask_images/6149_anno.png  \n",
            "  inflating: mask_images/7480_anno.png  \n",
            "  inflating: mask_images/7139_anno.png  \n",
            "  inflating: mask_images/6624_anno.png  \n",
            "  inflating: mask_images/3906_anno.png  \n",
            "  inflating: mask_images/5292_anno.png  \n",
            "  inflating: mask_images/6348_anno.png  \n",
            "  inflating: mask_images/2048_anno.png  \n",
            "  inflating: mask_images/3907_anno.png  \n",
            "  inflating: mask_images/4438_anno.png  \n",
            "  inflating: mask_images/3949_anno.png  \n",
            "  inflating: mask_images/372_anno.png  \n",
            "  inflating: mask_images/6554_anno.png  \n",
            "  inflating: mask_images/6556_anno.png  \n",
            "  inflating: mask_images/2146_anno.png  \n",
            "  inflating: mask_images/2236_anno.png  \n",
            "  inflating: mask_images/2748_anno.png  \n",
            "  inflating: mask_images/3155_anno.png  \n",
            "  inflating: mask_images/2015_anno.png  \n",
            "  inflating: mask_images/5203_anno.png  \n",
            "  inflating: mask_images/6078_anno.png  \n",
            "  inflating: mask_images/7371_anno.png  \n",
            "  inflating: mask_images/1933_anno.png  \n",
            "  inflating: mask_images/3027_anno.png  \n",
            "  inflating: mask_images/4276_anno.png  \n",
            "  inflating: mask_images/2492_anno.png  \n",
            "  inflating: mask_images/333_anno.png  \n",
            "  inflating: mask_images/5439_anno.png  \n",
            "  inflating: mask_images/5451_anno.png  \n",
            "  inflating: mask_images/4816_anno.png  \n",
            "  inflating: mask_images/2014_anno.png  \n",
            "  inflating: mask_images/4362_anno.png  \n",
            "  inflating: mask_images/4344_anno.png  \n",
            "  inflating: mask_images/4886_anno.png  \n",
            "  inflating: mask_images/6566_anno.png  \n",
            "  inflating: mask_images/1999_anno.png  \n",
            "  inflating: mask_images/2763_anno.png  \n",
            "  inflating: mask_images/6043_anno.png  \n",
            "  inflating: mask_images/2774_anno.png  \n",
            "  inflating: mask_images/5101_anno.png  \n",
            "  inflating: mask_images/3087_anno.png  \n",
            "  inflating: mask_images/5259_anno.png  \n",
            "  inflating: mask_images/6745_anno.png  \n",
            "  inflating: mask_images/2784_anno.png  \n",
            "  inflating: mask_images/5608_anno.png  \n",
            "  inflating: mask_images/3816_anno.png  \n",
            "  inflating: mask_images/7250_anno.png  \n",
            "  inflating: mask_images/1929_anno.png  \n",
            "  inflating: mask_images/4704_anno.png  \n",
            "  inflating: mask_images/4228_anno.png  \n",
            "  inflating: mask_images/2327_anno.png  \n",
            "  inflating: mask_images/2907_anno.png  \n",
            "  inflating: mask_images/312_anno.png  \n",
            "  inflating: mask_images/6696_anno.png  \n",
            "  inflating: mask_images/5897_anno.png  \n",
            "  inflating: mask_images/7150_anno.png  \n",
            "  inflating: mask_images/548_anno.png  \n",
            "  inflating: mask_images/6589_anno.png  \n",
            "  inflating: mask_images/2019_anno.png  \n",
            "  inflating: mask_images/2057_anno.png  \n",
            "  inflating: mask_images/785_anno.png  \n",
            "  inflating: mask_images/2488_anno.png  \n",
            "  inflating: mask_images/2590_anno.png  \n",
            "  inflating: mask_images/243_anno.png  \n",
            "  inflating: mask_images/4880_anno.png  \n",
            "  inflating: mask_images/3310_anno.png  \n",
            "  inflating: mask_images/2343_anno.png  \n",
            "  inflating: mask_images/814_anno.png  \n",
            "  inflating: mask_images/5787_anno.png  \n",
            "  inflating: mask_images/6612_anno.png  \n",
            "  inflating: mask_images/3266_anno.png  \n",
            "  inflating: mask_images/2808_anno.png  \n",
            "  inflating: mask_images/5360_anno.png  \n",
            "  inflating: mask_images/5912_anno.png  \n",
            "  inflating: mask_images/652_anno.png  \n",
            "  inflating: mask_images/2335_anno.png  \n",
            "  inflating: mask_images/4070_anno.png  \n",
            "  inflating: mask_images/4959_anno.png  \n",
            "  inflating: mask_images/5789_anno.png  \n",
            "  inflating: mask_images/5715_anno.png  \n",
            "  inflating: mask_images/4017_anno.png  \n",
            "  inflating: mask_images/3745_anno.png  \n",
            "  inflating: mask_images/5091_anno.png  \n",
            "  inflating: mask_images/6163_anno.png  \n",
            "  inflating: mask_images/3601_anno.png  \n",
            "  inflating: mask_images/6970_anno.png  \n",
            "  inflating: mask_images/377_anno.png  \n",
            "  inflating: mask_images/3142_anno.png  \n",
            "  inflating: mask_images/535_anno.png  \n",
            "  inflating: mask_images/5056_anno.png  \n",
            "  inflating: mask_images/5083_anno.png  \n",
            "  inflating: mask_images/6248_anno.png  \n",
            "  inflating: mask_images/2246_anno.png  \n",
            "  inflating: mask_images/5435_anno.png  \n",
            "  inflating: mask_images/3591_anno.png  \n",
            "  inflating: mask_images/2150_anno.png  \n",
            "  inflating: mask_images/7302_anno.png  \n",
            "  inflating: mask_images/3169_anno.png  \n",
            "  inflating: mask_images/4781_anno.png  \n",
            "  inflating: mask_images/4121_anno.png  \n",
            "  inflating: mask_images/4219_anno.png  \n",
            "  inflating: mask_images/6451_anno.png  \n",
            "  inflating: mask_images/7325_anno.png  \n",
            "  inflating: mask_images/1875_anno.png  \n",
            "  inflating: mask_images/2199_anno.png  \n",
            "  inflating: mask_images/6465_anno.png  \n",
            "  inflating: mask_images/7682_anno.png  \n",
            "  inflating: mask_images/7598_anno.png  \n",
            "  inflating: mask_images/5189_anno.png  \n",
            "  inflating: mask_images/5862_anno.png  \n",
            "  inflating: mask_images/7448_anno.png  \n",
            "  inflating: mask_images/5358_anno.png  \n",
            "  inflating: mask_images/2992_anno.png  \n",
            "  inflating: mask_images/198_anno.png  \n",
            "  inflating: mask_images/6937_anno.png  \n",
            "  inflating: mask_images/5980_anno.png  \n",
            "  inflating: mask_images/4865_anno.png  \n",
            "  inflating: mask_images/3575_anno.png  \n",
            "  inflating: mask_images/5244_anno.png  \n",
            "  inflating: mask_images/7196_anno.png  \n",
            "  inflating: mask_images/906_anno.png  \n",
            "  inflating: mask_images/351_anno.png  \n",
            "  inflating: mask_images/6270_anno.png  \n",
            "  inflating: mask_images/3371_anno.png  \n",
            "  inflating: mask_images/5650_anno.png  \n",
            "  inflating: mask_images/6033_anno.png  \n",
            "  inflating: mask_images/7090_anno.png  \n",
            "  inflating: mask_images/4679_anno.png  \n",
            "  inflating: mask_images/771_anno.png  \n",
            "  inflating: mask_images/2074_anno.png  \n",
            "  inflating: mask_images/2745_anno.png  \n",
            "  inflating: mask_images/4248_anno.png  \n",
            "  inflating: mask_images/6222_anno.png  \n",
            "  inflating: mask_images/6520_anno.png  \n",
            "  inflating: mask_images/3464_anno.png  \n",
            "  inflating: mask_images/441_anno.png  \n",
            "  inflating: mask_images/4074_anno.png  \n",
            "  inflating: mask_images/3625_anno.png  \n",
            "  inflating: mask_images/463_anno.png  \n",
            "  inflating: mask_images/2963_anno.png  \n",
            "  inflating: mask_images/4736_anno.png  \n",
            "  inflating: mask_images/3448_anno.png  \n",
            "  inflating: mask_images/492_anno.png  \n",
            "  inflating: mask_images/7673_anno.png  \n",
            "  inflating: mask_images/7252_anno.png  \n",
            "  inflating: mask_images/5988_anno.png  \n",
            "  inflating: mask_images/3000_anno.png  \n",
            "  inflating: mask_images/596_anno.png  \n",
            "  inflating: mask_images/257_anno.png  \n",
            "  inflating: mask_images/2065_anno.png  \n",
            "  inflating: mask_images/5441_anno.png  \n",
            "  inflating: mask_images/2738_anno.png  \n",
            "  inflating: mask_images/5063_anno.png  \n",
            "  inflating: mask_images/6398_anno.png  \n",
            "  inflating: mask_images/2970_anno.png  \n",
            "  inflating: mask_images/212_anno.png  \n",
            "  inflating: mask_images/5849_anno.png  \n",
            "  inflating: mask_images/4829_anno.png  \n",
            "  inflating: mask_images/6459_anno.png  \n",
            "  inflating: mask_images/5865_anno.png  \n",
            "  inflating: mask_images/7156_anno.png  \n",
            "  inflating: mask_images/2703_anno.png  \n",
            "  inflating: mask_images/4310_anno.png  \n",
            "  inflating: mask_images/6325_anno.png  \n",
            "  inflating: mask_images/6817_anno.png  \n",
            "  inflating: mask_images/6237_anno.png  \n",
            "  inflating: mask_images/7033_anno.png  \n",
            "  inflating: mask_images/4004_anno.png  \n",
            "  inflating: mask_images/6189_anno.png  \n",
            "  inflating: mask_images/6084_anno.png  \n",
            "  inflating: mask_images/4533_anno.png  \n",
            "  inflating: mask_images/985_anno.png  \n",
            "  inflating: mask_images/5727_anno.png  \n",
            "  inflating: mask_images/7102_anno.png  \n",
            "  inflating: mask_images/2933_anno.png  \n",
            "  inflating: mask_images/7407_anno.png  \n",
            "  inflating: mask_images/2680_anno.png  \n",
            "  inflating: mask_images/4328_anno.png  \n",
            "  inflating: mask_images/433_anno.png  \n",
            "  inflating: mask_images/5530_anno.png  \n",
            "  inflating: mask_images/5577_anno.png  \n",
            "  inflating: mask_images/2184_anno.png  \n",
            "  inflating: mask_images/4517_anno.png  \n",
            "  inflating: mask_images/5804_anno.png  \n",
            "  inflating: mask_images/2119_anno.png  \n",
            "  inflating: mask_images/2268_anno.png  \n",
            "  inflating: mask_images/1887_anno.png  \n",
            "  inflating: mask_images/4772_anno.png  \n",
            "  inflating: mask_images/3944_anno.png  \n",
            "  inflating: mask_images/4569_anno.png  \n",
            "  inflating: mask_images/3044_anno.png  \n",
            "  inflating: mask_images/6921_anno.png  \n",
            "  inflating: mask_images/4602_anno.png  \n",
            "  inflating: mask_images/6726_anno.png  \n",
            "  inflating: mask_images/4690_anno.png  \n",
            "  inflating: mask_images/4399_anno.png  \n",
            "  inflating: mask_images/5779_anno.png  \n",
            "  inflating: mask_images/1951_anno.png  \n",
            "  inflating: mask_images/7294_anno.png  \n",
            "  inflating: mask_images/2912_anno.png  \n",
            "  inflating: mask_images/5502_anno.png  \n",
            "  inflating: mask_images/5946_anno.png  \n",
            "  inflating: mask_images/4863_anno.png  \n",
            "  inflating: mask_images/895_anno.png  \n",
            "  inflating: mask_images/5388_anno.png  \n",
            "  inflating: mask_images/657_anno.png  \n",
            "  inflating: mask_images/397_anno.png  \n",
            "  inflating: mask_images/2039_anno.png  \n",
            "  inflating: mask_images/1074_anno.png  \n",
            "  inflating: mask_images/5334_anno.png  \n",
            "  inflating: mask_images/3585_anno.png  \n",
            "  inflating: mask_images/5035_anno.png  \n",
            "  inflating: mask_images/4197_anno.png  \n",
            "  inflating: mask_images/2257_anno.png  \n",
            "  inflating: mask_images/4223_anno.png  \n",
            "  inflating: mask_images/6703_anno.png  \n",
            "  inflating: mask_images/2053_anno.png  \n",
            "  inflating: mask_images/3790_anno.png  \n",
            "  inflating: mask_images/7562_anno.png  \n",
            "  inflating: mask_images/2961_anno.png  \n",
            "  inflating: mask_images/2846_anno.png  \n",
            "  inflating: mask_images/6201_anno.png  \n",
            "  inflating: mask_images/554_anno.png  \n",
            "  inflating: mask_images/5853_anno.png  \n",
            "  inflating: mask_images/4154_anno.png  \n",
            "  inflating: mask_images/6273_anno.png  \n",
            "  inflating: mask_images/6049_anno.png  \n",
            "  inflating: mask_images/2791_anno.png  \n",
            "  inflating: mask_images/4424_anno.png  \n",
            "  inflating: mask_images/232_anno.png  \n",
            "  inflating: mask_images/6455_anno.png  \n",
            "  inflating: mask_images/2439_anno.png  \n",
            "  inflating: mask_images/6122_anno.png  \n",
            "  inflating: mask_images/4450_anno.png  \n",
            "  inflating: mask_images/4434_anno.png  \n",
            "  inflating: mask_images/2635_anno.png  \n",
            "  inflating: mask_images/4541_anno.png  \n",
            "  inflating: mask_images/5622_anno.png  \n",
            "  inflating: mask_images/2426_anno.png  \n",
            "  inflating: mask_images/5228_anno.png  \n",
            "  inflating: mask_images/6766_anno.png  \n",
            "  inflating: mask_images/6761_anno.png  \n",
            " extracting: mask_images/709_anno.png  \n",
            "  inflating: mask_images/6414_anno.png  \n",
            "  inflating: mask_images/6689_anno.png  \n",
            "  inflating: mask_images/882_anno.png  \n",
            "  inflating: mask_images/5594_anno.png  \n",
            "  inflating: mask_images/3547_anno.png  \n",
            "  inflating: mask_images/2269_anno.png  \n",
            "  inflating: mask_images/392_anno.png  \n",
            "  inflating: mask_images/499_anno.png  \n",
            "  inflating: mask_images/5377_anno.png  \n",
            "  inflating: mask_images/3533_anno.png  \n",
            "  inflating: mask_images/3127_anno.png  \n",
            "  inflating: mask_images/3375_anno.png  \n",
            "  inflating: mask_images/2683_anno.png  \n",
            "  inflating: mask_images/5331_anno.png  \n",
            "  inflating: mask_images/419_anno.png  \n",
            "  inflating: mask_images/2561_anno.png  \n",
            "  inflating: mask_images/7081_anno.png  \n",
            "  inflating: mask_images/7308_anno.png  \n",
            "  inflating: mask_images/1903_anno.png  \n",
            "  inflating: mask_images/6258_anno.png  \n",
            "  inflating: mask_images/218_anno.png  \n",
            "  inflating: mask_images/2538_anno.png  \n",
            "  inflating: mask_images/4509_anno.png  \n",
            "  inflating: mask_images/3977_anno.png  \n",
            "  inflating: mask_images/32_anno.png  \n",
            "  inflating: mask_images/7278_anno.png  \n",
            "  inflating: mask_images/5525_anno.png  \n",
            "  inflating: mask_images/5514_anno.png  \n",
            "  inflating: mask_images/4298_anno.png  \n",
            "  inflating: mask_images/4788_anno.png  \n",
            "  inflating: mask_images/5501_anno.png  \n",
            "  inflating: mask_images/613_anno.png  \n",
            "  inflating: mask_images/3857_anno.png  \n",
            "  inflating: mask_images/2102_anno.png  \n",
            "  inflating: mask_images/5195_anno.png  \n",
            "  inflating: mask_images/3699_anno.png  \n",
            "  inflating: mask_images/5993_anno.png  \n",
            "  inflating: mask_images/5418_anno.png  \n",
            "  inflating: mask_images/2713_anno.png  \n",
            "  inflating: mask_images/479_anno.png  \n",
            "  inflating: mask_images/1959_anno.png  \n",
            "  inflating: mask_images/6197_anno.png  \n",
            "  inflating: mask_images/2770_anno.png  \n",
            "  inflating: mask_images/376_anno.png  \n",
            "  inflating: mask_images/727_anno.png  \n",
            "  inflating: mask_images/6965_anno.png  \n",
            "  inflating: mask_images/7432_anno.png  \n",
            "  inflating: mask_images/4492_anno.png  \n",
            "  inflating: mask_images/2708_anno.png  \n",
            "  inflating: mask_images/7328_anno.png  \n",
            "  inflating: mask_images/4771_anno.png  \n",
            "  inflating: mask_images/259_anno.png  \n",
            "  inflating: mask_images/6155_anno.png  \n",
            "  inflating: mask_images/5141_anno.png  \n",
            "  inflating: mask_images/993_anno.png  \n",
            "  inflating: mask_images/6919_anno.png  \n",
            "  inflating: mask_images/2625_anno.png  \n",
            "  inflating: mask_images/7608_anno.png  \n",
            "  inflating: mask_images/5206_anno.png  \n",
            "  inflating: mask_images/6436_anno.png  \n",
            "  inflating: mask_images/3377_anno.png  \n",
            "  inflating: mask_images/7647_anno.png  \n",
            "  inflating: mask_images/5180_anno.png  \n",
            "  inflating: mask_images/4443_anno.png  \n",
            "  inflating: mask_images/4971_anno.png  \n",
            "  inflating: mask_images/5794_anno.png  \n",
            "  inflating: mask_images/4833_anno.png  \n",
            "  inflating: mask_images/7666_anno.png  \n",
            "  inflating: mask_images/7491_anno.png  \n",
            "  inflating: mask_images/7602_anno.png  \n",
            "  inflating: mask_images/3409_anno.png  \n",
            "  inflating: mask_images/5673_anno.png  \n",
            "  inflating: mask_images/7115_anno.png  \n",
            "  inflating: mask_images/6251_anno.png  \n",
            "  inflating: mask_images/22_anno.png  \n",
            "  inflating: mask_images/4919_anno.png  \n",
            "  inflating: mask_images/7290_anno.png  \n",
            "  inflating: mask_images/4072_anno.png  \n",
            "  inflating: mask_images/6052_anno.png  \n",
            "  inflating: mask_images/3940_anno.png  \n",
            "  inflating: mask_images/7147_anno.png  \n",
            "  inflating: mask_images/2162_anno.png  \n",
            "  inflating: mask_images/4300_anno.png  \n",
            "  inflating: mask_images/5754_anno.png  \n",
            "  inflating: mask_images/6317_anno.png  \n",
            "  inflating: mask_images/922_anno.png  \n",
            "  inflating: mask_images/7603_anno.png  \n",
            "  inflating: mask_images/4062_anno.png  \n",
            "  inflating: mask_images/2459_anno.png  \n",
            "  inflating: mask_images/2937_anno.png  \n",
            "  inflating: mask_images/3226_anno.png  \n",
            "  inflating: mask_images/913_anno.png  \n",
            "  inflating: mask_images/6083_anno.png  \n",
            "  inflating: mask_images/1930_anno.png  \n",
            "  inflating: mask_images/822_anno.png  \n",
            "  inflating: mask_images/4414_anno.png  \n",
            "  inflating: mask_images/2005_anno.png  \n",
            "  inflating: mask_images/2537_anno.png  \n",
            "  inflating: mask_images/2218_anno.png  \n",
            "  inflating: mask_images/7210_anno.png  \n",
            "  inflating: mask_images/6190_anno.png  \n",
            "  inflating: mask_images/2032_anno.png  \n",
            "  inflating: mask_images/5580_anno.png  \n",
            "  inflating: mask_images/6470_anno.png  \n",
            "  inflating: mask_images/5437_anno.png  \n",
            "  inflating: mask_images/308_anno.png  \n",
            "  inflating: mask_images/5258_anno.png  \n",
            "  inflating: mask_images/4446_anno.png  \n",
            "  inflating: mask_images/4240_anno.png  \n",
            "  inflating: mask_images/3734_anno.png  \n",
            "  inflating: mask_images/4916_anno.png  \n",
            "  inflating: mask_images/3416_anno.png  \n",
            "  inflating: mask_images/898_anno.png  \n",
            "  inflating: mask_images/791_anno.png  \n",
            "  inflating: mask_images/6553_anno.png  \n",
            "  inflating: mask_images/3485_anno.png  \n",
            "  inflating: mask_images/5709_anno.png  \n",
            "  inflating: mask_images/2531_anno.png  \n",
            "  inflating: mask_images/813_anno.png  \n",
            "  inflating: mask_images/1668_anno.png  \n",
            "  inflating: mask_images/6432_anno.png  \n",
            "  inflating: mask_images/3232_anno.png  \n",
            "  inflating: mask_images/6843_anno.png  \n",
            "  inflating: mask_images/1952_anno.png  \n",
            "  inflating: mask_images/2783_anno.png  \n",
            "  inflating: mask_images/471_anno.png  \n",
            "  inflating: mask_images/382_anno.png  \n",
            "  inflating: mask_images/6368_anno.png  \n",
            "  inflating: mask_images/2913_anno.png  \n",
            "  inflating: mask_images/7430_anno.png  \n",
            "  inflating: mask_images/5280_anno.png  \n",
            "  inflating: mask_images/3649_anno.png  \n",
            "  inflating: mask_images/1881_anno.png  \n",
            "  inflating: mask_images/867_anno.png  \n",
            "  inflating: mask_images/2438_anno.png  \n",
            "  inflating: mask_images/6242_anno.png  \n",
            "  inflating: mask_images/3810_anno.png  \n",
            "  inflating: mask_images/347_anno.png  \n",
            "  inflating: mask_images/7061_anno.png  \n",
            "  inflating: mask_images/5833_anno.png  \n",
            "  inflating: mask_images/1912_anno.png  \n",
            "  inflating: mask_images/6785_anno.png  \n",
            "  inflating: mask_images/5197_anno.png  \n",
            "  inflating: mask_images/2567_anno.png  \n",
            "  inflating: mask_images/2316_anno.png  \n",
            "  inflating: mask_images/5114_anno.png  \n",
            "  inflating: mask_images/3297_anno.png  \n",
            "  inflating: mask_images/3364_anno.png  \n",
            "  inflating: mask_images/7190_anno.png  \n",
            "  inflating: mask_images/6066_anno.png  \n",
            "  inflating: mask_images/7155_anno.png  \n",
            "  inflating: mask_images/541_anno.png  \n",
            "  inflating: mask_images/6026_anno.png  \n",
            "  inflating: mask_images/2469_anno.png  \n",
            "  inflating: mask_images/5449_anno.png  \n",
            "  inflating: mask_images/6394_anno.png  \n",
            "  inflating: mask_images/6464_anno.png  \n",
            "  inflating: mask_images/7260_anno.png  \n",
            "  inflating: mask_images/1936_anno.png  \n",
            "  inflating: mask_images/4962_anno.png  \n",
            "  inflating: mask_images/440_anno.png  \n",
            "  inflating: mask_images/2424_anno.png  \n",
            "  inflating: mask_images/648_anno.png  \n",
            "  inflating: mask_images/6047_anno.png  \n",
            "  inflating: mask_images/2850_anno.png  \n",
            "  inflating: mask_images/2877_anno.png  \n",
            "  inflating: mask_images/5222_anno.png  \n",
            "  inflating: mask_images/2033_anno.png  \n",
            "  inflating: mask_images/5084_anno.png  \n",
            "  inflating: mask_images/5102_anno.png  \n",
            "  inflating: mask_images/5263_anno.png  \n",
            "  inflating: mask_images/4726_anno.png  \n",
            "  inflating: mask_images/733_anno.png  \n",
            "  inflating: mask_images/5399_anno.png  \n",
            "  inflating: mask_images/6088_anno.png  \n",
            "  inflating: mask_images/3449_anno.png  \n",
            "  inflating: mask_images/451_anno.png  \n",
            "  inflating: mask_images/568_anno.png  \n",
            "  inflating: mask_images/6962_anno.png  \n",
            "  inflating: mask_images/7711_anno.png  \n",
            "  inflating: mask_images/4731_anno.png  \n",
            "  inflating: mask_images/2179_anno.png  \n",
            "  inflating: mask_images/1996_anno.png  \n",
            "  inflating: mask_images/4846_anno.png  \n",
            "  inflating: mask_images/527_anno.png  \n",
            "  inflating: mask_images/3852_anno.png  \n",
            "  inflating: mask_images/3484_anno.png  \n",
            "  inflating: mask_images/5685_anno.png  \n",
            "  inflating: mask_images/6364_anno.png  \n",
            "  inflating: mask_images/6131_anno.png  \n",
            "  inflating: mask_images/4069_anno.png  \n",
            "  inflating: mask_images/6097_anno.png  \n",
            "  inflating: mask_images/3217_anno.png  \n",
            "  inflating: mask_images/6045_anno.png  \n",
            "  inflating: mask_images/2818_anno.png  \n",
            "  inflating: mask_images/5611_anno.png  \n",
            "  inflating: mask_images/4966_anno.png  \n",
            "  inflating: mask_images/6710_anno.png  \n",
            "  inflating: mask_images/5125_anno.png  \n",
            "  inflating: mask_images/4642_anno.png  \n",
            "  inflating: mask_images/256_anno.png  \n",
            "  inflating: mask_images/7691_anno.png  \n",
            "  inflating: mask_images/6056_anno.png  \n",
            "  inflating: mask_images/1956_anno.png  \n",
            "  inflating: mask_images/2217_anno.png  \n",
            "  inflating: mask_images/7615_anno.png  \n",
            "  inflating: mask_images/991_anno.png  \n",
            "  inflating: mask_images/5671_anno.png  \n",
            "  inflating: mask_images/3721_anno.png  \n",
            "  inflating: mask_images/6417_anno.png  \n",
            "  inflating: mask_images/276_anno.png  \n",
            "  inflating: mask_images/4993_anno.png  \n",
            "  inflating: mask_images/557_anno.png  \n",
            "  inflating: mask_images/2304_anno.png  \n",
            "  inflating: mask_images/2552_anno.png  \n",
            "  inflating: mask_images/789_anno.png  \n",
            "  inflating: mask_images/6750_anno.png  \n",
            "  inflating: mask_images/4028_anno.png  \n",
            "  inflating: mask_images/7327_anno.png  \n",
            "  inflating: mask_images/54_anno.png  \n",
            "  inflating: mask_images/3318_anno.png  \n",
            "  inflating: mask_images/3255_anno.png  \n",
            "  inflating: mask_images/2083_anno.png  \n",
            "  inflating: mask_images/5050_anno.png  \n",
            "  inflating: mask_images/6987_anno.png  \n",
            "  inflating: mask_images/3339_anno.png  \n",
            "  inflating: mask_images/3775_anno.png  \n",
            "  inflating: mask_images/4604_anno.png  \n",
            "  inflating: mask_images/4636_anno.png  \n",
            "  inflating: mask_images/7446_anno.png  \n",
            "  inflating: mask_images/6463_anno.png  \n",
            "  inflating: mask_images/5288_anno.png  \n",
            "  inflating: mask_images/5193_anno.png  \n",
            "  inflating: mask_images/6124_anno.png  \n",
            "  inflating: mask_images/5749_anno.png  \n",
            "  inflating: mask_images/6978_anno.png  \n",
            "  inflating: mask_images/2812_anno.png  \n",
            "  inflating: mask_images/2749_anno.png  \n",
            "  inflating: mask_images/2503_anno.png  \n",
            "  inflating: mask_images/6468_anno.png  \n",
            "  inflating: mask_images/2732_anno.png  \n",
            "  inflating: mask_images/4573_anno.png  \n",
            "  inflating: mask_images/4304_anno.png  \n",
            "  inflating: mask_images/2733_anno.png  \n",
            "  inflating: mask_images/5029_anno.png  \n",
            "  inflating: mask_images/3607_anno.png  \n",
            "  inflating: mask_images/2115_anno.png  \n",
            "  inflating: mask_images/1282_anno.png  \n",
            " extracting: mask_images/7180_anno.png  \n",
            "  inflating: mask_images/5100_anno.png  \n",
            "  inflating: mask_images/603_anno.png  \n",
            "  inflating: mask_images/6908_anno.png  \n",
            "  inflating: mask_images/4459_anno.png  \n",
            "  inflating: mask_images/4570_anno.png  \n",
            "  inflating: mask_images/7426_anno.png  \n",
            "  inflating: mask_images/6876_anno.png  \n",
            "  inflating: mask_images/4897_anno.png  \n",
            "  inflating: mask_images/7323_anno.png  \n",
            "  inflating: mask_images/4140_anno.png  \n",
            "  inflating: mask_images/6471_anno.png  \n",
            "  inflating: mask_images/3102_anno.png  \n",
            "  inflating: mask_images/3809_anno.png  \n",
            "  inflating: mask_images/4202_anno.png  \n",
            "  inflating: mask_images/7272_anno.png  \n",
            "  inflating: mask_images/2016_anno.png  \n",
            "  inflating: mask_images/5563_anno.png  \n",
            "  inflating: mask_images/3839_anno.png  \n",
            "  inflating: mask_images/778_anno.png  \n",
            "  inflating: mask_images/7167_anno.png  \n",
            "  inflating: mask_images/3204_anno.png  \n",
            "  inflating: mask_images/6753_anno.png  \n",
            "  inflating: mask_images/6920_anno.png  \n",
            "  inflating: mask_images/4255_anno.png  \n",
            "  inflating: mask_images/6166_anno.png  \n",
            "  inflating: mask_images/7546_anno.png  \n",
            "  inflating: mask_images/865_anno.png  \n",
            "  inflating: mask_images/374_anno.png  \n",
            "  inflating: mask_images/5495_anno.png  \n",
            "  inflating: mask_images/622_anno.png  \n",
            "  inflating: mask_images/3858_anno.png  \n",
            "  inflating: mask_images/390_anno.png  \n",
            " extracting: mask_images/5095_anno.png  \n",
            "  inflating: mask_images/3583_anno.png  \n",
            "  inflating: mask_images/7032_anno.png  \n",
            "  inflating: mask_images/5310_anno.png  \n",
            "  inflating: mask_images/6590_anno.png  \n",
            "  inflating: mask_images/415_anno.png  \n",
            "  inflating: mask_images/4805_anno.png  \n",
            "  inflating: mask_images/3693_anno.png  \n",
            "  inflating: mask_images/5695_anno.png  \n",
            "  inflating: mask_images/4565_anno.png  \n",
            "  inflating: mask_images/4638_anno.png  \n",
            "  inflating: mask_images/5500_anno.png  \n",
            "  inflating: mask_images/4453_anno.png  \n",
            "  inflating: mask_images/7483_anno.png  \n",
            "  inflating: mask_images/201_anno.png  \n",
            "  inflating: mask_images/2192_anno.png  \n",
            "  inflating: mask_images/6607_anno.png  \n",
            "  inflating: mask_images/6182_anno.png  \n",
            "  inflating: mask_images/3267_anno.png  \n",
            "  inflating: mask_images/528_anno.png  \n",
            "  inflating: mask_images/4650_anno.png  \n",
            "  inflating: mask_images/6462_anno.png  \n",
            "  inflating: mask_images/7352_anno.png  \n",
            "  inflating: mask_images/5634_anno.png  \n",
            "  inflating: mask_images/5672_anno.png  \n",
            "  inflating: mask_images/6904_anno.png  \n",
            "  inflating: mask_images/2422_anno.png  \n",
            "  inflating: mask_images/5470_anno.png  \n",
            "  inflating: mask_images/5373_anno.png  \n",
            "  inflating: mask_images/6694_anno.png  \n",
            "  inflating: mask_images/4836_anno.png  \n",
            "  inflating: mask_images/6478_anno.png  \n",
            "  inflating: mask_images/7572_anno.png  \n",
            "  inflating: mask_images/7548_anno.png  \n",
            "  inflating: mask_images/7089_anno.png  \n",
            "  inflating: mask_images/6971_anno.png  \n",
            "  inflating: mask_images/4336_anno.png  \n",
            "  inflating: mask_images/3038_anno.png  \n",
            "  inflating: mask_images/3219_anno.png  \n",
            "  inflating: mask_images/2752_anno.png  \n",
            "  inflating: mask_images/6329_anno.png  \n",
            "  inflating: mask_images/6648_anno.png  \n",
            "  inflating: mask_images/305_anno.png  \n",
            "  inflating: mask_images/6799_anno.png  \n",
            "  inflating: mask_images/5117_anno.png  \n",
            "  inflating: mask_images/2332_anno.png  \n",
            "  inflating: mask_images/6151_anno.png  \n",
            "  inflating: mask_images/4196_anno.png  \n",
            "  inflating: mask_images/5144_anno.png  \n",
            "  inflating: mask_images/4173_anno.png  \n",
            "  inflating: mask_images/4654_anno.png  \n",
            "  inflating: mask_images/6029_anno.png  \n",
            "  inflating: mask_images/3323_anno.png  \n",
            "  inflating: mask_images/3042_anno.png  \n",
            "  inflating: mask_images/5156_anno.png  \n",
            "  inflating: mask_images/5858_anno.png  \n",
            "  inflating: mask_images/4956_anno.png  \n",
            "  inflating: mask_images/3996_anno.png  \n",
            "  inflating: mask_images/969_anno.png  \n",
            "  inflating: mask_images/5268_anno.png  \n",
            "  inflating: mask_images/2421_anno.png  \n",
            "  inflating: mask_images/6345_anno.png  \n",
            "  inflating: mask_images/5907_anno.png  \n",
            "  inflating: mask_images/3126_anno.png  \n",
            "  inflating: mask_images/5042_anno.png  \n",
            "  inflating: mask_images/5293_anno.png  \n",
            "  inflating: mask_images/6004_anno.png  \n",
            "  inflating: mask_images/3640_anno.png  \n",
            "  inflating: mask_images/6768_anno.png  \n",
            "  inflating: mask_images/7171_anno.png  \n",
            "  inflating: mask_images/5883_anno.png  \n",
            "  inflating: mask_images/6874_anno.png  \n",
            "  inflating: mask_images/4433_anno.png  \n",
            "  inflating: mask_images/412_anno.png  \n",
            "  inflating: mask_images/3564_anno.png  \n",
            "  inflating: mask_images/2772_anno.png  \n",
            "  inflating: mask_images/3864_anno.png  \n",
            "  inflating: mask_images/6509_anno.png  \n",
            "  inflating: mask_images/4597_anno.png  \n",
            "  inflating: mask_images/3611_anno.png  \n",
            "  inflating: mask_images/7164_anno.png  \n",
            "  inflating: mask_images/2647_anno.png  \n",
            "  inflating: mask_images/6415_anno.png  \n",
            "  inflating: mask_images/2300_anno.png  \n",
            "  inflating: mask_images/7063_anno.png  \n",
            "  inflating: mask_images/3141_anno.png  \n",
            "  inflating: mask_images/5212_anno.png  \n",
            "  inflating: mask_images/7416_anno.png  \n",
            "  inflating: mask_images/472_anno.png  \n",
            "  inflating: mask_images/860_anno.png  \n",
            "  inflating: mask_images/6739_anno.png  \n",
            "  inflating: mask_images/4409_anno.png  \n",
            "  inflating: mask_images/7463_anno.png  \n",
            "  inflating: mask_images/3098_anno.png  \n",
            "  inflating: mask_images/676_anno.png  \n",
            "  inflating: mask_images/2446_anno.png  \n",
            "  inflating: mask_images/942_anno.png  \n",
            "  inflating: mask_images/5477_anno.png  \n",
            "  inflating: mask_images/346_anno.png  \n",
            "  inflating: mask_images/4954_anno.png  \n",
            "  inflating: mask_images/4229_anno.png  \n",
            "  inflating: mask_images/7050_anno.png  \n",
            "  inflating: mask_images/6293_anno.png  \n",
            "  inflating: mask_images/93_anno.png  \n",
            "  inflating: mask_images/680_anno.png  \n",
            "  inflating: mask_images/28_anno.png  \n",
            "  inflating: mask_images/4822_anno.png  \n",
            "  inflating: mask_images/5888_anno.png  \n",
            "  inflating: mask_images/5812_anno.png  \n",
            "  inflating: mask_images/4472_anno.png  \n",
            "  inflating: mask_images/3933_anno.png  \n",
            "  inflating: mask_images/5097_anno.png  \n",
            "  inflating: mask_images/1937_anno.png  \n",
            "  inflating: mask_images/6950_anno.png  \n",
            "  inflating: mask_images/4614_anno.png  \n",
            "  inflating: mask_images/3499_anno.png  \n",
            "  inflating: mask_images/3760_anno.png  \n",
            "  inflating: mask_images/6953_anno.png  \n",
            "  inflating: mask_images/4873_anno.png  \n",
            "  inflating: mask_images/6150_anno.png  \n",
            "  inflating: mask_images/2410_anno.png  \n",
            "  inflating: mask_images/7467_anno.png  \n",
            "  inflating: mask_images/2872_anno.png  \n",
            "  inflating: mask_images/5142_anno.png  \n",
            "  inflating: mask_images/4940_anno.png  \n",
            "  inflating: mask_images/3890_anno.png  \n",
            "  inflating: mask_images/4852_anno.png  \n",
            "  inflating: mask_images/298_anno.png  \n",
            "  inflating: mask_images/5135_anno.png  \n",
            "  inflating: mask_images/2695_anno.png  \n",
            "  inflating: mask_images/2938_anno.png  \n",
            "  inflating: mask_images/2725_anno.png  \n",
            "  inflating: mask_images/6401_anno.png  \n",
            "  inflating: mask_images/2281_anno.png  \n",
            "  inflating: mask_images/7159_anno.png  \n",
            "  inflating: mask_images/7679_anno.png  \n",
            "  inflating: mask_images/4909_anno.png  \n",
            "  inflating: mask_images/5824_anno.png  \n",
            "  inflating: mask_images/5071_anno.png  \n",
            "  inflating: mask_images/831_anno.png  \n",
            "  inflating: mask_images/6241_anno.png  \n",
            "  inflating: mask_images/4735_anno.png  \n",
            "  inflating: mask_images/3942_anno.png  \n",
            "  inflating: mask_images/4808_anno.png  \n",
            "  inflating: mask_images/6570_anno.png  \n",
            "  inflating: mask_images/828_anno.png  \n",
            "  inflating: mask_images/3422_anno.png  \n",
            "  inflating: mask_images/6220_anno.png  \n",
            "  inflating: mask_images/6559_anno.png  \n",
            "  inflating: mask_images/3541_anno.png  \n",
            "  inflating: mask_images/3345_anno.png  \n",
            "  inflating: mask_images/2342_anno.png  \n",
            "  inflating: mask_images/2848_anno.png  \n",
            "  inflating: mask_images/4060_anno.png  \n",
            "  inflating: mask_images/7631_anno.png  \n",
            "  inflating: mask_images/1964_anno.png  \n",
            "  inflating: mask_images/3559_anno.png  \n",
            "  inflating: mask_images/2672_anno.png  \n",
            "  inflating: mask_images/427_anno.png  \n",
            "  inflating: mask_images/2504_anno.png  \n",
            "  inflating: mask_images/3698_anno.png  \n",
            "  inflating: mask_images/3899_anno.png  \n",
            "  inflating: mask_images/6983_anno.png  \n",
            "  inflating: mask_images/3999_anno.png  \n",
            "  inflating: mask_images/5043_anno.png  \n",
            "  inflating: mask_images/6427_anno.png  \n",
            "  inflating: mask_images/6206_anno.png  \n",
            "  inflating: mask_images/4700_anno.png  \n",
            "  inflating: mask_images/3755_anno.png  \n",
            "  inflating: mask_images/6878_anno.png  \n",
            "  inflating: mask_images/6699_anno.png  \n",
            "  inflating: mask_images/6116_anno.png  \n",
            "  inflating: mask_images/5282_anno.png  \n",
            "  inflating: mask_images/7473_anno.png  \n",
            "  inflating: mask_images/571_anno.png  \n",
            "  inflating: mask_images/6031_anno.png  \n",
            "  inflating: mask_images/5305_anno.png  \n",
            "  inflating: mask_images/4551_anno.png  \n",
            "  inflating: mask_images/6838_anno.png  \n",
            "  inflating: mask_images/793_anno.png  \n",
            "  inflating: mask_images/4186_anno.png  \n",
            "  inflating: mask_images/2163_anno.png  \n",
            "  inflating: mask_images/4955_anno.png  \n",
            "  inflating: mask_images/2471_anno.png  \n",
            "  inflating: mask_images/490_anno.png  \n",
            "  inflating: mask_images/7513_anno.png  \n",
            "  inflating: mask_images/7130_anno.png  \n",
            "  inflating: mask_images/5225_anno.png  \n",
            "  inflating: mask_images/6747_anno.png  \n",
            "  inflating: mask_images/3988_anno.png  \n",
            "  inflating: mask_images/4456_anno.png  \n",
            "  inflating: mask_images/7286_anno.png  \n",
            "  inflating: mask_images/4099_anno.png  \n",
            "  inflating: mask_images/3145_anno.png  \n",
            "  inflating: mask_images/810_anno.png  \n",
            "  inflating: mask_images/6295_anno.png  \n",
            "  inflating: mask_images/5235_anno.png  \n",
            "  inflating: mask_images/7202_anno.png  \n",
            "  inflating: mask_images/339_anno.png  \n",
            "  inflating: mask_images/2197_anno.png  \n",
            "  inflating: mask_images/7423_anno.png  \n",
            "  inflating: mask_images/934_anno.png  \n",
            "  inflating: mask_images/3302_anno.png  \n",
            "  inflating: mask_images/4525_anno.png  \n",
            "  inflating: mask_images/4834_anno.png  \n",
            "  inflating: mask_images/3831_anno.png  \n",
            "  inflating: mask_images/4354_anno.png  \n",
            "  inflating: mask_images/4491_anno.png  \n",
            "  inflating: mask_images/3678_anno.png  \n",
            "  inflating: mask_images/1911_anno.png  \n",
            "  inflating: mask_images/4582_anno.png  \n",
            "  inflating: mask_images/4267_anno.png  \n",
            "  inflating: mask_images/4536_anno.png  \n",
            "  inflating: mask_images/7678_anno.png  \n",
            "  inflating: mask_images/4901_anno.png  \n",
            "  inflating: mask_images/3218_anno.png  \n",
            "  inflating: mask_images/545_anno.png  \n",
            "  inflating: mask_images/4860_anno.png  \n",
            "  inflating: mask_images/6697_anno.png  \n",
            "  inflating: mask_images/1993_anno.png  \n",
            "  inflating: mask_images/2799_anno.png  \n",
            "  inflating: mask_images/328_anno.png  \n",
            "  inflating: mask_images/90_anno.png  \n",
            "  inflating: mask_images/3394_anno.png  \n",
            "  inflating: mask_images/2718_anno.png  \n",
            "  inflating: mask_images/845_anno.png  \n",
            "  inflating: mask_images/1986_anno.png  \n",
            "  inflating: mask_images/6050_anno.png  \n",
            "  inflating: mask_images/4355_anno.png  \n",
            "  inflating: mask_images/3599_anno.png  \n",
            "  inflating: mask_images/1891_anno.png  \n",
            "  inflating: mask_images/3234_anno.png  \n",
            "  inflating: mask_images/6383_anno.png  \n",
            "  inflating: mask_images/4893_anno.png  \n",
            "  inflating: mask_images/3567_anno.png  \n",
            "  inflating: mask_images/4960_anno.png  \n",
            "  inflating: mask_images/367_anno.png  \n",
            "  inflating: mask_images/6647_anno.png  \n",
            "  inflating: mask_images/907_anno.png  \n",
            "  inflating: mask_images/5665_anno.png  \n",
            "  inflating: mask_images/6715_anno.png  \n",
            "  inflating: mask_images/6275_anno.png  \n",
            "  inflating: mask_images/6669_anno.png  \n",
            "  inflating: mask_images/7577_anno.png  \n",
            "  inflating: mask_images/343_anno.png  \n",
            "  inflating: mask_images/7249_anno.png  \n",
            "  inflating: mask_images/2135_anno.png  \n",
            "  inflating: mask_images/6507_anno.png  \n",
            "  inflating: mask_images/553_anno.png  \n",
            "  inflating: mask_images/2837_anno.png  \n",
            "  inflating: mask_images/4752_anno.png  \n",
            "  inflating: mask_images/2133_anno.png  \n",
            "  inflating: mask_images/252_anno.png  \n",
            "  inflating: mask_images/4007_anno.png  \n",
            "  inflating: mask_images/3501_anno.png  \n",
            "  inflating: mask_images/6373_anno.png  \n",
            "  inflating: mask_images/7362_anno.png  \n",
            "  inflating: mask_images/7002_anno.png  \n",
            "  inflating: mask_images/4020_anno.png  \n",
            "  inflating: mask_images/7543_anno.png  \n",
            "  inflating: mask_images/6881_anno.png  \n",
            "  inflating: mask_images/6296_anno.png  \n",
            "  inflating: mask_images/5813_anno.png  \n",
            "  inflating: mask_images/6154_anno.png  \n",
            "  inflating: mask_images/4377_anno.png  \n",
            "  inflating: mask_images/6107_anno.png  \n",
            "  inflating: mask_images/3389_anno.png  \n",
            "  inflating: mask_images/6024_anno.png  \n",
            "  inflating: mask_images/4848_anno.png  \n",
            "  inflating: mask_images/3435_anno.png  \n",
            "  inflating: mask_images/6256_anno.png  \n",
            "  inflating: mask_images/2866_anno.png  \n",
            "  inflating: mask_images/7417_anno.png  \n",
            "  inflating: mask_images/4740_anno.png  \n",
            "  inflating: mask_images/6336_anno.png  \n",
            "  inflating: mask_images/207_anno.png  \n",
            "  inflating: mask_images/4475_anno.png  \n",
            "  inflating: mask_images/5702_anno.png  \n",
            "  inflating: mask_images/4264_anno.png  \n",
            "  inflating: mask_images/5809_anno.png  \n",
            "  inflating: mask_images/6923_anno.png  \n",
            "  inflating: mask_images/6443_anno.png  \n",
            "  inflating: mask_images/5790_anno.png  \n",
            "  inflating: mask_images/7347_anno.png  \n",
            "  inflating: mask_images/3440_anno.png  \n",
            "  inflating: mask_images/5739_anno.png  \n",
            "  inflating: mask_images/3924_anno.png  \n",
            "  inflating: mask_images/7404_anno.png  \n",
            "  inflating: mask_images/925_anno.png  \n",
            "  inflating: mask_images/4532_anno.png  \n",
            "  inflating: mask_images/4710_anno.png  \n",
            "  inflating: mask_images/6039_anno.png  \n",
            "  inflating: mask_images/7270_anno.png  \n",
            "  inflating: mask_images/5207_anno.png  \n",
            "  inflating: mask_images/2303_anno.png  \n",
            "  inflating: mask_images/279_anno.png  \n",
            "  inflating: mask_images/7244_anno.png  \n",
            "  inflating: mask_images/6606_anno.png  \n",
            "  inflating: mask_images/6749_anno.png  \n",
            "  inflating: mask_images/4105_anno.png  \n",
            "  inflating: mask_images/4163_anno.png  \n",
            "  inflating: mask_images/5015_anno.png  \n",
            "  inflating: mask_images/6158_anno.png  \n",
            "  inflating: mask_images/2898_anno.png  \n",
            "  inflating: mask_images/3022_anno.png  \n",
            "  inflating: mask_images/4722_anno.png  \n",
            "  inflating: mask_images/3712_anno.png  \n",
            "  inflating: mask_images/7586_anno.png  \n",
            "  inflating: mask_images/905_anno.png  \n",
            "  inflating: mask_images/1386_anno.png  \n",
            "  inflating: mask_images/5058_anno.png  \n",
            "  inflating: mask_images/4391_anno.png  \n",
            "  inflating: mask_images/7336_anno.png  \n",
            "  inflating: mask_images/2759_anno.png  \n",
            "  inflating: mask_images/3366_anno.png  \n",
            "  inflating: mask_images/3951_anno.png  \n",
            "  inflating: mask_images/3406_anno.png  \n",
            "  inflating: mask_images/5362_anno.png  \n",
            "  inflating: mask_images/6110_anno.png  \n",
            "  inflating: mask_images/7553_anno.png  \n",
            "  inflating: mask_images/3181_anno.png  \n",
            "  inflating: mask_images/4719_anno.png  \n",
            "  inflating: mask_images/3923_anno.png  \n",
            "  inflating: mask_images/4904_anno.png  \n",
            "  inflating: mask_images/7395_anno.png  \n",
            "  inflating: mask_images/7677_anno.png  \n",
            "  inflating: mask_images/282_anno.png  \n",
            "  inflating: mask_images/6262_anno.png  \n",
            "  inflating: mask_images/6597_anno.png  \n",
            "  inflating: mask_images/3228_anno.png  \n",
            "  inflating: mask_images/5251_anno.png  \n",
            "  inflating: mask_images/6858_anno.png  \n",
            "  inflating: mask_images/263_anno.png  \n",
            "  inflating: mask_images/6809_anno.png  \n",
            "  inflating: mask_images/3407_anno.png  \n",
            "  inflating: mask_images/3560_anno.png  \n",
            "  inflating: mask_images/3361_anno.png  \n",
            "  inflating: mask_images/5722_anno.png  \n",
            "  inflating: mask_images/3295_anno.png  \n",
            "  inflating: mask_images/3161_anno.png  \n",
            "  inflating: mask_images/2_anno.png  \n",
            "  inflating: mask_images/3094_anno.png  \n",
            "  inflating: mask_images/4943_anno.png  \n",
            "  inflating: mask_images/6087_anno.png  \n",
            "  inflating: mask_images/6100_anno.png  \n",
            "  inflating: mask_images/31_anno.png  \n",
            "  inflating: mask_images/6893_anno.png  \n",
            "  inflating: mask_images/6164_anno.png  \n",
            "  inflating: mask_images/3687_anno.png  \n",
            "  inflating: mask_images/2007_anno.png  \n",
            "  inflating: mask_images/1979_anno.png  \n",
            "  inflating: mask_images/6949_anno.png  \n",
            "  inflating: mask_images/2072_anno.png  \n",
            "  inflating: mask_images/5158_anno.png  \n",
            "  inflating: mask_images/6546_anno.png  \n",
            "  inflating: mask_images/5052_anno.png  \n",
            "  inflating: mask_images/383_anno.png  \n",
            "  inflating: mask_images/4671_anno.png  \n",
            "  inflating: mask_images/5656_anno.png  \n",
            "  inflating: mask_images/4185_anno.png  \n",
            "  inflating: mask_images/4811_anno.png  \n",
            "  inflating: mask_images/95_anno.png  \n",
            "  inflating: mask_images/4842_anno.png  \n",
            "  inflating: mask_images/293_anno.png  \n",
            "  inflating: mask_images/2054_anno.png  \n",
            "  inflating: mask_images/5557_anno.png  \n",
            "  inflating: mask_images/2947_anno.png  \n",
            "  inflating: mask_images/5823_anno.png  \n",
            "  inflating: mask_images/2734_anno.png  \n",
            "  inflating: mask_images/2021_anno.png  \n",
            "  inflating: mask_images/7700_anno.png  \n",
            "  inflating: mask_images/6358_anno.png  \n",
            "  inflating: mask_images/5847_anno.png  \n",
            "  inflating: mask_images/6054_anno.png  \n",
            "  inflating: mask_images/6705_anno.png  \n",
            "  inflating: mask_images/5559_anno.png  \n",
            "  inflating: mask_images/3331_anno.png  \n",
            "  inflating: mask_images/2293_anno.png  \n",
            "  inflating: mask_images/5317_anno.png  \n",
            "  inflating: mask_images/2721_anno.png  \n",
            "  inflating: mask_images/5285_anno.png  \n",
            "  inflating: mask_images/2286_anno.png  \n",
            "  inflating: mask_images/6042_anno.png  \n",
            "  inflating: mask_images/6128_anno.png  \n",
            "  inflating: mask_images/4969_anno.png  \n",
            "  inflating: mask_images/5828_anno.png  \n",
            "  inflating: mask_images/5985_anno.png  \n",
            "  inflating: mask_images/6085_anno.png  \n",
            "  inflating: mask_images/544_anno.png  \n",
            "  inflating: mask_images/1874_anno.png  \n",
            "  inflating: mask_images/4466_anno.png  \n",
            "  inflating: mask_images/4224_anno.png  \n",
            "  inflating: mask_images/5797_anno.png  \n",
            "  inflating: mask_images/3848_anno.png  \n",
            "  inflating: mask_images/2796_anno.png  \n",
            "  inflating: mask_images/6769_anno.png  \n",
            "  inflating: mask_images/7564_anno.png  \n",
            "  inflating: mask_images/7346_anno.png  \n",
            "  inflating: mask_images/6801_anno.png  \n",
            "  inflating: mask_images/7639_anno.png  \n",
            "  inflating: mask_images/3286_anno.png  \n",
            "  inflating: mask_images/7656_anno.png  \n",
            "  inflating: mask_images/5793_anno.png  \n",
            "  inflating: mask_images/6331_anno.png  \n",
            "  inflating: mask_images/5819_anno.png  \n",
            "  inflating: mask_images/7600_anno.png  \n",
            "  inflating: mask_images/6174_anno.png  \n",
            "  inflating: mask_images/4898_anno.png  \n",
            "  inflating: mask_images/5624_anno.png  \n",
            "  inflating: mask_images/1968_anno.png  \n",
            "  inflating: mask_images/39_anno.png  \n",
            "  inflating: mask_images/3207_anno.png  \n",
            "  inflating: mask_images/6020_anno.png  \n",
            "  inflating: mask_images/5546_anno.png  \n",
            "  inflating: mask_images/5_anno.png  \n",
            "  inflating: mask_images/5040_anno.png  \n",
            "  inflating: mask_images/3174_anno.png  \n",
            "  inflating: mask_images/396_anno.png  \n",
            "  inflating: mask_images/461_anno.png  \n",
            "  inflating: mask_images/5003_anno.png  \n",
            "  inflating: mask_images/2995_anno.png  \n",
            "  inflating: mask_images/414_anno.png  \n",
            "  inflating: mask_images/5802_anno.png  \n",
            "  inflating: mask_images/3861_anno.png  \n",
            "  inflating: mask_images/2080_anno.png  \n",
            "  inflating: mask_images/4595_anno.png  \n",
            "  inflating: mask_images/2977_anno.png  \n",
            "  inflating: mask_images/6577_anno.png  \n",
            "  inflating: mask_images/5662_anno.png  \n",
            "  inflating: mask_images/1973_anno.png  \n",
            "  inflating: mask_images/5215_anno.png  \n",
            "  inflating: mask_images/6513_anno.png  \n",
            "  inflating: mask_images/4832_anno.png  \n",
            "  inflating: mask_images/7333_anno.png  \n",
            "  inflating: mask_images/7690_anno.png  \n",
            "  inflating: mask_images/760_anno.png  \n",
            "  inflating: mask_images/3602_anno.png  \n",
            "  inflating: mask_images/2157_anno.png  \n",
            "  inflating: mask_images/6795_anno.png  \n",
            "  inflating: mask_images/6266_anno.png  \n",
            "  inflating: mask_images/5169_anno.png  \n",
            "  inflating: mask_images/5431_anno.png  \n",
            "  inflating: mask_images/7455_anno.png  \n",
            "  inflating: mask_images/7597_anno.png  \n",
            "  inflating: mask_images/4088_anno.png  \n",
            "  inflating: mask_images/723_anno.png  \n",
            "  inflating: mask_images/4170_anno.png  \n",
            "  inflating: mask_images/3015_anno.png  \n",
            "  inflating: mask_images/7165_anno.png  \n",
            "  inflating: mask_images/387_anno.png  \n",
            "  inflating: mask_images/4301_anno.png  \n",
            "  inflating: mask_images/4769_anno.png  \n",
            "  inflating: mask_images/496_anno.png  \n",
            "  inflating: mask_images/4910_anno.png  \n",
            "  inflating: mask_images/500_anno.png  \n",
            "  inflating: mask_images/5041_anno.png  \n",
            "  inflating: mask_images/7301_anno.png  \n",
            "  inflating: mask_images/4324_anno.png  \n",
            "  inflating: mask_images/5318_anno.png  \n",
            "  inflating: mask_images/2455_anno.png  \n",
            "  inflating: mask_images/2664_anno.png  \n",
            "  inflating: mask_images/4625_anno.png  \n",
            "  inflating: mask_images/7119_anno.png  \n",
            "  inflating: mask_images/2202_anno.png  \n",
            "  inflating: mask_images/4753_anno.png  \n",
            "  inflating: mask_images/7388_anno.png  \n",
            "  inflating: mask_images/422_anno.png  \n",
            "  inflating: mask_images/6748_anno.png  \n",
            "  inflating: mask_images/5173_anno.png  \n",
            "  inflating: mask_images/2849_anno.png  \n",
            "  inflating: mask_images/3655_anno.png  \n",
            "  inflating: mask_images/4189_anno.png  \n",
            "  inflating: mask_images/3902_anno.png  \n",
            "  inflating: mask_images/5937_anno.png  \n",
            "  inflating: mask_images/879_anno.png  \n",
            "  inflating: mask_images/6938_anno.png  \n",
            "  inflating: mask_images/6942_anno.png  \n",
            "  inflating: mask_images/5566_anno.png  \n",
            "  inflating: mask_images/7484_anno.png  \n",
            "  inflating: mask_images/5636_anno.png  \n",
            "  inflating: mask_images/659_anno.png  \n",
            "  inflating: mask_images/5910_anno.png  \n",
            "  inflating: mask_images/5999_anno.png  \n",
            "  inflating: mask_images/6479_anno.png  \n",
            "  inflating: mask_images/6495_anno.png  \n",
            "  inflating: mask_images/5681_anno.png  \n",
            "  inflating: mask_images/679_anno.png  \n",
            "  inflating: mask_images/3528_anno.png  \n",
            "  inflating: mask_images/316_anno.png  \n",
            "  inflating: mask_images/945_anno.png  \n",
            "  inflating: mask_images/7655_anno.png  \n",
            "  inflating: mask_images/4371_anno.png  \n",
            "  inflating: mask_images/6320_anno.png  \n",
            "  inflating: mask_images/4784_anno.png  \n",
            "  inflating: mask_images/4447_anno.png  \n",
            "  inflating: mask_images/4567_anno.png  \n",
            "  inflating: mask_images/2893_anno.png  \n",
            "  inflating: mask_images/7043_anno.png  \n",
            "  inflating: mask_images/7490_anno.png  \n",
            "  inflating: mask_images/2861_anno.png  \n",
            "  inflating: mask_images/3031_anno.png  \n",
            "  inflating: mask_images/3827_anno.png  \n",
            "  inflating: mask_images/4668_anno.png  \n",
            "  inflating: mask_images/3290_anno.png  \n",
            "  inflating: mask_images/7277_anno.png  \n",
            "  inflating: mask_images/4894_anno.png  \n",
            "  inflating: mask_images/199_anno.png  \n",
            "  inflating: mask_images/58_anno.png  \n",
            "  inflating: mask_images/3510_anno.png  \n",
            "  inflating: mask_images/509_anno.png  \n",
            "  inflating: mask_images/7234_anno.png  \n",
            "  inflating: mask_images/7200_anno.png  \n",
            "  inflating: mask_images/3633_anno.png  \n",
            "  inflating: mask_images/3013_anno.png  \n",
            "  inflating: mask_images/3725_anno.png  \n",
            "  inflating: mask_images/6355_anno.png  \n",
            "  inflating: mask_images/6633_anno.png  \n",
            "  inflating: mask_images/3660_anno.png  \n",
            "  inflating: mask_images/3451_anno.png  \n",
            "  inflating: mask_images/5286_anno.png  \n",
            "  inflating: mask_images/2170_anno.png  \n",
            "  inflating: mask_images/5945_anno.png  \n",
            " extracting: mask_images/4984_anno.png  \n",
            "  inflating: mask_images/2513_anno.png  \n",
            "  inflating: mask_images/3500_anno.png  \n",
            "  inflating: mask_images/6982_anno.png  \n",
            "  inflating: mask_images/2399_anno.png  \n",
            "  inflating: mask_images/2302_anno.png  \n",
            "  inflating: mask_images/2800_anno.png  \n",
            "  inflating: mask_images/3522_anno.png  \n",
            "  inflating: mask_images/5409_anno.png  \n",
            "  inflating: mask_images/4445_anno.png  \n",
            "  inflating: mask_images/7027_anno.png  \n",
            "  inflating: mask_images/3336_anno.png  \n",
            "  inflating: mask_images/6091_anno.png  \n",
            "  inflating: mask_images/5850_anno.png  \n",
            "  inflating: mask_images/5073_anno.png  \n",
            "  inflating: mask_images/3110_anno.png  \n",
            "  inflating: mask_images/3885_anno.png  \n",
            "  inflating: mask_images/6584_anno.png  \n",
            "  inflating: mask_images/6227_anno.png  \n",
            "  inflating: mask_images/2517_anno.png  \n",
            "  inflating: mask_images/4501_anno.png  \n",
            "  inflating: mask_images/1325_anno.png  \n",
            "  inflating: mask_images/4859_anno.png  \n",
            "  inflating: mask_images/4908_anno.png  \n",
            "  inflating: mask_images/2277_anno.png  \n",
            "  inflating: mask_images/4588_anno.png  \n",
            "  inflating: mask_images/6678_anno.png  \n",
            "  inflating: mask_images/4432_anno.png  \n",
            "  inflating: mask_images/2498_anno.png  \n",
            "  inflating: mask_images/2008_anno.png  \n",
            "  inflating: mask_images/6409_anno.png  \n",
            "  inflating: mask_images/7034_anno.png  \n",
            "  inflating: mask_images/4106_anno.png  \n",
            "  inflating: mask_images/3695_anno.png  \n",
            "  inflating: mask_images/812_anno.png  \n",
            "  inflating: mask_images/5494_anno.png  \n",
            "  inflating: mask_images/2265_anno.png  \n",
            "  inflating: mask_images/2890_anno.png  \n",
            "  inflating: mask_images/2134_anno.png  \n",
            "  inflating: mask_images/3075_anno.png  \n",
            "  inflating: mask_images/6772_anno.png  \n",
            "  inflating: mask_images/6989_anno.png  \n",
            "  inflating: mask_images/5869_anno.png  \n",
            "  inflating: mask_images/3643_anno.png  \n",
            "  inflating: mask_images/765_anno.png  \n",
            "  inflating: mask_images/3355_anno.png  \n",
            "  inflating: mask_images/3460_anno.png  \n",
            "  inflating: mask_images/7696_anno.png  \n",
            "  inflating: mask_images/2036_anno.png  \n",
            "  inflating: mask_images/7601_anno.png  \n",
            "  inflating: mask_images/761_anno.png  \n",
            "  inflating: mask_images/6818_anno.png  \n",
            "  inflating: mask_images/5877_anno.png  \n",
            "  inflating: mask_images/5511_anno.png  \n",
            "  inflating: mask_images/2502_anno.png  \n",
            "  inflating: mask_images/5440_anno.png  \n",
            "  inflating: mask_images/4232_anno.png  \n",
            "  inflating: mask_images/2755_anno.png  \n",
            "  inflating: mask_images/998_anno.png  \n",
            "  inflating: mask_images/6177_anno.png  \n",
            "  inflating: mask_images/6927_anno.png  \n",
            "  inflating: mask_images/6674_anno.png  \n",
            "  inflating: mask_images/3143_anno.png  \n",
            "  inflating: mask_images/4308_anno.png  \n",
            "  inflating: mask_images/2076_anno.png  \n",
            "  inflating: mask_images/4079_anno.png  \n",
            "  inflating: mask_images/2575_anno.png  \n",
            "  inflating: mask_images/3713_anno.png  \n",
            "  inflating: mask_images/5535_anno.png  \n",
            "  inflating: mask_images/6861_anno.png  \n",
            "  inflating: mask_images/5675_anno.png  \n",
            "  inflating: mask_images/6245_anno.png  \n",
            "  inflating: mask_images/3393_anno.png  \n",
            "  inflating: mask_images/362_anno.png  \n",
            "  inflating: mask_images/5736_anno.png  \n",
            "  inflating: mask_images/4114_anno.png  \n",
            "  inflating: mask_images/7338_anno.png  \n",
            "  inflating: mask_images/6514_anno.png  \n",
            "  inflating: mask_images/6506_anno.png  \n",
            "  inflating: mask_images/3920_anno.png  \n",
            "  inflating: mask_images/4077_anno.png  \n",
            "  inflating: mask_images/6896_anno.png  \n",
            "  inflating: mask_images/4925_anno.png  \n",
            "  inflating: mask_images/3670_anno.png  \n",
            "  inflating: mask_images/7519_anno.png  \n",
            "  inflating: mask_images/4156_anno.png  \n",
            "  inflating: mask_images/5270_anno.png  \n",
            "  inflating: mask_images/3348_anno.png  \n",
            "  inflating: mask_images/2923_anno.png  \n",
            "  inflating: mask_images/7312_anno.png  \n",
            "  inflating: mask_images/7635_anno.png  \n",
            "  inflating: mask_images/7569_anno.png  \n",
            "  inflating: mask_images/3418_anno.png  \n",
            "  inflating: mask_images/2132_anno.png  \n",
            "  inflating: mask_images/3308_anno.png  \n",
            "  inflating: mask_images/7144_anno.png  \n",
            "  inflating: mask_images/6825_anno.png  \n",
            "  inflating: mask_images/6687_anno.png  \n",
            "  inflating: mask_images/3860_anno.png  \n",
            "  inflating: mask_images/2779_anno.png  \n",
            "  inflating: mask_images/4268_anno.png  \n",
            "  inflating: mask_images/5868_anno.png  \n",
            "  inflating: mask_images/5143_anno.png  \n",
            "  inflating: mask_images/6636_anno.png  \n",
            "  inflating: mask_images/6357_anno.png  \n",
            "  inflating: mask_images/3411_anno.png  \n",
            "  inflating: mask_images/7589_anno.png  \n",
            "  inflating: mask_images/3231_anno.png  \n",
            "  inflating: mask_images/6028_anno.png  \n",
            "  inflating: mask_images/5308_anno.png  \n",
            "  inflating: mask_images/2274_anno.png  \n",
            "  inflating: mask_images/7220_anno.png  \n",
            "  inflating: mask_images/3465_anno.png  \n",
            "  inflating: mask_images/773_anno.png  \n",
            "  inflating: mask_images/3106_anno.png  \n",
            "  inflating: mask_images/3489_anno.png  \n",
            "  inflating: mask_images/6977_anno.png  \n",
            "  inflating: mask_images/990_anno.png  \n",
            "  inflating: mask_images/883_anno.png  \n",
            "  inflating: mask_images/3781_anno.png  \n",
            "  inflating: mask_images/6498_anno.png  \n",
            "  inflating: mask_images/3242_anno.png  \n",
            "  inflating: mask_images/4097_anno.png  \n",
            "  inflating: mask_images/2173_anno.png  \n",
            "  inflating: mask_images/627_anno.png  \n",
            "  inflating: mask_images/486_anno.png  \n",
            "  inflating: mask_images/6269_anno.png  \n",
            "  inflating: mask_images/7184_anno.png  \n",
            "  inflating: mask_images/2062_anno.png  \n",
            "  inflating: mask_images/2313_anno.png  \n",
            "  inflating: mask_images/3707_anno.png  \n",
            "  inflating: mask_images/6452_anno.png  \n",
            "  inflating: mask_images/2840_anno.png  \n",
            "  inflating: mask_images/481_anno.png  \n",
            "  inflating: mask_images/5645_anno.png  \n",
            "  inflating: mask_images/3618_anno.png  \n",
            "  inflating: mask_images/7685_anno.png  \n",
            "  inflating: mask_images/4972_anno.png  \n",
            "  inflating: mask_images/3396_anno.png  \n",
            "  inflating: mask_images/3874_anno.png  \n",
            "  inflating: mask_images/3658_anno.png  \n",
            "  inflating: mask_images/5733_anno.png  \n",
            "  inflating: mask_images/6968_anno.png  \n",
            "  inflating: mask_images/2468_anno.png  \n",
            "  inflating: mask_images/3978_anno.png  \n",
            "  inflating: mask_images/6096_anno.png  \n",
            "  inflating: mask_images/2820_anno.png  \n",
            "  inflating: mask_images/5815_anno.png  \n",
            "  inflating: mask_images/3453_anno.png  \n",
            "  inflating: mask_images/5309_anno.png  \n",
            "  inflating: mask_images/2085_anno.png  \n",
            "  inflating: mask_images/4092_anno.png  \n",
            "  inflating: mask_images/5406_anno.png  \n",
            "  inflating: mask_images/620_anno.png  \n",
            "  inflating: mask_images/6450_anno.png  \n",
            "  inflating: mask_images/4302_anno.png  \n",
            "  inflating: mask_images/767_anno.png  \n",
            "  inflating: mask_images/4338_anno.png  \n",
            "  inflating: mask_images/2936_anno.png  \n",
            "  inflating: mask_images/7332_anno.png  \n",
            "  inflating: mask_images/675_anno.png  \n",
            "  inflating: mask_images/216_anno.png  \n",
            "  inflating: mask_images/2165_anno.png  \n",
            "  inflating: mask_images/6391_anno.png  \n",
            "  inflating: mask_images/1892_anno.png  \n",
            "  inflating: mask_images/7370_anno.png  \n",
            "  inflating: mask_images/2106_anno.png  \n",
            "  inflating: mask_images/6827_anno.png  \n",
            "  inflating: mask_images/6727_anno.png  \n",
            "  inflating: mask_images/7229_anno.png  \n",
            "  inflating: mask_images/7649_anno.png  \n",
            "  inflating: mask_images/4513_anno.png  \n",
            "  inflating: mask_images/5626_anno.png  \n",
            "  inflating: mask_images/6491_anno.png  \n",
            "  inflating: mask_images/3606_anno.png  \n",
            "  inflating: mask_images/4043_anno.png  \n",
            "  inflating: mask_images/2204_anno.png  \n",
            "  inflating: mask_images/5776_anno.png  \n",
            "  inflating: mask_images/6660_anno.png  \n",
            "  inflating: mask_images/64_anno.png  \n",
            "  inflating: mask_images/3690_anno.png  \n",
            "  inflating: mask_images/5838_anno.png  \n",
            "  inflating: mask_images/4395_anno.png  \n",
            "  inflating: mask_images/5459_anno.png  \n",
            "  inflating: mask_images/7406_anno.png  \n",
            "  inflating: mask_images/7398_anno.png  \n",
            "  inflating: mask_images/6866_anno.png  \n",
            "  inflating: mask_images/3_anno.png  \n",
            "  inflating: mask_images/1960_anno.png  \n",
            "  inflating: mask_images/4129_anno.png  \n",
            "  inflating: mask_images/2525_anno.png  \n",
            "  inflating: mask_images/2239_anno.png  \n",
            "  inflating: mask_images/3056_anno.png  \n",
            "  inflating: mask_images/619_anno.png  \n",
            "  inflating: mask_images/711_anno.png  \n",
            "  inflating: mask_images/6204_anno.png  \n",
            "  inflating: mask_images/740_anno.png  \n",
            "  inflating: mask_images/6276_anno.png  \n",
            "  inflating: mask_images/5856_anno.png  \n",
            "  inflating: mask_images/2473_anno.png  \n",
            "  inflating: mask_images/6382_anno.png  \n",
            "  inflating: mask_images/1946_anno.png  \n",
            "  inflating: mask_images/3322_anno.png  \n",
            "  inflating: mask_images/722_anno.png  \n",
            "  inflating: mask_images/5246_anno.png  \n",
            "  inflating: mask_images/5529_anno.png  \n",
            "  inflating: mask_images/3918_anno.png  \n",
            "  inflating: mask_images/6700_anno.png  \n",
            "  inflating: mask_images/4867_anno.png  \n",
            "  inflating: mask_images/70_anno.png  \n",
            "  inflating: mask_images/5764_anno.png  \n",
            "  inflating: mask_images/3962_anno.png  \n",
            "  inflating: mask_images/7298_anno.png  \n",
            "  inflating: mask_images/6802_anno.png  \n",
            "  inflating: mask_images/7082_anno.png  \n",
            "  inflating: mask_images/7397_anno.png  \n",
            "  inflating: mask_images/6519_anno.png  \n",
            "  inflating: mask_images/7025_anno.png  \n",
            "  inflating: mask_images/687_anno.png  \n",
            "  inflating: mask_images/3530_anno.png  \n",
            "  inflating: mask_images/4747_anno.png  \n",
            "  inflating: mask_images/5078_anno.png  \n",
            "  inflating: mask_images/4774_anno.png  \n",
            "  inflating: mask_images/4369_anno.png  \n",
            "  inflating: mask_images/7561_anno.png  \n",
            "  inflating: mask_images/5902_anno.png  \n",
            "  inflating: mask_images/4053_anno.png  \n",
            "  inflating: mask_images/365_anno.png  \n",
            "  inflating: mask_images/3285_anno.png  \n",
            "  inflating: mask_images/2908_anno.png  \n",
            "  inflating: mask_images/6880_anno.png  \n",
            "  inflating: mask_images/335_anno.png  \n",
            "  inflating: mask_images/5639_anno.png  \n",
            "  inflating: mask_images/880_anno.png  \n",
            "  inflating: mask_images/7472_anno.png  \n",
            "  inflating: mask_images/946_anno.png  \n",
            "  inflating: mask_images/2935_anno.png  \n",
            "  inflating: mask_images/827_anno.png  \n",
            "  inflating: mask_images/5010_anno.png  \n",
            "  inflating: mask_images/7494_anno.png  \n",
            "  inflating: mask_images/7706_anno.png  \n",
            "  inflating: mask_images/5844_anno.png  \n",
            "  inflating: mask_images/5112_anno.png  \n",
            "  inflating: mask_images/5721_anno.png  \n",
            "  inflating: mask_images/7011_anno.png  \n",
            "  inflating: mask_images/3512_anno.png  \n",
            "  inflating: mask_images/3433_anno.png  \n",
            "  inflating: mask_images/3922_anno.png  \n",
            "  inflating: mask_images/5254_anno.png  \n",
            "  inflating: mask_images/7320_anno.png  \n",
            "  inflating: mask_images/3786_anno.png  \n",
            "  inflating: mask_images/5123_anno.png  \n",
            "  inflating: mask_images/2284_anno.png  \n",
            "  inflating: mask_images/6764_anno.png  \n",
            "  inflating: mask_images/6681_anno.png  \n",
            "  inflating: mask_images/260_anno.png  \n",
            "  inflating: mask_images/4857_anno.png  \n",
            "  inflating: mask_images/2868_anno.png  \n",
            "  inflating: mask_images/6343_anno.png  \n",
            "  inflating: mask_images/7688_anno.png  \n",
            "  inflating: mask_images/2720_anno.png  \n",
            "  inflating: mask_images/531_anno.png  \n",
            "  inflating: mask_images/2851_anno.png  \n",
            "  inflating: mask_images/4419_anno.png  \n",
            "  inflating: mask_images/5077_anno.png  \n",
            "  inflating: mask_images/4782_anno.png  \n",
            "  inflating: mask_images/7185_anno.png  \n",
            "  inflating: mask_images/3150_anno.png  \n",
            "  inflating: mask_images/5110_anno.png  \n",
            "  inflating: mask_images/6431_anno.png  \n",
            "  inflating: mask_images/3803_anno.png  \n",
            " extracting: mask_images/4164_anno.png  \n",
            "  inflating: mask_images/7479_anno.png  \n",
            "  inflating: mask_images/261_anno.png  \n",
            "  inflating: mask_images/4190_anno.png  \n",
            "  inflating: mask_images/2071_anno.png  \n",
            "  inflating: mask_images/973_anno.png  \n",
            "  inflating: mask_images/3553_anno.png  \n",
            "  inflating: mask_images/7037_anno.png  \n",
            "  inflating: mask_images/2710_anno.png  \n",
            "  inflating: mask_images/75_anno.png  \n",
            "  inflating: mask_images/6236_anno.png  \n",
            "  inflating: mask_images/3243_anno.png  \n",
            "  inflating: mask_images/1497_anno.png  \n",
            "  inflating: mask_images/5834_anno.png  \n",
            "  inflating: mask_images/360_anno.png  \n",
            "  inflating: mask_images/7285_anno.png  \n",
            "  inflating: mask_images/2255_anno.png  \n",
            "  inflating: mask_images/5549_anno.png  \n",
            "  inflating: mask_images/4683_anno.png  \n",
            "  inflating: mask_images/6558_anno.png  \n",
            "  inflating: mask_images/5737_anno.png  \n",
            "  inflating: mask_images/5428_anno.png  \n",
            "  inflating: mask_images/6959_anno.png  \n",
            "  inflating: mask_images/336_anno.png  \n",
            "  inflating: mask_images/6217_anno.png  \n",
            "  inflating: mask_images/5234_anno.png  \n",
            "  inflating: mask_images/6510_anno.png  \n",
            "  inflating: mask_images/5339_anno.png  \n",
            "  inflating: mask_images/6070_anno.png  \n",
            "  inflating: mask_images/7581_anno.png  \n",
            "  inflating: mask_images/5895_anno.png  \n",
            "  inflating: mask_images/320_anno.png  \n",
            "  inflating: mask_images/3930_anno.png  \n",
            "  inflating: mask_images/616_anno.png  \n",
            "  inflating: mask_images/3773_anno.png  \n",
            "  inflating: mask_images/6232_anno.png  \n",
            "  inflating: mask_images/2617_anno.png  \n",
            "  inflating: mask_images/5782_anno.png  \n",
            "  inflating: mask_images/2586_anno.png  \n",
            "  inflating: mask_images/4607_anno.png  \n",
            "  inflating: mask_images/900_anno.png  \n",
            "  inflating: mask_images/4318_anno.png  \n",
            "  inflating: mask_images/78_anno.png  \n",
            "  inflating: mask_images/5960_anno.png  \n",
            "  inflating: mask_images/6751_anno.png  \n",
            "  inflating: mask_images/532_anno.png  \n",
            "  inflating: mask_images/886_anno.png  \n",
            "  inflating: mask_images/570_anno.png  \n",
            "  inflating: mask_images/7098_anno.png  \n",
            "  inflating: mask_images/7583_anno.png  \n",
            "  inflating: mask_images/5294_anno.png  \n",
            "  inflating: mask_images/4905_anno.png  \n",
            "  inflating: mask_images/3486_anno.png  \n",
            "  inflating: mask_images/512_anno.png  \n",
            "  inflating: mask_images/7019_anno.png  \n",
            "  inflating: mask_images/5147_anno.png  \n",
            "  inflating: mask_images/2806_anno.png  \n",
            "  inflating: mask_images/6547_anno.png  \n",
            "  inflating: mask_images/2855_anno.png  \n",
            "  inflating: mask_images/423_anno.png  \n",
            "  inflating: mask_images/5613_anno.png  \n",
            "  inflating: mask_images/4201_anno.png  \n",
            "  inflating: mask_images/6675_anno.png  \n",
            "  inflating: mask_images/4996_anno.png  \n",
            "  inflating: mask_images/5712_anno.png  \n",
            "  inflating: mask_images/802_anno.png  \n",
            "  inflating: mask_images/3948_anno.png  \n",
            "  inflating: mask_images/7214_anno.png  \n",
            "  inflating: mask_images/6352_anno.png  \n",
            "  inflating: mask_images/5843_anno.png  \n",
            "  inflating: mask_images/3444_anno.png  \n",
            "  inflating: mask_images/3536_anno.png  \n",
            "  inflating: mask_images/6501_anno.png  \n",
            "  inflating: mask_images/6213_anno.png  \n",
            "  inflating: mask_images/5610_anno.png  \n",
            "  inflating: mask_images/1907_anno.png  \n",
            "  inflating: mask_images/4520_anno.png  \n",
            "  inflating: mask_images/2011_anno.png  \n",
            "  inflating: mask_images/5526_anno.png  \n",
            "  inflating: mask_images/5014_anno.png  \n",
            "  inflating: mask_images/5357_anno.png  \n",
            "  inflating: mask_images/510_anno.png  \n",
            "  inflating: mask_images/3439_anno.png  \n",
            "  inflating: mask_images/3935_anno.png  \n",
            "  inflating: mask_images/4101_anno.png  \n",
            "  inflating: mask_images/7674_anno.png  \n",
            "  inflating: mask_images/5023_anno.png  \n",
            "  inflating: mask_images/327_anno.png  \n",
            "  inflating: mask_images/4356_anno.png  \n",
            "  inflating: mask_images/3194_anno.png  \n",
            "  inflating: mask_images/3666_anno.png  \n",
            "  inflating: mask_images/7348_anno.png  \n",
            "  inflating: mask_images/2243_anno.png  \n",
            "  inflating: mask_images/5913_anno.png  \n",
            "  inflating: mask_images/4217_anno.png  \n",
            "  inflating: mask_images/6300_anno.png  \n",
            "  inflating: mask_images/7584_anno.png  \n",
            "  inflating: mask_images/7321_anno.png  \n",
            "  inflating: mask_images/2706_anno.png  \n",
            "  inflating: mask_images/4331_anno.png  \n",
            "  inflating: mask_images/6632_anno.png  \n",
            "  inflating: mask_images/625_anno.png  \n",
            "  inflating: mask_images/3921_anno.png  \n",
            "  inflating: mask_images/5320_anno.png  \n",
            "  inflating: mask_images/4696_anno.png  \n",
            "  inflating: mask_images/3763_anno.png  \n",
            "  inflating: mask_images/4819_anno.png  \n",
            "  inflating: mask_images/4064_anno.png  \n",
            "  inflating: mask_images/3474_anno.png  \n",
            "  inflating: mask_images/245_anno.png  \n",
            "  inflating: mask_images/2613_anno.png  \n",
            "  inflating: mask_images/5783_anno.png  \n",
            "  inflating: mask_images/6592_anno.png  \n",
            "  inflating: mask_images/2707_anno.png  \n",
            "  inflating: mask_images/7457_anno.png  \n",
            "  inflating: mask_images/7010_anno.png  \n",
            "  inflating: mask_images/7120_anno.png  \n",
            "  inflating: mask_images/7377_anno.png  \n",
            "  inflating: mask_images/5401_anno.png  \n",
            "  inflating: mask_images/4213_anno.png  \n",
            "  inflating: mask_images/6224_anno.png  \n",
            "  inflating: mask_images/630_anno.png  \n",
            "  inflating: mask_images/4915_anno.png  \n",
            "  inflating: mask_images/291_anno.png  \n",
            "  inflating: mask_images/5871_anno.png  \n",
            "  inflating: mask_images/2450_anno.png  \n",
            "  inflating: mask_images/655_anno.png  \n",
            "  inflating: mask_images/559_anno.png  \n",
            "  inflating: mask_images/239_anno.png  \n",
            "  inflating: mask_images/539_anno.png  \n",
            "  inflating: mask_images/321_anno.png  \n",
            "  inflating: mask_images/2000_anno.png  \n",
            "  inflating: mask_images/6899_anno.png  \n",
            "  inflating: mask_images/3386_anno.png  \n",
            "  inflating: mask_images/5651_anno.png  \n",
            "  inflating: mask_images/4713_anno.png  \n",
            "  inflating: mask_images/5807_anno.png  \n",
            "  inflating: mask_images/295_anno.png  \n",
            "  inflating: mask_images/1987_anno.png  \n",
            "  inflating: mask_images/4589_anno.png  \n",
            "  inflating: mask_images/2648_anno.png  \n",
            "  inflating: mask_images/6839_anno.png  \n",
            "  inflating: mask_images/4484_anno.png  \n",
            "  inflating: mask_images/5791_anno.png  \n",
            "  inflating: mask_images/4575_anno.png  \n",
            "  inflating: mask_images/5750_anno.png  \n",
            "  inflating: mask_images/4008_anno.png  \n",
            "  inflating: mask_images/7132_anno.png  \n",
            "  inflating: mask_images/3108_anno.png  \n",
            "  inflating: mask_images/1992_anno.png  \n",
            "  inflating: mask_images/1464_anno.png  \n",
            "  inflating: mask_images/3159_anno.png  \n",
            "  inflating: mask_images/4422_anno.png  \n",
            "  inflating: mask_images/2761_anno.png  \n",
            "  inflating: mask_images/2520_anno.png  \n",
            "  inflating: mask_images/7154_anno.png  \n",
            "  inflating: mask_images/3130_anno.png  \n",
            "  inflating: mask_images/3909_anno.png  \n",
            "  inflating: mask_images/533_anno.png  \n",
            "  inflating: mask_images/6517_anno.png  \n",
            "  inflating: mask_images/5581_anno.png  \n",
            "  inflating: mask_images/5131_anno.png  \n",
            "  inflating: mask_images/3578_anno.png  \n",
            "  inflating: mask_images/5069_anno.png  \n",
            "  inflating: mask_images/5374_anno.png  \n",
            "  inflating: mask_images/4016_anno.png  \n",
            "  inflating: mask_images/3735_anno.png  \n",
            "  inflating: mask_images/4804_anno.png  \n",
            "  inflating: mask_images/3008_anno.png  \n",
            "  inflating: mask_images/6425_anno.png  \n",
            "  inflating: mask_images/6719_anno.png  \n",
            "  inflating: mask_images/4187_anno.png  \n",
            "  inflating: mask_images/3524_anno.png  \n",
            "  inflating: mask_images/5978_anno.png  \n",
            "  inflating: mask_images/5089_anno.png  \n",
            "  inflating: mask_images/3158_anno.png  \n",
            "  inflating: mask_images/5629_anno.png  \n",
            "  inflating: mask_images/5686_anno.png  \n",
            "  inflating: mask_images/6875_anno.png  \n",
            "  inflating: mask_images/7256_anno.png  \n",
            "  inflating: mask_images/715_anno.png  \n",
            "  inflating: mask_images/4725_anno.png  \n",
            "  inflating: mask_images/5475_anno.png  \n",
            "  inflating: mask_images/7237_anno.png  \n",
            "  inflating: mask_images/3478_anno.png  \n",
            "  inflating: mask_images/4973_anno.png  \n",
            "  inflating: mask_images/6172_anno.png  \n",
            "  inflating: mask_images/5901_anno.png  \n",
            "  inflating: mask_images/6526_anno.png  \n",
            "  inflating: mask_images/7014_anno.png  \n",
            "  inflating: mask_images/7315_anno.png  \n",
            "  inflating: mask_images/7128_anno.png  \n",
            "  inflating: mask_images/3441_anno.png  \n",
            "  inflating: mask_images/6623_anno.png  \n",
            "  inflating: mask_images/5541_anno.png  \n",
            "  inflating: mask_images/5356_anno.png  \n",
            "  inflating: mask_images/5000_anno.png  \n",
            "  inflating: mask_images/6075_anno.png  \n",
            "  inflating: mask_images/3002_anno.png  \n",
            "  inflating: mask_images/5646_anno.png  \n",
            "  inflating: mask_images/3459_anno.png  \n",
            "  inflating: mask_images/5811_anno.png  \n",
            "  inflating: mask_images/3148_anno.png  \n",
            "  inflating: mask_images/3395_anno.png  \n",
            "  inflating: mask_images/3321_anno.png  \n",
            "  inflating: mask_images/5504_anno.png  \n",
            "  inflating: mask_images/4374_anno.png  \n",
            "  inflating: mask_images/6027_anno.png  \n",
            "  inflating: mask_images/4534_anno.png  \n",
            "  inflating: mask_images/933_anno.png  \n",
            "  inflating: mask_images/5478_anno.png  \n",
            "  inflating: mask_images/4659_anno.png  \n",
            "  inflating: mask_images/6615_anno.png  \n",
            "  inflating: mask_images/315_anno.png  \n",
            "  inflating: mask_images/7384_anno.png  \n",
            "  inflating: mask_images/435_anno.png  \n",
            "  inflating: mask_images/5628_anno.png  \n",
            "  inflating: mask_images/7424_anno.png  \n",
            "  inflating: mask_images/300_anno.png  \n",
            "  inflating: mask_images/3442_anno.png  \n",
            "  inflating: mask_images/2524_anno.png  \n",
            "  inflating: mask_images/4311_anno.png  \n",
            "  inflating: mask_images/5047_anno.png  \n",
            "  inflating: mask_images/6437_anno.png  \n",
            "  inflating: mask_images/2480_anno.png  \n",
            "  inflating: mask_images/5886_anno.png  \n",
            "  inflating: mask_images/4421_anno.png  \n",
            "  inflating: mask_images/4707_anno.png  \n",
            "  inflating: mask_images/5152_anno.png  \n",
            "  inflating: mask_images/3744_anno.png  \n",
            "  inflating: mask_images/7217_anno.png  \n",
            "  inflating: mask_images/598_anno.png  \n",
            "  inflating: mask_images/3076_anno.png  \n",
            "  inflating: mask_images/4417_anno.png  \n",
            "  inflating: mask_images/7648_anno.png  \n",
            "  inflating: mask_images/5635_anno.png  \n",
            "  inflating: mask_images/5870_anno.png  \n",
            "  inflating: mask_images/6847_anno.png  \n",
            "  inflating: mask_images/3233_anno.png  \n",
            "  inflating: mask_images/6635_anno.png  \n",
            "  inflating: mask_images/7401_anno.png  \n",
            "  inflating: mask_images/7403_anno.png  \n",
            "  inflating: mask_images/4576_anno.png  \n",
            "  inflating: mask_images/5770_anno.png  \n",
            "  inflating: mask_images/4503_anno.png  \n",
            "  inflating: mask_images/2687_anno.png  \n",
            "  inflating: mask_images/2484_anno.png  \n",
            "  inflating: mask_images/1768_anno.png  \n",
            "  inflating: mask_images/5889_anno.png  \n",
            "  inflating: mask_images/7065_anno.png  \n",
            "  inflating: mask_images/4723_anno.png  \n",
            "  inflating: mask_images/5223_anno.png  \n",
            "  inflating: mask_images/6549_anno.png  \n",
            "  inflating: mask_images/4127_anno.png  \n",
            "  inflating: mask_images/7149_anno.png  \n",
            "  inflating: mask_images/6485_anno.png  \n",
            "  inflating: mask_images/2248_anno.png  \n",
            "  inflating: mask_images/6956_anno.png  \n",
            "  inflating: mask_images/3487_anno.png  \n",
            "  inflating: mask_images/7687_anno.png  \n",
            "  inflating: mask_images/4824_anno.png  \n",
            "  inflating: mask_images/6001_anno.png  \n",
            "  inflating: mask_images/7393_anno.png  \n",
            "  inflating: mask_images/3282_anno.png  \n",
            "  inflating: mask_images/6105_anno.png  \n",
            "  inflating: mask_images/7203_anno.png  \n",
            "  inflating: mask_images/5204_anno.png  \n",
            "  inflating: mask_images/7111_anno.png  \n",
            "  inflating: mask_images/5598_anno.png  \n",
            "  inflating: mask_images/452_anno.png  \n",
            "  inflating: mask_images/6225_anno.png  \n",
            "  inflating: mask_images/66_anno.png  \n",
            "  inflating: mask_images/6081_anno.png  \n",
            "  inflating: mask_images/6353_anno.png  \n",
            "  inflating: mask_images/7269_anno.png  \n",
            "  inflating: mask_images/2027_anno.png  \n",
            "  inflating: mask_images/2045_anno.png  \n",
            "  inflating: mask_images/2495_anno.png  \n",
            "  inflating: mask_images/965_anno.png  \n",
            "  inflating: mask_images/5939_anno.png  \n",
            "  inflating: mask_images/2142_anno.png  \n",
            "  inflating: mask_images/4018_anno.png  \n",
            "  inflating: mask_images/2925_anno.png  \n",
            "  inflating: mask_images/7092_anno.png  \n",
            "  inflating: mask_images/7331_anno.png  \n",
            "  inflating: mask_images/524_anno.png  \n",
            "  inflating: mask_images/7689_anno.png  \n",
            "  inflating: mask_images/734_anno.png  \n",
            "  inflating: mask_images/251_anno.png  \n",
            "  inflating: mask_images/5615_anno.png  \n",
            "  inflating: mask_images/6557_anno.png  \n",
            "  inflating: mask_images/6545_anno.png  \n",
            "  inflating: mask_images/3759_anno.png  \n",
            "  inflating: mask_images/2915_anno.png  \n",
            "  inflating: mask_images/7329_anno.png  \n",
            "  inflating: mask_images/6323_anno.png  \n",
            "  inflating: mask_images/3717_anno.png  \n",
            "  inflating: mask_images/7097_anno.png  \n",
            "  inflating: mask_images/476_anno.png  \n",
            "  inflating: mask_images/418_anno.png  \n",
            "  inflating: mask_images/4892_anno.png  \n",
            "  inflating: mask_images/5863_anno.png  \n",
            "  inflating: mask_images/5177_anno.png  \n",
            "  inflating: mask_images/7100_anno.png  \n",
            "  inflating: mask_images/2653_anno.png  \n",
            "  inflating: mask_images/3856_anno.png  \n",
            "  inflating: mask_images/5276_anno.png  \n",
            "  inflating: mask_images/3483_anno.png  \n",
            "  inflating: mask_images/5130_anno.png  \n",
            "  inflating: mask_images/5817_anno.png  \n",
            " extracting: mask_images/5068_anno.png  \n",
            "  inflating: mask_images/6855_anno.png  \n",
            "  inflating: mask_images/4430_anno.png  \n",
            "  inflating: mask_images/4574_anno.png  \n",
            "  inflating: mask_images/3140_anno.png  \n",
            "  inflating: mask_images/5669_anno.png  \n",
            "  inflating: mask_images/720_anno.png  \n",
            "  inflating: mask_images/6132_anno.png  \n",
            "  inflating: mask_images/5397_anno.png  \n",
            "  inflating: mask_images/4084_anno.png  \n",
            "  inflating: mask_images/6249_anno.png  \n",
            "  inflating: mask_images/3294_anno.png  \n",
            "  inflating: mask_images/7193_anno.png  \n",
            "  inflating: mask_images/6913_anno.png  \n",
            "  inflating: mask_images/3897_anno.png  \n",
            "  inflating: mask_images/2988_anno.png  \n",
            "  inflating: mask_images/2043_anno.png  \n",
            "  inflating: mask_images/5155_anno.png  \n",
            "  inflating: mask_images/5638_anno.png  \n",
            "  inflating: mask_images/2789_anno.png  \n",
            "  inflating: mask_images/5692_anno.png  \n",
            "  inflating: mask_images/5453_anno.png  \n",
            "  inflating: mask_images/3157_anno.png  \n",
            "  inflating: mask_images/5187_anno.png  \n",
            "  inflating: mask_images/1873_anno.png  \n",
            "  inflating: mask_images/5405_anno.png  \n",
            "  inflating: mask_images/4319_anno.png  \n",
            "  inflating: mask_images/5609_anno.png  \n",
            "  inflating: mask_images/3668_anno.png  \n",
            "  inflating: mask_images/214_anno.png  \n",
            "  inflating: mask_images/7695_anno.png  \n",
            "  inflating: mask_images/2516_anno.png  \n",
            "  inflating: mask_images/7515_anno.png  \n",
            "  inflating: mask_images/3934_anno.png  \n",
            "  inflating: mask_images/4295_anno.png  \n",
            "  inflating: mask_images/5520_anno.png  \n",
            "  inflating: mask_images/841_anno.png  \n",
            "  inflating: mask_images/6594_anno.png  \n",
            "  inflating: mask_images/2122_anno.png  \n",
            "  inflating: mask_images/938_anno.png  \n",
            "  inflating: mask_images/3971_anno.png  \n",
            "  inflating: mask_images/1130_anno.png  \n",
            "  inflating: mask_images/6255_anno.png  \n",
            "  inflating: mask_images/3623_anno.png  \n",
            "  inflating: mask_images/2276_anno.png  \n",
            "  inflating: mask_images/3829_anno.png  \n",
            "  inflating: mask_images/5720_anno.png  \n",
            "  inflating: mask_images/565_anno.png  \n",
            "  inflating: mask_images/4068_anno.png  \n",
            "  inflating: mask_images/5354_anno.png  \n",
            "  inflating: mask_images/3080_anno.png  \n",
            "  inflating: mask_images/7340_anno.png  \n",
            "  inflating: mask_images/3370_anno.png  \n",
            "  inflating: mask_images/421_anno.png  \n",
            "  inflating: mask_images/4321_anno.png  \n",
            "  inflating: mask_images/6361_anno.png  \n",
            "  inflating: mask_images/4177_anno.png  \n",
            "  inflating: mask_images/6613_anno.png  \n",
            "  inflating: mask_images/2466_anno.png  \n",
            "  inflating: mask_images/7693_anno.png  \n",
            "  inflating: mask_images/5911_anno.png  \n",
            "  inflating: mask_images/7337_anno.png  \n",
            "  inflating: mask_images/7502_anno.png  \n",
            "  inflating: mask_images/3244_anno.png  \n",
            "  inflating: mask_images/2723_anno.png  \n",
            "  inflating: mask_images/5137_anno.png  \n",
            "  inflating: mask_images/3928_anno.png  \n",
            "  inflating: mask_images/6238_anno.png  \n",
            "  inflating: mask_images/7206_anno.png  \n",
            "  inflating: mask_images/6338_anno.png  \n",
            "  inflating: mask_images/3728_anno.png  \n",
            "  inflating: mask_images/7133_anno.png  \n",
            "  inflating: mask_images/6640_anno.png  \n",
            "  inflating: mask_images/299_anno.png  \n",
            "  inflating: mask_images/4929_anno.png  \n",
            "  inflating: mask_images/5006_anno.png  \n",
            "  inflating: mask_images/6239_anno.png  \n",
            "  inflating: mask_images/2998_anno.png  \n",
            "  inflating: mask_images/5104_anno.png  \n",
            "  inflating: mask_images/4325_anno.png  \n",
            "  inflating: mask_images/5139_anno.png  \n",
            "  inflating: mask_images/2857_anno.png  \n",
            "  inflating: mask_images/3990_anno.png  \n",
            "  inflating: mask_images/6586_anno.png  \n",
            "  inflating: mask_images/2919_anno.png  \n",
            "  inflating: mask_images/5020_anno.png  \n",
            "  inflating: mask_images/3293_anno.png  \n",
            "  inflating: mask_images/7390_anno.png  \n",
            "  inflating: mask_images/5026_anno.png  \n",
            "  inflating: mask_images/7563_anno.png  \n",
            "  inflating: mask_images/6041_anno.png  \n",
            "  inflating: mask_images/330_anno.png  \n",
            "  inflating: mask_images/7182_anno.png  \n",
            "  inflating: mask_images/3349_anno.png  \n",
            "  inflating: mask_images/3912_anno.png  \n",
            "  inflating: mask_images/6134_anno.png  \n",
            "  inflating: mask_images/585_anno.png  \n",
            "  inflating: mask_images/6411_anno.png  \n",
            "  inflating: mask_images/7239_anno.png  \n",
            "  inflating: mask_images/296_anno.png  \n",
            "  inflating: mask_images/322_anno.png  \n",
            "  inflating: mask_images/332_anno.png  \n",
            "  inflating: mask_images/329_anno.png  \n",
            "  inflating: mask_images/6945_anno.png  \n",
            "  inflating: mask_images/6655_anno.png  \n",
            "  inflating: mask_images/6499_anno.png  \n",
            "  inflating: mask_images/4987_anno.png  \n",
            "  inflating: mask_images/5740_anno.png  \n",
            "  inflating: mask_images/3639_anno.png  \n",
            "  inflating: mask_images/4427_anno.png  \n",
            "  inflating: mask_images/6813_anno.png  \n",
            "  inflating: mask_images/494_anno.png  \n",
            "  inflating: mask_images/1493_anno.png  \n",
            "  inflating: mask_images/4931_anno.png  \n",
            "  inflating: mask_images/3352_anno.png  \n",
            "  inflating: mask_images/5321_anno.png  \n",
            "  inflating: mask_images/609_anno.png  \n",
            "  inflating: mask_images/2270_anno.png  \n",
            "  inflating: mask_images/228_anno.png  \n",
            "  inflating: mask_images/3423_anno.png  \n",
            "  inflating: mask_images/7558_anno.png  \n",
            "  inflating: mask_images/6664_anno.png  \n",
            "  inflating: mask_images/2888_anno.png  \n",
            "  inflating: mask_images/3184_anno.png  \n",
            "  inflating: mask_images/394_anno.png  \n",
            "  inflating: mask_images/7551_anno.png  \n",
            "  inflating: mask_images/721_anno.png  \n",
            "  inflating: mask_images/3472_anno.png  \n",
            "  inflating: mask_images/4056_anno.png  \n",
            "  inflating: mask_images/1897_anno.png  \n",
            "  inflating: mask_images/7585_anno.png  \n",
            "  inflating: mask_images/5045_anno.png  \n",
            "  inflating: mask_images/6652_anno.png  \n",
            "  inflating: mask_images/6730_anno.png  \n",
            "  inflating: mask_images/45_anno.png  \n",
            "  inflating: mask_images/7394_anno.png  \n",
            "  inflating: mask_images/3493_anno.png  \n",
            "  inflating: mask_images/4656_anno.png  \n",
            "  inflating: mask_images/473_anno.png  \n",
            "  inflating: mask_images/5979_anno.png  \n",
            "  inflating: mask_images/4254_anno.png  \n",
            "  inflating: mask_images/4990_anno.png  \n",
            "  inflating: mask_images/6125_anno.png  \n",
            "  inflating: mask_images/6759_anno.png  \n",
            "  inflating: mask_images/3535_anno.png  \n",
            "  inflating: mask_images/577_anno.png  \n",
            "  inflating: mask_images/854_anno.png  \n",
            "  inflating: mask_images/3531_anno.png  \n",
            "  inflating: mask_images/3454_anno.png  \n",
            "  inflating: mask_images/7462_anno.png  \n",
            "  inflating: mask_images/449_anno.png  \n",
            "  inflating: mask_images/6917_anno.png  \n",
            "  inflating: mask_images/6711_anno.png  \n",
            "  inflating: mask_images/6845_anno.png  \n",
            "  inflating: mask_images/2556_anno.png  \n",
            "  inflating: mask_images/4883_anno.png  \n",
            "  inflating: mask_images/2760_anno.png  \n",
            "  inflating: mask_images/1991_anno.png  \n",
            "  inflating: mask_images/7535_anno.png  \n",
            "  inflating: mask_images/3515_anno.png  \n",
            "  inflating: mask_images/5466_anno.png  \n",
            "  inflating: mask_images/5689_anno.png  \n",
            "  inflating: mask_images/3751_anno.png  \n",
            "  inflating: mask_images/5081_anno.png  \n",
            "  inflating: mask_images/615_anno.png  \n",
            "  inflating: mask_images/560_anno.png  \n",
            "  inflating: mask_images/1978_anno.png  \n",
            "  inflating: mask_images/4942_anno.png  \n",
            "  inflating: mask_images/4872_anno.png  \n",
            "  inflating: mask_images/4400_anno.png  \n",
            "  inflating: mask_images/724_anno.png  \n",
            "  inflating: mask_images/3947_anno.png  \n",
            "  inflating: mask_images/236_anno.png  \n",
            "  inflating: mask_images/5359_anno.png  \n",
            "  inflating: mask_images/6889_anno.png  \n",
            "  inflating: mask_images/5670_anno.png  \n",
            "  inflating: mask_images/5992_anno.png  \n",
            "  inflating: mask_images/5633_anno.png  \n",
            "  inflating: mask_images/6782_anno.png  \n",
            "  inflating: mask_images/5659_anno.png  \n",
            "  inflating: mask_images/6862_anno.png  \n",
            "  inflating: mask_images/6886_anno.png  \n",
            "  inflating: mask_images/2271_anno.png  \n",
            "  inflating: mask_images/7368_anno.png  \n",
            "  inflating: mask_images/5233_anno.png  \n",
            "  inflating: mask_images/3019_anno.png  \n",
            "  inflating: mask_images/2997_anno.png  \n",
            "  inflating: mask_images/350_anno.png  \n",
            "  inflating: mask_images/2138_anno.png  \n",
            "  inflating: mask_images/6673_anno.png  \n",
            "  inflating: mask_images/719_anno.png  \n",
            "  inflating: mask_images/7324_anno.png  \n",
            "  inflating: mask_images/3187_anno.png  \n",
            "  inflating: mask_images/4297_anno.png  \n",
            "  inflating: mask_images/6752_anno.png  \n",
            "  inflating: mask_images/2123_anno.png  \n",
            "  inflating: mask_images/629_anno.png  \n",
            "  inflating: mask_images/4546_anno.png  \n",
            "  inflating: mask_images/4791_anno.png  \n",
            "  inflating: mask_images/5106_anno.png  \n",
            "  inflating: mask_images/2390_anno.png  \n",
            "  inflating: mask_images/2862_anno.png  \n",
            "  inflating: mask_images/7_anno.png  \n",
            "  inflating: mask_images/3877_anno.png  \n",
            "  inflating: mask_images/4751_anno.png  \n",
            "  inflating: mask_images/7537_anno.png  \n",
            "  inflating: mask_images/6928_anno.png  \n",
            "  inflating: mask_images/6877_anno.png  \n",
            "  inflating: mask_images/3562_anno.png  \n",
            "  inflating: mask_images/1997_anno.png  \n",
            "  inflating: mask_images/714_anno.png  \n",
            "  inflating: mask_images/4759_anno.png  \n",
            "  inflating: mask_images/1898_anno.png  \n",
            "  inflating: mask_images/4167_anno.png  \n",
            "  inflating: mask_images/4673_anno.png  \n",
            "  inflating: mask_images/5876_anno.png  \n",
            "  inflating: mask_images/1397_anno.png  \n",
            "  inflating: mask_images/2454_anno.png  \n",
            "  inflating: mask_images/2539_anno.png  \n",
            "  inflating: mask_images/844_anno.png  \n",
            "  inflating: mask_images/4948_anno.png  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVDHlN_h82Ea",
        "outputId": "e52e5481-f4b6-4397-a1d0-3bc5c93ac13d"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/LearningToCountEverything\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qX0nKUSR85Ty",
        "outputId": "fc251185-f35c-4d5a-f83f-0507150621ae"
      },
      "source": [
        "%ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/    learn2countEverything.png  orange_box_ex.txt  README.md  train.py\n",
            "demo.py  model.py                   orange.jpg         test.py    utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7HytJ7X86hn"
      },
      "source": [
        "# Demo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLWL7k5FUJ-b",
        "outputId": "8f56f6b3-bf1e-4433-d5b7-3c38aaa2d718"
      },
      "source": [
        "!python demo.py --input-image orange.jpg --bbox-file orange_box_ex.txt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
            "100% 97.8M/97.8M [00:00<00:00, 198MB/s]\n",
            "Bounding boxes: [[71, 49, 104, 83], [134, 119, 169, 151], [7, 200, 44, 236]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "===> The predicted count is:  29.15\n",
            "===> Visualized output is saved to ./orange_out.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeTTM54o89un"
      },
      "source": [
        "# 2.2 - without adapt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08KIgX-ibuKM",
        "outputId": "9482818f-c742-4d58-b3eb-31866f210eef"
      },
      "source": [
        "!python test.py --data_path 'data/' -ts 'val'"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation on val data\n",
            "\r  0% 0/1286 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "\r190.jpg : actual-predicted:     13,   60.9, error:   47.9. Current MAE: 47.91, RMSE: 47.91:   0% 0/1286 [00:00<?, ?it/s]\n",
            "\r190.jpg : actual-predicted:     13,   60.9, error:   47.9. Current MAE: 47.91, RMSE: 47.91:   0% 1/1286 [00:00<02:11,  9.80it/s]\r191.jpg : actual-predicted:     15,   16.3, error:    1.3. Current MAE: 24.60, RMSE: 33.89:   0% 1/1286 [00:00<02:11,  9.80it/s]\n",
            "192.jpg : actual-predicted:     19,   16.9, error:    2.1. Current MAE: 17.09, RMSE: 27.70:   0% 1/1286 [00:00<02:11,  9.80it/s]\n",
            "194.jpg : actual-predicted:     82,   63.6, error:   18.4. Current MAE: 17.41, RMSE: 25.68:   0% 3/1286 [00:00<01:51, 11.51it/s]\n",
            "195.jpg : actual-predicted:     10,    9.9, error:    0.1. Current MAE: 13.94, RMSE: 22.97:   0% 3/1286 [00:00<01:51, 11.51it/s]\n",
            "196.jpg : actual-predicted:     85,   61.3, error:   23.7. Current MAE: 15.57, RMSE: 23.10:   0% 5/1286 [00:00<01:56, 11.02it/s]\n",
            "197.jpg : actual-predicted:     77,   81.0, error:    4.0. Current MAE: 13.92, RMSE: 21.44:   0% 5/1286 [00:00<01:56, 11.02it/s]\n",
            "198.jpg : actual-predicted:     69,   61.2, error:    7.8. Current MAE: 13.16, RMSE: 20.24:   1% 7/1286 [00:00<01:42, 12.51it/s]\n",
            "214.jpg : actual-predicted:     64,   36.6, error:   27.4. Current MAE: 14.74, RMSE: 21.15:   1% 7/1286 [00:00<01:42, 12.51it/s]\n",
            "215.jpg : actual-predicted:    259,   96.4, error:  162.6. Current MAE: 29.53, RMSE: 55.20:   1% 9/1286 [00:00<01:33, 13.63it/s]\n",
            "216.jpg : actual-predicted:     46,   27.6, error:   18.4. Current MAE: 28.52, RMSE: 52.92:   1% 9/1286 [00:00<01:33, 13.63it/s]\n",
            "217.jpg : actual-predicted:     60,   72.3, error:   12.3. Current MAE: 27.16, RMSE: 50.79:   1% 9/1286 [00:00<01:33, 13.63it/s]\n",
            "218.jpg : actual-predicted:     58,   50.7, error:    7.3. Current MAE: 25.63, RMSE: 48.84:   1% 12/1286 [00:00<01:24, 15.13it/s]\n",
            "219.jpg : actual-predicted:     47,   50.3, error:    3.3. Current MAE: 24.04, RMSE: 47.07:   1% 12/1286 [00:00<01:24, 15.13it/s]\n",
            "220.jpg : actual-predicted:     59,   41.2, error:   17.8. Current MAE: 23.63, RMSE: 45.71:   1% 14/1286 [00:00<01:18, 16.26it/s]\n",
            "221.jpg : actual-predicted:     42,   23.8, error:   18.2. Current MAE: 23.29, RMSE: 44.49:   1% 14/1286 [00:00<01:18, 16.26it/s]\n",
            "222.jpg : actual-predicted:     65,   70.1, error:    5.1. Current MAE: 22.22, RMSE: 43.18:   1% 16/1286 [00:01<01:14, 17.05it/s]\n",
            "224.jpg : actual-predicted:     20,   16.0, error:    4.0. Current MAE: 21.20, RMSE: 41.98:   1% 16/1286 [00:01<01:14, 17.05it/s]\n",
            "226.jpg : actual-predicted:     78,   66.9, error:   11.1. Current MAE: 20.67, RMSE: 40.94:   1% 18/1286 [00:01<01:23, 15.25it/s]\n",
            "227.jpg : actual-predicted:     25,   69.7, error:   44.7. Current MAE: 21.87, RMSE: 41.13:   1% 18/1286 [00:01<01:23, 15.25it/s]\n",
            "228.jpg : actual-predicted:     44,   21.8, error:   22.2. Current MAE: 21.89, RMSE: 40.43:   1% 18/1286 [00:01<01:23, 15.25it/s]\n",
            "229.jpg : actual-predicted:     25,   47.6, error:   22.6. Current MAE: 21.92, RMSE: 39.79:   2% 21/1286 [00:01<01:21, 15.44it/s]\n",
            "231.jpg : actual-predicted:     24,   30.3, error:    6.3. Current MAE: 21.25, RMSE: 38.94:   2% 21/1286 [00:01<01:21, 15.44it/s]\n",
            "232.jpg : actual-predicted:     27,   47.7, error:   20.7. Current MAE: 21.22, RMSE: 38.36:   2% 23/1286 [00:01<01:20, 15.67it/s]\n",
            "233.jpg : actual-predicted:    126,  107.2, error:   18.8. Current MAE: 21.13, RMSE: 37.77:   2% 23/1286 [00:01<01:20, 15.67it/s]\n",
            "234.jpg : actual-predicted:     38,   40.8, error:    2.8. Current MAE: 20.42, RMSE: 37.04:   2% 25/1286 [00:01<01:17, 16.19it/s]\n",
            "236.jpg : actual-predicted:     11,   33.7, error:   22.7. Current MAE: 20.51, RMSE: 36.61:   2% 25/1286 [00:01<01:17, 16.19it/s]\n",
            "237.jpg : actual-predicted:     65,   75.4, error:   10.4. Current MAE: 20.15, RMSE: 36.00:   2% 27/1286 [00:01<01:20, 15.55it/s]\n",
            "238.jpg : actual-predicted:     20,   15.5, error:    4.5. Current MAE: 19.61, RMSE: 35.39:   2% 27/1286 [00:01<01:20, 15.55it/s]\n",
            "239.jpg : actual-predicted:     26,   24.6, error:    1.4. Current MAE: 19.00, RMSE: 34.79:   2% 29/1286 [00:01<01:25, 14.64it/s]\n",
            "240.jpg : actual-predicted:     37,   26.9, error:   10.1. Current MAE: 18.71, RMSE: 34.28:   2% 29/1286 [00:01<01:25, 14.64it/s]\n",
            "241.jpg : actual-predicted:     35,   36.8, error:    1.8. Current MAE: 18.19, RMSE: 33.74:   2% 31/1286 [00:02<01:19, 15.73it/s]\n",
            "243.jpg : actual-predicted:     33,   71.3, error:   38.3. Current MAE: 18.80, RMSE: 33.89:   2% 31/1286 [00:02<01:19, 15.73it/s]\n",
            "244.jpg : actual-predicted:     12,   48.4, error:   36.4. Current MAE: 19.32, RMSE: 33.96:   3% 33/1286 [00:02<01:14, 16.71it/s]\n",
            "245.jpg : actual-predicted:     55,   58.6, error:    3.6. Current MAE: 18.87, RMSE: 33.48:   3% 33/1286 [00:02<01:14, 16.71it/s]\n",
            "246.jpg : actual-predicted:     30,   21.4, error:    8.6. Current MAE: 18.58, RMSE: 33.04:   3% 33/1286 [00:02<01:14, 16.71it/s]\n",
            "248.jpg : actual-predicted:     48,   22.9, error:   25.1. Current MAE: 18.76, RMSE: 32.85:   3% 36/1286 [00:02<01:13, 16.90it/s]\n",
            "249.jpg : actual-predicted:     45,   29.0, error:   16.0. Current MAE: 18.69, RMSE: 32.52:   3% 36/1286 [00:02<01:13, 16.90it/s]\n",
            "250.jpg : actual-predicted:     50,   27.5, error:   22.5. Current MAE: 18.78, RMSE: 32.30:   3% 38/1286 [00:02<01:17, 16.18it/s]\n",
            "251.jpg : actual-predicted:     69,   66.5, error:    2.5. Current MAE: 18.38, RMSE: 31.90:   3% 38/1286 [00:02<01:17, 16.18it/s]\n",
            "252.jpg : actual-predicted:     22,   30.0, error:    8.0. Current MAE: 18.12, RMSE: 31.53:   3% 38/1286 [00:02<01:17, 16.18it/s]\n",
            "253.jpg : actual-predicted:    192,  170.3, error:   21.7. Current MAE: 18.21, RMSE: 31.34:   3% 41/1286 [00:02<01:11, 17.37it/s]\n",
            "254.jpg : actual-predicted:     74,   54.1, error:   19.9. Current MAE: 18.25, RMSE: 31.12:   3% 41/1286 [00:02<01:11, 17.37it/s]\n",
            "255.jpg : actual-predicted:     50,   42.3, error:    7.7. Current MAE: 18.01, RMSE: 30.78:   3% 43/1286 [00:02<01:11, 17.41it/s]\n",
            "256.jpg : actual-predicted:     38,   40.9, error:    2.9. Current MAE: 17.67, RMSE: 30.44:   3% 43/1286 [00:02<01:11, 17.41it/s]\n",
            "257.jpg : actual-predicted:    191,  132.5, error:   58.5. Current MAE: 18.56, RMSE: 31.32:   3% 43/1286 [00:02<01:11, 17.41it/s]\n",
            "271.jpg : actual-predicted:      9,   11.5, error:    2.5. Current MAE: 18.22, RMSE: 30.99:   4% 46/1286 [00:02<01:07, 18.30it/s]\n",
            "554.jpg : actual-predicted:     14,   21.7, error:    7.7. Current MAE: 18.00, RMSE: 30.68:   4% 46/1286 [00:02<01:07, 18.30it/s]\n",
            "555.jpg : actual-predicted:     12,   18.4, error:    6.4. Current MAE: 17.76, RMSE: 30.38:   4% 48/1286 [00:03<01:18, 15.86it/s]\n",
            "556.jpg : actual-predicted:     14,   30.5, error:   16.5. Current MAE: 17.74, RMSE: 30.17:   4% 48/1286 [00:03<01:18, 15.86it/s]\n",
            "557.jpg : actual-predicted:     18,   33.9, error:   15.9. Current MAE: 17.70, RMSE: 29.95:   4% 50/1286 [00:03<01:20, 15.38it/s]\n",
            "558.jpg : actual-predicted:     20,   28.0, error:    8.0. Current MAE: 17.51, RMSE: 29.69:   4% 50/1286 [00:03<01:20, 15.38it/s]\n",
            "559.jpg : actual-predicted:     20,   34.1, error:   14.1. Current MAE: 17.45, RMSE: 29.47:   4% 52/1286 [00:03<01:21, 15.15it/s]\n",
            "560.jpg : actual-predicted:     13,   30.7, error:   17.7. Current MAE: 17.45, RMSE: 29.29:   4% 52/1286 [00:03<01:21, 15.15it/s]\n",
            "561.jpg : actual-predicted:     13,   10.6, error:    2.4. Current MAE: 17.18, RMSE: 29.03:   4% 54/1286 [00:03<01:22, 15.01it/s]\n",
            "562.jpg : actual-predicted:     13,   43.7, error:   30.7. Current MAE: 17.42, RMSE: 29.06:   4% 54/1286 [00:03<01:22, 15.01it/s]\n",
            "564.jpg : actual-predicted:     10,   40.8, error:   30.8. Current MAE: 17.65, RMSE: 29.09:   4% 56/1286 [00:03<01:33, 13.21it/s]\n",
            "565.jpg : actual-predicted:     18,   16.4, error:    1.6. Current MAE: 17.38, RMSE: 28.84:   4% 56/1286 [00:03<01:33, 13.21it/s]\n",
            "566.jpg : actual-predicted:     15,   32.6, error:   17.6. Current MAE: 17.38, RMSE: 28.68:   5% 58/1286 [00:03<01:31, 13.37it/s]\n",
            "567.jpg : actual-predicted:     10,   16.1, error:    6.1. Current MAE: 17.19, RMSE: 28.45:   5% 58/1286 [00:03<01:31, 13.37it/s]\n",
            "568.jpg : actual-predicted:      9,   17.6, error:    8.6. Current MAE: 17.05, RMSE: 28.24:   5% 60/1286 [00:03<01:36, 12.66it/s]\n",
            "569.jpg : actual-predicted:     17,   23.7, error:    6.7. Current MAE: 16.89, RMSE: 28.03:   5% 60/1286 [00:04<01:36, 12.66it/s]\n",
            "570.jpg : actual-predicted:     19,   12.6, error:    6.4. Current MAE: 16.72, RMSE: 27.81:   5% 62/1286 [00:04<01:35, 12.82it/s]\n",
            "571.jpg : actual-predicted:     15,   26.2, error:   11.2. Current MAE: 16.63, RMSE: 27.63:   5% 62/1286 [00:04<01:35, 12.82it/s]\n",
            "572.jpg : actual-predicted:     31,   46.3, error:   15.3. Current MAE: 16.61, RMSE: 27.48:   5% 64/1286 [00:04<01:37, 12.54it/s]\n",
            "573.jpg : actual-predicted:     10,   24.4, error:   14.4. Current MAE: 16.58, RMSE: 27.33:   5% 64/1286 [00:04<01:37, 12.54it/s]\n",
            "574.jpg : actual-predicted:     25,   20.2, error:    4.8. Current MAE: 16.40, RMSE: 27.13:   5% 66/1286 [00:04<01:32, 13.20it/s]\n",
            "575.jpg : actual-predicted:     12,   31.0, error:   19.0. Current MAE: 16.44, RMSE: 27.03:   5% 66/1286 [00:04<01:32, 13.20it/s]\n",
            "576.jpg : actual-predicted:     19,   21.0, error:    2.0. Current MAE: 16.23, RMSE: 26.84:   5% 68/1286 [00:04<01:37, 12.55it/s]\n",
            "577.jpg : actual-predicted:     11,   15.9, error:    4.9. Current MAE: 16.07, RMSE: 26.65:   5% 68/1286 [00:04<01:37, 12.55it/s]\n",
            "578.jpg : actual-predicted:     12,   66.4, error:   54.4. Current MAE: 16.61, RMSE: 27.24:   5% 70/1286 [00:04<01:34, 12.85it/s]\n",
            "579.jpg : actual-predicted:      9,    9.4, error:    0.4. Current MAE: 16.38, RMSE: 27.05:   5% 70/1286 [00:04<01:34, 12.85it/s]\n",
            "580.jpg : actual-predicted:     10,   50.1, error:   40.1. Current MAE: 16.71, RMSE: 27.27:   6% 72/1286 [00:04<01:35, 12.75it/s]\n",
            "581.jpg : actual-predicted:      8,    9.4, error:    1.4. Current MAE: 16.50, RMSE: 27.08:   6% 72/1286 [00:04<01:35, 12.75it/s]\n",
            "582.jpg : actual-predicted:     14,   28.2, error:   14.2. Current MAE: 16.47, RMSE: 26.95:   6% 74/1286 [00:05<01:33, 12.91it/s]\n",
            "583.jpg : actual-predicted:     11,   29.1, error:   18.1. Current MAE: 16.49, RMSE: 26.85:   6% 74/1286 [00:05<01:33, 12.91it/s]\n",
            "584.jpg : actual-predicted:     13,   11.5, error:    1.5. Current MAE: 16.30, RMSE: 26.68:   6% 76/1286 [00:05<01:29, 13.50it/s]\n",
            "585.jpg : actual-predicted:     12,   19.6, error:    7.6. Current MAE: 16.19, RMSE: 26.52:   6% 76/1286 [00:05<01:29, 13.50it/s]\n",
            "586.jpg : actual-predicted:     11,   25.5, error:   14.5. Current MAE: 16.17, RMSE: 26.40:   6% 78/1286 [00:05<01:40, 12.02it/s]\n",
            "587.jpg : actual-predicted:     15,   29.6, error:   14.6. Current MAE: 16.15, RMSE: 26.29:   6% 78/1286 [00:05<01:40, 12.02it/s]\n",
            "588.jpg : actual-predicted:      9,   36.4, error:   27.4. Current MAE: 16.28, RMSE: 26.30:   6% 80/1286 [00:05<01:40, 12.04it/s]\n",
            "589.jpg : actual-predicted:     15,   24.0, error:    9.0. Current MAE: 16.19, RMSE: 26.16:   6% 80/1286 [00:05<01:40, 12.04it/s]\n",
            "590.jpg : actual-predicted:     16,   84.5, error:   68.5. Current MAE: 16.82, RMSE: 27.07:   6% 82/1286 [00:05<01:42, 11.78it/s]\n",
            "591.jpg : actual-predicted:     11,   21.8, error:   10.8. Current MAE: 16.75, RMSE: 26.93:   6% 82/1286 [00:05<01:42, 11.78it/s]\n",
            "592.jpg : actual-predicted:     10,   24.4, error:   14.4. Current MAE: 16.73, RMSE: 26.82:   7% 84/1286 [00:05<01:30, 13.23it/s]\n",
            "593.jpg : actual-predicted:     23,   13.1, error:    9.9. Current MAE: 16.65, RMSE: 26.68:   7% 84/1286 [00:05<01:30, 13.23it/s]\n",
            "595.jpg : actual-predicted:      9,   54.7, error:   45.7. Current MAE: 16.98, RMSE: 26.98:   7% 86/1286 [00:05<01:23, 14.31it/s]\n",
            "596.jpg : actual-predicted:     14,   34.8, error:   20.8. Current MAE: 17.02, RMSE: 26.92:   7% 86/1286 [00:05<01:23, 14.31it/s]\n",
            "597.jpg : actual-predicted:     54,   63.6, error:    9.6. Current MAE: 16.94, RMSE: 26.78:   7% 88/1286 [00:06<01:17, 15.49it/s]\n",
            "598.jpg : actual-predicted:     13,   27.6, error:   14.6. Current MAE: 16.91, RMSE: 26.68:   7% 88/1286 [00:06<01:17, 15.49it/s]\n",
            "599.jpg : actual-predicted:     15,   28.7, error:   13.7. Current MAE: 16.88, RMSE: 26.57:   7% 88/1286 [00:06<01:17, 15.49it/s]\n",
            "600.jpg : actual-predicted:     19,   29.9, error:   10.9. Current MAE: 16.81, RMSE: 26.45:   7% 91/1286 [00:06<01:12, 16.43it/s]\n",
            "601.jpg : actual-predicted:      9,   22.2, error:   13.2. Current MAE: 16.78, RMSE: 26.34:   7% 91/1286 [00:06<01:12, 16.43it/s]\n",
            "602.jpg : actual-predicted:     46,   61.5, error:   15.5. Current MAE: 16.76, RMSE: 26.25:   7% 93/1286 [00:06<01:11, 16.71it/s]\n",
            "603.jpg : actual-predicted:     25,   56.4, error:   31.4. Current MAE: 16.92, RMSE: 26.31:   7% 93/1286 [00:06<01:11, 16.71it/s]\n",
            "604.jpg : actual-predicted:     39,   68.6, error:   29.6. Current MAE: 17.05, RMSE: 26.35:   7% 95/1286 [00:06<01:18, 15.26it/s]\n",
            "605.jpg : actual-predicted:     13,   59.0, error:   46.0. Current MAE: 17.35, RMSE: 26.62:   7% 95/1286 [00:06<01:18, 15.26it/s]\n",
            "606.jpg : actual-predicted:     27,   63.4, error:   36.4. Current MAE: 17.54, RMSE: 26.74:   8% 97/1286 [00:06<01:16, 15.64it/s]\n",
            "607.jpg : actual-predicted:     12,   29.3, error:   17.3. Current MAE: 17.54, RMSE: 26.66:   8% 97/1286 [00:06<01:16, 15.64it/s]\n",
            "609.jpg : actual-predicted:     12,   38.0, error:   26.0. Current MAE: 17.62, RMSE: 26.66:   8% 99/1286 [00:06<01:19, 14.89it/s]\n",
            "610.jpg : actual-predicted:     20,   13.7, error:    6.3. Current MAE: 17.51, RMSE: 26.53:   8% 99/1286 [00:06<01:19, 14.89it/s]\n",
            "611.jpg : actual-predicted:     14,   29.0, error:   15.0. Current MAE: 17.49, RMSE: 26.44:   8% 101/1286 [00:06<01:23, 14.25it/s]\n",
            "613.jpg : actual-predicted:      7,   25.6, error:   18.6. Current MAE: 17.50, RMSE: 26.38:   8% 101/1286 [00:06<01:23, 14.25it/s]\n",
            "614.jpg : actual-predicted:     10,   19.2, error:    9.2. Current MAE: 17.42, RMSE: 26.27:   8% 101/1286 [00:07<01:23, 14.25it/s]\n",
            "615.jpg : actual-predicted:     23,   31.2, error:    8.2. Current MAE: 17.33, RMSE: 26.15:   8% 104/1286 [00:07<02:24,  8.18it/s]\n",
            "616.jpg : actual-predicted:    119,  154.0, error:   35.0. Current MAE: 17.50, RMSE: 26.25:   8% 104/1286 [00:07<02:24,  8.18it/s]\n",
            "617.jpg : actual-predicted:     11,   37.5, error:   26.5. Current MAE: 17.58, RMSE: 26.25:   8% 106/1286 [00:07<02:02,  9.61it/s]\n",
            "618.jpg : actual-predicted:     20,   27.9, error:    7.9. Current MAE: 17.49, RMSE: 26.14:   8% 106/1286 [00:07<02:02,  9.61it/s]\n",
            "619.jpg : actual-predicted:     13,   37.5, error:   24.5. Current MAE: 17.55, RMSE: 26.13:   8% 108/1286 [00:07<01:47, 10.98it/s]\n",
            "620.jpg : actual-predicted:      9,   25.8, error:   16.8. Current MAE: 17.55, RMSE: 26.06:   8% 108/1286 [00:07<01:47, 10.98it/s]\n",
            "621.jpg : actual-predicted:     12,   29.9, error:   17.9. Current MAE: 17.55, RMSE: 26.00:   9% 110/1286 [00:08<01:44, 11.22it/s]\n",
            "622.jpg : actual-predicted:     34,   71.6, error:   37.6. Current MAE: 17.73, RMSE: 26.12:   9% 110/1286 [00:08<01:44, 11.22it/s]\n",
            "623.jpg : actual-predicted:      9,   17.5, error:    8.5. Current MAE: 17.65, RMSE: 26.02:   9% 112/1286 [00:08<01:33, 12.62it/s]\n",
            "624.jpg : actual-predicted:     10,   25.0, error:   15.0. Current MAE: 17.62, RMSE: 25.94:   9% 112/1286 [00:08<01:33, 12.62it/s]\n",
            "625.jpg : actual-predicted:     14,   65.9, error:   51.9. Current MAE: 17.92, RMSE: 26.28:   9% 112/1286 [00:08<01:33, 12.62it/s]\n",
            "626.jpg : actual-predicted:     12,    5.9, error:    6.1. Current MAE: 17.82, RMSE: 26.17:   9% 115/1286 [00:08<01:21, 14.39it/s]\n",
            "734.jpg : actual-predicted:     20,   37.0, error:   17.0. Current MAE: 17.81, RMSE: 26.11:   9% 115/1286 [00:08<01:21, 14.39it/s]\n",
            "735.jpg : actual-predicted:     14,   15.2, error:    1.2. Current MAE: 17.67, RMSE: 26.00:   9% 117/1286 [00:08<01:32, 12.59it/s]\n",
            "736.jpg : actual-predicted:     44,   32.1, error:   11.9. Current MAE: 17.62, RMSE: 25.91:   9% 117/1286 [00:08<01:32, 12.59it/s]\n",
            "737.jpg : actual-predicted:      9,   19.0, error:   10.0. Current MAE: 17.56, RMSE: 25.82:   9% 119/1286 [00:08<01:23, 14.03it/s]\n",
            "738.jpg : actual-predicted:     13,   22.0, error:    9.0. Current MAE: 17.49, RMSE: 25.72:   9% 119/1286 [00:08<01:23, 14.03it/s]\n",
            "740.jpg : actual-predicted:     10,   16.2, error:    6.2. Current MAE: 17.40, RMSE: 25.62:   9% 121/1286 [00:08<01:18, 14.91it/s]\n",
            "741.jpg : actual-predicted:     13,    1.8, error:   11.2. Current MAE: 17.35, RMSE: 25.54:   9% 121/1286 [00:08<01:18, 14.91it/s]\n",
            "742.jpg : actual-predicted:     13,    2.4, error:   10.6. Current MAE: 17.29, RMSE: 25.45:  10% 123/1286 [00:08<01:27, 13.37it/s]\n",
            "744.jpg : actual-predicted:      8,   37.5, error:   29.5. Current MAE: 17.39, RMSE: 25.49:  10% 123/1286 [00:09<01:27, 13.37it/s]\n",
            "745.jpg : actual-predicted:     60,   60.9, error:    0.9. Current MAE: 17.26, RMSE: 25.39:  10% 125/1286 [00:09<01:36, 12.04it/s]\n",
            "746.jpg : actual-predicted:      8,   15.9, error:    7.9. Current MAE: 17.19, RMSE: 25.30:  10% 125/1286 [00:09<01:36, 12.04it/s]\n",
            "747.jpg : actual-predicted:     16,   25.3, error:    9.3. Current MAE: 17.13, RMSE: 25.21:  10% 127/1286 [00:09<01:31, 12.61it/s]\n",
            "749.jpg : actual-predicted:     10,   77.6, error:   67.6. Current MAE: 17.52, RMSE: 25.81:  10% 127/1286 [00:09<01:31, 12.61it/s]\n",
            "750.jpg : actual-predicted:      8,   16.7, error:    8.7. Current MAE: 17.45, RMSE: 25.72:  10% 129/1286 [00:09<01:22, 14.06it/s]\n",
            "751.jpg : actual-predicted:     58,   99.8, error:   41.8. Current MAE: 17.63, RMSE: 25.88:  10% 129/1286 [00:09<01:22, 14.06it/s]\n",
            "752.jpg : actual-predicted:     36,   34.4, error:    1.6. Current MAE: 17.51, RMSE: 25.78:  10% 131/1286 [00:09<01:15, 15.25it/s]\n",
            "753.jpg : actual-predicted:     12,   11.1, error:    0.9. Current MAE: 17.39, RMSE: 25.69:  10% 131/1286 [00:09<01:15, 15.25it/s]\n",
            "754.jpg : actual-predicted:      9,   25.3, error:   16.3. Current MAE: 17.38, RMSE: 25.63:  10% 133/1286 [00:09<01:17, 14.93it/s]\n",
            "755.jpg : actual-predicted:     13,    9.4, error:    3.6. Current MAE: 17.28, RMSE: 25.54:  10% 133/1286 [00:09<01:17, 14.93it/s]\n",
            "756.jpg : actual-predicted:     15,   18.3, error:    3.3. Current MAE: 17.17, RMSE: 25.44:  10% 135/1286 [00:09<01:17, 14.81it/s]\n",
            "757.jpg : actual-predicted:      9,   29.3, error:   20.3. Current MAE: 17.20, RMSE: 25.41:  10% 135/1286 [00:09<01:17, 14.81it/s]\n",
            "758.jpg : actual-predicted:     14,    8.9, error:    5.1. Current MAE: 17.11, RMSE: 25.32:  11% 137/1286 [00:09<01:13, 15.61it/s]\n",
            "759.jpg : actual-predicted:     10,   15.5, error:    5.5. Current MAE: 17.03, RMSE: 25.23:  11% 137/1286 [00:10<01:13, 15.61it/s]\n",
            "760.jpg : actual-predicted:     21,   38.0, error:   17.0. Current MAE: 17.03, RMSE: 25.18:  11% 139/1286 [00:10<01:30, 12.68it/s]\n",
            "761.jpg : actual-predicted:     16,   43.9, error:   27.9. Current MAE: 17.10, RMSE: 25.20:  11% 139/1286 [00:10<01:30, 12.68it/s]\n",
            "762.jpg : actual-predicted:     77,  156.7, error:   79.7. Current MAE: 17.54, RMSE: 25.99:  11% 141/1286 [00:10<01:23, 13.76it/s]\n",
            "763.jpg : actual-predicted:     56,   67.4, error:   11.4. Current MAE: 17.50, RMSE: 25.92:  11% 141/1286 [00:10<01:23, 13.76it/s]\n",
            "764.jpg : actual-predicted:     85,   60.3, error:   24.7. Current MAE: 17.55, RMSE: 25.91:  11% 143/1286 [00:10<01:16, 15.01it/s]\n",
            "765.jpg : actual-predicted:     11,   49.2, error:   38.2. Current MAE: 17.69, RMSE: 26.01:  11% 143/1286 [00:10<01:16, 15.01it/s]\n",
            "766.jpg : actual-predicted:     50,   64.9, error:   14.9. Current MAE: 17.67, RMSE: 25.95:  11% 145/1286 [00:10<01:18, 14.60it/s]\n",
            "767.jpg : actual-predicted:     55,   42.4, error:   12.6. Current MAE: 17.64, RMSE: 25.89:  11% 145/1286 [00:10<01:18, 14.60it/s]\n",
            "768.jpg : actual-predicted:     16,    9.4, error:    6.6. Current MAE: 17.56, RMSE: 25.80:  11% 147/1286 [00:10<01:36, 11.77it/s]\n",
            "769.jpg : actual-predicted:     13,   27.3, error:   14.3. Current MAE: 17.54, RMSE: 25.74:  11% 147/1286 [00:10<01:36, 11.77it/s]\n",
            "770.jpg : actual-predicted:     83,   49.1, error:   33.9. Current MAE: 17.65, RMSE: 25.81:  12% 149/1286 [00:10<01:56,  9.80it/s]\n",
            "771.jpg : actual-predicted:     15,    8.2, error:    6.8. Current MAE: 17.58, RMSE: 25.73:  12% 149/1286 [00:11<01:56,  9.80it/s]\n",
            "772.jpg : actual-predicted:     28,   85.1, error:   57.1. Current MAE: 17.84, RMSE: 26.06:  12% 151/1286 [00:11<01:52, 10.13it/s]\n",
            "773.jpg : actual-predicted:     10,    9.4, error:    0.6. Current MAE: 17.73, RMSE: 25.97:  12% 151/1286 [00:11<01:52, 10.13it/s]\n",
            "774.jpg : actual-predicted:      8,   10.2, error:    2.2. Current MAE: 17.63, RMSE: 25.89:  12% 153/1286 [00:11<01:43, 10.90it/s]\n",
            "775.jpg : actual-predicted:     20,   35.0, error:   15.0. Current MAE: 17.61, RMSE: 25.83:  12% 153/1286 [00:11<01:43, 10.90it/s]\n",
            "776.jpg : actual-predicted:     15,   26.5, error:   11.5. Current MAE: 17.57, RMSE: 25.77:  12% 155/1286 [00:11<01:47, 10.48it/s]\n",
            "778.jpg : actual-predicted:     13,   16.3, error:    3.3. Current MAE: 17.48, RMSE: 25.69:  12% 155/1286 [00:11<01:47, 10.48it/s]\n",
            "807.jpg : actual-predicted:     36,   32.5, error:    3.5. Current MAE: 17.39, RMSE: 25.61:  12% 157/1286 [00:11<01:46, 10.59it/s]\n",
            "808.jpg : actual-predicted:    182,  164.0, error:   18.0. Current MAE: 17.39, RMSE: 25.57:  12% 157/1286 [00:11<01:46, 10.59it/s]\n",
            "809.jpg : actual-predicted:    323,  331.9, error:    8.9. Current MAE: 17.34, RMSE: 25.50:  12% 159/1286 [00:11<01:34, 11.92it/s]\n",
            "810.jpg : actual-predicted:     22,   32.4, error:   10.4. Current MAE: 17.30, RMSE: 25.43:  12% 159/1286 [00:11<01:34, 11.92it/s]\n",
            "811.jpg : actual-predicted:     17,   26.1, error:    9.1. Current MAE: 17.25, RMSE: 25.36:  13% 161/1286 [00:11<01:24, 13.26it/s]\n",
            "812.jpg : actual-predicted:     51,   73.2, error:   22.2. Current MAE: 17.28, RMSE: 25.34:  13% 161/1286 [00:11<01:24, 13.26it/s]\n",
            "813.jpg : actual-predicted:    185,  204.6, error:   19.6. Current MAE: 17.29, RMSE: 25.31:  13% 163/1286 [00:12<01:21, 13.86it/s]\n",
            "814.jpg : actual-predicted:     21,   26.4, error:    5.4. Current MAE: 17.22, RMSE: 25.24:  13% 163/1286 [00:12<01:21, 13.86it/s]\n",
            "817.jpg : actual-predicted:     34,   47.8, error:   13.8. Current MAE: 17.20, RMSE: 25.18:  13% 165/1286 [00:12<01:14, 15.12it/s]\n",
            "819.jpg : actual-predicted:     40,   38.2, error:    1.8. Current MAE: 17.11, RMSE: 25.11:  13% 165/1286 [00:12<01:14, 15.12it/s]\n",
            "820.jpg : actual-predicted:    437,  347.7, error:   89.3. Current MAE: 17.54, RMSE: 25.97:  13% 167/1286 [00:12<01:17, 14.50it/s]\n",
            "822.jpg : actual-predicted:     53,   52.4, error:    0.6. Current MAE: 17.44, RMSE: 25.89:  13% 167/1286 [00:12<01:17, 14.50it/s]\n",
            "823.jpg : actual-predicted:    195,  151.7, error:   43.3. Current MAE: 17.59, RMSE: 26.03:  13% 169/1286 [00:12<01:14, 15.08it/s]\n",
            "824.jpg : actual-predicted:      9,   20.3, error:   11.3. Current MAE: 17.55, RMSE: 25.96:  13% 169/1286 [00:12<01:14, 15.08it/s]\n",
            "825.jpg : actual-predicted:     50,   34.9, error:   15.1. Current MAE: 17.54, RMSE: 25.91:  13% 171/1286 [00:12<01:13, 15.27it/s]\n",
            "826.jpg : actual-predicted:     70,   54.7, error:   15.3. Current MAE: 17.53, RMSE: 25.87:  13% 171/1286 [00:12<01:13, 15.27it/s]\n",
            "827.jpg : actual-predicted:     40,   35.9, error:    4.1. Current MAE: 17.45, RMSE: 25.79:  13% 173/1286 [00:12<01:13, 15.06it/s]\n",
            "828.jpg : actual-predicted:     87,   65.3, error:   21.7. Current MAE: 17.47, RMSE: 25.77:  13% 173/1286 [00:12<01:13, 15.06it/s]\n",
            "830.jpg : actual-predicted:    577,  505.5, error:   71.5. Current MAE: 17.78, RMSE: 26.26:  14% 175/1286 [00:12<01:09, 15.88it/s]\n",
            "831.jpg : actual-predicted:    117,   87.6, error:   29.4. Current MAE: 17.85, RMSE: 26.28:  14% 175/1286 [00:12<01:09, 15.88it/s]\n",
            "832.jpg : actual-predicted:    116,   97.2, error:   18.8. Current MAE: 17.85, RMSE: 26.24:  14% 177/1286 [00:12<01:08, 16.30it/s]\n",
            "833.jpg : actual-predicted:     54,   56.3, error:    2.3. Current MAE: 17.76, RMSE: 26.17:  14% 177/1286 [00:12<01:08, 16.30it/s]\n",
            "834.jpg : actual-predicted:     80,   62.2, error:   17.8. Current MAE: 17.76, RMSE: 26.13:  14% 179/1286 [00:13<01:07, 16.44it/s]\n",
            "835.jpg : actual-predicted:     22,   52.4, error:   30.4. Current MAE: 17.83, RMSE: 26.15:  14% 179/1286 [00:13<01:07, 16.44it/s]\n",
            "836.jpg : actual-predicted:    230,  148.8, error:   81.2. Current MAE: 18.18, RMSE: 26.77:  14% 181/1286 [00:13<01:09, 15.87it/s]\n",
            "837.jpg : actual-predicted:     35,    0.9, error:   34.1. Current MAE: 18.27, RMSE: 26.81:  14% 181/1286 [00:13<01:09, 15.87it/s]\n",
            "838.jpg : actual-predicted:    113,   84.2, error:   28.8. Current MAE: 18.33, RMSE: 26.82:  14% 183/1286 [00:13<01:29, 12.29it/s]\n",
            "840.jpg : actual-predicted:    637,  240.7, error:  396.3. Current MAE: 20.37, RMSE: 39.55:  14% 183/1286 [00:13<01:29, 12.29it/s]\n",
            "841.jpg : actual-predicted:     11,   13.9, error:    2.9. Current MAE: 20.28, RMSE: 39.45:  14% 185/1286 [00:13<01:25, 12.83it/s]\n",
            "842.jpg : actual-predicted:     46,   35.5, error:   10.5. Current MAE: 20.22, RMSE: 39.35:  14% 185/1286 [00:13<01:25, 12.83it/s]\n",
            "844.jpg : actual-predicted:    191,  123.5, error:   67.5. Current MAE: 20.48, RMSE: 39.55:  15% 187/1286 [00:13<01:41, 10.86it/s]\n",
            "845.jpg : actual-predicted:    142,  121.8, error:   20.2. Current MAE: 20.47, RMSE: 39.47:  15% 187/1286 [00:13<01:41, 10.86it/s]\n",
            "846.jpg : actual-predicted:     35,   16.6, error:   18.4. Current MAE: 20.46, RMSE: 39.39:  15% 189/1286 [00:13<01:33, 11.74it/s]\n",
            "849.jpg : actual-predicted:     21,   12.7, error:    8.3. Current MAE: 20.40, RMSE: 39.29:  15% 189/1286 [00:14<01:33, 11.74it/s]\n",
            "850.jpg : actual-predicted:    183,   78.5, error:  104.5. Current MAE: 20.84, RMSE: 39.91:  15% 191/1286 [00:14<01:35, 11.45it/s]\n",
            "851.jpg : actual-predicted:    320,  119.6, error:  200.4. Current MAE: 21.77, RMSE: 42.34:  15% 191/1286 [00:14<01:35, 11.45it/s]\n",
            "852.jpg : actual-predicted:     41,   48.3, error:    7.3. Current MAE: 21.69, RMSE: 42.23:  15% 191/1286 [00:14<01:35, 11.45it/s]\n",
            "853.jpg : actual-predicted:     10,    5.9, error:    4.1. Current MAE: 21.60, RMSE: 42.13:  15% 194/1286 [00:14<01:28, 12.33it/s]\n",
            "854.jpg : actual-predicted:     10,   52.0, error:   42.0. Current MAE: 21.71, RMSE: 42.13:  15% 194/1286 [00:14<01:28, 12.33it/s]\n",
            "856.jpg : actual-predicted:     44,   31.0, error:   13.0. Current MAE: 21.66, RMSE: 42.03:  15% 196/1286 [00:14<01:40, 10.83it/s]\n",
            "857.jpg : actual-predicted:    162,  204.7, error:   42.7. Current MAE: 21.77, RMSE: 42.03:  15% 196/1286 [00:14<01:40, 10.83it/s]\n",
            "859.jpg : actual-predicted:     97,   21.1, error:   75.9. Current MAE: 22.04, RMSE: 42.27:  15% 198/1286 [00:14<01:38, 11.02it/s]\n",
            "860.jpg : actual-predicted:    240,  190.7, error:   49.3. Current MAE: 22.18, RMSE: 42.31:  15% 198/1286 [00:14<01:38, 11.02it/s]\n",
            "861.jpg : actual-predicted:     65,   29.3, error:   35.7. Current MAE: 22.24, RMSE: 42.28:  16% 200/1286 [00:14<01:31, 11.81it/s]\n",
            "862.jpg : actual-predicted:     15,   21.9, error:    6.9. Current MAE: 22.17, RMSE: 42.18:  16% 200/1286 [00:14<01:31, 11.81it/s]\n",
            "864.jpg : actual-predicted:     84,   78.9, error:    5.1. Current MAE: 22.08, RMSE: 42.07:  16% 202/1286 [00:15<01:31, 11.85it/s]\n",
            "865.jpg : actual-predicted:   1022,  193.4, error:  828.6. Current MAE: 26.04, RMSE: 71.60:  16% 202/1286 [00:15<01:31, 11.85it/s]\n",
            "866.jpg : actual-predicted:    230,   44.6, error:  185.4. Current MAE: 26.82, RMSE: 72.59:  16% 204/1286 [00:15<01:29, 12.04it/s]\n",
            "867.jpg : actual-predicted:     23,   17.1, error:    5.9. Current MAE: 26.71, RMSE: 72.42:  16% 204/1286 [00:15<01:29, 12.04it/s]\n",
            "868.jpg : actual-predicted:      8,    1.7, error:    6.3. Current MAE: 26.61, RMSE: 72.24:  16% 206/1286 [00:15<01:27, 12.30it/s]\n",
            "869.jpg : actual-predicted:    250,   94.4, error:  155.6. Current MAE: 27.23, RMSE: 72.87:  16% 206/1286 [00:16<01:27, 12.30it/s]\n",
            "871.jpg : actual-predicted:     18,   29.8, error:   11.8. Current MAE: 27.16, RMSE: 72.70:  16% 208/1286 [00:16<03:02,  5.90it/s]\n",
            "873.jpg : actual-predicted:     21,   22.3, error:    1.3. Current MAE: 27.04, RMSE: 72.53:  16% 208/1286 [00:16<03:02,  5.90it/s]\n",
            "876.jpg : actual-predicted:    207,   15.3, error:  191.7. Current MAE: 27.82, RMSE: 73.55:  16% 210/1286 [00:16<02:37,  6.83it/s]\n",
            "913.jpg : actual-predicted:      9,   24.1, error:   15.1. Current MAE: 27.76, RMSE: 73.38:  16% 210/1286 [00:16<02:37,  6.83it/s]\n",
            "914.jpg : actual-predicted:     65,   23.3, error:   41.7. Current MAE: 27.82, RMSE: 73.27:  16% 212/1286 [00:16<02:14,  7.99it/s]\n",
            "915.jpg : actual-predicted:     11,    0.8, error:   10.2. Current MAE: 27.74, RMSE: 73.10:  16% 212/1286 [00:17<02:14,  7.99it/s]\n",
            "916.jpg : actual-predicted:      9,   16.3, error:    7.3. Current MAE: 27.65, RMSE: 72.93:  17% 214/1286 [00:17<04:10,  4.28it/s]\n",
            "917.jpg : actual-predicted:     10,    7.7, error:    2.3. Current MAE: 27.53, RMSE: 72.76:  17% 214/1286 [00:17<04:10,  4.28it/s]\n",
            "918.jpg : actual-predicted:     47,   43.2, error:    3.8. Current MAE: 27.42, RMSE: 72.59:  17% 216/1286 [00:17<03:25,  5.21it/s]\n",
            "919.jpg : actual-predicted:     32,   12.3, error:   19.7. Current MAE: 27.38, RMSE: 72.44:  17% 216/1286 [00:17<03:25,  5.21it/s]\n",
            "920.jpg : actual-predicted:     12,    6.4, error:    5.6. Current MAE: 27.28, RMSE: 72.28:  17% 218/1286 [00:17<02:53,  6.14it/s]\n",
            "922.jpg : actual-predicted:      8,   38.4, error:   30.4. Current MAE: 27.30, RMSE: 72.14:  17% 219/1286 [00:18<02:59,  5.95it/s]\n",
            "923.jpg : actual-predicted:    122,  112.5, error:    9.5. Current MAE: 27.22, RMSE: 71.98:  17% 219/1286 [00:18<02:59,  5.95it/s]\n",
            "925.jpg : actual-predicted:     47,    6.6, error:   40.4. Current MAE: 27.28, RMSE: 71.87:  17% 221/1286 [00:18<02:27,  7.22it/s]\n",
            "926.jpg : actual-predicted:     39,  111.0, error:   72.0. Current MAE: 27.48, RMSE: 71.87:  17% 221/1286 [00:18<02:27,  7.22it/s]\n",
            "929.jpg : actual-predicted:     23,   37.8, error:   14.8. Current MAE: 27.42, RMSE: 71.72:  17% 223/1286 [00:18<02:03,  8.61it/s]\n",
            "930.jpg : actual-predicted:     15,   22.1, error:    7.1. Current MAE: 27.33, RMSE: 71.56:  17% 223/1286 [00:18<02:03,  8.61it/s]\n",
            "931.jpg : actual-predicted:    298,  376.8, error:   78.8. Current MAE: 27.56, RMSE: 71.59:  17% 225/1286 [00:18<01:49,  9.66it/s]\n",
            "932.jpg : actual-predicted:     53,   59.5, error:    6.5. Current MAE: 27.47, RMSE: 71.44:  17% 225/1286 [00:18<01:49,  9.66it/s]\n",
            "933.jpg : actual-predicted:     67,   72.1, error:    5.1. Current MAE: 27.37, RMSE: 71.28:  18% 227/1286 [00:18<01:34, 11.21it/s]\n",
            "934.jpg : actual-predicted:     13,   13.1, error:    0.1. Current MAE: 27.25, RMSE: 71.12:  18% 227/1286 [00:18<01:34, 11.21it/s]\n",
            "935.jpg : actual-predicted:   2092, 1148.4, error:  943.6. Current MAE: 31.23, RMSE: 94.38:  18% 229/1286 [00:18<01:27, 12.02it/s]\n",
            "938.jpg : actual-predicted:     12,   20.0, error:    8.0. Current MAE: 31.13, RMSE: 94.18:  18% 229/1286 [00:18<01:27, 12.02it/s]\n",
            "941.jpg : actual-predicted:     13,   19.7, error:    6.7. Current MAE: 31.03, RMSE: 93.98:  18% 229/1286 [00:18<01:27, 12.02it/s]\n",
            "942.jpg : actual-predicted:     37,   30.7, error:    6.3. Current MAE: 30.92, RMSE: 93.78:  18% 232/1286 [00:18<01:16, 13.74it/s]\n",
            "943.jpg : actual-predicted:     97,   87.5, error:    9.5. Current MAE: 30.83, RMSE: 93.58:  18% 232/1286 [00:18<01:16, 13.74it/s]\n",
            "945.jpg : actual-predicted:    122,  152.5, error:   30.5. Current MAE: 30.83, RMSE: 93.40:  18% 234/1286 [00:18<01:09, 15.16it/s]\n",
            "946.jpg : actual-predicted:     20,   27.0, error:    7.0. Current MAE: 30.73, RMSE: 93.20:  18% 234/1286 [00:18<01:09, 15.16it/s]\n",
            "948.jpg : actual-predicted:     24,   31.6, error:    7.6. Current MAE: 30.63, RMSE: 93.01:  18% 236/1286 [00:19<01:09, 15.21it/s]\n",
            "949.jpg : actual-predicted:   1092,  129.5, error:  962.5. Current MAE: 34.55, RMSE: 111.83:  18% 236/1286 [00:19<01:09, 15.21it/s]\n",
            "952.jpg : actual-predicted:    139,  125.2, error:   13.8. Current MAE: 34.46, RMSE: 111.60:  19% 238/1286 [00:19<01:04, 16.25it/s]\n",
            "955.jpg : actual-predicted:     86,   23.1, error:   62.9. Current MAE: 34.58, RMSE: 111.44:  19% 238/1286 [00:19<01:04, 16.25it/s]\n",
            "957.jpg : actual-predicted:    530,  243.2, error:  286.8. Current MAE: 35.62, RMSE: 112.74:  19% 240/1286 [00:19<01:04, 16.25it/s]\n",
            "959.jpg : actual-predicted:     18,   25.6, error:    7.6. Current MAE: 35.51, RMSE: 112.50:  19% 240/1286 [00:19<01:04, 16.25it/s]\n",
            "960.jpg : actual-predicted:     13,   25.9, error:   12.9. Current MAE: 35.42, RMSE: 112.27:  19% 242/1286 [00:19<01:08, 15.16it/s]\n",
            "961.jpg : actual-predicted:     48,   28.2, error:   19.8. Current MAE: 35.35, RMSE: 112.05:  19% 242/1286 [00:19<01:08, 15.16it/s]\n",
            "962.jpg : actual-predicted:      7,   14.9, error:    7.9. Current MAE: 35.24, RMSE: 111.82:  19% 244/1286 [00:19<01:07, 15.50it/s]\n",
            "963.jpg : actual-predicted:     63,   54.3, error:    8.7. Current MAE: 35.13, RMSE: 111.60:  19% 244/1286 [00:19<01:07, 15.50it/s]\n",
            "964.jpg : actual-predicted:     18,   83.4, error:   65.4. Current MAE: 35.25, RMSE: 111.45:  19% 246/1286 [00:19<01:15, 13.83it/s]\n",
            "965.jpg : actual-predicted:     10,   26.9, error:   16.9. Current MAE: 35.18, RMSE: 111.23:  19% 246/1286 [00:19<01:15, 13.83it/s]\n",
            "966.jpg : actual-predicted:     76,  161.5, error:   85.5. Current MAE: 35.38, RMSE: 111.14:  19% 248/1286 [00:19<01:10, 14.82it/s]\n",
            "969.jpg : actual-predicted:     38,   56.0, error:   18.0. Current MAE: 35.31, RMSE: 110.92:  19% 248/1286 [00:19<01:10, 14.82it/s]\n",
            "970.jpg : actual-predicted:     63,   76.6, error:   13.6. Current MAE: 35.23, RMSE: 110.70:  19% 248/1286 [00:19<01:10, 14.82it/s]\n",
            "972.jpg : actual-predicted:    485,  558.0, error:   73.0. Current MAE: 35.38, RMSE: 110.58:  20% 251/1286 [00:19<01:04, 15.98it/s]\n",
            "973.jpg : actual-predicted:     45,   51.9, error:    6.9. Current MAE: 35.26, RMSE: 110.36:  20% 251/1286 [00:20<01:04, 15.98it/s]\n",
            "975.jpg : actual-predicted:    718,  276.2, error:  441.8. Current MAE: 36.86, RMSE: 113.58:  20% 251/1286 [00:20<01:04, 15.98it/s]\n",
            "976.jpg : actual-predicted:     85,   88.9, error:    3.9. Current MAE: 36.73, RMSE: 113.36:  20% 254/1286 [00:20<01:00, 17.19it/s]\n",
            "977.jpg : actual-predicted:    165,  174.6, error:    9.6. Current MAE: 36.63, RMSE: 113.14:  20% 254/1286 [00:20<01:00, 17.19it/s]\n",
            "979.jpg : actual-predicted:    108,   95.2, error:   12.8. Current MAE: 36.54, RMSE: 112.92:  20% 256/1286 [00:20<00:58, 17.60it/s]\n",
            "982.jpg : actual-predicted:     50,   81.8, error:   31.8. Current MAE: 36.52, RMSE: 112.72:  20% 256/1286 [00:20<00:58, 17.60it/s]\n",
            "984.jpg : actual-predicted:     64,   62.7, error:    1.3. Current MAE: 36.38, RMSE: 112.50:  20% 258/1286 [00:20<01:02, 16.34it/s]\n",
            "1386.jpg: actual-predicted:     35,  124.3, error:   89.3. Current MAE: 36.58, RMSE: 112.42:  20% 258/1286 [00:20<01:02, 16.34it/s]\n",
            "1391.jpg: actual-predicted:     42,   67.8, error:   25.8. Current MAE: 36.54, RMSE: 112.22:  20% 258/1286 [00:20<01:02, 16.34it/s]\n",
            "1397.jpg: actual-predicted:    166,   74.5, error:   91.5. Current MAE: 36.75, RMSE: 112.14:  20% 261/1286 [00:20<00:58, 17.49it/s]\n",
            "1890.jpg: actual-predicted:     76,   62.7, error:   13.3. Current MAE: 36.66, RMSE: 111.93:  20% 261/1286 [00:20<00:58, 17.49it/s]\n",
            "1891.jpg: actual-predicted:     31,   35.9, error:    4.9. Current MAE: 36.54, RMSE: 111.72:  20% 261/1286 [00:20<00:58, 17.49it/s]\n",
            "1892.jpg: actual-predicted:    180,  204.9, error:   24.9. Current MAE: 36.50, RMSE: 111.52:  21% 264/1286 [00:20<00:58, 17.37it/s]\n",
            "1894.jpg: actual-predicted:     32,   27.5, error:    4.5. Current MAE: 36.38, RMSE: 111.31:  21% 264/1286 [00:20<00:58, 17.37it/s]\n",
            "1895.jpg: actual-predicted:     30,   26.3, error:    3.7. Current MAE: 36.26, RMSE: 111.10:  21% 266/1286 [00:20<00:57, 17.88it/s]\n",
            "1896.jpg: actual-predicted:    123,  152.2, error:   29.2. Current MAE: 36.23, RMSE: 110.91:  21% 266/1286 [00:20<00:57, 17.88it/s]\n",
            "1897.jpg: actual-predicted:     12,   16.6, error:    4.6. Current MAE: 36.11, RMSE: 110.70:  21% 268/1286 [00:20<01:01, 16.64it/s]\n",
            "1898.jpg: actual-predicted:    149,  153.5, error:    4.5. Current MAE: 36.00, RMSE: 110.50:  21% 268/1286 [00:21<01:01, 16.64it/s]\n",
            "1899.jpg: actual-predicted:      8,    8.1, error:    0.1. Current MAE: 35.86, RMSE: 110.29:  21% 270/1286 [00:21<01:08, 14.94it/s]\n",
            "1900.jpg: actual-predicted:     12,   15.6, error:    3.6. Current MAE: 35.75, RMSE: 110.09:  21% 270/1286 [00:21<01:08, 14.94it/s]\n",
            "1901.jpg: actual-predicted:     17,   27.3, error:   10.3. Current MAE: 35.65, RMSE: 109.89:  21% 272/1286 [00:21<01:17, 13.05it/s]\n",
            "1902.jpg: actual-predicted:     94,   97.6, error:    3.6. Current MAE: 35.54, RMSE: 109.69:  21% 272/1286 [00:21<01:17, 13.05it/s]\n",
            "1903.jpg: actual-predicted:    139,  142.6, error:    3.6. Current MAE: 35.42, RMSE: 109.49:  21% 274/1286 [00:21<01:09, 14.51it/s]\n",
            "1906.jpg: actual-predicted:     70,   57.2, error:   12.8. Current MAE: 35.34, RMSE: 109.30:  21% 274/1286 [00:21<01:09, 14.51it/s]\n",
            "1907.jpg: actual-predicted:     28,   33.4, error:    5.4. Current MAE: 35.23, RMSE: 109.10:  21% 276/1286 [00:21<01:05, 15.38it/s]\n",
            "1910.jpg: actual-predicted:     28,   31.5, error:    3.5. Current MAE: 35.11, RMSE: 108.90:  21% 276/1286 [00:21<01:05, 15.38it/s]\n",
            "1911.jpg: actual-predicted:    119,  167.5, error:   48.5. Current MAE: 35.16, RMSE: 108.75:  22% 278/1286 [00:21<01:07, 15.03it/s]\n",
            "1912.jpg: actual-predicted:     46,   38.2, error:    7.8. Current MAE: 35.06, RMSE: 108.55:  22% 278/1286 [00:21<01:07, 15.03it/s]\n",
            "1913.jpg: actual-predicted:     50,   54.4, error:    4.4. Current MAE: 34.96, RMSE: 108.36:  22% 280/1286 [00:21<01:04, 15.63it/s]\n",
            "1915.jpg: actual-predicted:    684,  280.7, error:  403.3. Current MAE: 36.26, RMSE: 110.80:  22% 280/1286 [00:21<01:04, 15.63it/s]\n",
            "1916.jpg: actual-predicted:     20,   32.5, error:   12.5. Current MAE: 36.18, RMSE: 110.61:  22% 280/1286 [00:21<01:04, 15.63it/s]\n",
            "1917.jpg: actual-predicted:     17,   32.8, error:   15.8. Current MAE: 36.11, RMSE: 110.42:  22% 283/1286 [00:21<01:00, 16.46it/s]\n",
            "1918.jpg: actual-predicted:     18,   22.1, error:    4.1. Current MAE: 35.99, RMSE: 110.22:  22% 283/1286 [00:21<01:00, 16.46it/s]\n",
            "1919.jpg: actual-predicted:    436,  358.3, error:   77.7. Current MAE: 36.14, RMSE: 110.13:  22% 285/1286 [00:22<01:00, 16.62it/s]\n",
            "1920.jpg: actual-predicted:    138,  133.4, error:    4.6. Current MAE: 36.03, RMSE: 109.94:  22% 285/1286 [00:22<01:00, 16.62it/s]\n",
            "1921.jpg: actual-predicted:     49,   18.3, error:   30.7. Current MAE: 36.01, RMSE: 109.76:  22% 285/1286 [00:22<01:00, 16.62it/s]\n",
            "1922.jpg: actual-predicted:     45,   51.8, error:    6.8. Current MAE: 35.91, RMSE: 109.57:  22% 288/1286 [00:22<00:59, 16.88it/s]\n",
            "1924.jpg: actual-predicted:     48,   35.5, error:   12.5. Current MAE: 35.83, RMSE: 109.38:  22% 288/1286 [00:22<00:59, 16.88it/s]\n",
            "1925.jpg: actual-predicted:     29,   39.9, error:   10.9. Current MAE: 35.74, RMSE: 109.20:  23% 290/1286 [00:22<00:58, 16.97it/s]\n",
            "1927.jpg: actual-predicted:     68,   27.5, error:   40.5. Current MAE: 35.76, RMSE: 109.04:  23% 290/1286 [00:22<00:58, 16.97it/s]\n",
            "1928.jpg: actual-predicted:     13,   16.3, error:    3.3. Current MAE: 35.65, RMSE: 108.85:  23% 292/1286 [00:22<01:05, 15.19it/s]\n",
            "1929.jpg: actual-predicted:     86,  109.4, error:   23.4. Current MAE: 35.61, RMSE: 108.67:  23% 292/1286 [00:22<01:05, 15.19it/s]\n",
            "1930.jpg: actual-predicted:     18,   24.2, error:    6.2. Current MAE: 35.51, RMSE: 108.49:  23% 294/1286 [00:22<01:07, 14.74it/s]\n",
            "1931.jpg: actual-predicted:     54,   41.3, error:   12.7. Current MAE: 35.43, RMSE: 108.31:  23% 294/1286 [00:22<01:07, 14.74it/s]\n",
            "1933.jpg: actual-predicted:    215,  182.0, error:   33.0. Current MAE: 35.42, RMSE: 108.14:  23% 296/1286 [00:22<01:07, 14.67it/s]\n",
            "1934.jpg: actual-predicted:    171,  162.8, error:    8.2. Current MAE: 35.33, RMSE: 107.96:  23% 296/1286 [00:22<01:07, 14.67it/s]\n",
            "1935.jpg: actual-predicted:    175,  132.6, error:   42.4. Current MAE: 35.35, RMSE: 107.81:  23% 298/1286 [00:22<01:03, 15.66it/s]\n",
            "1936.jpg: actual-predicted:    501,  706.9, error:  205.9. Current MAE: 35.92, RMSE: 108.28:  23% 298/1286 [00:22<01:03, 15.66it/s]\n",
            "1937.jpg: actual-predicted:    117,  113.6, error:    3.4. Current MAE: 35.82, RMSE: 108.10:  23% 298/1286 [00:22<01:03, 15.66it/s]\n",
            "1938.jpg: actual-predicted:      9,   30.3, error:   21.3. Current MAE: 35.77, RMSE: 107.93:  23% 301/1286 [00:23<00:57, 17.05it/s]\n",
            "1939.jpg: actual-predicted:     69,   44.0, error:   25.0. Current MAE: 35.73, RMSE: 107.76:  23% 301/1286 [00:23<00:57, 17.05it/s]\n",
            "1942.jpg: actual-predicted:    163,  164.5, error:    1.5. Current MAE: 35.62, RMSE: 107.59:  24% 303/1286 [00:23<00:59, 16.39it/s]\n",
            "1943.jpg: actual-predicted:    221,  307.9, error:   86.9. Current MAE: 35.79, RMSE: 107.53:  24% 303/1286 [00:23<00:59, 16.39it/s]\n",
            "1944.jpg: actual-predicted:     48,   22.3, error:   25.7. Current MAE: 35.75, RMSE: 107.36:  24% 305/1286 [00:23<00:57, 17.01it/s]\n",
            "1945.jpg: actual-predicted:     44,   35.3, error:    8.7. Current MAE: 35.67, RMSE: 107.19:  24% 305/1286 [00:23<00:57, 17.01it/s]\n",
            "1946.jpg: actual-predicted:     40,   49.0, error:    9.0. Current MAE: 35.58, RMSE: 107.01:  24% 307/1286 [00:23<01:03, 15.52it/s]\n",
            "1947.jpg: actual-predicted:     12,   16.0, error:    4.0. Current MAE: 35.48, RMSE: 106.84:  24% 307/1286 [00:23<01:03, 15.52it/s]\n",
            "1948.jpg: actual-predicted:     22,   16.0, error:    6.0. Current MAE: 35.38, RMSE: 106.67:  24% 309/1286 [00:23<01:08, 14.27it/s]\n",
            "1949.jpg: actual-predicted:    150,  140.4, error:    9.6. Current MAE: 35.30, RMSE: 106.50:  24% 309/1286 [00:23<01:08, 14.27it/s]\n",
            "1950.jpg: actual-predicted:     21,   23.9, error:    2.9. Current MAE: 35.20, RMSE: 106.33:  24% 311/1286 [00:23<01:05, 14.91it/s]\n",
            "1951.jpg: actual-predicted:     19,   13.7, error:    5.3. Current MAE: 35.10, RMSE: 106.16:  24% 311/1286 [00:23<01:05, 14.91it/s]\n",
            "1952.jpg: actual-predicted:     37,   39.5, error:    2.5. Current MAE: 35.00, RMSE: 105.99:  24% 313/1286 [00:24<01:28, 10.96it/s]\n",
            "1955.jpg: actual-predicted:     13,   24.0, error:   11.0. Current MAE: 34.92, RMSE: 105.82:  24% 313/1286 [00:24<01:28, 10.96it/s]\n",
            "1956.jpg: actual-predicted:   1229,  760.3, error:  468.7. Current MAE: 36.29, RMSE: 108.89:  24% 315/1286 [00:24<01:20, 12.05it/s]\n",
            "1957.jpg: actual-predicted:     39,   49.6, error:   10.6. Current MAE: 36.21, RMSE: 108.72:  24% 315/1286 [00:24<01:20, 12.05it/s]\n",
            "1958.jpg: actual-predicted:     12,   23.0, error:   11.0. Current MAE: 36.13, RMSE: 108.55:  25% 317/1286 [00:24<01:15, 12.83it/s]\n",
            "1959.jpg: actual-predicted:     68,   33.9, error:   34.1. Current MAE: 36.13, RMSE: 108.40:  25% 317/1286 [00:24<01:15, 12.83it/s]\n",
            "1960.jpg: actual-predicted:    163,  146.5, error:   16.5. Current MAE: 36.06, RMSE: 108.24:  25% 319/1286 [00:24<01:10, 13.67it/s]\n",
            "1961.jpg: actual-predicted:    111,  101.1, error:    9.9. Current MAE: 35.98, RMSE: 108.07:  25% 319/1286 [00:24<01:10, 13.67it/s]\n",
            "1962.jpg: actual-predicted:     13,   16.8, error:    3.8. Current MAE: 35.88, RMSE: 107.90:  25% 321/1286 [00:24<01:05, 14.78it/s]\n",
            "1964.jpg: actual-predicted:      8,    9.7, error:    1.7. Current MAE: 35.78, RMSE: 107.73:  25% 321/1286 [00:24<01:05, 14.78it/s]\n",
            "1965.jpg: actual-predicted:     96,   84.9, error:   11.1. Current MAE: 35.70, RMSE: 107.57:  25% 323/1286 [00:24<01:13, 13.16it/s]\n",
            "1966.jpg: actual-predicted:     19,   27.0, error:    8.0. Current MAE: 35.62, RMSE: 107.40:  25% 323/1286 [00:24<01:13, 13.16it/s]\n",
            "1967.jpg: actual-predicted:     36,   29.9, error:    6.1. Current MAE: 35.53, RMSE: 107.24:  25% 325/1286 [00:24<01:07, 14.33it/s]\n",
            "1968.jpg: actual-predicted:     13,   17.0, error:    4.0. Current MAE: 35.43, RMSE: 107.08:  25% 325/1286 [00:24<01:07, 14.33it/s]\n",
            "1969.jpg: actual-predicted:    134,  111.0, error:   23.0. Current MAE: 35.39, RMSE: 106.92:  25% 327/1286 [00:24<01:06, 14.49it/s]\n",
            "1971.jpg: actual-predicted:     19,   14.9, error:    4.1. Current MAE: 35.30, RMSE: 106.76:  25% 327/1286 [00:25<01:06, 14.49it/s]\n",
            "1972.jpg: actual-predicted:      8,    9.2, error:    1.2. Current MAE: 35.19, RMSE: 106.60:  26% 329/1286 [00:25<01:06, 14.41it/s]\n",
            "1973.jpg: actual-predicted:     12,   17.4, error:    5.4. Current MAE: 35.10, RMSE: 106.44:  26% 329/1286 [00:25<01:06, 14.41it/s]\n",
            "1976.jpg: actual-predicted:     32,   15.0, error:   17.0. Current MAE: 35.05, RMSE: 106.28:  26% 331/1286 [00:25<01:15, 12.73it/s]\n",
            "1977.jpg: actual-predicted:    132,  114.5, error:   17.5. Current MAE: 35.00, RMSE: 106.12:  26% 331/1286 [00:25<01:15, 12.73it/s]\n",
            "1978.jpg: actual-predicted:     35,   30.7, error:    4.3. Current MAE: 34.90, RMSE: 105.96:  26% 333/1286 [00:25<01:16, 12.46it/s]\n",
            "1979.jpg: actual-predicted:     40,   38.8, error:    1.2. Current MAE: 34.80, RMSE: 105.81:  26% 333/1286 [00:25<01:16, 12.46it/s]\n",
            "1981.jpg: actual-predicted:    159,  181.2, error:   22.2. Current MAE: 34.77, RMSE: 105.66:  26% 335/1286 [00:25<01:19, 12.01it/s]\n",
            "1982.jpg: actual-predicted:      8,    7.9, error:    0.1. Current MAE: 34.66, RMSE: 105.50:  26% 335/1286 [00:25<01:19, 12.01it/s]\n",
            "1983.jpg: actual-predicted:    172,  141.6, error:   30.4. Current MAE: 34.65, RMSE: 105.36:  26% 337/1286 [00:25<01:14, 12.73it/s]\n",
            "1984.jpg: actual-predicted:     35,   42.7, error:    7.7. Current MAE: 34.57, RMSE: 105.20:  26% 337/1286 [00:25<01:14, 12.73it/s]\n",
            "1986.jpg: actual-predicted:    248,  123.2, error:  124.8. Current MAE: 34.84, RMSE: 105.26:  26% 339/1286 [00:25<01:11, 13.28it/s]\n",
            "1987.jpg: actual-predicted:     95,   48.4, error:   46.6. Current MAE: 34.87, RMSE: 105.14:  26% 339/1286 [00:25<01:11, 13.28it/s]\n",
            "1988.jpg: actual-predicted:     20,   27.7, error:    7.7. Current MAE: 34.79, RMSE: 104.99:  27% 341/1286 [00:26<01:07, 13.91it/s]\n",
            "1989.jpg: actual-predicted:    148,  129.5, error:   18.5. Current MAE: 34.74, RMSE: 104.84:  27% 341/1286 [00:26<01:07, 13.91it/s]\n",
            "1990.jpg: actual-predicted:    476,  288.4, error:  187.6. Current MAE: 35.19, RMSE: 105.17:  27% 343/1286 [00:26<01:07, 13.98it/s]\n",
            "1991.jpg: actual-predicted:    119,   79.5, error:   39.5. Current MAE: 35.20, RMSE: 105.04:  27% 343/1286 [00:26<01:07, 13.98it/s]\n",
            "1992.jpg: actual-predicted:     18,   27.0, error:    9.0. Current MAE: 35.12, RMSE: 104.89:  27% 345/1286 [00:26<01:03, 14.76it/s]\n",
            "1993.jpg: actual-predicted:     48,   47.5, error:    0.5. Current MAE: 35.03, RMSE: 104.74:  27% 345/1286 [00:26<01:03, 14.76it/s]\n",
            "1994.jpg: actual-predicted:    313,  407.4, error:   94.4. Current MAE: 35.20, RMSE: 104.71:  27% 347/1286 [00:26<01:07, 13.98it/s]\n",
            "1996.jpg: actual-predicted:     24,   31.4, error:    7.4. Current MAE: 35.12, RMSE: 104.56:  27% 347/1286 [00:26<01:07, 13.98it/s]\n",
            "1997.jpg: actual-predicted:     14,   13.4, error:    0.6. Current MAE: 35.02, RMSE: 104.41:  27% 349/1286 [00:26<01:04, 14.49it/s]\n",
            "1999.jpg: actual-predicted:     83,  125.6, error:   42.6. Current MAE: 35.04, RMSE: 104.29:  27% 349/1286 [00:26<01:04, 14.49it/s]\n",
            "2000.jpg: actual-predicted:     18,   41.5, error:   23.5. Current MAE: 35.01, RMSE: 104.15:  27% 351/1286 [00:26<01:05, 14.32it/s]\n",
            "2001.jpg: actual-predicted:    100,   83.4, error:   16.6. Current MAE: 34.95, RMSE: 104.00:  27% 351/1286 [00:26<01:05, 14.32it/s]\n",
            "2003.jpg: actual-predicted:     20,   12.1, error:    7.9. Current MAE: 34.88, RMSE: 103.86:  27% 353/1286 [00:26<01:00, 15.30it/s]\n",
            "2137.jpg: actual-predicted:     72,   75.1, error:    3.1. Current MAE: 34.79, RMSE: 103.71:  27% 353/1286 [00:26<01:00, 15.30it/s]\n",
            "2298.jpg: actual-predicted:      8,   17.1, error:    9.1. Current MAE: 34.72, RMSE: 103.57:  28% 355/1286 [00:27<01:09, 13.34it/s]\n",
            "2300.jpg: actual-predicted:     19,   29.2, error:   10.2. Current MAE: 34.65, RMSE: 103.42:  28% 355/1286 [00:27<01:09, 13.34it/s]\n",
            "2301.jpg: actual-predicted:     14,   38.4, error:   24.4. Current MAE: 34.62, RMSE: 103.29:  28% 357/1286 [00:27<01:05, 14.12it/s]\n",
            "2302.jpg: actual-predicted:     11,   29.1, error:   18.1. Current MAE: 34.57, RMSE: 103.15:  28% 357/1286 [00:27<01:05, 14.12it/s]\n",
            "2303.jpg: actual-predicted:     12,   21.0, error:    9.0. Current MAE: 34.50, RMSE: 103.01:  28% 359/1286 [00:27<01:01, 15.18it/s]\n",
            "2304.jpg: actual-predicted:      9,   14.9, error:    5.9. Current MAE: 34.42, RMSE: 102.86:  28% 359/1286 [00:27<01:01, 15.18it/s]\n",
            "2305.jpg: actual-predicted:     27,   43.6, error:   16.6. Current MAE: 34.37, RMSE: 102.72:  28% 361/1286 [00:27<01:01, 15.00it/s]\n",
            "2306.jpg: actual-predicted:     14,    7.4, error:    6.6. Current MAE: 34.30, RMSE: 102.58:  28% 361/1286 [00:27<01:01, 15.00it/s]\n",
            "2312.jpg: actual-predicted:     14,   10.8, error:    3.2. Current MAE: 34.21, RMSE: 102.44:  28% 363/1286 [00:27<01:03, 14.60it/s]\n",
            "2313.jpg: actual-predicted:      8,   11.1, error:    3.1. Current MAE: 34.13, RMSE: 102.30:  28% 363/1286 [00:27<01:03, 14.60it/s]\n",
            "2316.jpg: actual-predicted:     58,   33.1, error:   24.9. Current MAE: 34.10, RMSE: 102.17:  28% 365/1286 [00:27<01:02, 14.79it/s]\n",
            "2317.jpg: actual-predicted:     10,   13.0, error:    3.0. Current MAE: 34.02, RMSE: 102.03:  28% 365/1286 [00:27<01:02, 14.79it/s]\n",
            "2404.jpg: actual-predicted:      9,   46.5, error:   37.5. Current MAE: 34.02, RMSE: 101.91:  29% 367/1286 [00:27<01:04, 14.27it/s]\n",
            "2406.jpg: actual-predicted:     17,   15.0, error:    2.0. Current MAE: 33.94, RMSE: 101.77:  29% 367/1286 [00:27<01:04, 14.27it/s]\n",
            "2409.jpg: actual-predicted:     59,    2.3, error:   56.7. Current MAE: 34.00, RMSE: 101.68:  29% 369/1286 [00:27<01:01, 14.84it/s]\n",
            "2410.jpg: actual-predicted:     25,   45.6, error:   20.6. Current MAE: 33.96, RMSE: 101.55:  29% 369/1286 [00:28<01:01, 14.84it/s]\n",
            "2411.jpg: actual-predicted:      9,   19.6, error:   10.6. Current MAE: 33.90, RMSE: 101.41:  29% 371/1286 [00:28<01:10, 12.91it/s]\n",
            "2412.jpg: actual-predicted:     15,   14.9, error:    0.1. Current MAE: 33.81, RMSE: 101.28:  29% 371/1286 [00:28<01:10, 12.91it/s]\n",
            "2413.jpg: actual-predicted:      8,   15.6, error:    7.6. Current MAE: 33.74, RMSE: 101.14:  29% 373/1286 [00:28<01:11, 12.78it/s]\n",
            "2807.jpg: actual-predicted:    263,  259.1, error:    3.9. Current MAE: 33.66, RMSE: 101.01:  29% 373/1286 [00:28<01:11, 12.78it/s]\n",
            "2808.jpg: actual-predicted:     26,   20.6, error:    5.4. Current MAE: 33.58, RMSE: 100.87:  29% 375/1286 [00:28<01:04, 14.07it/s]\n",
            "2809.jpg: actual-predicted:     45,   50.7, error:    5.7. Current MAE: 33.51, RMSE: 100.74:  29% 375/1286 [00:28<01:04, 14.07it/s]\n",
            "2812.jpg: actual-predicted:    158,   24.9, error:  133.1. Current MAE: 33.77, RMSE: 100.84:  29% 377/1286 [00:28<01:10, 12.93it/s]\n",
            "2815.jpg: actual-predicted:     49,   27.7, error:   21.3. Current MAE: 33.74, RMSE: 100.71:  29% 377/1286 [00:28<01:10, 12.93it/s]\n",
            "2816.jpg: actual-predicted:     45,   48.3, error:    3.3. Current MAE: 33.66, RMSE: 100.58:  29% 379/1286 [00:28<01:16, 11.90it/s]\n",
            "2818.jpg: actual-predicted:    252,   54.2, error:  197.8. Current MAE: 34.09, RMSE: 100.96:  29% 379/1286 [00:28<01:16, 11.90it/s]\n",
            "2820.jpg: actual-predicted:     34,   12.5, error:   21.5. Current MAE: 34.06, RMSE: 100.83:  30% 381/1286 [00:28<01:14, 12.08it/s]\n",
            "2822.jpg: actual-predicted:    136,   32.9, error:  103.1. Current MAE: 34.24, RMSE: 100.84:  30% 381/1286 [00:29<01:14, 12.08it/s]\n",
            "2825.jpg: actual-predicted:      8,   12.1, error:    4.1. Current MAE: 34.16, RMSE: 100.71:  30% 383/1286 [00:29<01:15, 11.94it/s]\n",
            "2826.jpg: actual-predicted:     22,    3.5, error:   18.5. Current MAE: 34.12, RMSE: 100.58:  30% 383/1286 [00:29<01:15, 11.94it/s]\n",
            "2827.jpg: actual-predicted:    140,   85.3, error:   54.7. Current MAE: 34.17, RMSE: 100.49:  30% 385/1286 [00:29<01:21, 11.10it/s]\n",
            "2828.jpg: actual-predicted:     58,   88.2, error:   30.2. Current MAE: 34.16, RMSE: 100.37:  30% 385/1286 [00:29<01:21, 11.10it/s]\n",
            "2829.jpg: actual-predicted:     61,   30.5, error:   30.5. Current MAE: 34.15, RMSE: 100.25:  30% 387/1286 [00:29<01:13, 12.28it/s]\n",
            "2830.jpg: actual-predicted:     62,   33.9, error:   28.1. Current MAE: 34.14, RMSE: 100.13:  30% 387/1286 [00:29<01:13, 12.28it/s]\n",
            "2834.jpg: actual-predicted:      9,    8.3, error:    0.7. Current MAE: 34.05, RMSE: 100.00:  30% 389/1286 [00:29<01:10, 12.71it/s]\n",
            "2835.jpg: actual-predicted:     89,   26.1, error:   62.9. Current MAE: 34.13, RMSE: 99.93:  30% 389/1286 [00:29<01:10, 12.71it/s] \n",
            "2836.jpg: actual-predicted:      9,    7.9, error:    1.1. Current MAE: 34.04, RMSE: 99.80:  30% 391/1286 [00:29<01:15, 11.81it/s]\n",
            "2837.jpg: actual-predicted:     25,   19.7, error:    5.3. Current MAE: 33.97, RMSE: 99.67:  30% 391/1286 [00:29<01:15, 11.81it/s]\n",
            "2839.jpg: actual-predicted:     67,   23.4, error:   43.6. Current MAE: 33.99, RMSE: 99.57:  31% 393/1286 [00:29<01:12, 12.37it/s]\n",
            "2840.jpg: actual-predicted:     35,   23.2, error:   11.8. Current MAE: 33.94, RMSE: 99.45:  31% 393/1286 [00:29<01:12, 12.37it/s]\n",
            "2842.jpg: actual-predicted:    124,   37.9, error:   86.1. Current MAE: 34.07, RMSE: 99.41:  31% 395/1286 [00:30<01:06, 13.44it/s]\n",
            "2846.jpg: actual-predicted:     38,   16.8, error:   21.2. Current MAE: 34.04, RMSE: 99.29:  31% 395/1286 [00:30<01:06, 13.44it/s]\n",
            "2847.jpg: actual-predicted:     20,   26.7, error:    6.7. Current MAE: 33.97, RMSE: 99.17:  31% 397/1286 [00:30<01:05, 13.64it/s]\n",
            "2848.jpg: actual-predicted:     57,   47.7, error:    9.3. Current MAE: 33.91, RMSE: 99.05:  31% 397/1286 [00:30<01:05, 13.64it/s]\n",
            "2850.jpg: actual-predicted:    287,   94.5, error:  192.5. Current MAE: 34.30, RMSE: 99.39:  31% 399/1286 [00:30<01:05, 13.47it/s]\n",
            "2851.jpg: actual-predicted:     61,   17.6, error:   43.4. Current MAE: 34.33, RMSE: 99.29:  31% 399/1286 [00:30<01:05, 13.47it/s]\n",
            "2854.jpg: actual-predicted:     16,    3.8, error:   12.2. Current MAE: 34.27, RMSE: 99.17:  31% 401/1286 [00:30<01:04, 13.71it/s]\n",
            "2855.jpg: actual-predicted:     56,   42.9, error:   13.1. Current MAE: 34.22, RMSE: 99.05:  31% 401/1286 [00:30<01:04, 13.71it/s]\n",
            "2857.jpg: actual-predicted:    107,   52.3, error:   54.7. Current MAE: 34.27, RMSE: 98.96:  31% 403/1286 [00:30<01:05, 13.42it/s]\n",
            "2858.jpg: actual-predicted:    131,  216.9, error:   85.9. Current MAE: 34.40, RMSE: 98.93:  31% 403/1286 [00:30<01:05, 13.42it/s]\n",
            "2860.jpg: actual-predicted:     38,   38.8, error:    0.8. Current MAE: 34.31, RMSE: 98.81:  31% 405/1286 [00:30<01:02, 14.03it/s]\n",
            "2861.jpg: actual-predicted:     40,   19.5, error:   20.5. Current MAE: 34.28, RMSE: 98.69:  31% 405/1286 [00:30<01:02, 14.03it/s]\n",
            "2862.jpg: actual-predicted:     85,   43.8, error:   41.2. Current MAE: 34.30, RMSE: 98.59:  32% 407/1286 [00:30<01:04, 13.53it/s]\n",
            "2863.jpg: actual-predicted:    151,   73.1, error:   77.9. Current MAE: 34.40, RMSE: 98.55:  32% 407/1286 [00:30<01:04, 13.53it/s]\n",
            "2864.jpg: actual-predicted:     45,   21.5, error:   23.5. Current MAE: 34.38, RMSE: 98.44:  32% 409/1286 [00:31<01:00, 14.61it/s]\n",
            "2866.jpg: actual-predicted:     25,   28.0, error:    3.0. Current MAE: 34.30, RMSE: 98.32:  32% 409/1286 [00:31<01:00, 14.61it/s]\n",
            "2867.jpg: actual-predicted:      8,    9.3, error:    1.3. Current MAE: 34.22, RMSE: 98.20:  32% 411/1286 [00:31<01:03, 13.89it/s]\n",
            "2868.jpg: actual-predicted:     13,    4.7, error:    8.3. Current MAE: 34.16, RMSE: 98.08:  32% 411/1286 [00:31<01:03, 13.89it/s]\n",
            "2869.jpg: actual-predicted:    119,   79.6, error:   39.4. Current MAE: 34.17, RMSE: 97.98:  32% 413/1286 [00:31<01:18, 11.18it/s]\n",
            "2870.jpg: actual-predicted:     23,    0.9, error:   22.1. Current MAE: 34.14, RMSE: 97.87:  32% 413/1286 [00:31<01:18, 11.18it/s]\n",
            "2871.jpg: actual-predicted:     48,   31.9, error:   16.1. Current MAE: 34.10, RMSE: 97.75:  32% 415/1286 [00:31<01:25, 10.23it/s]\n",
            "2872.jpg: actual-predicted:     10,    3.6, error:    6.4. Current MAE: 34.03, RMSE: 97.64:  32% 415/1286 [00:31<01:25, 10.23it/s]\n",
            "2873.jpg: actual-predicted:     11,   19.9, error:    8.9. Current MAE: 33.97, RMSE: 97.52:  32% 417/1286 [00:31<01:24, 10.29it/s]\n",
            "2875.jpg: actual-predicted:     60,   72.2, error:   12.2. Current MAE: 33.92, RMSE: 97.40:  32% 417/1286 [00:31<01:24, 10.29it/s]\n",
            "2877.jpg: actual-predicted:    111,   46.5, error:   64.5. Current MAE: 33.99, RMSE: 97.34:  33% 419/1286 [00:32<01:17, 11.25it/s]\n",
            "2878.jpg: actual-predicted:    301,  170.6, error:  130.4. Current MAE: 34.22, RMSE: 97.43:  33% 419/1286 [00:32<01:17, 11.25it/s]\n",
            "2879.jpg: actual-predicted:    150,  122.2, error:   27.8. Current MAE: 34.21, RMSE: 97.33:  33% 421/1286 [00:32<01:10, 12.33it/s]\n",
            "2880.jpg: actual-predicted:    158,   38.8, error:  119.2. Current MAE: 34.41, RMSE: 97.38:  33% 421/1286 [00:32<01:10, 12.33it/s]\n",
            "2881.jpg: actual-predicted:    131,  120.1, error:   10.9. Current MAE: 34.35, RMSE: 97.27:  33% 423/1286 [00:32<01:06, 13.06it/s]\n",
            "2882.jpg: actual-predicted:    174,  180.2, error:    6.2. Current MAE: 34.28, RMSE: 97.16:  33% 423/1286 [00:32<01:06, 13.06it/s]\n",
            "2884.jpg: actual-predicted:    165,  142.4, error:   22.6. Current MAE: 34.26, RMSE: 97.05:  33% 425/1286 [00:32<01:01, 13.97it/s]\n",
            "2888.jpg: actual-predicted:     18,   32.2, error:   14.2. Current MAE: 34.21, RMSE: 96.94:  33% 425/1286 [00:32<01:01, 13.97it/s]\n",
            "2890.jpg: actual-predicted:     32,    4.7, error:   27.3. Current MAE: 34.19, RMSE: 96.83:  33% 427/1286 [00:32<01:07, 12.77it/s]\n",
            "2899.jpg: actual-predicted:     39,   23.1, error:   15.9. Current MAE: 34.15, RMSE: 96.72:  33% 427/1286 [00:32<01:07, 12.77it/s]\n",
            "2900.jpg: actual-predicted:     35,   37.5, error:    2.5. Current MAE: 34.08, RMSE: 96.61:  33% 429/1286 [00:32<01:09, 12.27it/s]\n",
            "2901.jpg: actual-predicted:      9,    1.1, error:    7.9. Current MAE: 34.02, RMSE: 96.50:  33% 429/1286 [00:33<01:09, 12.27it/s]\n",
            "2902.jpg: actual-predicted:     14,   40.8, error:   26.8. Current MAE: 34.00, RMSE: 96.39:  34% 431/1286 [00:33<01:36,  8.82it/s]\n",
            "2903.jpg: actual-predicted:     69,   53.7, error:   15.3. Current MAE: 33.96, RMSE: 96.29:  34% 431/1286 [00:33<01:36,  8.82it/s]\n",
            "2906.jpg: actual-predicted:     16,   28.4, error:   12.4. Current MAE: 33.91, RMSE: 96.18:  34% 433/1286 [00:33<01:23, 10.16it/s]\n",
            "3265.jpg: actual-predicted:     35,   34.7, error:    0.3. Current MAE: 33.83, RMSE: 96.07:  34% 433/1286 [00:33<01:23, 10.16it/s]\n",
            "3266.jpg: actual-predicted:     20,   29.8, error:    9.8. Current MAE: 33.77, RMSE: 95.96:  34% 435/1286 [00:33<01:15, 11.23it/s]\n",
            "3267.jpg: actual-predicted:     25,   24.9, error:    0.1. Current MAE: 33.70, RMSE: 95.85:  34% 435/1286 [00:33<01:15, 11.23it/s]\n",
            "3425.jpg: actual-predicted:    885, 1142.7, error:  257.7. Current MAE: 34.21, RMSE: 96.53:  34% 437/1286 [00:33<01:16, 11.05it/s]\n",
            "3426.jpg: actual-predicted:    219,  140.0, error:   79.0. Current MAE: 34.31, RMSE: 96.49:  34% 437/1286 [00:33<01:16, 11.05it/s]\n",
            "3427.jpg: actual-predicted:     24,   26.7, error:    2.7. Current MAE: 34.24, RMSE: 96.38:  34% 437/1286 [00:33<01:16, 11.05it/s]\n",
            "3428.jpg: actual-predicted:    458,  179.7, error:  278.3. Current MAE: 34.79, RMSE: 97.18:  34% 440/1286 [00:33<01:03, 13.38it/s]\n",
            "3430.jpg: actual-predicted:     36,   36.8, error:    0.8. Current MAE: 34.72, RMSE: 97.07:  34% 440/1286 [00:33<01:03, 13.38it/s]\n",
            "3431.jpg: actual-predicted:     75,   89.3, error:   14.3. Current MAE: 34.67, RMSE: 96.96:  34% 440/1286 [00:33<01:03, 13.38it/s]\n",
            "3432.jpg: actual-predicted:     49,   45.6, error:    3.4. Current MAE: 34.60, RMSE: 96.85:  34% 443/1286 [00:33<00:53, 15.65it/s]\n",
            "3433.jpg: actual-predicted:    538,  287.1, error:  250.9. Current MAE: 35.09, RMSE: 97.47:  34% 443/1286 [00:33<00:53, 15.65it/s]\n",
            "3434.jpg: actual-predicted:    305,  195.9, error:  109.1. Current MAE: 35.25, RMSE: 97.50:  34% 443/1286 [00:33<00:53, 15.65it/s]\n",
            "3435.jpg: actual-predicted:    116,  117.7, error:    1.7. Current MAE: 35.18, RMSE: 97.39:  35% 446/1286 [00:33<00:46, 17.94it/s]\n",
            "3436.jpg: actual-predicted:    443,  301.6, error:  141.4. Current MAE: 35.41, RMSE: 97.51:  35% 446/1286 [00:33<00:46, 17.94it/s]\n",
            "3437.jpg: actual-predicted:    501,  657.2, error:  156.2. Current MAE: 35.68, RMSE: 97.68:  35% 446/1286 [00:33<00:46, 17.94it/s]\n",
            "3438.jpg: actual-predicted:     60,   66.4, error:    6.4. Current MAE: 35.62, RMSE: 97.57:  35% 449/1286 [00:34<00:41, 20.03it/s]\n",
            "3476.jpg: actual-predicted:    262,  216.2, error:   45.8. Current MAE: 35.64, RMSE: 97.49:  35% 449/1286 [00:34<00:41, 20.03it/s]\n",
            "3477.jpg: actual-predicted:    344,  316.7, error:   27.3. Current MAE: 35.62, RMSE: 97.39:  35% 449/1286 [00:34<00:41, 20.03it/s]\n",
            "3478.jpg: actual-predicted:     41,   31.4, error:    9.6. Current MAE: 35.56, RMSE: 97.28:  35% 452/1286 [00:34<00:38, 21.40it/s]\n",
            "3481.jpg: actual-predicted:    431,  276.0, error:  155.0. Current MAE: 35.83, RMSE: 97.45:  35% 452/1286 [00:34<00:38, 21.40it/s]\n",
            "3482.jpg: actual-predicted:    315,  281.0, error:   34.0. Current MAE: 35.82, RMSE: 97.35:  35% 452/1286 [00:34<00:38, 21.40it/s]\n",
            "3483.jpg: actual-predicted:    261,   96.4, error:  164.6. Current MAE: 36.11, RMSE: 97.55:  35% 455/1286 [00:34<00:36, 22.97it/s]\n",
            "3484.jpg: actual-predicted:    356,   65.4, error:  290.6. Current MAE: 36.66, RMSE: 98.39:  35% 455/1286 [00:34<00:36, 22.97it/s]\n",
            "3485.jpg: actual-predicted:    174,  121.4, error:   52.6. Current MAE: 36.70, RMSE: 98.31:  35% 455/1286 [00:34<00:36, 22.97it/s]\n",
            "3486.jpg: actual-predicted:     81,  106.7, error:   25.7. Current MAE: 36.67, RMSE: 98.21:  36% 458/1286 [00:34<00:34, 23.69it/s]\n",
            "3487.jpg: actual-predicted:    321,  199.6, error:  121.4. Current MAE: 36.86, RMSE: 98.27:  36% 458/1286 [00:34<00:34, 23.69it/s]\n",
            "3488.jpg: actual-predicted:    431,  270.0, error:  161.0. Current MAE: 37.13, RMSE: 98.45:  36% 458/1286 [00:34<00:34, 23.69it/s]\n",
            "3489.jpg: actual-predicted:    278,  146.8, error:  131.2. Current MAE: 37.33, RMSE: 98.53:  36% 461/1286 [00:34<00:33, 24.39it/s]\n",
            "3490.jpg: actual-predicted:     64,   65.0, error:    1.0. Current MAE: 37.25, RMSE: 98.42:  36% 461/1286 [00:34<00:33, 24.39it/s]\n",
            "3491.jpg: actual-predicted:     69,   54.0, error:   15.0. Current MAE: 37.20, RMSE: 98.32:  36% 461/1286 [00:34<00:33, 24.39it/s]\n",
            "3492.jpg: actual-predicted:     25,   47.9, error:   22.9. Current MAE: 37.17, RMSE: 98.22:  36% 464/1286 [00:34<00:32, 25.25it/s]\n",
            "3518.jpg: actual-predicted:      8,    9.8, error:    1.8. Current MAE: 37.10, RMSE: 98.11:  36% 464/1286 [00:34<00:32, 25.25it/s]\n",
            "3519.jpg: actual-predicted:     30,   29.5, error:    0.5. Current MAE: 37.02, RMSE: 98.01:  36% 464/1286 [00:34<00:32, 25.25it/s]\n",
            "3520.jpg: actual-predicted:     10,    6.0, error:    4.0. Current MAE: 36.95, RMSE: 97.90:  36% 467/1286 [00:34<00:39, 20.70it/s]\n",
            "3521.jpg: actual-predicted:     27,   45.4, error:   18.4. Current MAE: 36.91, RMSE: 97.80:  36% 467/1286 [00:34<00:39, 20.70it/s]\n",
            "3522.jpg: actual-predicted:     27,   34.4, error:    7.4. Current MAE: 36.85, RMSE: 97.70:  36% 467/1286 [00:34<00:39, 20.70it/s]\n",
            "3524.jpg: actual-predicted:     42,   16.1, error:   25.9. Current MAE: 36.82, RMSE: 97.60:  37% 470/1286 [00:35<00:46, 17.71it/s]\n",
            "3525.jpg: actual-predicted:     11,   23.6, error:   12.6. Current MAE: 36.77, RMSE: 97.50:  37% 470/1286 [00:35<00:46, 17.71it/s]\n",
            "3526.jpg: actual-predicted:     18,   20.4, error:    2.4. Current MAE: 36.70, RMSE: 97.40:  37% 472/1286 [00:35<00:51, 15.84it/s]\n",
            "3527.jpg: actual-predicted:     12,   31.7, error:   19.7. Current MAE: 36.66, RMSE: 97.30:  37% 472/1286 [00:35<00:51, 15.84it/s]\n",
            "3528.jpg: actual-predicted:     29,   22.7, error:    6.3. Current MAE: 36.60, RMSE: 97.20:  37% 474/1286 [00:35<01:01, 13.22it/s]\n",
            "3529.jpg: actual-predicted:     30,   23.4, error:    6.6. Current MAE: 36.54, RMSE: 97.10:  37% 474/1286 [00:35<01:01, 13.22it/s]\n",
            "3530.jpg: actual-predicted:      8,    5.6, error:    2.4. Current MAE: 36.46, RMSE: 97.00:  37% 476/1286 [00:35<01:03, 12.75it/s]\n",
            "3531.jpg: actual-predicted:     11,   14.6, error:    3.6. Current MAE: 36.40, RMSE: 96.89:  37% 476/1286 [00:35<01:03, 12.75it/s]\n",
            "3532.jpg: actual-predicted:     20,    5.0, error:   15.0. Current MAE: 36.35, RMSE: 96.80:  37% 478/1286 [00:35<01:14, 10.83it/s]\n",
            "3533.jpg: actual-predicted:     23,   50.2, error:   27.2. Current MAE: 36.33, RMSE: 96.70:  37% 478/1286 [00:35<01:14, 10.83it/s]\n",
            "3534.jpg: actual-predicted:     11,   15.8, error:    4.8. Current MAE: 36.27, RMSE: 96.60:  37% 480/1286 [00:36<01:15, 10.74it/s]\n",
            "3535.jpg: actual-predicted:     24,   18.8, error:    5.2. Current MAE: 36.20, RMSE: 96.50:  37% 480/1286 [00:36<01:15, 10.74it/s]\n",
            "3536.jpg: actual-predicted:     18,   31.9, error:   13.9. Current MAE: 36.16, RMSE: 96.40:  37% 482/1286 [00:36<01:17, 10.43it/s]\n",
            "3538.jpg: actual-predicted:     19,    4.5, error:   14.5. Current MAE: 36.11, RMSE: 96.31:  37% 482/1286 [00:36<01:17, 10.43it/s]\n",
            "3539.jpg: actual-predicted:     11,   11.2, error:    0.2. Current MAE: 36.04, RMSE: 96.21:  38% 484/1286 [00:36<01:22,  9.74it/s]\n",
            "3540.jpg: actual-predicted:     28,   43.9, error:   15.9. Current MAE: 36.00, RMSE: 96.11:  38% 484/1286 [00:36<01:22,  9.74it/s]\n",
            "3541.jpg: actual-predicted:     10,    4.1, error:    5.9. Current MAE: 35.93, RMSE: 96.01:  38% 486/1286 [00:36<01:17, 10.27it/s]\n",
            "3542.jpg: actual-predicted:     11,   16.4, error:    5.4. Current MAE: 35.87, RMSE: 95.91:  38% 486/1286 [00:36<01:17, 10.27it/s]\n",
            "3543.jpg: actual-predicted:     30,   14.5, error:   15.5. Current MAE: 35.83, RMSE: 95.82:  38% 488/1286 [00:36<01:14, 10.68it/s]\n",
            "3544.jpg: actual-predicted:      9,    1.3, error:    7.7. Current MAE: 35.77, RMSE: 95.72:  38% 488/1286 [00:37<01:14, 10.68it/s]\n",
            "3546.jpg: actual-predicted:     16,   12.4, error:    3.6. Current MAE: 35.71, RMSE: 95.62:  38% 490/1286 [00:37<01:30,  8.76it/s]\n",
            "3547.jpg: actual-predicted:     21,    6.5, error:   14.5. Current MAE: 35.66, RMSE: 95.53:  38% 490/1286 [00:37<01:30,  8.76it/s]\n",
            "3548.jpg: actual-predicted:     24,   12.3, error:   11.7. Current MAE: 35.61, RMSE: 95.43:  38% 492/1286 [00:37<01:30,  8.77it/s]\n",
            "3549.jpg: actual-predicted:     10,    4.8, error:    5.2. Current MAE: 35.55, RMSE: 95.34:  38% 492/1286 [00:37<01:30,  8.77it/s]\n",
            "3550.jpg: actual-predicted:     18,   11.6, error:    6.4. Current MAE: 35.49, RMSE: 95.24:  38% 494/1286 [00:37<01:24,  9.33it/s]\n",
            "3552.jpg: actual-predicted:     17,   17.5, error:    0.5. Current MAE: 35.42, RMSE: 95.15:  38% 494/1286 [00:37<01:24,  9.33it/s]\n",
            "3553.jpg: actual-predicted:     16,   14.8, error:    1.2. Current MAE: 35.36, RMSE: 95.05:  39% 496/1286 [00:37<01:20,  9.80it/s]\n",
            "3554.jpg: actual-predicted:     15,   10.6, error:    4.4. Current MAE: 35.29, RMSE: 94.95:  39% 496/1286 [00:37<01:20,  9.80it/s]\n",
            "3556.jpg: actual-predicted:     20,   90.0, error:   70.0. Current MAE: 35.36, RMSE: 94.91:  39% 498/1286 [00:37<01:18,  9.99it/s]\n",
            "3558.jpg: actual-predicted:     20,   17.5, error:    2.5. Current MAE: 35.30, RMSE: 94.82:  39% 498/1286 [00:38<01:18,  9.99it/s]\n",
            "3559.jpg: actual-predicted:     22,   13.0, error:    9.0. Current MAE: 35.24, RMSE: 94.72:  39% 500/1286 [00:38<01:14, 10.58it/s]\n",
            "3560.jpg: actual-predicted:     23,    5.8, error:   17.2. Current MAE: 35.21, RMSE: 94.63:  39% 500/1286 [00:38<01:14, 10.58it/s]\n",
            "3561.jpg: actual-predicted:     19,    3.9, error:   15.1. Current MAE: 35.17, RMSE: 94.54:  39% 502/1286 [00:38<01:12, 10.88it/s]\n",
            "3562.jpg: actual-predicted:     22,   10.6, error:   11.4. Current MAE: 35.12, RMSE: 94.45:  39% 502/1286 [00:38<01:12, 10.88it/s]\n",
            "3563.jpg: actual-predicted:     13,    6.5, error:    6.5. Current MAE: 35.06, RMSE: 94.35:  39% 504/1286 [00:38<01:14, 10.49it/s]\n",
            "3564.jpg: actual-predicted:     20,   77.3, error:   57.3. Current MAE: 35.11, RMSE: 94.29:  39% 504/1286 [00:38<01:14, 10.49it/s]\n",
            "3565.jpg: actual-predicted:     22,    8.8, error:   13.2. Current MAE: 35.07, RMSE: 94.20:  39% 506/1286 [00:38<01:12, 10.71it/s]\n",
            "3566.jpg: actual-predicted:     17,    1.1, error:   15.9. Current MAE: 35.03, RMSE: 94.11:  39% 506/1286 [00:38<01:12, 10.71it/s]\n",
            "3567.jpg: actual-predicted:      8,    3.8, error:    4.2. Current MAE: 34.97, RMSE: 94.02:  40% 508/1286 [00:38<01:20,  9.67it/s]\n",
            "3568.jpg: actual-predicted:     23,    4.8, error:   18.2. Current MAE: 34.93, RMSE: 93.93:  40% 509/1286 [00:39<01:27,  8.92it/s]\n",
            "3569.jpg: actual-predicted:     10,   22.7, error:   12.7. Current MAE: 34.89, RMSE: 93.84:  40% 509/1286 [00:39<01:27,  8.92it/s]\n",
            "3570.jpg: actual-predicted:     12,   10.6, error:    1.4. Current MAE: 34.83, RMSE: 93.75:  40% 511/1286 [00:39<01:17, 10.02it/s]\n",
            "3571.jpg: actual-predicted:     25,   35.3, error:   10.3. Current MAE: 34.78, RMSE: 93.66:  40% 511/1286 [00:39<01:17, 10.02it/s]\n",
            "3572.jpg: actual-predicted:     30,   24.4, error:    5.6. Current MAE: 34.72, RMSE: 93.57:  40% 513/1286 [00:39<01:14, 10.36it/s]\n",
            "3573.jpg: actual-predicted:      9,    1.5, error:    7.5. Current MAE: 34.67, RMSE: 93.48:  40% 513/1286 [00:39<01:14, 10.36it/s]\n",
            "3574.jpg: actual-predicted:     42,   37.5, error:    4.5. Current MAE: 34.61, RMSE: 93.39:  40% 515/1286 [00:39<01:12, 10.58it/s]\n",
            "3575.jpg: actual-predicted:     32,   40.2, error:    8.2. Current MAE: 34.56, RMSE: 93.30:  40% 515/1286 [00:39<01:12, 10.58it/s]\n",
            "3576.jpg: actual-predicted:     26,   39.5, error:   13.5. Current MAE: 34.52, RMSE: 93.21:  40% 517/1286 [00:39<01:08, 11.22it/s]\n",
            "3578.jpg: actual-predicted:     13,    1.3, error:   11.7. Current MAE: 34.47, RMSE: 93.12:  40% 517/1286 [00:39<01:08, 11.22it/s]\n",
            "3580.jpg: actual-predicted:     11,   11.2, error:    0.2. Current MAE: 34.41, RMSE: 93.03:  40% 519/1286 [00:39<01:18,  9.80it/s]\n",
            "3581.jpg: actual-predicted:      8,    7.0, error:    1.0. Current MAE: 34.34, RMSE: 92.94:  40% 519/1286 [00:40<01:18,  9.80it/s]\n",
            "3582.jpg: actual-predicted:     37,    5.2, error:   31.8. Current MAE: 34.34, RMSE: 92.86:  41% 521/1286 [00:40<01:13, 10.47it/s]\n",
            "3583.jpg: actual-predicted:     20,   11.7, error:    8.3. Current MAE: 34.29, RMSE: 92.78:  41% 521/1286 [00:40<01:13, 10.47it/s]\n",
            "3584.jpg: actual-predicted:     22,   17.6, error:    4.4. Current MAE: 34.23, RMSE: 92.69:  41% 523/1286 [00:40<01:16, 10.04it/s]\n",
            "3585.jpg: actual-predicted:     12,   19.2, error:    7.2. Current MAE: 34.18, RMSE: 92.60:  41% 523/1286 [00:40<01:16, 10.04it/s]\n",
            "3586.jpg: actual-predicted:     20,   27.5, error:    7.5. Current MAE: 34.13, RMSE: 92.51:  41% 525/1286 [00:40<01:13, 10.36it/s]\n",
            "3587.jpg: actual-predicted:      9,    1.9, error:    7.1. Current MAE: 34.08, RMSE: 92.43:  41% 525/1286 [00:40<01:13, 10.36it/s]\n",
            "3588.jpg: actual-predicted:     22,   13.4, error:    8.6. Current MAE: 34.03, RMSE: 92.34:  41% 527/1286 [00:40<01:09, 10.87it/s]\n",
            "3591.jpg: actual-predicted:      9,   11.3, error:    2.3. Current MAE: 33.97, RMSE: 92.25:  41% 527/1286 [00:40<01:09, 10.87it/s]\n",
            "3592.jpg: actual-predicted:     12,    5.6, error:    6.4. Current MAE: 33.92, RMSE: 92.17:  41% 529/1286 [00:40<01:06, 11.42it/s]\n",
            "3660.jpg: actual-predicted:     18,   22.8, error:    4.8. Current MAE: 33.86, RMSE: 92.08:  41% 529/1286 [00:40<01:06, 11.42it/s]\n",
            "3661.jpg: actual-predicted:      9,   15.0, error:    6.0. Current MAE: 33.81, RMSE: 91.99:  41% 531/1286 [00:40<01:04, 11.76it/s]\n",
            "3662.jpg: actual-predicted:     10,   12.7, error:    2.7. Current MAE: 33.75, RMSE: 91.91:  41% 531/1286 [00:41<01:04, 11.76it/s]\n",
            "3663.jpg: actual-predicted:     17,   18.9, error:    1.9. Current MAE: 33.69, RMSE: 91.82:  41% 533/1286 [00:41<01:03, 11.94it/s]\n",
            "3664.jpg: actual-predicted:     50,   58.5, error:    8.5. Current MAE: 33.65, RMSE: 91.73:  41% 533/1286 [00:41<01:03, 11.94it/s]\n",
            "3665.jpg: actual-predicted:    907,  290.5, error:  616.5. Current MAE: 34.73, RMSE: 95.44:  42% 535/1286 [00:41<00:59, 12.57it/s]\n",
            "3666.jpg: actual-predicted:     32,   25.9, error:    6.1. Current MAE: 34.68, RMSE: 95.35:  42% 535/1286 [00:41<00:59, 12.57it/s]\n",
            "3668.jpg: actual-predicted:     31,   57.4, error:   26.4. Current MAE: 34.66, RMSE: 95.27:  42% 535/1286 [00:41<00:59, 12.57it/s]\n",
            "3669.jpg: actual-predicted:      8,    9.6, error:    1.6. Current MAE: 34.60, RMSE: 95.18:  42% 538/1286 [00:41<00:50, 14.69it/s]\n",
            "3670.jpg: actual-predicted:     36,   38.7, error:    2.7. Current MAE: 34.54, RMSE: 95.09:  42% 538/1286 [00:41<00:50, 14.69it/s]\n",
            "3671.jpg: actual-predicted:     15,   22.5, error:    7.5. Current MAE: 34.49, RMSE: 95.00:  42% 540/1286 [00:41<00:56, 13.25it/s]\n",
            "3672.jpg: actual-predicted:     12,   17.7, error:    5.7. Current MAE: 34.44, RMSE: 94.92:  42% 540/1286 [00:41<00:56, 13.25it/s]\n",
            "3673.jpg: actual-predicted:     46,   87.9, error:   41.9. Current MAE: 34.45, RMSE: 94.85:  42% 540/1286 [00:41<00:56, 13.25it/s]\n",
            "3674.jpg: actual-predicted:     33,   44.5, error:   11.5. Current MAE: 34.41, RMSE: 94.76:  42% 543/1286 [00:41<00:50, 14.83it/s]\n",
            "3675.jpg: actual-predicted:     10,   21.5, error:   11.5. Current MAE: 34.37, RMSE: 94.68:  42% 543/1286 [00:41<00:50, 14.83it/s]\n",
            "3757.jpg: actual-predicted:      8,    7.6, error:    0.4. Current MAE: 34.31, RMSE: 94.59:  42% 545/1286 [00:42<00:55, 13.32it/s]\n",
            "3758.jpg: actual-predicted:      9,    9.9, error:    0.9. Current MAE: 34.25, RMSE: 94.50:  42% 545/1286 [00:42<00:55, 13.32it/s]\n",
            "3759.jpg: actual-predicted:     12,   16.4, error:    4.4. Current MAE: 34.19, RMSE: 94.42:  43% 547/1286 [00:42<01:10, 10.48it/s]\n",
            "3760.jpg: actual-predicted:     12,    5.7, error:    6.3. Current MAE: 34.14, RMSE: 94.33:  43% 547/1286 [00:42<01:10, 10.48it/s]\n",
            "3761.jpg: actual-predicted:     12,   10.2, error:    1.8. Current MAE: 34.08, RMSE: 94.24:  43% 549/1286 [00:42<01:10, 10.51it/s]\n",
            "3762.jpg: actual-predicted:     11,   17.5, error:    6.5. Current MAE: 34.03, RMSE: 94.16:  43% 549/1286 [00:42<01:10, 10.51it/s]\n",
            "3763.jpg: actual-predicted:     16,   21.0, error:    5.0. Current MAE: 33.98, RMSE: 94.07:  43% 551/1286 [00:42<01:16,  9.59it/s]\n",
            "3764.jpg: actual-predicted:     12,   11.0, error:    1.0. Current MAE: 33.92, RMSE: 93.99:  43% 551/1286 [00:42<01:16,  9.59it/s]\n",
            "3765.jpg: actual-predicted:     12,   15.6, error:    3.6. Current MAE: 33.87, RMSE: 93.90:  43% 553/1286 [00:42<01:10, 10.43it/s]\n",
            "3766.jpg: actual-predicted:     12,   12.3, error:    0.3. Current MAE: 33.81, RMSE: 93.82:  43% 553/1286 [00:42<01:10, 10.43it/s]\n",
            "3767.jpg: actual-predicted:     20,   17.1, error:    2.9. Current MAE: 33.75, RMSE: 93.74:  43% 555/1286 [00:43<01:17,  9.48it/s]\n",
            "3768.jpg: actual-predicted:      9,   13.5, error:    4.5. Current MAE: 33.70, RMSE: 93.65:  43% 555/1286 [00:43<01:17,  9.48it/s]\n",
            "3769.jpg: actual-predicted:      9,   10.0, error:    1.0. Current MAE: 33.64, RMSE: 93.57:  43% 557/1286 [00:43<01:16,  9.54it/s]\n",
            "3770.jpg: actual-predicted:     10,   13.4, error:    3.4. Current MAE: 33.58, RMSE: 93.48:  43% 557/1286 [00:43<01:16,  9.54it/s]\n",
            "3771.jpg: actual-predicted:     10,   17.6, error:    7.6. Current MAE: 33.54, RMSE: 93.40:  43% 559/1286 [00:43<01:11, 10.17it/s]\n",
            "3772.jpg: actual-predicted:     16,   19.6, error:    3.6. Current MAE: 33.48, RMSE: 93.32:  43% 559/1286 [00:43<01:11, 10.17it/s]\n",
            "3773.jpg: actual-predicted:     12,    9.0, error:    3.0. Current MAE: 33.43, RMSE: 93.23:  44% 561/1286 [00:43<01:07, 10.81it/s]\n",
            "3774.jpg: actual-predicted:     31,   29.4, error:    1.6. Current MAE: 33.37, RMSE: 93.15:  44% 561/1286 [00:43<01:07, 10.81it/s]\n",
            "3775.jpg: actual-predicted:     12,   22.1, error:   10.1. Current MAE: 33.33, RMSE: 93.07:  44% 563/1286 [00:43<01:18,  9.21it/s]\n",
            "3777.jpg: actual-predicted:     14,   11.6, error:    2.4. Current MAE: 33.28, RMSE: 92.99:  44% 563/1286 [00:44<01:18,  9.21it/s]\n",
            "3778.jpg: actual-predicted:     12,   13.9, error:    1.9. Current MAE: 33.22, RMSE: 92.91:  44% 565/1286 [00:44<01:16,  9.45it/s]\n",
            "3779.jpg: actual-predicted:     12,   16.3, error:    4.3. Current MAE: 33.17, RMSE: 92.82:  44% 565/1286 [00:44<01:16,  9.45it/s]\n",
            "3780.jpg: actual-predicted:     11,   15.9, error:    4.9. Current MAE: 33.12, RMSE: 92.74:  44% 567/1286 [00:44<01:07, 10.63it/s]\n",
            "3781.jpg: actual-predicted:     10,   32.4, error:   22.4. Current MAE: 33.10, RMSE: 92.67:  44% 567/1286 [00:44<01:07, 10.63it/s]\n",
            "3782.jpg: actual-predicted:     12,   16.1, error:    4.1. Current MAE: 33.05, RMSE: 92.58:  44% 569/1286 [00:44<01:01, 11.69it/s]\n",
            "3783.jpg: actual-predicted:     11,   13.6, error:    2.6. Current MAE: 33.00, RMSE: 92.50:  44% 569/1286 [00:44<01:01, 11.69it/s]\n",
            "3784.jpg: actual-predicted:      8,    1.3, error:    6.7. Current MAE: 32.95, RMSE: 92.42:  44% 571/1286 [00:44<01:03, 11.18it/s]\n",
            "3785.jpg: actual-predicted:      9,   22.6, error:   13.6. Current MAE: 32.92, RMSE: 92.34:  44% 571/1286 [00:44<01:03, 11.18it/s]\n",
            "3870.jpg: actual-predicted:     17,   20.9, error:    3.9. Current MAE: 32.87, RMSE: 92.26:  45% 573/1286 [00:44<01:08, 10.37it/s]\n",
            "3871.jpg: actual-predicted:     31,   26.0, error:    5.0. Current MAE: 32.82, RMSE: 92.18:  45% 573/1286 [00:44<01:08, 10.37it/s]\n",
            "3872.jpg: actual-predicted:     20,   32.0, error:   12.0. Current MAE: 32.78, RMSE: 92.10:  45% 575/1286 [00:44<01:03, 11.17it/s]\n",
            "3873.jpg: actual-predicted:      7,    2.9, error:    4.1. Current MAE: 32.73, RMSE: 92.03:  45% 575/1286 [00:45<01:03, 11.17it/s]\n",
            "3979.jpg: actual-predicted:      9,    3.1, error:    5.9. Current MAE: 32.69, RMSE: 91.95:  45% 577/1286 [00:45<01:07, 10.47it/s]\n",
            "3980.jpg: actual-predicted:     16,    4.6, error:   11.4. Current MAE: 32.65, RMSE: 91.87:  45% 577/1286 [00:45<01:07, 10.47it/s]\n",
            "3981.jpg: actual-predicted:      8,    4.1, error:    3.9. Current MAE: 32.60, RMSE: 91.79:  45% 579/1286 [00:45<01:11,  9.88it/s]\n",
            "4091.jpg: actual-predicted:     40,   16.5, error:   23.5. Current MAE: 32.58, RMSE: 91.71:  45% 579/1286 [00:45<01:11,  9.88it/s]\n",
            "4092.jpg: actual-predicted:     19,   14.5, error:    4.5. Current MAE: 32.54, RMSE: 91.64:  45% 581/1286 [00:45<01:05, 10.75it/s]\n",
            "4093.jpg: actual-predicted:      8,   11.9, error:    3.9. Current MAE: 32.49, RMSE: 91.56:  45% 581/1286 [00:45<01:05, 10.75it/s]\n",
            "4094.jpg: actual-predicted:     14,   48.4, error:   34.4. Current MAE: 32.49, RMSE: 91.49:  45% 583/1286 [00:45<01:00, 11.70it/s]\n",
            "4095.jpg: actual-predicted:     11,   23.8, error:   12.8. Current MAE: 32.46, RMSE: 91.41:  45% 583/1286 [00:45<01:00, 11.70it/s]\n",
            "4096.jpg: actual-predicted:      8,   11.0, error:    3.0. Current MAE: 32.41, RMSE: 91.34:  45% 585/1286 [00:45<00:54, 12.89it/s]\n",
            "4097.jpg: actual-predicted:     20,   17.0, error:    3.0. Current MAE: 32.36, RMSE: 91.26:  45% 585/1286 [00:45<00:54, 12.89it/s]\n",
            "4098.jpg: actual-predicted:     17,   16.8, error:    0.2. Current MAE: 32.30, RMSE: 91.18:  46% 587/1286 [00:46<01:04, 10.87it/s]\n",
            "4101.jpg: actual-predicted:     10,   13.0, error:    3.0. Current MAE: 32.25, RMSE: 91.10:  46% 587/1286 [00:46<01:04, 10.87it/s]\n",
            "4102.jpg: actual-predicted:     15,   33.7, error:   18.7. Current MAE: 32.23, RMSE: 91.03:  46% 589/1286 [00:46<01:11,  9.70it/s]\n",
            "4103.jpg: actual-predicted:     12,    5.9, error:    6.1. Current MAE: 32.18, RMSE: 90.95:  46% 589/1286 [00:46<01:11,  9.70it/s]\n",
            "4104.jpg: actual-predicted:     44,   51.2, error:    7.2. Current MAE: 32.14, RMSE: 90.88:  46% 591/1286 [00:46<01:07, 10.30it/s]\n",
            "4105.jpg: actual-predicted:     12,   27.4, error:   15.4. Current MAE: 32.11, RMSE: 90.80:  46% 591/1286 [00:46<01:07, 10.30it/s]\n",
            "4106.jpg: actual-predicted:      9,   34.4, error:   25.4. Current MAE: 32.10, RMSE: 90.73:  46% 593/1286 [00:46<00:59, 11.57it/s]\n",
            "4107.jpg: actual-predicted:      9,    3.9, error:    5.1. Current MAE: 32.06, RMSE: 90.65:  46% 593/1286 [00:46<00:59, 11.57it/s]\n",
            "4108.jpg: actual-predicted:     49,   13.4, error:   35.6. Current MAE: 32.06, RMSE: 90.59:  46% 595/1286 [00:46<01:00, 11.47it/s]\n",
            "4109.jpg: actual-predicted:      9,   11.8, error:    2.8. Current MAE: 32.01, RMSE: 90.51:  46% 595/1286 [00:46<01:00, 11.47it/s]\n",
            "4137.jpg: actual-predicted:     13,   17.9, error:    4.9. Current MAE: 31.97, RMSE: 90.44:  46% 597/1286 [00:46<00:53, 12.80it/s]\n",
            "4139.jpg: actual-predicted:      8,   14.5, error:    6.5. Current MAE: 31.93, RMSE: 90.36:  46% 597/1286 [00:47<00:53, 12.80it/s]\n",
            "4163.jpg: actual-predicted:     26,   85.0, error:   59.0. Current MAE: 31.97, RMSE: 90.32:  47% 599/1286 [00:47<01:01, 11.21it/s]\n",
            "4164.jpg: actual-predicted:     14,   27.6, error:   13.6. Current MAE: 31.94, RMSE: 90.25:  47% 599/1286 [00:47<01:01, 11.21it/s]\n",
            "4165.jpg: actual-predicted:    104,   28.3, error:   75.7. Current MAE: 32.01, RMSE: 90.23:  47% 601/1286 [00:47<01:06, 10.33it/s]\n",
            "4167.jpg: actual-predicted:     10,   14.6, error:    4.6. Current MAE: 31.97, RMSE: 90.15:  47% 601/1286 [00:47<01:06, 10.33it/s]\n",
            "4168.jpg: actual-predicted:     25,   34.8, error:    9.8. Current MAE: 31.93, RMSE: 90.08:  47% 603/1286 [00:47<01:02, 10.91it/s]\n",
            "4529.jpg: actual-predicted:     12,   32.2, error:   20.2. Current MAE: 31.91, RMSE: 90.01:  47% 603/1286 [00:47<01:02, 10.91it/s]\n",
            "4530.jpg: actual-predicted:     44,   59.7, error:   15.7. Current MAE: 31.89, RMSE: 89.93:  47% 605/1286 [00:47<01:01, 11.10it/s]\n",
            "4532.jpg: actual-predicted:     22,   28.1, error:    6.1. Current MAE: 31.84, RMSE: 89.86:  47% 605/1286 [00:47<01:01, 11.10it/s]\n",
            "4533.jpg: actual-predicted:     14,   34.5, error:   20.5. Current MAE: 31.82, RMSE: 89.79:  47% 607/1286 [00:47<00:56, 12.09it/s]\n",
            "4534.jpg: actual-predicted:     11,   44.7, error:   33.7. Current MAE: 31.83, RMSE: 89.73:  47% 607/1286 [00:47<00:56, 12.09it/s]\n",
            "4535.jpg: actual-predicted:     22,   33.4, error:   11.4. Current MAE: 31.79, RMSE: 89.65:  47% 609/1286 [00:47<00:56, 12.00it/s]\n",
            "4536.jpg: actual-predicted:     27,   21.8, error:    5.2. Current MAE: 31.75, RMSE: 89.58:  47% 609/1286 [00:48<00:56, 12.00it/s]\n",
            "4537.jpg: actual-predicted:     51,   68.1, error:   17.1. Current MAE: 31.73, RMSE: 89.51:  48% 611/1286 [00:48<00:56, 11.86it/s]\n",
            "4538.jpg: actual-predicted:     16,   15.4, error:    0.6. Current MAE: 31.68, RMSE: 89.44:  48% 611/1286 [00:48<00:56, 11.86it/s]\n",
            "4539.jpg: actual-predicted:     16,   33.0, error:   17.0. Current MAE: 31.65, RMSE: 89.37:  48% 613/1286 [00:48<00:56, 11.91it/s]\n",
            "4540.jpg: actual-predicted:     23,   26.9, error:    3.9. Current MAE: 31.61, RMSE: 89.29:  48% 613/1286 [00:48<00:56, 11.91it/s]\n",
            "4541.jpg: actual-predicted:     13,   28.1, error:   15.1. Current MAE: 31.58, RMSE: 89.22:  48% 615/1286 [00:48<00:52, 12.74it/s]\n",
            "4542.jpg: actual-predicted:     17,   22.8, error:    5.8. Current MAE: 31.54, RMSE: 89.15:  48% 615/1286 [00:48<00:52, 12.74it/s]\n",
            "4543.jpg: actual-predicted:     23,   50.2, error:   27.2. Current MAE: 31.53, RMSE: 89.09:  48% 617/1286 [00:48<00:48, 13.87it/s]\n",
            "4544.jpg: actual-predicted:     33,   55.1, error:   22.1. Current MAE: 31.52, RMSE: 89.02:  48% 617/1286 [00:48<00:48, 13.87it/s]\n",
            "4545.jpg: actual-predicted:     21,   35.3, error:   14.3. Current MAE: 31.49, RMSE: 88.95:  48% 619/1286 [00:48<00:46, 14.43it/s]\n",
            "4546.jpg: actual-predicted:     35,   46.1, error:   11.1. Current MAE: 31.46, RMSE: 88.88:  48% 619/1286 [00:48<00:46, 14.43it/s]\n",
            "4547.jpg: actual-predicted:     35,   41.6, error:    6.6. Current MAE: 31.42, RMSE: 88.81:  48% 621/1286 [00:48<00:43, 15.40it/s]\n",
            "4548.jpg: actual-predicted:     55,   61.4, error:    6.4. Current MAE: 31.37, RMSE: 88.74:  48% 621/1286 [00:48<00:43, 15.40it/s]\n",
            "4549.jpg: actual-predicted:     33,   35.5, error:    2.5. Current MAE: 31.33, RMSE: 88.67:  48% 623/1286 [00:48<00:41, 15.89it/s]\n",
            "4551.jpg: actual-predicted:     42,   86.3, error:   44.3. Current MAE: 31.35, RMSE: 88.61:  48% 623/1286 [00:48<00:41, 15.89it/s]\n",
            "4552.jpg: actual-predicted:     17,   52.3, error:   35.3. Current MAE: 31.36, RMSE: 88.55:  49% 625/1286 [00:49<00:40, 16.43it/s]\n",
            "4554.jpg: actual-predicted:     65,   46.6, error:   18.4. Current MAE: 31.34, RMSE: 88.49:  49% 625/1286 [00:49<00:40, 16.43it/s]\n",
            "4555.jpg: actual-predicted:     10,   15.4, error:    5.4. Current MAE: 31.29, RMSE: 88.42:  49% 627/1286 [00:49<00:41, 15.79it/s]\n",
            "4556.jpg: actual-predicted:    133,  145.3, error:   12.3. Current MAE: 31.26, RMSE: 88.35:  49% 627/1286 [00:49<00:41, 15.79it/s]\n",
            "4557.jpg: actual-predicted:     29,   32.2, error:    3.2. Current MAE: 31.22, RMSE: 88.28:  49% 629/1286 [00:49<00:47, 13.88it/s]\n",
            "4558.jpg: actual-predicted:     13,   31.9, error:   18.9. Current MAE: 31.20, RMSE: 88.21:  49% 629/1286 [00:49<00:47, 13.88it/s]\n",
            "4559.jpg: actual-predicted:     35,   31.1, error:    3.9. Current MAE: 31.16, RMSE: 88.14:  49% 631/1286 [00:49<00:47, 13.71it/s]\n",
            "4560.jpg: actual-predicted:      9,   29.5, error:   20.5. Current MAE: 31.14, RMSE: 88.07:  49% 631/1286 [00:49<00:47, 13.71it/s]\n",
            "4561.jpg: actual-predicted:     11,   21.9, error:   10.9. Current MAE: 31.11, RMSE: 88.01:  49% 633/1286 [00:49<01:08,  9.58it/s]\n",
            "4562.jpg: actual-predicted:     11,   13.3, error:    2.3. Current MAE: 31.06, RMSE: 87.94:  49% 633/1286 [00:49<01:08,  9.58it/s]\n",
            "4563.jpg: actual-predicted:      8,   16.0, error:    8.0. Current MAE: 31.03, RMSE: 87.87:  49% 635/1286 [00:50<01:00, 10.85it/s]\n",
            "4564.jpg: actual-predicted:    133,  165.1, error:   32.1. Current MAE: 31.03, RMSE: 87.81:  49% 635/1286 [00:50<01:00, 10.85it/s]\n",
            "4565.jpg: actual-predicted:     24,   23.5, error:    0.5. Current MAE: 30.98, RMSE: 87.74:  50% 637/1286 [00:50<01:01, 10.56it/s]\n",
            "4566.jpg: actual-predicted:     37,   48.2, error:   11.2. Current MAE: 30.95, RMSE: 87.67:  50% 637/1286 [00:50<01:01, 10.56it/s]\n",
            "4567.jpg: actual-predicted:     13,   26.6, error:   13.6. Current MAE: 30.92, RMSE: 87.60:  50% 639/1286 [00:50<00:53, 12.13it/s]\n",
            "4568.jpg: actual-predicted:      9,   27.6, error:   18.6. Current MAE: 30.90, RMSE: 87.54:  50% 639/1286 [00:50<00:53, 12.13it/s]\n",
            "4569.jpg: actual-predicted:     21,   44.5, error:   23.5. Current MAE: 30.89, RMSE: 87.48:  50% 641/1286 [00:50<00:52, 12.21it/s]\n",
            "4570.jpg: actual-predicted:     11,   25.3, error:   14.3. Current MAE: 30.87, RMSE: 87.41:  50% 641/1286 [00:50<00:52, 12.21it/s]\n",
            "4571.jpg: actual-predicted:     47,   44.2, error:    2.8. Current MAE: 30.82, RMSE: 87.34:  50% 643/1286 [00:50<00:55, 11.69it/s]\n",
            "4572.jpg: actual-predicted:    141,  147.5, error:    6.5. Current MAE: 30.78, RMSE: 87.27:  50% 643/1286 [00:50<00:55, 11.69it/s]\n",
            "4573.jpg: actual-predicted:     36,  111.7, error:   75.7. Current MAE: 30.85, RMSE: 87.26:  50% 645/1286 [00:50<00:48, 13.18it/s]\n",
            "4574.jpg: actual-predicted:    402,  287.9, error:  114.1. Current MAE: 30.98, RMSE: 87.31:  50% 645/1286 [00:50<00:48, 13.18it/s]\n",
            "4575.jpg: actual-predicted:     22,   53.9, error:   31.9. Current MAE: 30.98, RMSE: 87.25:  50% 647/1286 [00:50<00:45, 13.97it/s]\n",
            "4576.jpg: actual-predicted:     38,   47.7, error:    9.7. Current MAE: 30.95, RMSE: 87.18:  50% 647/1286 [00:50<00:45, 13.97it/s]\n",
            "4577.jpg: actual-predicted:     37,   33.2, error:    3.8. Current MAE: 30.91, RMSE: 87.11:  50% 649/1286 [00:50<00:44, 14.30it/s]\n",
            "4578.jpg: actual-predicted:     24,   27.3, error:    3.3. Current MAE: 30.87, RMSE: 87.05:  50% 649/1286 [00:51<00:44, 14.30it/s]\n",
            "4579.jpg: actual-predicted:     34,   71.5, error:   37.5. Current MAE: 30.88, RMSE: 86.99:  51% 651/1286 [00:51<00:44, 14.41it/s]\n",
            "4580.jpg: actual-predicted:    165,  168.9, error:    3.9. Current MAE: 30.84, RMSE: 86.93:  51% 651/1286 [00:51<00:44, 14.41it/s]\n",
            "4581.jpg: actual-predicted:     42,   38.2, error:    3.8. Current MAE: 30.79, RMSE: 86.86:  51% 653/1286 [00:51<00:43, 14.52it/s]\n",
            "4582.jpg: actual-predicted:     16,   32.1, error:   16.1. Current MAE: 30.77, RMSE: 86.80:  51% 653/1286 [00:51<00:43, 14.52it/s]\n",
            "4583.jpg: actual-predicted:     15,   22.6, error:    7.6. Current MAE: 30.74, RMSE: 86.73:  51% 655/1286 [00:51<00:40, 15.47it/s]\n",
            "4584.jpg: actual-predicted:     10,   12.6, error:    2.6. Current MAE: 30.69, RMSE: 86.66:  51% 655/1286 [00:51<00:40, 15.47it/s]\n",
            "4585.jpg: actual-predicted:     12,   10.5, error:    1.5. Current MAE: 30.65, RMSE: 86.60:  51% 657/1286 [00:51<00:47, 13.28it/s]\n",
            "4586.jpg: actual-predicted:     12,   18.6, error:    6.6. Current MAE: 30.61, RMSE: 86.53:  51% 657/1286 [00:51<00:47, 13.28it/s]\n",
            "4587.jpg: actual-predicted:     33,   35.6, error:    2.6. Current MAE: 30.57, RMSE: 86.47:  51% 659/1286 [00:51<00:57, 10.86it/s]\n",
            "4588.jpg: actual-predicted:      8,   10.3, error:    2.3. Current MAE: 30.53, RMSE: 86.40:  51% 659/1286 [00:51<00:57, 10.86it/s]\n",
            "4589.jpg: actual-predicted:     34,   16.8, error:   17.2. Current MAE: 30.51, RMSE: 86.34:  51% 661/1286 [00:52<00:56, 11.14it/s]\n",
            "4590.jpg: actual-predicted:      8,   10.0, error:    2.0. Current MAE: 30.46, RMSE: 86.27:  51% 661/1286 [00:52<00:56, 11.14it/s]\n",
            "4591.jpg: actual-predicted:     38,   25.0, error:   13.0. Current MAE: 30.44, RMSE: 86.21:  52% 663/1286 [00:52<00:58, 10.71it/s]\n",
            "4593.jpg: actual-predicted:     14,   14.8, error:    0.8. Current MAE: 30.39, RMSE: 86.15:  52% 663/1286 [00:52<00:58, 10.71it/s]\n",
            "4594.jpg: actual-predicted:     34,   18.9, error:   15.1. Current MAE: 30.37, RMSE: 86.08:  52% 665/1286 [00:52<00:58, 10.60it/s]\n",
            "4595.jpg: actual-predicted:     16,   11.9, error:    4.1. Current MAE: 30.33, RMSE: 86.02:  52% 665/1286 [00:52<00:58, 10.60it/s]\n",
            "4596.jpg: actual-predicted:     24,   24.6, error:    0.6. Current MAE: 30.29, RMSE: 85.95:  52% 667/1286 [00:52<00:56, 10.90it/s]\n",
            "4597.jpg: actual-predicted:     64,   92.0, error:   28.0. Current MAE: 30.28, RMSE: 85.90:  52% 667/1286 [00:52<00:56, 10.90it/s]\n",
            "4598.jpg: actual-predicted:     22,    9.0, error:   13.0. Current MAE: 30.26, RMSE: 85.83:  52% 669/1286 [00:52<01:00, 10.18it/s]\n",
            "4599.jpg: actual-predicted:     19,    9.8, error:    9.2. Current MAE: 30.23, RMSE: 85.77:  52% 669/1286 [00:52<01:00, 10.18it/s]\n",
            "4600.jpg: actual-predicted:     41,   48.1, error:    7.1. Current MAE: 30.19, RMSE: 85.71:  52% 671/1286 [00:52<00:58, 10.50it/s]\n",
            "4601.jpg: actual-predicted:      8,    7.3, error:    0.7. Current MAE: 30.15, RMSE: 85.64:  52% 671/1286 [00:53<00:58, 10.50it/s]\n",
            "4602.jpg: actual-predicted:     54,   49.1, error:    4.9. Current MAE: 30.11, RMSE: 85.58:  52% 673/1286 [00:53<00:58, 10.52it/s]\n",
            "4603.jpg: actual-predicted:     25,   44.8, error:   19.8. Current MAE: 30.09, RMSE: 85.52:  52% 673/1286 [00:53<00:58, 10.52it/s]\n",
            "4604.jpg: actual-predicted:     87,  100.0, error:   13.0. Current MAE: 30.07, RMSE: 85.46:  52% 675/1286 [00:53<00:54, 11.30it/s]\n",
            "4605.jpg: actual-predicted:     34,   33.3, error:    0.7. Current MAE: 30.03, RMSE: 85.40:  52% 675/1286 [00:53<00:54, 11.30it/s]\n",
            "4606.jpg: actual-predicted:     54,   56.0, error:    2.0. Current MAE: 29.98, RMSE: 85.33:  53% 677/1286 [00:53<00:49, 12.31it/s]\n",
            "4607.jpg: actual-predicted:     13,   11.4, error:    1.6. Current MAE: 29.94, RMSE: 85.27:  53% 677/1286 [00:53<00:49, 12.31it/s]\n",
            "4608.jpg: actual-predicted:     19,   44.4, error:   25.4. Current MAE: 29.94, RMSE: 85.21:  53% 679/1286 [00:53<00:45, 13.21it/s]\n",
            "4611.jpg: actual-predicted:     51,   44.2, error:    6.8. Current MAE: 29.90, RMSE: 85.15:  53% 679/1286 [00:53<00:45, 13.21it/s]\n",
            "4703.jpg: actual-predicted:     13,   23.0, error:   10.0. Current MAE: 29.87, RMSE: 85.09:  53% 681/1286 [00:53<00:45, 13.23it/s]\n",
            "4704.jpg: actual-predicted:      8,    9.0, error:    1.0. Current MAE: 29.83, RMSE: 85.03:  53% 681/1286 [00:53<00:45, 13.23it/s]\n",
            "4705.jpg: actual-predicted:     47,   39.6, error:    7.4. Current MAE: 29.80, RMSE: 84.96:  53% 683/1286 [00:53<00:44, 13.67it/s]\n",
            "4706.jpg: actual-predicted:     14,   30.4, error:   16.4. Current MAE: 29.78, RMSE: 84.91:  53% 683/1286 [00:53<00:44, 13.67it/s]\n",
            "4707.jpg: actual-predicted:      8,   11.7, error:    3.7. Current MAE: 29.74, RMSE: 84.84:  53% 685/1286 [00:53<00:42, 14.16it/s]\n",
            "4708.jpg: actual-predicted:     21,   57.2, error:   36.2. Current MAE: 29.75, RMSE: 84.79:  53% 685/1286 [00:54<00:42, 14.16it/s]\n",
            "4709.jpg: actual-predicted:     13,   24.1, error:   11.1. Current MAE: 29.72, RMSE: 84.73:  53% 687/1286 [00:54<00:40, 14.66it/s]\n",
            "4710.jpg: actual-predicted:     10,   41.3, error:   31.3. Current MAE: 29.72, RMSE: 84.68:  53% 687/1286 [00:54<00:40, 14.66it/s]\n",
            "4711.jpg: actual-predicted:    117,  108.1, error:    8.9. Current MAE: 29.69, RMSE: 84.62:  53% 687/1286 [00:54<00:40, 14.66it/s]\n",
            "4713.jpg: actual-predicted:     18,   27.2, error:    9.2. Current MAE: 29.67, RMSE: 84.56:  54% 690/1286 [00:54<00:37, 15.69it/s]\n",
            "4715.jpg: actual-predicted:      8,   50.2, error:   42.2. Current MAE: 29.68, RMSE: 84.51:  54% 690/1286 [00:54<00:37, 15.69it/s]\n",
            "4716.jpg: actual-predicted:     26,   35.1, error:    9.1. Current MAE: 29.65, RMSE: 84.45:  54% 692/1286 [00:54<00:37, 15.69it/s]\n",
            "4718.jpg: actual-predicted:     15,   24.1, error:    9.1. Current MAE: 29.62, RMSE: 84.39:  54% 692/1286 [00:54<00:37, 15.69it/s]\n",
            "4719.jpg: actual-predicted:     33,   31.8, error:    1.2. Current MAE: 29.58, RMSE: 84.33:  54% 694/1286 [00:54<00:37, 15.85it/s]\n",
            "4720.jpg: actual-predicted:      9,   33.2, error:   24.2. Current MAE: 29.58, RMSE: 84.28:  54% 694/1286 [00:54<00:37, 15.85it/s]\n",
            "4721.jpg: actual-predicted:     17,   34.3, error:   17.3. Current MAE: 29.56, RMSE: 84.22:  54% 696/1286 [00:54<00:35, 16.47it/s]\n",
            "4722.jpg: actual-predicted:     14,   21.8, error:    7.8. Current MAE: 29.53, RMSE: 84.16:  54% 696/1286 [00:54<00:35, 16.47it/s]\n",
            "4723.jpg: actual-predicted:      9,   27.8, error:   18.8. Current MAE: 29.51, RMSE: 84.10:  54% 698/1286 [00:54<00:35, 16.40it/s]\n",
            "4724.jpg: actual-predicted:     15,   58.0, error:   43.0. Current MAE: 29.53, RMSE: 84.06:  54% 698/1286 [00:54<00:35, 16.40it/s]\n",
            "4725.jpg: actual-predicted:      9,    8.4, error:    0.6. Current MAE: 29.49, RMSE: 84.00:  54% 700/1286 [00:54<00:36, 16.15it/s]\n",
            "4726.jpg: actual-predicted:      8,   22.6, error:   14.6. Current MAE: 29.47, RMSE: 83.94:  54% 700/1286 [00:54<00:36, 16.15it/s]\n",
            "4727.jpg: actual-predicted:     21,   43.5, error:   22.5. Current MAE: 29.46, RMSE: 83.88:  55% 702/1286 [00:55<00:43, 13.38it/s]\n",
            "4728.jpg: actual-predicted:     11,   55.8, error:   44.8. Current MAE: 29.48, RMSE: 83.84:  55% 702/1286 [00:55<00:43, 13.38it/s]\n",
            "4729.jpg: actual-predicted:     23,   45.0, error:   22.0. Current MAE: 29.47, RMSE: 83.78:  55% 704/1286 [00:55<00:44, 13.18it/s]\n",
            "4730.jpg: actual-predicted:     15,   17.7, error:    2.7. Current MAE: 29.43, RMSE: 83.73:  55% 704/1286 [00:55<00:44, 13.18it/s]\n",
            "4731.jpg: actual-predicted:     12,   16.7, error:    4.7. Current MAE: 29.40, RMSE: 83.67:  55% 706/1286 [00:55<00:40, 14.33it/s]\n",
            "4732.jpg: actual-predicted:     56,   54.0, error:    2.0. Current MAE: 29.36, RMSE: 83.61:  55% 706/1286 [00:55<00:40, 14.33it/s]\n",
            "4733.jpg: actual-predicted:      9,   37.5, error:   28.5. Current MAE: 29.36, RMSE: 83.55:  55% 706/1286 [00:55<00:40, 14.33it/s]\n",
            "4734.jpg: actual-predicted:    104,  106.8, error:    2.8. Current MAE: 29.32, RMSE: 83.50:  55% 709/1286 [00:55<00:37, 15.29it/s]\n",
            "4735.jpg: actual-predicted:     13,    6.1, error:    6.9. Current MAE: 29.29, RMSE: 83.44:  55% 709/1286 [00:55<00:37, 15.29it/s]\n",
            "4736.jpg: actual-predicted:     28,   67.4, error:   39.4. Current MAE: 29.30, RMSE: 83.39:  55% 711/1286 [00:55<00:41, 13.73it/s]\n",
            "4737.jpg: actual-predicted:      9,    8.6, error:    0.4. Current MAE: 29.26, RMSE: 83.33:  55% 711/1286 [00:55<00:41, 13.73it/s]\n",
            "4738.jpg: actual-predicted:     23,   16.5, error:    6.5. Current MAE: 29.23, RMSE: 83.28:  55% 713/1286 [00:55<00:42, 13.44it/s]\n",
            "4739.jpg: actual-predicted:     40,   28.1, error:   11.9. Current MAE: 29.21, RMSE: 83.22:  55% 713/1286 [00:55<00:42, 13.44it/s]\n",
            "4740.jpg: actual-predicted:     14,   12.1, error:    1.9. Current MAE: 29.17, RMSE: 83.16:  56% 715/1286 [00:56<00:48, 11.88it/s]\n",
            "4741.jpg: actual-predicted:     41,   38.3, error:    2.7. Current MAE: 29.13, RMSE: 83.10:  56% 715/1286 [00:56<00:48, 11.88it/s]\n",
            "4742.jpg: actual-predicted:     47,   52.2, error:    5.2. Current MAE: 29.10, RMSE: 83.04:  56% 717/1286 [00:56<00:55, 10.18it/s]\n",
            "4743.jpg: actual-predicted:      8,    7.4, error:    0.6. Current MAE: 29.06, RMSE: 82.99:  56% 717/1286 [00:56<00:55, 10.18it/s]\n",
            "4744.jpg: actual-predicted:     41,   35.7, error:    5.3. Current MAE: 29.02, RMSE: 82.93:  56% 719/1286 [00:56<00:53, 10.52it/s]\n",
            "4745.jpg: actual-predicted:     24,   14.2, error:    9.8. Current MAE: 29.00, RMSE: 82.87:  56% 719/1286 [00:56<00:53, 10.52it/s]\n",
            "4746.jpg: actual-predicted:     39,   64.9, error:   25.9. Current MAE: 28.99, RMSE: 82.82:  56% 721/1286 [00:56<00:52, 10.84it/s]\n",
            "4747.jpg: actual-predicted:     55,   50.0, error:    5.0. Current MAE: 28.96, RMSE: 82.76:  56% 721/1286 [00:56<00:52, 10.84it/s]\n",
            "4748.jpg: actual-predicted:     20,   27.1, error:    7.1. Current MAE: 28.93, RMSE: 82.71:  56% 723/1286 [00:56<00:47, 11.84it/s]\n",
            "4749.jpg: actual-predicted:    133,  125.7, error:    7.3. Current MAE: 28.90, RMSE: 82.65:  56% 723/1286 [00:56<00:47, 11.84it/s]\n",
            "4750.jpg: actual-predicted:     39,   30.5, error:    8.5. Current MAE: 28.87, RMSE: 82.59:  56% 725/1286 [00:56<00:47, 11.78it/s]\n",
            "4751.jpg: actual-predicted:     42,   38.6, error:    3.4. Current MAE: 28.84, RMSE: 82.54:  56% 725/1286 [00:57<00:47, 11.78it/s]\n",
            "4752.jpg: actual-predicted:     40,   70.1, error:   30.1. Current MAE: 28.84, RMSE: 82.49:  57% 727/1286 [00:57<00:45, 12.16it/s]\n",
            "4753.jpg: actual-predicted:     22,    9.2, error:   12.8. Current MAE: 28.82, RMSE: 82.43:  57% 727/1286 [00:57<00:45, 12.16it/s]\n",
            "4754.jpg: actual-predicted:     20,   30.4, error:   10.4. Current MAE: 28.79, RMSE: 82.38:  57% 729/1286 [00:57<00:49, 11.14it/s]\n",
            "4755.jpg: actual-predicted:    109,  102.2, error:    6.8. Current MAE: 28.76, RMSE: 82.32:  57% 729/1286 [00:57<00:49, 11.14it/s]\n",
            "4756.jpg: actual-predicted:     14,   26.5, error:   12.5. Current MAE: 28.74, RMSE: 82.27:  57% 731/1286 [00:57<00:44, 12.48it/s]\n",
            "4758.jpg: actual-predicted:     42,   46.7, error:    4.7. Current MAE: 28.71, RMSE: 82.21:  57% 731/1286 [00:57<00:44, 12.48it/s]\n",
            "4759.jpg: actual-predicted:     22,   17.6, error:    4.4. Current MAE: 28.67, RMSE: 82.15:  57% 733/1286 [00:57<00:40, 13.60it/s]\n",
            "4760.jpg: actual-predicted:     30,   35.6, error:    5.6. Current MAE: 28.64, RMSE: 82.10:  57% 733/1286 [00:57<00:40, 13.60it/s]\n",
            "4761.jpg: actual-predicted:     24,   23.1, error:    0.9. Current MAE: 28.60, RMSE: 82.04:  57% 735/1286 [00:57<00:46, 11.74it/s]\n",
            "4762.jpg: actual-predicted:     21,   14.9, error:    6.1. Current MAE: 28.57, RMSE: 81.99:  57% 735/1286 [00:57<00:46, 11.74it/s]\n",
            "4763.jpg: actual-predicted:    114,  108.4, error:    5.6. Current MAE: 28.54, RMSE: 81.93:  57% 737/1286 [00:57<00:47, 11.48it/s]\n",
            "4764.jpg: actual-predicted:     21,   19.7, error:    1.3. Current MAE: 28.51, RMSE: 81.88:  57% 737/1286 [00:58<00:47, 11.48it/s]\n",
            "4765.jpg: actual-predicted:     14,   16.4, error:    2.4. Current MAE: 28.47, RMSE: 81.82:  57% 739/1286 [00:58<00:45, 12.11it/s]\n",
            "4794.jpg: actual-predicted:     55,   45.5, error:    9.5. Current MAE: 28.44, RMSE: 81.77:  57% 739/1286 [00:58<00:45, 12.11it/s]\n",
            "4795.jpg: actual-predicted:     11,    9.5, error:    1.5. Current MAE: 28.41, RMSE: 81.71:  58% 741/1286 [00:58<00:40, 13.32it/s]\n",
            "4796.jpg: actual-predicted:    196,  146.9, error:   49.1. Current MAE: 28.44, RMSE: 81.68:  58% 741/1286 [00:58<00:40, 13.32it/s]\n",
            "4797.jpg: actual-predicted:     80,   98.4, error:   18.4. Current MAE: 28.42, RMSE: 81.63:  58% 743/1286 [00:58<00:38, 14.05it/s]\n",
            "4798.jpg: actual-predicted:     15,   15.4, error:    0.4. Current MAE: 28.39, RMSE: 81.57:  58% 743/1286 [00:58<00:38, 14.05it/s]\n",
            "4799.jpg: actual-predicted:    122,  113.7, error:    8.3. Current MAE: 28.36, RMSE: 81.52:  58% 745/1286 [00:58<00:36, 14.67it/s]\n",
            "4800.jpg: actual-predicted:     32,   18.1, error:   13.9. Current MAE: 28.34, RMSE: 81.46:  58% 745/1286 [00:58<00:36, 14.67it/s]\n",
            "4801.jpg: actual-predicted:     60,   57.6, error:    2.4. Current MAE: 28.30, RMSE: 81.41:  58% 747/1286 [00:58<00:35, 15.34it/s]\n",
            "4802.jpg: actual-predicted:     61,   46.7, error:   14.3. Current MAE: 28.29, RMSE: 81.36:  58% 747/1286 [00:58<00:35, 15.34it/s]\n",
            "4803.jpg: actual-predicted:     50,   53.6, error:    3.6. Current MAE: 28.25, RMSE: 81.30:  58% 747/1286 [00:58<00:35, 15.34it/s]\n",
            "4804.jpg: actual-predicted:     34,   37.0, error:    3.0. Current MAE: 28.22, RMSE: 81.25:  58% 750/1286 [00:58<00:32, 16.49it/s]\n",
            "4805.jpg: actual-predicted:     73,   56.0, error:   17.0. Current MAE: 28.20, RMSE: 81.20:  58% 750/1286 [00:58<00:32, 16.49it/s]\n",
            "4806.jpg: actual-predicted:     41,   57.6, error:   16.6. Current MAE: 28.19, RMSE: 81.14:  58% 752/1286 [00:58<00:31, 16.88it/s]\n",
            "4807.jpg: actual-predicted:     25,   34.4, error:    9.4. Current MAE: 28.16, RMSE: 81.09:  58% 752/1286 [00:58<00:31, 16.88it/s]\n",
            "4808.jpg: actual-predicted:    120,  107.2, error:   12.8. Current MAE: 28.14, RMSE: 81.04:  59% 754/1286 [00:58<00:30, 17.19it/s]\n",
            "4809.jpg: actual-predicted:    306,  202.3, error:  103.7. Current MAE: 28.24, RMSE: 81.07:  59% 754/1286 [00:58<00:30, 17.19it/s]\n",
            "4810.jpg: actual-predicted:    112,   82.4, error:   29.6. Current MAE: 28.24, RMSE: 81.03:  59% 754/1286 [00:59<00:30, 17.19it/s]\n",
            "4811.jpg: actual-predicted:    213,  179.2, error:   33.8. Current MAE: 28.25, RMSE: 80.98:  59% 757/1286 [00:59<00:29, 18.09it/s]\n",
            "4812.jpg: actual-predicted:     67,   43.3, error:   23.7. Current MAE: 28.25, RMSE: 80.93:  59% 757/1286 [00:59<00:29, 18.09it/s]\n",
            "4813.jpg: actual-predicted:     43,   49.5, error:    6.5. Current MAE: 28.22, RMSE: 80.88:  59% 757/1286 [00:59<00:29, 18.09it/s]\n",
            "4814.jpg: actual-predicted:     19,   18.1, error:    0.9. Current MAE: 28.18, RMSE: 80.83:  59% 760/1286 [00:59<00:28, 18.33it/s]\n",
            "4815.jpg: actual-predicted:     70,   62.3, error:    7.7. Current MAE: 28.15, RMSE: 80.78:  59% 760/1286 [00:59<00:28, 18.33it/s]\n",
            "4816.jpg: actual-predicted:     33,   55.5, error:   22.5. Current MAE: 28.15, RMSE: 80.73:  59% 762/1286 [00:59<00:29, 17.85it/s]\n",
            "4817.jpg: actual-predicted:     57,   45.9, error:   11.1. Current MAE: 28.12, RMSE: 80.67:  59% 762/1286 [00:59<00:29, 17.85it/s]\n",
            "4818.jpg: actual-predicted:     37,   40.4, error:    3.4. Current MAE: 28.09, RMSE: 80.62:  59% 764/1286 [00:59<00:29, 17.62it/s]\n",
            "4819.jpg: actual-predicted:     41,   53.9, error:   12.9. Current MAE: 28.07, RMSE: 80.57:  59% 764/1286 [00:59<00:29, 17.62it/s]\n",
            "4820.jpg: actual-predicted:    144,  121.8, error:   22.2. Current MAE: 28.07, RMSE: 80.52:  60% 766/1286 [00:59<00:28, 17.97it/s]\n",
            "4821.jpg: actual-predicted:     90,   74.1, error:   15.9. Current MAE: 28.05, RMSE: 80.47:  60% 766/1286 [00:59<00:28, 17.97it/s]\n",
            "4822.jpg: actual-predicted:     29,   34.0, error:    5.0. Current MAE: 28.02, RMSE: 80.42:  60% 768/1286 [00:59<00:28, 17.91it/s]\n",
            "4824.jpg: actual-predicted:     49,   45.6, error:    3.4. Current MAE: 27.99, RMSE: 80.37:  60% 768/1286 [00:59<00:28, 17.91it/s]\n",
            "4825.jpg: actual-predicted:     36,   67.2, error:   31.2. Current MAE: 27.99, RMSE: 80.32:  60% 770/1286 [00:59<00:28, 17.96it/s]\n",
            "4826.jpg: actual-predicted:     39,   24.6, error:   14.4. Current MAE: 27.97, RMSE: 80.27:  60% 770/1286 [00:59<00:28, 17.96it/s]\n",
            "4827.jpg: actual-predicted:     84,   91.6, error:    7.6. Current MAE: 27.95, RMSE: 80.22:  60% 772/1286 [00:59<00:30, 16.96it/s]\n",
            "4828.jpg: actual-predicted:     39,   36.2, error:    2.8. Current MAE: 27.92, RMSE: 80.17:  60% 772/1286 [01:00<00:30, 16.96it/s]\n",
            "4829.jpg: actual-predicted:     40,   31.4, error:    8.6. Current MAE: 27.89, RMSE: 80.12:  60% 774/1286 [01:00<00:29, 17.11it/s]\n",
            "4830.jpg: actual-predicted:     90,   65.9, error:   24.1. Current MAE: 27.89, RMSE: 80.07:  60% 774/1286 [01:00<00:29, 17.11it/s]\n",
            "4831.jpg: actual-predicted:    122,  130.8, error:    8.8. Current MAE: 27.86, RMSE: 80.02:  60% 774/1286 [01:00<00:29, 17.11it/s]\n",
            "4832.jpg: actual-predicted:     50,   52.0, error:    2.0. Current MAE: 27.83, RMSE: 79.97:  60% 777/1286 [01:00<00:28, 17.79it/s]\n",
            "4833.jpg: actual-predicted:     98,   63.4, error:   34.6. Current MAE: 27.84, RMSE: 79.93:  60% 777/1286 [01:00<00:28, 17.79it/s]\n",
            "4834.jpg: actual-predicted:     46,   44.8, error:    1.2. Current MAE: 27.80, RMSE: 79.88:  60% 777/1286 [01:00<00:28, 17.79it/s]\n",
            "4835.jpg: actual-predicted:     65,   63.7, error:    1.3. Current MAE: 27.77, RMSE: 79.82:  61% 780/1286 [01:00<00:27, 18.73it/s]\n",
            "4836.jpg: actual-predicted:     42,   39.0, error:    3.0. Current MAE: 27.74, RMSE: 79.77:  61% 780/1286 [01:00<00:27, 18.73it/s]\n",
            "4837.jpg: actual-predicted:     26,   25.3, error:    0.7. Current MAE: 27.70, RMSE: 79.72:  61% 782/1286 [01:00<00:26, 18.67it/s]\n",
            "4839.jpg: actual-predicted:     46,   41.9, error:    4.1. Current MAE: 27.67, RMSE: 79.67:  61% 782/1286 [01:00<00:26, 18.67it/s]\n",
            "4840.jpg: actual-predicted:     46,   64.4, error:   18.4. Current MAE: 27.66, RMSE: 79.62:  61% 784/1286 [01:00<00:29, 16.83it/s]\n",
            "4841.jpg: actual-predicted:     57,   43.6, error:   13.4. Current MAE: 27.64, RMSE: 79.57:  61% 784/1286 [01:00<00:29, 16.83it/s]\n",
            "4842.jpg: actual-predicted:    122,   98.2, error:   23.8. Current MAE: 27.64, RMSE: 79.53:  61% 784/1286 [01:00<00:29, 16.83it/s]\n",
            "4844.jpg: actual-predicted:     43,   36.2, error:    6.8. Current MAE: 27.61, RMSE: 79.48:  61% 787/1286 [01:00<00:27, 18.13it/s]\n",
            "4845.jpg: actual-predicted:     21,   24.0, error:    3.0. Current MAE: 27.58, RMSE: 79.43:  61% 787/1286 [01:00<00:27, 18.13it/s]\n",
            "4846.jpg: actual-predicted:     55,   53.2, error:    1.8. Current MAE: 27.55, RMSE: 79.38:  61% 789/1286 [01:00<00:28, 17.26it/s]\n",
            "4847.jpg: actual-predicted:     61,   51.9, error:    9.1. Current MAE: 27.52, RMSE: 79.33:  61% 789/1286 [01:00<00:28, 17.26it/s]\n",
            "4848.jpg: actual-predicted:     80,   87.1, error:    7.1. Current MAE: 27.50, RMSE: 79.28:  61% 789/1286 [01:00<00:28, 17.26it/s]\n",
            "4849.jpg: actual-predicted:    121,   90.6, error:   30.4. Current MAE: 27.50, RMSE: 79.24:  62% 792/1286 [01:01<00:27, 17.87it/s]\n",
            "4850.jpg: actual-predicted:    101,  100.1, error:    0.9. Current MAE: 27.47, RMSE: 79.19:  62% 792/1286 [01:01<00:27, 17.87it/s]\n",
            "4851.jpg: actual-predicted:     32,   37.4, error:    5.4. Current MAE: 27.44, RMSE: 79.14:  62% 792/1286 [01:01<00:27, 17.87it/s]\n",
            "4852.jpg: actual-predicted:     31,   16.2, error:   14.8. Current MAE: 27.42, RMSE: 79.09:  62% 795/1286 [01:01<00:26, 18.74it/s]\n",
            "4853.jpg: actual-predicted:     50,   45.6, error:    4.4. Current MAE: 27.40, RMSE: 79.04:  62% 795/1286 [01:01<00:26, 18.74it/s]\n",
            "4854.jpg: actual-predicted:     36,   70.2, error:   34.2. Current MAE: 27.40, RMSE: 79.00:  62% 797/1286 [01:01<00:27, 17.91it/s]\n",
            "4855.jpg: actual-predicted:     22,   35.3, error:   13.3. Current MAE: 27.39, RMSE: 78.95:  62% 797/1286 [01:01<00:27, 17.91it/s]\n",
            "5043.jpg: actual-predicted:    134,  123.3, error:   10.7. Current MAE: 27.37, RMSE: 78.90:  62% 799/1286 [01:01<00:28, 17.38it/s]\n",
            "5044.jpg: actual-predicted:    100,   73.5, error:   26.5. Current MAE: 27.36, RMSE: 78.86:  62% 799/1286 [01:01<00:28, 17.38it/s]\n",
            "5045.jpg: actual-predicted:    131,  197.1, error:   66.1. Current MAE: 27.41, RMSE: 78.84:  62% 799/1286 [01:01<00:28, 17.38it/s]\n",
            "5046.jpg: actual-predicted:    215,  136.7, error:   78.3. Current MAE: 27.48, RMSE: 78.84:  62% 802/1286 [01:01<00:25, 19.30it/s]\n",
            "5047.jpg: actual-predicted:     30,   44.1, error:   14.1. Current MAE: 27.46, RMSE: 78.80:  62% 802/1286 [01:01<00:25, 19.30it/s]\n",
            "5048.jpg: actual-predicted:     39,   39.2, error:    0.2. Current MAE: 27.43, RMSE: 78.75:  62% 802/1286 [01:01<00:25, 19.30it/s]\n",
            "5059.jpg: actual-predicted:    286,  254.8, error:   31.2. Current MAE: 27.43, RMSE: 78.71:  63% 805/1286 [01:01<00:23, 20.84it/s]\n",
            "5060.jpg: actual-predicted:     98,   73.8, error:   24.2. Current MAE: 27.43, RMSE: 78.66:  63% 805/1286 [01:01<00:23, 20.84it/s]\n",
            "5061.jpg: actual-predicted:      9,   22.5, error:   13.5. Current MAE: 27.41, RMSE: 78.61:  63% 805/1286 [01:01<00:23, 20.84it/s]\n",
            "5062.jpg: actual-predicted:     32,   36.3, error:    4.3. Current MAE: 27.38, RMSE: 78.57:  63% 808/1286 [01:01<00:22, 20.88it/s]\n",
            "5063.jpg: actual-predicted:     72,   65.8, error:    6.2. Current MAE: 27.35, RMSE: 78.52:  63% 808/1286 [01:01<00:22, 20.88it/s]\n",
            "5064.jpg: actual-predicted:     19,    2.4, error:   16.6. Current MAE: 27.34, RMSE: 78.47:  63% 808/1286 [01:01<00:22, 20.88it/s]\n",
            "5065.jpg: actual-predicted:     24,   14.1, error:    9.9. Current MAE: 27.32, RMSE: 78.42:  63% 811/1286 [01:02<00:26, 17.91it/s]\n",
            "5066.jpg: actual-predicted:     10,   10.6, error:    0.6. Current MAE: 27.29, RMSE: 78.38:  63% 811/1286 [01:02<00:26, 17.91it/s]\n",
            "5068.jpg: actual-predicted:     16,   13.8, error:    2.2. Current MAE: 27.26, RMSE: 78.33:  63% 813/1286 [01:02<00:29, 15.77it/s]\n",
            "5069.jpg: actual-predicted:     20,   84.4, error:   64.4. Current MAE: 27.30, RMSE: 78.31:  63% 813/1286 [01:02<00:29, 15.77it/s]\n",
            "5071.jpg: actual-predicted:     11,   14.9, error:    3.9. Current MAE: 27.27, RMSE: 78.26:  63% 815/1286 [01:02<00:33, 14.09it/s]\n",
            "5072.jpg: actual-predicted:     10,    1.0, error:    9.0. Current MAE: 27.25, RMSE: 78.22:  63% 815/1286 [01:02<00:33, 14.09it/s]\n",
            "5073.jpg: actual-predicted:     24,   19.1, error:    4.9. Current MAE: 27.22, RMSE: 78.17:  64% 817/1286 [01:02<00:39, 11.82it/s]\n",
            "5074.jpg: actual-predicted:     17,    9.8, error:    7.2. Current MAE: 27.20, RMSE: 78.12:  64% 817/1286 [01:02<00:39, 11.82it/s]\n",
            "5075.jpg: actual-predicted:     16,   16.0, error:    0.0. Current MAE: 27.17, RMSE: 78.07:  64% 819/1286 [01:02<00:41, 11.22it/s]\n",
            "5076.jpg: actual-predicted:     10,    5.2, error:    4.8. Current MAE: 27.14, RMSE: 78.03:  64% 819/1286 [01:02<00:41, 11.22it/s]\n",
            "5077.jpg: actual-predicted:     52,   33.3, error:   18.7. Current MAE: 27.13, RMSE: 77.98:  64% 821/1286 [01:02<00:41, 11.25it/s]\n",
            "5078.jpg: actual-predicted:     20,   40.6, error:   20.6. Current MAE: 27.12, RMSE: 77.94:  64% 821/1286 [01:03<00:41, 11.25it/s]\n",
            "5079.jpg: actual-predicted:     27,   38.5, error:   11.5. Current MAE: 27.10, RMSE: 77.89:  64% 823/1286 [01:03<00:39, 11.60it/s]\n",
            "5080.jpg: actual-predicted:     51,   31.7, error:   19.3. Current MAE: 27.09, RMSE: 77.85:  64% 823/1286 [01:03<00:39, 11.60it/s]\n",
            "5081.jpg: actual-predicted:     12,   12.6, error:    0.6. Current MAE: 27.06, RMSE: 77.80:  64% 825/1286 [01:03<00:35, 12.92it/s]\n",
            "5082.jpg: actual-predicted:     13,    1.7, error:   11.3. Current MAE: 27.04, RMSE: 77.75:  64% 825/1286 [01:03<00:35, 12.92it/s]\n",
            "5083.jpg: actual-predicted:     24,   16.7, error:    7.3. Current MAE: 27.02, RMSE: 77.71:  64% 827/1286 [01:03<00:44, 10.37it/s]\n",
            "5084.jpg: actual-predicted:     28,   47.3, error:   19.3. Current MAE: 27.01, RMSE: 77.66:  64% 827/1286 [01:03<00:44, 10.37it/s]\n",
            "5085.jpg: actual-predicted:      9,    1.1, error:    7.9. Current MAE: 26.98, RMSE: 77.62:  64% 829/1286 [01:03<00:40, 11.38it/s]\n",
            "5086.jpg: actual-predicted:     12,    9.5, error:    2.5. Current MAE: 26.95, RMSE: 77.57:  64% 829/1286 [01:03<00:40, 11.38it/s]\n",
            "5087.jpg: actual-predicted:     31,   17.4, error:   13.6. Current MAE: 26.94, RMSE: 77.53:  65% 831/1286 [01:04<00:50,  9.04it/s]\n",
            "5088.jpg: actual-predicted:     24,    5.0, error:   19.0. Current MAE: 26.93, RMSE: 77.48:  65% 831/1286 [01:04<00:50,  9.04it/s]\n",
            "5089.jpg: actual-predicted:     11,   14.8, error:    3.8. Current MAE: 26.90, RMSE: 77.44:  65% 833/1286 [01:04<00:50,  8.91it/s]\n",
            "5090.jpg: actual-predicted:     14,    7.6, error:    6.4. Current MAE: 26.88, RMSE: 77.39:  65% 833/1286 [01:04<00:50,  8.91it/s]\n",
            "5091.jpg: actual-predicted:     15,    8.4, error:    6.6. Current MAE: 26.85, RMSE: 77.34:  65% 835/1286 [01:04<00:51,  8.70it/s]\n",
            "5092.jpg: actual-predicted:     15,    9.0, error:    6.0. Current MAE: 26.83, RMSE: 77.30:  65% 836/1286 [01:04<00:57,  7.88it/s]\n",
            "5093.jpg: actual-predicted:     11,   12.9, error:    1.9. Current MAE: 26.80, RMSE: 77.25:  65% 837/1286 [01:04<00:54,  8.26it/s]\n",
            "5094.jpg: actual-predicted:     14,   13.3, error:    0.7. Current MAE: 26.77, RMSE: 77.21:  65% 838/1286 [01:04<00:52,  8.46it/s]\n",
            "5095.jpg: actual-predicted:     16,   21.6, error:    5.6. Current MAE: 26.74, RMSE: 77.16:  65% 838/1286 [01:04<00:52,  8.46it/s]\n",
            "5096.jpg: actual-predicted:     11,   19.2, error:    8.2. Current MAE: 26.72, RMSE: 77.11:  65% 840/1286 [01:05<00:48,  9.24it/s]\n",
            "5097.jpg: actual-predicted:     27,   31.1, error:    4.1. Current MAE: 26.69, RMSE: 77.07:  65% 840/1286 [01:05<00:48,  9.24it/s]\n",
            "5098.jpg: actual-predicted:     30,   28.7, error:    1.3. Current MAE: 26.66, RMSE: 77.02:  65% 842/1286 [01:05<00:44,  9.92it/s]\n",
            "5099.jpg: actual-predicted:     22,   16.9, error:    5.1. Current MAE: 26.64, RMSE: 76.98:  65% 842/1286 [01:05<00:44,  9.92it/s]\n",
            "5100.jpg: actual-predicted:      9,    6.4, error:    2.6. Current MAE: 26.61, RMSE: 76.93:  66% 844/1286 [01:05<00:41, 10.75it/s]\n",
            "5101.jpg: actual-predicted:     23,   22.1, error:    0.9. Current MAE: 26.58, RMSE: 76.89:  66% 844/1286 [01:05<00:41, 10.75it/s]\n",
            "5102.jpg: actual-predicted:     21,    1.3, error:   19.7. Current MAE: 26.57, RMSE: 76.84:  66% 846/1286 [01:05<00:44,  9.92it/s]\n",
            "5103.jpg: actual-predicted:     20,    8.9, error:   11.1. Current MAE: 26.55, RMSE: 76.80:  66% 846/1286 [01:05<00:44,  9.92it/s]\n",
            "5104.jpg: actual-predicted:     13,    9.9, error:    3.1. Current MAE: 26.52, RMSE: 76.75:  66% 848/1286 [01:05<00:46,  9.42it/s]\n",
            "5105.jpg: actual-predicted:     17,    6.1, error:   10.9. Current MAE: 26.51, RMSE: 76.71:  66% 849/1286 [01:05<00:47,  9.12it/s]\n",
            "5106.jpg: actual-predicted:     23,   21.8, error:    1.2. Current MAE: 26.48, RMSE: 76.67:  66% 849/1286 [01:06<00:47,  9.12it/s]\n",
            "5107.jpg: actual-predicted:     12,   12.9, error:    0.9. Current MAE: 26.45, RMSE: 76.62:  66% 851/1286 [01:06<00:43,  9.94it/s]\n",
            "5108.jpg: actual-predicted:     12,   14.4, error:    2.4. Current MAE: 26.42, RMSE: 76.58:  66% 851/1286 [01:06<00:43,  9.94it/s]\n",
            "5110.jpg: actual-predicted:      9,    2.5, error:    6.5. Current MAE: 26.39, RMSE: 76.53:  66% 853/1286 [01:06<00:43, 10.01it/s]\n",
            "5111.jpg: actual-predicted:     12,    5.7, error:    6.3. Current MAE: 26.37, RMSE: 76.49:  66% 853/1286 [01:06<00:43, 10.01it/s]\n",
            "5112.jpg: actual-predicted:     22,   11.9, error:   10.1. Current MAE: 26.35, RMSE: 76.44:  66% 855/1286 [01:06<00:42, 10.17it/s]\n",
            "5113.jpg: actual-predicted:     14,   10.9, error:    3.1. Current MAE: 26.32, RMSE: 76.40:  66% 855/1286 [01:06<00:42, 10.17it/s]\n",
            "5114.jpg: actual-predicted:     22,    7.8, error:   14.2. Current MAE: 26.31, RMSE: 76.35:  67% 857/1286 [01:06<00:41, 10.23it/s]\n",
            "5115.jpg: actual-predicted:     22,   14.9, error:    7.1. Current MAE: 26.29, RMSE: 76.31:  67% 857/1286 [01:06<00:41, 10.23it/s]\n",
            "5116.jpg: actual-predicted:     17,   15.3, error:    1.7. Current MAE: 26.26, RMSE: 76.27:  67% 859/1286 [01:06<00:39, 10.79it/s]\n",
            "5117.jpg: actual-predicted:     13,    1.2, error:   11.8. Current MAE: 26.24, RMSE: 76.22:  67% 859/1286 [01:06<00:39, 10.79it/s]\n",
            "5118.jpg: actual-predicted:     17,   10.6, error:    6.4. Current MAE: 26.22, RMSE: 76.18:  67% 861/1286 [01:07<00:42, 10.06it/s]\n",
            "5150.jpg: actual-predicted:     57,   75.6, error:   18.6. Current MAE: 26.21, RMSE: 76.14:  67% 861/1286 [01:07<00:42, 10.06it/s]\n",
            "5151.jpg: actual-predicted:     32,   15.4, error:   16.6. Current MAE: 26.20, RMSE: 76.10:  67% 863/1286 [01:07<00:39, 10.74it/s]\n",
            "5152.jpg: actual-predicted:      8,    9.5, error:    1.5. Current MAE: 26.17, RMSE: 76.05:  67% 863/1286 [01:07<00:39, 10.74it/s]\n",
            "5153.jpg: actual-predicted:     15,   32.6, error:   17.6. Current MAE: 26.16, RMSE: 76.01:  67% 865/1286 [01:07<00:35, 11.95it/s]\n",
            "5154.jpg: actual-predicted:     32,   46.2, error:   14.2. Current MAE: 26.15, RMSE: 75.97:  67% 865/1286 [01:07<00:35, 11.95it/s]\n",
            "5155.jpg: actual-predicted:     10,   19.7, error:    9.7. Current MAE: 26.13, RMSE: 75.92:  67% 865/1286 [01:07<00:35, 11.95it/s]\n",
            "5156.jpg: actual-predicted:     12,   17.0, error:    5.0. Current MAE: 26.10, RMSE: 75.88:  67% 868/1286 [01:07<00:32, 12.78it/s]\n",
            "5157.jpg: actual-predicted:     31,   47.1, error:   16.1. Current MAE: 26.09, RMSE: 75.84:  67% 868/1286 [01:07<00:32, 12.78it/s]\n",
            "5200.jpg: actual-predicted:      8,    9.5, error:    1.5. Current MAE: 26.06, RMSE: 75.80:  67% 868/1286 [01:07<00:32, 12.78it/s]\n",
            "5201.jpg: actual-predicted:     12,   10.4, error:    1.6. Current MAE: 26.04, RMSE: 75.75:  68% 871/1286 [01:07<00:30, 13.63it/s]\n",
            "5202.jpg: actual-predicted:     12,   15.5, error:    3.5. Current MAE: 26.01, RMSE: 75.71:  68% 871/1286 [01:07<00:30, 13.63it/s]\n",
            "5203.jpg: actual-predicted:     11,   14.4, error:    3.4. Current MAE: 25.98, RMSE: 75.67:  68% 873/1286 [01:08<00:39, 10.41it/s]\n",
            "5204.jpg: actual-predicted:     12,   12.2, error:    0.2. Current MAE: 25.96, RMSE: 75.62:  68% 873/1286 [01:08<00:39, 10.41it/s]\n",
            "5205.jpg: actual-predicted:     12,    8.1, error:    3.9. Current MAE: 25.93, RMSE: 75.58:  68% 875/1286 [01:08<00:38, 10.58it/s]\n",
            "5206.jpg: actual-predicted:     30,   42.4, error:   12.4. Current MAE: 25.91, RMSE: 75.54:  68% 875/1286 [01:08<00:38, 10.58it/s]\n",
            "5207.jpg: actual-predicted:     20,   17.3, error:    2.7. Current MAE: 25.89, RMSE: 75.50:  68% 877/1286 [01:08<00:36, 11.14it/s]\n",
            "5209.jpg: actual-predicted:     17,   24.7, error:    7.7. Current MAE: 25.87, RMSE: 75.45:  68% 877/1286 [01:08<00:36, 11.14it/s]\n",
            "5210.jpg: actual-predicted:     12,   16.3, error:    4.3. Current MAE: 25.84, RMSE: 75.41:  68% 879/1286 [01:08<00:35, 11.51it/s]\n",
            "5211.jpg: actual-predicted:      9,   13.0, error:    4.0. Current MAE: 25.82, RMSE: 75.37:  68% 879/1286 [01:08<00:35, 11.51it/s]\n",
            "5212.jpg: actual-predicted:     12,   13.0, error:    1.0. Current MAE: 25.79, RMSE: 75.32:  69% 881/1286 [01:08<00:35, 11.30it/s]\n",
            "5213.jpg: actual-predicted:     16,   19.4, error:    3.4. Current MAE: 25.76, RMSE: 75.28:  69% 881/1286 [01:08<00:35, 11.30it/s]\n",
            "5214.jpg: actual-predicted:      9,   14.4, error:    5.4. Current MAE: 25.74, RMSE: 75.24:  69% 883/1286 [01:08<00:33, 11.88it/s]\n",
            "5215.jpg: actual-predicted:     12,   21.3, error:    9.3. Current MAE: 25.72, RMSE: 75.20:  69% 883/1286 [01:08<00:33, 11.88it/s]\n",
            "5216.jpg: actual-predicted:      9,    8.9, error:    0.1. Current MAE: 25.69, RMSE: 75.16:  69% 885/1286 [01:09<00:35, 11.45it/s]\n",
            "5217.jpg: actual-predicted:     10,   11.7, error:    1.7. Current MAE: 25.67, RMSE: 75.11:  69% 885/1286 [01:09<00:35, 11.45it/s]\n",
            "5219.jpg: actual-predicted:     13,   16.4, error:    3.4. Current MAE: 25.64, RMSE: 75.07:  69% 887/1286 [01:09<00:34, 11.73it/s]\n",
            "5220.jpg: actual-predicted:      9,   19.2, error:   10.2. Current MAE: 25.62, RMSE: 75.03:  69% 887/1286 [01:09<00:34, 11.73it/s]\n",
            "5221.jpg: actual-predicted:     12,    8.8, error:    3.2. Current MAE: 25.60, RMSE: 74.99:  69% 889/1286 [01:09<00:36, 10.96it/s]\n",
            "5222.jpg: actual-predicted:     12,   12.5, error:    0.5. Current MAE: 25.57, RMSE: 74.94:  69% 889/1286 [01:09<00:36, 10.96it/s]\n",
            "5223.jpg: actual-predicted:      9,   12.5, error:    3.5. Current MAE: 25.55, RMSE: 74.90:  69% 891/1286 [01:09<00:37, 10.62it/s]\n",
            "5225.jpg: actual-predicted:     38,   24.8, error:   13.2. Current MAE: 25.53, RMSE: 74.86:  69% 891/1286 [01:09<00:37, 10.62it/s]\n",
            "5227.jpg: actual-predicted:     54,   32.7, error:   21.3. Current MAE: 25.53, RMSE: 74.82:  69% 893/1286 [01:09<00:35, 11.20it/s]\n",
            "5228.jpg: actual-predicted:     20,   31.8, error:   11.8. Current MAE: 25.51, RMSE: 74.78:  69% 893/1286 [01:09<00:35, 11.20it/s]\n",
            "5229.jpg: actual-predicted:     12,   15.4, error:    3.4. Current MAE: 25.49, RMSE: 74.74:  70% 895/1286 [01:09<00:35, 11.11it/s]\n",
            "5654.jpg: actual-predicted:     10,    4.7, error:    5.3. Current MAE: 25.47, RMSE: 74.70:  70% 895/1286 [01:10<00:35, 11.11it/s]\n",
            "5655.jpg: actual-predicted:      9,   11.0, error:    2.0. Current MAE: 25.44, RMSE: 74.66:  70% 897/1286 [01:10<00:36, 10.75it/s]\n",
            "5656.jpg: actual-predicted:     16,   23.2, error:    7.2. Current MAE: 25.42, RMSE: 74.62:  70% 897/1286 [01:10<00:36, 10.75it/s]\n",
            "5658.jpg: actual-predicted:      9,   11.5, error:    2.5. Current MAE: 25.39, RMSE: 74.58:  70% 899/1286 [01:10<00:35, 10.95it/s]\n",
            "5659.jpg: actual-predicted:     16,   18.6, error:    2.6. Current MAE: 25.37, RMSE: 74.53:  70% 899/1286 [01:10<00:35, 10.95it/s]\n",
            "5660.jpg: actual-predicted:     19,   19.9, error:    0.9. Current MAE: 25.34, RMSE: 74.49:  70% 901/1286 [01:10<00:34, 11.20it/s]\n",
            "5661.jpg: actual-predicted:     12,   13.9, error:    1.9. Current MAE: 25.32, RMSE: 74.45:  70% 901/1286 [01:10<00:34, 11.20it/s]\n",
            "5662.jpg: actual-predicted:     12,   14.3, error:    2.3. Current MAE: 25.29, RMSE: 74.41:  70% 903/1286 [01:10<00:32, 11.71it/s]\n",
            "5663.jpg: actual-predicted:     12,    8.8, error:    3.2. Current MAE: 25.27, RMSE: 74.37:  70% 903/1286 [01:10<00:32, 11.71it/s]\n",
            "5664.jpg: actual-predicted:     12,   14.0, error:    2.0. Current MAE: 25.24, RMSE: 74.33:  70% 905/1286 [01:10<00:37, 10.24it/s]\n",
            "5665.jpg: actual-predicted:     16,   13.9, error:    2.1. Current MAE: 25.21, RMSE: 74.29:  70% 905/1286 [01:11<00:37, 10.24it/s]\n",
            "5666.jpg: actual-predicted:      8,   10.0, error:    2.0. Current MAE: 25.19, RMSE: 74.25:  71% 907/1286 [01:11<00:38,  9.80it/s]\n",
            "5667.jpg: actual-predicted:     20,   17.8, error:    2.2. Current MAE: 25.16, RMSE: 74.21:  71% 907/1286 [01:11<00:38,  9.80it/s]\n",
            "5668.jpg: actual-predicted:     12,   13.1, error:    1.1. Current MAE: 25.14, RMSE: 74.17:  71% 909/1286 [01:11<00:36, 10.21it/s]\n",
            "5669.jpg: actual-predicted:     15,   21.5, error:    6.5. Current MAE: 25.12, RMSE: 74.12:  71% 909/1286 [01:11<00:36, 10.21it/s]\n",
            "5670.jpg: actual-predicted:     12,   12.0, error:    0.0. Current MAE: 25.09, RMSE: 74.08:  71% 911/1286 [01:11<00:33, 11.03it/s]\n",
            "5671.jpg: actual-predicted:     12,   11.6, error:    0.4. Current MAE: 25.06, RMSE: 74.04:  71% 911/1286 [01:11<00:33, 11.03it/s]\n",
            "5672.jpg: actual-predicted:     12,   23.2, error:   11.2. Current MAE: 25.05, RMSE: 74.00:  71% 913/1286 [01:11<00:39,  9.36it/s]\n",
            "5673.jpg: actual-predicted:     20,   23.4, error:    3.4. Current MAE: 25.02, RMSE: 73.96:  71% 913/1286 [01:11<00:39,  9.36it/s]\n",
            "5735.jpg: actual-predicted:     32,   59.5, error:   27.5. Current MAE: 25.03, RMSE: 73.93:  71% 915/1286 [01:11<00:35, 10.31it/s]\n",
            "5736.jpg: actual-predicted:    239,  279.2, error:   40.2. Current MAE: 25.04, RMSE: 73.90:  71% 915/1286 [01:11<00:35, 10.31it/s]\n",
            "5737.jpg: actual-predicted:    103,   82.4, error:   20.6. Current MAE: 25.04, RMSE: 73.86:  71% 915/1286 [01:11<00:35, 10.31it/s]\n",
            "5738.jpg: actual-predicted:     27,   48.4, error:   21.4. Current MAE: 25.03, RMSE: 73.83:  71% 918/1286 [01:11<00:29, 12.28it/s]\n",
            "5739.jpg: actual-predicted:     53,   37.2, error:   15.8. Current MAE: 25.02, RMSE: 73.79:  71% 918/1286 [01:12<00:29, 12.28it/s]\n",
            "5740.jpg: actual-predicted:     87,  108.4, error:   21.4. Current MAE: 25.02, RMSE: 73.75:  71% 918/1286 [01:12<00:29, 12.28it/s]\n",
            "5741.jpg: actual-predicted:     36,   31.9, error:    4.1. Current MAE: 25.00, RMSE: 73.71:  72% 921/1286 [01:12<00:24, 14.71it/s]\n",
            "5742.jpg: actual-predicted:     43,   47.5, error:    4.5. Current MAE: 24.97, RMSE: 73.67:  72% 921/1286 [01:12<00:24, 14.71it/s]\n",
            "5743.jpg: actual-predicted:    270,  208.4, error:   61.6. Current MAE: 25.01, RMSE: 73.66:  72% 921/1286 [01:12<00:24, 14.71it/s]\n",
            "5744.jpg: actual-predicted:    322,  113.5, error:  208.5. Current MAE: 25.21, RMSE: 73.94:  72% 924/1286 [01:12<00:21, 16.83it/s]\n",
            "5745.jpg: actual-predicted:    146,   87.4, error:   58.6. Current MAE: 25.25, RMSE: 73.92:  72% 924/1286 [01:12<00:21, 16.83it/s]\n",
            "5746.jpg: actual-predicted:    100,   81.1, error:   18.9. Current MAE: 25.24, RMSE: 73.89:  72% 924/1286 [01:12<00:21, 16.83it/s]\n",
            "5747.jpg: actual-predicted:    100,   54.3, error:   45.7. Current MAE: 25.26, RMSE: 73.86:  72% 927/1286 [01:12<00:18, 19.00it/s]\n",
            "5748.jpg: actual-predicted:     74,  159.4, error:   85.4. Current MAE: 25.33, RMSE: 73.88:  72% 927/1286 [01:12<00:18, 19.00it/s]\n",
            "5857.jpg: actual-predicted:     44,   40.0, error:    4.0. Current MAE: 25.31, RMSE: 73.84:  72% 927/1286 [01:12<00:18, 19.00it/s]\n",
            "5858.jpg: actual-predicted:    170,   77.9, error:   92.1. Current MAE: 25.38, RMSE: 73.86:  72% 930/1286 [01:12<00:17, 20.45it/s]\n",
            "5859.jpg: actual-predicted:     49,   56.6, error:    7.6. Current MAE: 25.36, RMSE: 73.82:  72% 930/1286 [01:12<00:17, 20.45it/s]\n",
            "5860.jpg: actual-predicted:    757,  351.9, error:  405.1. Current MAE: 25.77, RMSE: 74.96:  72% 930/1286 [01:12<00:17, 20.45it/s]\n",
            "5861.jpg: actual-predicted:     67,   65.4, error:    1.6. Current MAE: 25.74, RMSE: 74.92:  73% 933/1286 [01:12<00:17, 20.75it/s]\n",
            "5862.jpg: actual-predicted:     58,   59.8, error:    1.8. Current MAE: 25.71, RMSE: 74.88:  73% 933/1286 [01:12<00:17, 20.75it/s]\n",
            "5863.jpg: actual-predicted:     76,   51.4, error:   24.6. Current MAE: 25.71, RMSE: 74.85:  73% 933/1286 [01:12<00:17, 20.75it/s]\n",
            "5864.jpg: actual-predicted:     81,   72.9, error:    8.1. Current MAE: 25.69, RMSE: 74.81:  73% 936/1286 [01:12<00:17, 20.24it/s]\n",
            "5865.jpg: actual-predicted:    114,   97.4, error:   16.6. Current MAE: 25.68, RMSE: 74.77:  73% 936/1286 [01:12<00:17, 20.24it/s]\n",
            "5866.jpg: actual-predicted:    267,  236.8, error:   30.2. Current MAE: 25.69, RMSE: 74.74:  73% 936/1286 [01:12<00:17, 20.24it/s]\n",
            "5867.jpg: actual-predicted:     83,   59.5, error:   23.5. Current MAE: 25.69, RMSE: 74.70:  73% 939/1286 [01:12<00:17, 20.37it/s]\n",
            "5868.jpg: actual-predicted:     54,   48.4, error:    5.6. Current MAE: 25.67, RMSE: 74.66:  73% 939/1286 [01:12<00:17, 20.37it/s]\n",
            "5869.jpg: actual-predicted:     32,   31.1, error:    0.9. Current MAE: 25.64, RMSE: 74.62:  73% 939/1286 [01:13<00:17, 20.37it/s]\n",
            "5870.jpg: actual-predicted:     47,   26.5, error:   20.5. Current MAE: 25.63, RMSE: 74.58:  73% 942/1286 [01:13<00:18, 19.07it/s]\n",
            "5871.jpg: actual-predicted:     53,   65.8, error:   12.8. Current MAE: 25.62, RMSE: 74.55:  73% 942/1286 [01:13<00:18, 19.07it/s]\n",
            "5872.jpg: actual-predicted:    116,   90.1, error:   25.9. Current MAE: 25.62, RMSE: 74.51:  73% 944/1286 [01:13<00:17, 19.01it/s]\n",
            "5873.jpg: actual-predicted:     69,   62.1, error:    6.9. Current MAE: 25.60, RMSE: 74.47:  73% 944/1286 [01:13<00:17, 19.01it/s]\n",
            "5874.jpg: actual-predicted:    124,  125.1, error:    1.1. Current MAE: 25.57, RMSE: 74.43:  74% 946/1286 [01:13<00:18, 18.71it/s]\n",
            "5875.jpg: actual-predicted:     74,   61.2, error:   12.8. Current MAE: 25.56, RMSE: 74.39:  74% 946/1286 [01:13<00:18, 18.71it/s]\n",
            "5876.jpg: actual-predicted:    216,  186.4, error:   29.6. Current MAE: 25.57, RMSE: 74.36:  74% 948/1286 [01:13<00:19, 17.44it/s]\n",
            "5877.jpg: actual-predicted:     32,   22.0, error:   10.0. Current MAE: 25.55, RMSE: 74.32:  74% 948/1286 [01:13<00:19, 17.44it/s]\n",
            "5878.jpg: actual-predicted:     44,   45.4, error:    1.4. Current MAE: 25.52, RMSE: 74.28:  74% 950/1286 [01:13<00:19, 16.85it/s]\n",
            "5879.jpg: actual-predicted:     36,   30.6, error:    5.4. Current MAE: 25.50, RMSE: 74.24:  74% 950/1286 [01:13<00:19, 16.85it/s]\n",
            "5880.jpg: actual-predicted:     30,   33.2, error:    3.2. Current MAE: 25.48, RMSE: 74.21:  74% 952/1286 [01:13<00:21, 15.79it/s]\n",
            "5881.jpg: actual-predicted:     99,   89.2, error:    9.8. Current MAE: 25.46, RMSE: 74.17:  74% 952/1286 [01:13<00:21, 15.79it/s]\n",
            "5882.jpg: actual-predicted:     47,   42.7, error:    4.3. Current MAE: 25.44, RMSE: 74.13:  74% 954/1286 [01:13<00:20, 16.49it/s]\n",
            "5883.jpg: actual-predicted:     69,   78.6, error:    9.6. Current MAE: 25.42, RMSE: 74.09:  74% 954/1286 [01:13<00:20, 16.49it/s]\n",
            "5884.jpg: actual-predicted:     41,   50.1, error:    9.1. Current MAE: 25.41, RMSE: 74.05:  74% 956/1286 [01:13<00:19, 16.68it/s]\n",
            "5885.jpg: actual-predicted:    115,  114.8, error:    0.2. Current MAE: 25.38, RMSE: 74.01:  74% 956/1286 [01:14<00:19, 16.68it/s]\n",
            "5886.jpg: actual-predicted:     25,   76.2, error:   51.2. Current MAE: 25.41, RMSE: 73.99:  74% 958/1286 [01:14<00:20, 16.34it/s]\n",
            "5887.jpg: actual-predicted:     49,   41.1, error:    7.9. Current MAE: 25.39, RMSE: 73.96:  74% 958/1286 [01:14<00:20, 16.34it/s]\n",
            "5888.jpg: actual-predicted:     84,   55.4, error:   28.6. Current MAE: 25.39, RMSE: 73.92:  74% 958/1286 [01:14<00:20, 16.34it/s]\n",
            "5889.jpg: actual-predicted:     27,   31.0, error:    4.0. Current MAE: 25.37, RMSE: 73.88:  75% 961/1286 [01:14<00:19, 17.07it/s]\n",
            "5890.jpg: actual-predicted:     33,   33.5, error:    0.5. Current MAE: 25.34, RMSE: 73.85:  75% 961/1286 [01:14<00:19, 17.07it/s]\n",
            "5891.jpg: actual-predicted:     89,   63.4, error:   25.6. Current MAE: 25.35, RMSE: 73.81:  75% 963/1286 [01:14<00:20, 16.12it/s]\n",
            "5892.jpg: actual-predicted:    103,   64.2, error:   38.8. Current MAE: 25.36, RMSE: 73.78:  75% 963/1286 [01:14<00:20, 16.12it/s]\n",
            "5893.jpg: actual-predicted:     73,   64.6, error:    8.4. Current MAE: 25.34, RMSE: 73.75:  75% 963/1286 [01:14<00:20, 16.12it/s]\n",
            "5894.jpg: actual-predicted:     62,   75.2, error:   13.2. Current MAE: 25.33, RMSE: 73.71:  75% 966/1286 [01:14<00:18, 17.71it/s]\n",
            "5895.jpg: actual-predicted:     43,   38.1, error:    4.9. Current MAE: 25.31, RMSE: 73.67:  75% 966/1286 [01:14<00:18, 17.71it/s]\n",
            "5896.jpg: actual-predicted:     55,   48.1, error:    6.9. Current MAE: 25.29, RMSE: 73.63:  75% 968/1286 [01:14<00:18, 16.88it/s]\n",
            "5897.jpg: actual-predicted:    109,  125.8, error:   16.8. Current MAE: 25.28, RMSE: 73.60:  75% 968/1286 [01:14<00:18, 16.88it/s]\n",
            "5898.jpg: actual-predicted:     32,   54.9, error:   22.9. Current MAE: 25.28, RMSE: 73.56:  75% 970/1286 [01:14<00:19, 16.13it/s]\n",
            "5899.jpg: actual-predicted:     99,   96.1, error:    2.9. Current MAE: 25.25, RMSE: 73.53:  75% 970/1286 [01:14<00:19, 16.13it/s]\n",
            "5900.jpg: actual-predicted:     39,   37.4, error:    1.6. Current MAE: 25.23, RMSE: 73.49:  76% 972/1286 [01:14<00:18, 17.12it/s]\n",
            "5901.jpg: actual-predicted:     48,   49.3, error:    1.3. Current MAE: 25.21, RMSE: 73.45:  76% 972/1286 [01:14<00:18, 17.12it/s]\n",
            "5902.jpg: actual-predicted:    209,   74.7, error:  134.3. Current MAE: 25.32, RMSE: 73.54:  76% 974/1286 [01:14<00:17, 17.61it/s]\n",
            "5903.jpg: actual-predicted:     48,   53.1, error:    5.1. Current MAE: 25.30, RMSE: 73.50:  76% 974/1286 [01:15<00:17, 17.61it/s]\n",
            "5904.jpg: actual-predicted:     33,   35.9, error:    2.9. Current MAE: 25.27, RMSE: 73.46:  76% 974/1286 [01:15<00:17, 17.61it/s]\n",
            "5905.jpg: actual-predicted:    147,  127.4, error:   19.6. Current MAE: 25.27, RMSE: 73.43:  76% 977/1286 [01:15<00:18, 16.73it/s]\n",
            "5906.jpg: actual-predicted:    113,  116.3, error:    3.3. Current MAE: 25.25, RMSE: 73.39:  76% 977/1286 [01:15<00:18, 16.73it/s]\n",
            "5907.jpg: actual-predicted:    156,  132.3, error:   23.7. Current MAE: 25.24, RMSE: 73.36:  76% 979/1286 [01:15<00:18, 16.38it/s]\n",
            "5908.jpg: actual-predicted:    116,   84.0, error:   32.0. Current MAE: 25.25, RMSE: 73.33:  76% 979/1286 [01:15<00:18, 16.38it/s]\n",
            "5909.jpg: actual-predicted:     65,   62.2, error:    2.8. Current MAE: 25.23, RMSE: 73.29:  76% 979/1286 [01:15<00:18, 16.38it/s]\n",
            "5910.jpg: actual-predicted:     62,   54.3, error:    7.7. Current MAE: 25.21, RMSE: 73.25:  76% 982/1286 [01:15<00:17, 17.35it/s]\n",
            "5911.jpg: actual-predicted:     40,   18.7, error:   21.3. Current MAE: 25.21, RMSE: 73.22:  76% 982/1286 [01:15<00:17, 17.35it/s]\n",
            "5912.jpg: actual-predicted:     42,   40.0, error:    2.0. Current MAE: 25.18, RMSE: 73.18:  77% 984/1286 [01:15<00:17, 17.73it/s]\n",
            "5913.jpg: actual-predicted:    123,   73.3, error:   49.7. Current MAE: 25.21, RMSE: 73.16:  77% 984/1286 [01:15<00:17, 17.73it/s]\n",
            "5914.jpg: actual-predicted:     63,   55.3, error:    7.7. Current MAE: 25.19, RMSE: 73.13:  77% 984/1286 [01:15<00:17, 17.73it/s]\n",
            "5947.jpg: actual-predicted:     12,   11.4, error:    0.6. Current MAE: 25.17, RMSE: 73.09:  77% 987/1286 [01:15<00:15, 18.71it/s]\n",
            "5948.jpg: actual-predicted:     55,    6.8, error:   48.2. Current MAE: 25.19, RMSE: 73.07:  77% 987/1286 [01:15<00:15, 18.71it/s]\n",
            "5949.jpg: actual-predicted:     13,   47.0, error:   34.0. Current MAE: 25.20, RMSE: 73.04:  77% 989/1286 [01:15<00:19, 14.99it/s]\n",
            "5950.jpg: actual-predicted:      8,   15.5, error:    7.5. Current MAE: 25.18, RMSE: 73.00:  77% 989/1286 [01:15<00:19, 14.99it/s]\n",
            "5951.jpg: actual-predicted:     29,   23.2, error:    5.8. Current MAE: 25.16, RMSE: 72.97:  77% 991/1286 [01:16<00:20, 14.10it/s]\n",
            "5952.jpg: actual-predicted:     48,   88.5, error:   40.5. Current MAE: 25.18, RMSE: 72.94:  77% 991/1286 [01:16<00:20, 14.10it/s]\n",
            "6055.jpg: actual-predicted:     24,   38.2, error:   14.2. Current MAE: 25.16, RMSE: 72.91:  77% 993/1286 [01:16<00:20, 14.02it/s]\n",
            "6056.jpg: actual-predicted:     11,   52.6, error:   41.6. Current MAE: 25.18, RMSE: 72.88:  77% 993/1286 [01:16<00:20, 14.02it/s]\n",
            "6057.jpg: actual-predicted:     49,   39.1, error:    9.9. Current MAE: 25.17, RMSE: 72.84:  77% 995/1286 [01:16<00:19, 15.25it/s]\n",
            "6058.jpg: actual-predicted:     12,    6.3, error:    5.7. Current MAE: 25.15, RMSE: 72.81:  77% 995/1286 [01:16<00:19, 15.25it/s]\n",
            "6059.jpg: actual-predicted:     10,   26.0, error:   16.0. Current MAE: 25.14, RMSE: 72.77:  78% 997/1286 [01:16<00:22, 12.84it/s]\n",
            "6060.jpg: actual-predicted:     11,   20.0, error:    9.0. Current MAE: 25.12, RMSE: 72.74:  78% 997/1286 [01:16<00:22, 12.84it/s]\n",
            "6061.jpg: actual-predicted:    104,   86.3, error:   17.7. Current MAE: 25.11, RMSE: 72.70:  78% 999/1286 [01:16<00:20, 13.71it/s]\n",
            "6062.jpg: actual-predicted:     11,    4.9, error:    6.1. Current MAE: 25.09, RMSE: 72.67:  78% 999/1286 [01:16<00:20, 13.71it/s]\n",
            "6063.jpg: actual-predicted:     23,   25.3, error:    2.3. Current MAE: 25.07, RMSE: 72.63:  78% 1001/1286 [01:16<00:20, 14.08it/s]\n",
            "6064.jpg: actual-predicted:     33,   21.6, error:   11.4. Current MAE: 25.06, RMSE: 72.60:  78% 1001/1286 [01:16<00:20, 14.08it/s]\n",
            "6065.jpg: actual-predicted:     12,   37.9, error:   25.9. Current MAE: 25.06, RMSE: 72.56:  78% 1003/1286 [01:16<00:18, 15.44it/s]\n",
            "6066.jpg: actual-predicted:     36,   23.3, error:   12.7. Current MAE: 25.05, RMSE: 72.53:  78% 1003/1286 [01:16<00:18, 15.44it/s]\n",
            "6067.jpg: actual-predicted:     53,   39.6, error:   13.4. Current MAE: 25.03, RMSE: 72.49:  78% 1005/1286 [01:17<00:18, 15.22it/s]\n",
            "6068.jpg: actual-predicted:     10,   13.0, error:    3.0. Current MAE: 25.01, RMSE: 72.46:  78% 1005/1286 [01:17<00:18, 15.22it/s]\n",
            "6069.jpg: actual-predicted:     16,   25.1, error:    9.1. Current MAE: 25.00, RMSE: 72.42:  78% 1007/1286 [01:17<00:17, 15.71it/s]\n",
            "6070.jpg: actual-predicted:     24,   61.8, error:   37.8. Current MAE: 25.01, RMSE: 72.40:  78% 1007/1286 [01:17<00:17, 15.71it/s]\n",
            "6071.jpg: actual-predicted:      9,   42.1, error:   33.1. Current MAE: 25.02, RMSE: 72.37:  78% 1009/1286 [01:17<00:18, 14.85it/s]\n",
            "6072.jpg: actual-predicted:     36,   36.0, error:    0.0. Current MAE: 24.99, RMSE: 72.33:  78% 1009/1286 [01:17<00:18, 14.85it/s]\n",
            "6073.jpg: actual-predicted:     18,   20.4, error:    2.4. Current MAE: 24.97, RMSE: 72.30:  79% 1011/1286 [01:17<00:21, 12.53it/s]\n",
            "6074.jpg: actual-predicted:     25,   17.6, error:    7.4. Current MAE: 24.95, RMSE: 72.26:  79% 1011/1286 [01:17<00:21, 12.53it/s]\n",
            "6075.jpg: actual-predicted:     98,   49.5, error:   48.5. Current MAE: 24.98, RMSE: 72.24:  79% 1013/1286 [01:17<00:22, 12.16it/s]\n",
            "6076.jpg: actual-predicted:     16,   23.7, error:    7.7. Current MAE: 24.96, RMSE: 72.21:  79% 1013/1286 [01:17<00:22, 12.16it/s]\n",
            "6077.jpg: actual-predicted:     27,   19.3, error:    7.7. Current MAE: 24.94, RMSE: 72.17:  79% 1015/1286 [01:17<00:22, 12.05it/s]\n",
            "6078.jpg: actual-predicted:     37,   55.7, error:   18.7. Current MAE: 24.94, RMSE: 72.14:  79% 1015/1286 [01:17<00:22, 12.05it/s]\n",
            "6079.jpg: actual-predicted:     10,   14.1, error:    4.1. Current MAE: 24.92, RMSE: 72.10:  79% 1017/1286 [01:18<00:21, 12.57it/s]\n",
            "6080.jpg: actual-predicted:    277,  267.0, error:   10.0. Current MAE: 24.90, RMSE: 72.07:  79% 1017/1286 [01:18<00:21, 12.57it/s]\n",
            "6081.jpg: actual-predicted:      9,   19.5, error:   10.5. Current MAE: 24.89, RMSE: 72.03:  79% 1019/1286 [01:18<00:20, 12.92it/s]\n",
            "6082.jpg: actual-predicted:     31,   53.7, error:   22.7. Current MAE: 24.89, RMSE: 72.00:  79% 1019/1286 [01:18<00:20, 12.92it/s]\n",
            "6083.jpg: actual-predicted:      8,    3.9, error:    4.1. Current MAE: 24.86, RMSE: 71.97:  79% 1021/1286 [01:18<00:20, 13.00it/s]\n",
            "6084.jpg: actual-predicted:     30,   44.3, error:   14.3. Current MAE: 24.85, RMSE: 71.93:  79% 1021/1286 [01:18<00:20, 13.00it/s]\n",
            "6085.jpg: actual-predicted:     18,    5.7, error:   12.3. Current MAE: 24.84, RMSE: 71.90:  80% 1023/1286 [01:18<00:22, 11.58it/s]\n",
            "6086.jpg: actual-predicted:     11,    7.7, error:    3.3. Current MAE: 24.82, RMSE: 71.86:  80% 1023/1286 [01:18<00:22, 11.58it/s]\n",
            "6087.jpg: actual-predicted:     11,    5.6, error:    5.4. Current MAE: 24.80, RMSE: 71.83:  80% 1025/1286 [01:18<00:25, 10.19it/s]\n",
            "6088.jpg: actual-predicted:     32,   26.7, error:    5.3. Current MAE: 24.78, RMSE: 71.79:  80% 1025/1286 [01:18<00:25, 10.19it/s]\n",
            "6089.jpg: actual-predicted:     19,   17.9, error:    1.1. Current MAE: 24.76, RMSE: 71.76:  80% 1027/1286 [01:18<00:23, 11.23it/s]\n",
            "6090.jpg: actual-predicted:     21,   17.8, error:    3.2. Current MAE: 24.74, RMSE: 71.73:  80% 1027/1286 [01:18<00:23, 11.23it/s]\n",
            "6091.jpg: actual-predicted:     11,    2.9, error:    8.1. Current MAE: 24.72, RMSE: 71.69:  80% 1029/1286 [01:19<00:22, 11.39it/s]\n",
            "6092.jpg: actual-predicted:     12,    8.8, error:    3.2. Current MAE: 24.70, RMSE: 71.66:  80% 1029/1286 [01:19<00:22, 11.39it/s]\n",
            "6093.jpg: actual-predicted:     28,   35.2, error:    7.2. Current MAE: 24.69, RMSE: 71.62:  80% 1031/1286 [01:19<00:26,  9.79it/s]\n",
            "6094.jpg: actual-predicted:      9,    8.7, error:    0.3. Current MAE: 24.66, RMSE: 71.59:  80% 1031/1286 [01:19<00:26,  9.79it/s]\n",
            "6095.jpg: actual-predicted:     29,   50.9, error:   21.9. Current MAE: 24.66, RMSE: 71.56:  80% 1033/1286 [01:19<00:23, 10.56it/s]\n",
            "6096.jpg: actual-predicted:     18,   12.0, error:    6.0. Current MAE: 24.64, RMSE: 71.52:  80% 1033/1286 [01:19<00:23, 10.56it/s]\n",
            "6097.jpg: actual-predicted:     21,   31.5, error:   10.5. Current MAE: 24.63, RMSE: 71.49:  80% 1035/1286 [01:19<00:23, 10.66it/s]\n",
            "6098.jpg: actual-predicted:     13,   12.4, error:    0.6. Current MAE: 24.60, RMSE: 71.45:  80% 1035/1286 [01:19<00:23, 10.66it/s]\n",
            "6099.jpg: actual-predicted:     26,   13.8, error:   12.2. Current MAE: 24.59, RMSE: 71.42:  81% 1037/1286 [01:19<00:23, 10.82it/s]\n",
            "6100.jpg: actual-predicted:     12,   14.2, error:    2.2. Current MAE: 24.57, RMSE: 71.39:  81% 1037/1286 [01:19<00:23, 10.82it/s]\n",
            "6101.jpg: actual-predicted:      8,    6.4, error:    1.6. Current MAE: 24.55, RMSE: 71.35:  81% 1039/1286 [01:20<00:21, 11.47it/s]\n",
            "6102.jpg: actual-predicted:      9,    5.5, error:    3.5. Current MAE: 24.53, RMSE: 71.32:  81% 1039/1286 [01:20<00:21, 11.47it/s]\n",
            "6103.jpg: actual-predicted:     32,    5.0, error:   27.0. Current MAE: 24.53, RMSE: 71.29:  81% 1041/1286 [01:20<00:24, 10.20it/s]\n",
            "6104.jpg: actual-predicted:     27,   39.4, error:   12.4. Current MAE: 24.52, RMSE: 71.25:  81% 1041/1286 [01:20<00:24, 10.20it/s]\n",
            "6105.jpg: actual-predicted:     20,   39.6, error:   19.6. Current MAE: 24.51, RMSE: 71.22:  81% 1043/1286 [01:20<00:22, 10.57it/s]\n",
            "6106.jpg: actual-predicted:     18,    3.6, error:   14.4. Current MAE: 24.50, RMSE: 71.19:  81% 1043/1286 [01:20<00:22, 10.57it/s]\n",
            "6107.jpg: actual-predicted:     15,   27.3, error:   12.3. Current MAE: 24.49, RMSE: 71.16:  81% 1045/1286 [01:20<00:23, 10.34it/s]\n",
            "6108.jpg: actual-predicted:     18,    4.6, error:   13.4. Current MAE: 24.48, RMSE: 71.12:  81% 1045/1286 [01:20<00:23, 10.34it/s]\n",
            "6109.jpg: actual-predicted:     32,   25.2, error:    6.8. Current MAE: 24.47, RMSE: 71.09:  81% 1047/1286 [01:20<00:22, 10.62it/s]\n",
            "6110.jpg: actual-predicted:     15,   11.8, error:    3.2. Current MAE: 24.45, RMSE: 71.06:  81% 1047/1286 [01:20<00:22, 10.62it/s]\n",
            "6111.jpg: actual-predicted:     46,   53.1, error:    7.1. Current MAE: 24.43, RMSE: 71.02:  82% 1049/1286 [01:20<00:20, 11.56it/s]\n",
            "6112.jpg: actual-predicted:     23,   14.5, error:    8.5. Current MAE: 24.41, RMSE: 70.99:  82% 1049/1286 [01:20<00:20, 11.56it/s]\n",
            "6113.jpg: actual-predicted:     11,   29.4, error:   18.4. Current MAE: 24.41, RMSE: 70.96:  82% 1051/1286 [01:21<00:18, 12.82it/s]\n",
            "6114.jpg: actual-predicted:     21,    9.3, error:   11.7. Current MAE: 24.40, RMSE: 70.93:  82% 1051/1286 [01:21<00:18, 12.82it/s]\n",
            "6115.jpg: actual-predicted:     16,    8.0, error:    8.0. Current MAE: 24.38, RMSE: 70.89:  82% 1053/1286 [01:21<00:18, 12.74it/s]\n",
            "6116.jpg: actual-predicted:     14,   17.8, error:    3.8. Current MAE: 24.36, RMSE: 70.86:  82% 1053/1286 [01:21<00:18, 12.74it/s]\n",
            "6117.jpg: actual-predicted:     12,   23.9, error:   11.9. Current MAE: 24.35, RMSE: 70.83:  82% 1055/1286 [01:21<00:20, 11.28it/s]\n",
            "6118.jpg: actual-predicted:     17,   35.6, error:   18.6. Current MAE: 24.34, RMSE: 70.80:  82% 1055/1286 [01:21<00:20, 11.28it/s]\n",
            "6119.jpg: actual-predicted:     14,    5.4, error:    8.6. Current MAE: 24.33, RMSE: 70.76:  82% 1057/1286 [01:21<00:19, 11.69it/s]\n",
            "6120.jpg: actual-predicted:     14,   19.0, error:    5.0. Current MAE: 24.31, RMSE: 70.73:  82% 1057/1286 [01:21<00:19, 11.69it/s]\n",
            "6121.jpg: actual-predicted:     14,    7.5, error:    6.5. Current MAE: 24.29, RMSE: 70.70:  82% 1059/1286 [01:21<00:21, 10.46it/s]\n",
            "6122.jpg: actual-predicted:     15,    2.3, error:   12.7. Current MAE: 24.28, RMSE: 70.66:  82% 1059/1286 [01:22<00:21, 10.46it/s]\n",
            "6286.jpg: actual-predicted:     49,   42.6, error:    6.4. Current MAE: 24.27, RMSE: 70.63:  83% 1061/1286 [01:22<00:23,  9.65it/s]\n",
            "6287.jpg: actual-predicted:     23,   36.5, error:   13.5. Current MAE: 24.26, RMSE: 70.60:  83% 1061/1286 [01:22<00:23,  9.65it/s]\n",
            "6288.jpg: actual-predicted:     18,   44.4, error:   26.4. Current MAE: 24.26, RMSE: 70.57:  83% 1063/1286 [01:22<00:20, 11.14it/s]\n",
            "6289.jpg: actual-predicted:     16,   12.2, error:    3.8. Current MAE: 24.24, RMSE: 70.54:  83% 1063/1286 [01:22<00:20, 11.14it/s]\n",
            "6290.jpg: actual-predicted:     31,   39.4, error:    8.4. Current MAE: 24.22, RMSE: 70.50:  83% 1065/1286 [01:22<00:18, 12.16it/s]\n",
            "6291.jpg: actual-predicted:     15,   15.8, error:    0.8. Current MAE: 24.20, RMSE: 70.47:  83% 1065/1286 [01:22<00:18, 12.16it/s]\n",
            "6292.jpg: actual-predicted:      9,   16.3, error:    7.3. Current MAE: 24.19, RMSE: 70.44:  83% 1067/1286 [01:22<00:16, 13.30it/s]\n",
            "6293.jpg: actual-predicted:      9,   10.2, error:    1.2. Current MAE: 24.16, RMSE: 70.41:  83% 1067/1286 [01:22<00:16, 13.30it/s]\n",
            "6294.jpg: actual-predicted:     50,   29.7, error:   20.3. Current MAE: 24.16, RMSE: 70.38:  83% 1069/1286 [01:22<00:16, 13.42it/s]\n",
            "6295.jpg: actual-predicted:     70,   99.5, error:   29.5. Current MAE: 24.17, RMSE: 70.35:  83% 1069/1286 [01:22<00:16, 13.42it/s]\n",
            "6296.jpg: actual-predicted:     33,   50.3, error:   17.3. Current MAE: 24.16, RMSE: 70.32:  83% 1071/1286 [01:22<00:15, 13.67it/s]\n",
            "6297.jpg: actual-predicted:     16,   32.1, error:   16.1. Current MAE: 24.15, RMSE: 70.29:  83% 1071/1286 [01:22<00:15, 13.67it/s]\n",
            "6298.jpg: actual-predicted:     61,   42.7, error:   18.3. Current MAE: 24.15, RMSE: 70.26:  83% 1073/1286 [01:22<00:15, 13.86it/s]\n",
            "6299.jpg: actual-predicted:     28,   48.8, error:   20.8. Current MAE: 24.14, RMSE: 70.23:  83% 1073/1286 [01:22<00:15, 13.86it/s]\n",
            "6300.jpg: actual-predicted:     24,   21.7, error:    2.3. Current MAE: 24.12, RMSE: 70.19:  84% 1075/1286 [01:22<00:15, 13.59it/s]\n",
            "6301.jpg: actual-predicted:     24,   28.9, error:    4.9. Current MAE: 24.11, RMSE: 70.16:  84% 1075/1286 [01:23<00:15, 13.59it/s]\n",
            "6302.jpg: actual-predicted:     58,   37.5, error:   20.5. Current MAE: 24.10, RMSE: 70.13:  84% 1077/1286 [01:23<00:15, 13.30it/s]\n",
            "6303.jpg: actual-predicted:      9,   38.9, error:   29.9. Current MAE: 24.11, RMSE: 70.10:  84% 1077/1286 [01:23<00:15, 13.30it/s]\n",
            "6304.jpg: actual-predicted:     17,   16.1, error:    0.9. Current MAE: 24.09, RMSE: 70.07:  84% 1079/1286 [01:23<00:15, 13.31it/s]\n",
            "6305.jpg: actual-predicted:     32,   26.1, error:    5.9. Current MAE: 24.07, RMSE: 70.04:  84% 1079/1286 [01:23<00:15, 13.31it/s]\n",
            "6306.jpg: actual-predicted:     11,   20.1, error:    9.1. Current MAE: 24.06, RMSE: 70.01:  84% 1081/1286 [01:23<00:15, 13.65it/s]\n",
            "6307.jpg: actual-predicted:     10,   29.5, error:   19.5. Current MAE: 24.05, RMSE: 69.98:  84% 1081/1286 [01:23<00:15, 13.65it/s]\n",
            "7532.jpg: actual-predicted:     20,   15.4, error:    4.6. Current MAE: 24.03, RMSE: 69.95:  84% 1083/1286 [01:23<00:14, 14.36it/s]\n",
            "6927.jpg: actual-predicted:     32,   38.6, error:    6.6. Current MAE: 24.02, RMSE: 69.91:  84% 1083/1286 [01:23<00:14, 14.36it/s]\n",
            "6728.jpg: actual-predicted:     99,   79.3, error:   19.7. Current MAE: 24.01, RMSE: 69.88:  84% 1085/1286 [01:23<00:18, 10.89it/s]\n",
            "7228.jpg: actual-predicted:     63,   78.9, error:   15.9. Current MAE: 24.01, RMSE: 69.85:  84% 1085/1286 [01:23<00:18, 10.89it/s]\n",
            "7330.jpg: actual-predicted:     40,   54.5, error:   14.5. Current MAE: 24.00, RMSE: 69.82:  85% 1087/1286 [01:24<00:16, 12.02it/s]\n",
            "6779.jpg: actual-predicted:    119,   76.7, error:   42.3. Current MAE: 24.01, RMSE: 69.80:  85% 1087/1286 [01:24<00:16, 12.02it/s]\n",
            "7540.jpg: actual-predicted:     64,   81.5, error:   17.5. Current MAE: 24.01, RMSE: 69.77:  85% 1089/1286 [01:24<00:15, 12.63it/s]\n",
            "6885.jpg: actual-predicted:    167,  139.8, error:   27.2. Current MAE: 24.01, RMSE: 69.75:  85% 1089/1286 [01:24<00:15, 12.63it/s]\n",
            "7428.jpg: actual-predicted:     66,   69.9, error:    3.9. Current MAE: 23.99, RMSE: 69.71:  85% 1091/1286 [01:24<00:14, 13.46it/s]\n",
            "7334.jpg: actual-predicted:     53,   34.1, error:   18.9. Current MAE: 23.99, RMSE: 69.68:  85% 1091/1286 [01:24<00:14, 13.46it/s]\n",
            "7390.jpg: actual-predicted:    177,  111.0, error:   66.0. Current MAE: 24.03, RMSE: 69.68:  85% 1093/1286 [01:24<00:15, 12.70it/s]\n",
            "7012.jpg: actual-predicted:     66,   66.1, error:    0.1. Current MAE: 24.00, RMSE: 69.65:  85% 1093/1286 [01:24<00:15, 12.70it/s]\n",
            "6877.jpg: actual-predicted:     66,   58.7, error:    7.3. Current MAE: 23.99, RMSE: 69.62:  85% 1095/1286 [01:24<00:14, 13.48it/s]\n",
            "7461.jpg: actual-predicted:     22,   13.9, error:    8.1. Current MAE: 23.97, RMSE: 69.59:  85% 1095/1286 [01:24<00:14, 13.48it/s]\n",
            "7143.jpg: actual-predicted:    121,  110.7, error:   10.3. Current MAE: 23.96, RMSE: 69.56:  85% 1097/1286 [01:24<00:14, 13.00it/s]\n",
            "7537.jpg: actual-predicted:     39,   52.8, error:   13.8. Current MAE: 23.95, RMSE: 69.53:  85% 1097/1286 [01:24<00:14, 13.00it/s]\n",
            "6897.jpg: actual-predicted:     59,   32.3, error:   26.7. Current MAE: 23.96, RMSE: 69.50:  85% 1099/1286 [01:24<00:14, 12.90it/s]\n",
            "7169.jpg: actual-predicted:     34,   40.9, error:    6.9. Current MAE: 23.94, RMSE: 69.47:  85% 1099/1286 [01:24<00:14, 12.90it/s]\n",
            "6872.jpg: actual-predicted:     49,   75.4, error:   26.4. Current MAE: 23.94, RMSE: 69.44:  86% 1101/1286 [01:25<00:14, 12.85it/s]\n",
            "7088.jpg: actual-predicted:    110,   65.5, error:   44.5. Current MAE: 23.96, RMSE: 69.42:  86% 1101/1286 [01:25<00:14, 12.85it/s]\n",
            "7371.jpg: actual-predicted:    136,  168.5, error:   32.5. Current MAE: 23.97, RMSE: 69.40:  86% 1103/1286 [01:25<00:14, 12.34it/s]\n",
            "7545.jpg: actual-predicted:    106,  117.3, error:   11.3. Current MAE: 23.96, RMSE: 69.37:  86% 1103/1286 [01:25<00:14, 12.34it/s]\n",
            "7269.jpg: actual-predicted:     73,   13.4, error:   59.6. Current MAE: 23.99, RMSE: 69.36:  86% 1105/1286 [01:25<00:14, 12.45it/s]\n",
            "7148.jpg: actual-predicted:     67,   11.3, error:   55.7. Current MAE: 24.02, RMSE: 69.35:  86% 1105/1286 [01:25<00:14, 12.45it/s]\n",
            "7501.jpg: actual-predicted:    218,  153.9, error:   64.1. Current MAE: 24.05, RMSE: 69.34:  86% 1107/1286 [01:25<00:18,  9.79it/s]\n",
            "7658.jpg: actual-predicted:    211,  183.9, error:   27.1. Current MAE: 24.06, RMSE: 69.32:  86% 1107/1286 [01:25<00:18,  9.79it/s]\n",
            "7133.jpg: actual-predicted:     35,   46.5, error:   11.5. Current MAE: 24.05, RMSE: 69.29:  86% 1109/1286 [01:25<00:16, 10.78it/s]\n",
            "7197.jpg: actual-predicted:     79,   27.5, error:   51.5. Current MAE: 24.07, RMSE: 69.27:  86% 1109/1286 [01:25<00:16, 10.78it/s]\n",
            "7601.jpg: actual-predicted:    142,  156.1, error:   14.1. Current MAE: 24.06, RMSE: 69.24:  86% 1111/1286 [01:26<00:16, 10.43it/s]\n",
            "7257.jpg: actual-predicted:     33,   23.0, error:   10.0. Current MAE: 24.05, RMSE: 69.21:  86% 1111/1286 [01:26<00:16, 10.43it/s]\n",
            "7069.jpg: actual-predicted:    142,  122.4, error:   19.6. Current MAE: 24.04, RMSE: 69.18:  87% 1113/1286 [01:26<00:16, 10.75it/s]\n",
            "7029.jpg: actual-predicted:    199,   80.1, error:  118.9. Current MAE: 24.13, RMSE: 69.24:  87% 1113/1286 [01:26<00:16, 10.75it/s]\n",
            "7368.jpg: actual-predicted:     74,    7.2, error:   66.8. Current MAE: 24.17, RMSE: 69.24:  87% 1113/1286 [01:26<00:16, 10.75it/s]\n",
            "7619.jpg: actual-predicted:     16,   16.2, error:    0.2. Current MAE: 24.15, RMSE: 69.21:  87% 1116/1286 [01:26<00:14, 11.38it/s]\n",
            "6875.jpg: actual-predicted:     20,   22.4, error:    2.4. Current MAE: 24.13, RMSE: 69.18:  87% 1116/1286 [01:26<00:14, 11.38it/s]\n",
            "7660.jpg: actual-predicted:     11,   16.7, error:    5.7. Current MAE: 24.11, RMSE: 69.15:  87% 1118/1286 [01:26<00:14, 11.40it/s]\n",
            "7604.jpg: actual-predicted:     17,    4.8, error:   12.2. Current MAE: 24.10, RMSE: 69.12:  87% 1118/1286 [01:26<00:14, 11.40it/s]\n",
            "7344.jpg: actual-predicted:     30,   24.8, error:    5.2. Current MAE: 24.08, RMSE: 69.09:  87% 1120/1286 [01:26<00:16, 10.25it/s]\n",
            "7651.jpg: actual-predicted:     75,   93.5, error:   18.5. Current MAE: 24.08, RMSE: 69.06:  87% 1120/1286 [01:26<00:16, 10.25it/s]\n",
            "6896.jpg: actual-predicted:     15,    7.8, error:    7.2. Current MAE: 24.06, RMSE: 69.03:  87% 1122/1286 [01:27<00:14, 11.19it/s]\n",
            "6944.jpg: actual-predicted:     26,   19.0, error:    7.0. Current MAE: 24.05, RMSE: 69.00:  87% 1122/1286 [01:27<00:14, 11.19it/s]\n",
            "7558.jpg: actual-predicted:     37,   39.9, error:    2.9. Current MAE: 24.03, RMSE: 68.97:  87% 1124/1286 [01:27<00:15, 10.62it/s]\n",
            "6866.jpg: actual-predicted:    207,   84.3, error:  122.7. Current MAE: 24.12, RMSE: 69.03:  87% 1124/1286 [01:27<00:15, 10.62it/s]\n",
            "6784.jpg: actual-predicted:     52,   55.6, error:    3.6. Current MAE: 24.10, RMSE: 69.00:  88% 1126/1286 [01:27<00:13, 11.80it/s]\n",
            "6778.jpg: actual-predicted:     47,   49.9, error:    2.9. Current MAE: 24.08, RMSE: 68.97:  88% 1126/1286 [01:27<00:13, 11.80it/s]\n",
            "7077.jpg: actual-predicted:    140,  113.5, error:   26.5. Current MAE: 24.08, RMSE: 68.95:  88% 1128/1286 [01:27<00:13, 11.95it/s]\n",
            "6801.jpg: actual-predicted:     29,   29.8, error:    0.8. Current MAE: 24.06, RMSE: 68.92:  88% 1128/1286 [01:27<00:13, 11.95it/s]\n",
            "7280.jpg: actual-predicted:    116,   95.3, error:   20.7. Current MAE: 24.06, RMSE: 68.89:  88% 1130/1286 [01:27<00:12, 12.34it/s]\n",
            "7003.jpg: actual-predicted:    182,  167.0, error:   15.0. Current MAE: 24.05, RMSE: 68.86:  88% 1130/1286 [01:27<00:12, 12.34it/s]\n",
            "6836.jpg: actual-predicted:     15,   12.4, error:    2.6. Current MAE: 24.03, RMSE: 68.83:  88% 1132/1286 [01:27<00:12, 12.71it/s]\n",
            "7317.jpg: actual-predicted:     11,    9.7, error:    1.3. Current MAE: 24.01, RMSE: 68.80:  88% 1132/1286 [01:27<00:12, 12.71it/s]\n",
            "7063.jpg: actual-predicted:     17,   11.1, error:    5.9. Current MAE: 23.99, RMSE: 68.77:  88% 1134/1286 [01:28<00:13, 11.24it/s]\n",
            "7304.jpg: actual-predicted:     12,   17.2, error:    5.2. Current MAE: 23.98, RMSE: 68.74:  88% 1134/1286 [01:28<00:13, 11.24it/s]\n",
            "7434.jpg: actual-predicted:    169,  117.2, error:   51.8. Current MAE: 24.00, RMSE: 68.73:  88% 1136/1286 [01:28<00:13, 10.87it/s]\n",
            "7107.jpg: actual-predicted:     19,    9.1, error:    9.9. Current MAE: 23.99, RMSE: 68.70:  88% 1136/1286 [01:28<00:13, 10.87it/s]\n",
            "6939.jpg: actual-predicted:     62,   77.6, error:   15.6. Current MAE: 23.98, RMSE: 68.67:  88% 1138/1286 [01:28<00:15,  9.54it/s]\n",
            "6729.jpg: actual-predicted:    251,  210.4, error:   40.6. Current MAE: 24.00, RMSE: 68.65:  88% 1138/1286 [01:28<00:15,  9.54it/s]\n",
            "7656.jpg: actual-predicted:   1231,  268.7, error:  962.3. Current MAE: 24.82, RMSE: 74.30:  89% 1140/1286 [01:28<00:14,  9.85it/s]\n",
            "6775.jpg: actual-predicted:    191,  160.3, error:   30.7. Current MAE: 24.83, RMSE: 74.27:  89% 1140/1286 [01:28<00:14,  9.85it/s]\n",
            "6722.jpg: actual-predicted:     36,   56.8, error:   20.8. Current MAE: 24.82, RMSE: 74.24:  89% 1142/1286 [01:28<00:12, 11.35it/s]\n",
            "7223.jpg: actual-predicted:    105,  114.4, error:    9.4. Current MAE: 24.81, RMSE: 74.21:  89% 1142/1286 [01:28<00:12, 11.35it/s]\n",
            "7308.jpg: actual-predicted:    186,  146.7, error:   39.3. Current MAE: 24.82, RMSE: 74.19:  89% 1144/1286 [01:28<00:11, 11.90it/s]\n",
            "6741.jpg: actual-predicted:     22,    3.2, error:   18.8. Current MAE: 24.82, RMSE: 74.16:  89% 1144/1286 [01:29<00:11, 11.90it/s]\n",
            "7125.jpg: actual-predicted:     37,   43.6, error:    6.6. Current MAE: 24.80, RMSE: 74.12:  89% 1146/1286 [01:29<00:12, 10.97it/s]\n",
            "7028.jpg: actual-predicted:    214,  100.7, error:  113.3. Current MAE: 24.88, RMSE: 74.17:  89% 1146/1286 [01:29<00:12, 10.97it/s]\n",
            "7258.jpg: actual-predicted:     20,   14.2, error:    5.8. Current MAE: 24.86, RMSE: 74.13:  89% 1148/1286 [01:29<00:11, 11.58it/s]\n",
            "6794.jpg: actual-predicted:     27,   10.6, error:   16.4. Current MAE: 24.85, RMSE: 74.10:  89% 1148/1286 [01:29<00:11, 11.58it/s]\n",
            "7360.jpg: actual-predicted:     13,   32.6, error:   19.6. Current MAE: 24.85, RMSE: 74.07:  89% 1150/1286 [01:29<00:12, 10.86it/s]\n",
            "7636.jpg: actual-predicted:     22,   32.4, error:   10.4. Current MAE: 24.84, RMSE: 74.04:  89% 1150/1286 [01:29<00:12, 10.86it/s]\n",
            "7649.jpg: actual-predicted:     19,   29.8, error:   10.8. Current MAE: 24.82, RMSE: 74.01:  90% 1152/1286 [01:29<00:11, 11.58it/s]\n",
            "7568.jpg: actual-predicted:     24,   60.4, error:   36.4. Current MAE: 24.83, RMSE: 73.99:  90% 1152/1286 [01:29<00:11, 11.58it/s]\n",
            "7655.jpg: actual-predicted:     72,   43.1, error:   28.9. Current MAE: 24.84, RMSE: 73.96:  90% 1154/1286 [01:29<00:10, 12.17it/s]\n",
            "6787.jpg: actual-predicted:     28,   33.0, error:    5.0. Current MAE: 24.82, RMSE: 73.93:  90% 1154/1286 [01:29<00:10, 12.17it/s]\n",
            "7435.jpg: actual-predicted:     40,   32.8, error:    7.2. Current MAE: 24.80, RMSE: 73.90:  90% 1156/1286 [01:29<00:09, 13.49it/s]\n",
            "7544.jpg: actual-predicted:     67,  110.1, error:   43.1. Current MAE: 24.82, RMSE: 73.87:  90% 1156/1286 [01:29<00:09, 13.49it/s]\n",
            "6926.jpg: actual-predicted:    238,  120.6, error:  117.4. Current MAE: 24.90, RMSE: 73.92:  90% 1158/1286 [01:30<00:08, 14.42it/s]\n",
            "7433.jpg: actual-predicted:     13,   37.7, error:   24.7. Current MAE: 24.90, RMSE: 73.89:  90% 1158/1286 [01:30<00:08, 14.42it/s]\n",
            "6744.jpg: actual-predicted:     17,   41.1, error:   24.1. Current MAE: 24.90, RMSE: 73.87:  90% 1160/1286 [01:30<00:08, 15.33it/s]\n",
            "7193.jpg: actual-predicted:     13,   19.2, error:    6.2. Current MAE: 24.88, RMSE: 73.83:  90% 1160/1286 [01:30<00:08, 15.33it/s]\n",
            "7348.jpg: actual-predicted:     12,   23.1, error:   11.1. Current MAE: 24.87, RMSE: 73.80:  90% 1162/1286 [01:30<00:08, 14.00it/s]\n",
            "6882.jpg: actual-predicted:     10,    8.0, error:    2.0. Current MAE: 24.85, RMSE: 73.77:  90% 1162/1286 [01:30<00:08, 14.00it/s]\n",
            "6957.jpg: actual-predicted:     11,   20.3, error:    9.3. Current MAE: 24.84, RMSE: 73.74:  91% 1164/1286 [01:30<00:10, 11.79it/s]\n",
            "7393.jpg: actual-predicted:     18,   26.5, error:    8.5. Current MAE: 24.82, RMSE: 73.71:  91% 1164/1286 [01:30<00:10, 11.79it/s]\n",
            "6796.jpg: actual-predicted:     12,   20.1, error:    8.1. Current MAE: 24.81, RMSE: 73.68:  91% 1166/1286 [01:30<00:10, 11.99it/s]\n",
            "7391.jpg: actual-predicted:     14,   19.4, error:    5.4. Current MAE: 24.79, RMSE: 73.65:  91% 1166/1286 [01:30<00:10, 11.99it/s]\n",
            "6979.jpg: actual-predicted:     11,   15.5, error:    4.5. Current MAE: 24.78, RMSE: 73.62:  91% 1168/1286 [01:30<00:09, 12.40it/s]\n",
            "7421.jpg: actual-predicted:     10,   20.6, error:   10.6. Current MAE: 24.76, RMSE: 73.58:  91% 1168/1286 [01:30<00:09, 12.40it/s]\n",
            "7543.jpg: actual-predicted:     19,   11.1, error:    7.9. Current MAE: 24.75, RMSE: 73.55:  91% 1170/1286 [01:31<00:09, 12.61it/s]\n",
            "7208.jpg: actual-predicted:     10,   12.2, error:    2.2. Current MAE: 24.73, RMSE: 73.52:  91% 1170/1286 [01:31<00:09, 12.61it/s]\n",
            "6825.jpg: actual-predicted:     14,   33.2, error:   19.2. Current MAE: 24.73, RMSE: 73.49:  91% 1172/1286 [01:31<00:08, 12.70it/s]\n",
            "7602.jpg: actual-predicted:     14,   32.3, error:   18.3. Current MAE: 24.72, RMSE: 73.46:  91% 1172/1286 [01:31<00:08, 12.70it/s]\n",
            "7531.jpg: actual-predicted:     65,   45.5, error:   19.5. Current MAE: 24.72, RMSE: 73.43:  91% 1174/1286 [01:31<00:08, 13.21it/s]\n",
            "6871.jpg: actual-predicted:     17,   26.6, error:    9.6. Current MAE: 24.70, RMSE: 73.40:  91% 1174/1286 [01:31<00:08, 13.21it/s]\n",
            "6814.jpg: actual-predicted:     28,   30.9, error:    2.9. Current MAE: 24.68, RMSE: 73.37:  91% 1176/1286 [01:31<00:07, 14.68it/s]\n",
            "6751.jpg: actual-predicted:    142,  104.9, error:   37.1. Current MAE: 24.70, RMSE: 73.35:  91% 1176/1286 [01:31<00:07, 14.68it/s]\n",
            "7518.jpg: actual-predicted:     21,   44.6, error:   23.6. Current MAE: 24.69, RMSE: 73.32:  92% 1178/1286 [01:31<00:07, 14.28it/s]\n",
            "7224.jpg: actual-predicted:     50,   62.3, error:   12.3. Current MAE: 24.68, RMSE: 73.29:  92% 1178/1286 [01:31<00:07, 14.28it/s]\n",
            "6753.jpg: actual-predicted:     18,   19.6, error:    1.6. Current MAE: 24.66, RMSE: 73.26:  92% 1180/1286 [01:31<00:07, 15.10it/s]\n",
            "6886.jpg: actual-predicted:     84,   67.0, error:   17.0. Current MAE: 24.66, RMSE: 73.23:  92% 1180/1286 [01:31<00:07, 15.10it/s]\n",
            "7423.jpg: actual-predicted:    138,  157.3, error:   19.3. Current MAE: 24.65, RMSE: 73.20:  92% 1182/1286 [01:31<00:06, 15.68it/s]\n",
            "7305.jpg: actual-predicted:     31,  121.8, error:   90.8. Current MAE: 24.71, RMSE: 73.22:  92% 1182/1286 [01:31<00:06, 15.68it/s]\n",
            "7615.jpg: actual-predicted:    144,  145.7, error:    1.7. Current MAE: 24.69, RMSE: 73.19:  92% 1184/1286 [01:31<00:06, 16.60it/s]\n",
            "6764.jpg: actual-predicted:    112,  107.6, error:    4.4. Current MAE: 24.67, RMSE: 73.16:  92% 1184/1286 [01:31<00:06, 16.60it/s]\n",
            "7477.jpg: actual-predicted:     60,  183.7, error:  123.7. Current MAE: 24.76, RMSE: 73.21:  92% 1186/1286 [01:31<00:06, 16.57it/s]\n",
            "6931.jpg: actual-predicted:    355,  341.6, error:   13.4. Current MAE: 24.75, RMSE: 73.19:  92% 1186/1286 [01:32<00:06, 16.57it/s]\n",
            "6714.jpg: actual-predicted:     26,   31.9, error:    5.9. Current MAE: 24.73, RMSE: 73.15:  92% 1188/1286 [01:32<00:05, 17.34it/s]\n",
            "6948.jpg: actual-predicted:    166,  160.5, error:    5.5. Current MAE: 24.71, RMSE: 73.12:  92% 1188/1286 [01:32<00:05, 17.34it/s]\n",
            "7033.jpg: actual-predicted:     83,  102.9, error:   19.9. Current MAE: 24.71, RMSE: 73.10:  93% 1190/1286 [01:32<00:05, 17.12it/s]\n",
            "6873.jpg: actual-predicted:     11,   11.9, error:    0.9. Current MAE: 24.69, RMSE: 73.06:  93% 1190/1286 [01:32<00:05, 17.12it/s]\n",
            "6969.jpg: actual-predicted:    949,  789.4, error:  159.6. Current MAE: 24.80, RMSE: 73.18:  93% 1190/1286 [01:32<00:05, 17.12it/s]\n",
            "6981.jpg: actual-predicted:     57,   61.9, error:    4.9. Current MAE: 24.79, RMSE: 73.15:  93% 1193/1286 [01:32<00:05, 17.57it/s]\n",
            "7301.jpg: actual-predicted:     36,   47.2, error:   11.2. Current MAE: 24.78, RMSE: 73.12:  93% 1193/1286 [01:32<00:05, 17.57it/s]\n",
            "6783.jpg: actual-predicted:     17,   28.9, error:   11.9. Current MAE: 24.76, RMSE: 73.09:  93% 1195/1286 [01:32<00:05, 17.47it/s]\n",
            "7561.jpg: actual-predicted:     20,   25.2, error:    5.2. Current MAE: 24.75, RMSE: 73.06:  93% 1195/1286 [01:32<00:05, 17.47it/s]\n",
            "7510.jpg: actual-predicted:     61,   63.8, error:    2.8. Current MAE: 24.73, RMSE: 73.03:  93% 1195/1286 [01:32<00:05, 17.47it/s]\n",
            "7418.jpg: actual-predicted:     39,   46.0, error:    7.0. Current MAE: 24.72, RMSE: 73.00:  93% 1198/1286 [01:32<00:04, 18.08it/s]\n",
            "7159.jpg: actual-predicted:     42,   44.5, error:    2.5. Current MAE: 24.70, RMSE: 72.97:  93% 1198/1286 [01:32<00:04, 18.08it/s]\n",
            "7415.jpg: actual-predicted:     23,   27.2, error:    4.2. Current MAE: 24.68, RMSE: 72.94:  93% 1200/1286 [01:32<00:04, 17.49it/s]\n",
            "7004.jpg: actual-predicted:    117,  135.8, error:   18.8. Current MAE: 24.67, RMSE: 72.91:  93% 1200/1286 [01:32<00:04, 17.49it/s]\n",
            "7691.jpg: actual-predicted:     43,   31.3, error:   11.7. Current MAE: 24.66, RMSE: 72.88:  93% 1202/1286 [01:32<00:05, 16.79it/s]\n",
            "7589.jpg: actual-predicted:     18,   19.0, error:    1.0. Current MAE: 24.64, RMSE: 72.85:  93% 1202/1286 [01:32<00:05, 16.79it/s]\n",
            "7149.jpg: actual-predicted:     17,   32.0, error:   15.0. Current MAE: 24.64, RMSE: 72.82:  94% 1204/1286 [01:33<00:05, 16.21it/s]\n",
            "7271.jpg: actual-predicted:    127,  126.1, error:    0.9. Current MAE: 24.62, RMSE: 72.79:  94% 1204/1286 [01:33<00:05, 16.21it/s]\n",
            "7019.jpg: actual-predicted:     65,    7.4, error:   57.6. Current MAE: 24.64, RMSE: 72.78:  94% 1206/1286 [01:33<00:05, 14.73it/s]\n",
            "7403.jpg: actual-predicted:     14,   14.0, error:    0.0. Current MAE: 24.62, RMSE: 72.75:  94% 1206/1286 [01:33<00:05, 14.73it/s]\n",
            "7116.jpg: actual-predicted:     78,   68.9, error:    9.1. Current MAE: 24.61, RMSE: 72.72:  94% 1208/1286 [01:33<00:06, 11.29it/s]\n",
            "7314.jpg: actual-predicted:     23,   21.6, error:    1.4. Current MAE: 24.59, RMSE: 72.69:  94% 1208/1286 [01:33<00:06, 11.29it/s]\n",
            "7498.jpg: actual-predicted:     53,   51.2, error:    1.8. Current MAE: 24.57, RMSE: 72.66:  94% 1210/1286 [01:33<00:06, 11.58it/s]\n",
            "7507.jpg: actual-predicted:     35,   13.1, error:   21.9. Current MAE: 24.57, RMSE: 72.63:  94% 1210/1286 [01:33<00:06, 11.58it/s]\n",
            "6919.jpg: actual-predicted:     26,   18.3, error:    7.7. Current MAE: 24.56, RMSE: 72.60:  94% 1212/1286 [01:33<00:06, 11.93it/s]\n",
            "7051.jpg: actual-predicted:     48,   62.0, error:   14.0. Current MAE: 24.55, RMSE: 72.57:  94% 1212/1286 [01:33<00:06, 11.93it/s]\n",
            "6989.jpg: actual-predicted:     76,   72.2, error:    3.8. Current MAE: 24.53, RMSE: 72.54:  94% 1214/1286 [01:34<00:06, 10.98it/s]\n",
            "7318.jpg: actual-predicted:     30,   32.4, error:    2.4. Current MAE: 24.51, RMSE: 72.51:  94% 1214/1286 [01:34<00:06, 10.98it/s]\n",
            "7250.jpg: actual-predicted:     18,    7.0, error:   11.0. Current MAE: 24.50, RMSE: 72.49:  95% 1216/1286 [01:34<00:05, 12.14it/s]\n",
            "7367.jpg: actual-predicted:     27,   18.7, error:    8.3. Current MAE: 24.49, RMSE: 72.46:  95% 1216/1286 [01:34<00:05, 12.14it/s]\n",
            "6840.jpg: actual-predicted:     19,   26.5, error:    7.5. Current MAE: 24.47, RMSE: 72.43:  95% 1218/1286 [01:34<00:05, 11.93it/s]\n",
            "7006.jpg: actual-predicted:     15,    6.8, error:    8.2. Current MAE: 24.46, RMSE: 72.40:  95% 1218/1286 [01:34<00:05, 11.93it/s]\n",
            "7503.jpg: actual-predicted:     22,   18.1, error:    3.9. Current MAE: 24.44, RMSE: 72.37:  95% 1220/1286 [01:34<00:06, 10.93it/s]\n",
            "6748.jpg: actual-predicted:     27,   54.6, error:   27.6. Current MAE: 24.45, RMSE: 72.34:  95% 1220/1286 [01:34<00:06, 10.93it/s]\n",
            "7164.jpg: actual-predicted:     83,   91.9, error:    8.9. Current MAE: 24.43, RMSE: 72.31:  95% 1222/1286 [01:34<00:06, 10.61it/s]\n",
            "6782.jpg: actual-predicted:     17,   14.5, error:    2.5. Current MAE: 24.42, RMSE: 72.28:  95% 1222/1286 [01:34<00:06, 10.61it/s]\n",
            "6983.jpg: actual-predicted:     40,   47.2, error:    7.2. Current MAE: 24.40, RMSE: 72.25:  95% 1224/1286 [01:35<00:06,  9.13it/s]\n",
            "7673.jpg: actual-predicted:     15,   23.6, error:    8.6. Current MAE: 24.39, RMSE: 72.23:  95% 1225/1286 [01:35<00:06,  9.07it/s]\n",
            "6911.jpg: actual-predicted:     39,   45.3, error:    6.3. Current MAE: 24.37, RMSE: 72.20:  95% 1225/1286 [01:35<00:06,  9.07it/s]\n",
            "7249.jpg: actual-predicted:     61,   28.9, error:   32.1. Current MAE: 24.38, RMSE: 72.17:  95% 1227/1286 [01:35<00:05, 10.08it/s]\n",
            "6767.jpg: actual-predicted:     28,   40.3, error:   12.3. Current MAE: 24.37, RMSE: 72.14:  95% 1227/1286 [01:35<00:05, 10.08it/s]\n",
            "6721.jpg: actual-predicted:     11,   15.2, error:    4.2. Current MAE: 24.35, RMSE: 72.12:  96% 1229/1286 [01:35<00:05, 10.56it/s]\n",
            "6988.jpg: actual-predicted:     24,   19.0, error:    5.0. Current MAE: 24.34, RMSE: 72.09:  96% 1229/1286 [01:35<00:05, 10.56it/s]\n",
            "6846.jpg: actual-predicted:     28,   34.5, error:    6.5. Current MAE: 24.32, RMSE: 72.06:  96% 1231/1286 [01:35<00:04, 11.68it/s]\n",
            "7582.jpg: actual-predicted:     25,   48.6, error:   23.6. Current MAE: 24.32, RMSE: 72.03:  96% 1231/1286 [01:35<00:04, 11.68it/s]\n",
            "7233.jpg: actual-predicted:     24,   28.1, error:    4.1. Current MAE: 24.31, RMSE: 72.00:  96% 1233/1286 [01:35<00:04, 12.55it/s]\n",
            "6955.jpg: actual-predicted:     25,   24.7, error:    0.3. Current MAE: 24.29, RMSE: 71.97:  96% 1233/1286 [01:35<00:04, 12.55it/s]\n",
            "6725.jpg: actual-predicted:     20,   20.9, error:    0.9. Current MAE: 24.27, RMSE: 71.94:  96% 1235/1286 [01:35<00:03, 13.17it/s]\n",
            "7265.jpg: actual-predicted:     42,   61.7, error:   19.7. Current MAE: 24.26, RMSE: 71.92:  96% 1235/1286 [01:35<00:03, 13.17it/s]\n",
            "7487.jpg: actual-predicted:     18,   19.4, error:    1.4. Current MAE: 24.25, RMSE: 71.89:  96% 1237/1286 [01:35<00:03, 13.41it/s]\n",
            "7024.jpg: actual-predicted:     68,   65.2, error:    2.8. Current MAE: 24.23, RMSE: 71.86:  96% 1237/1286 [01:36<00:03, 13.41it/s]\n",
            "7209.jpg: actual-predicted:     40,   56.7, error:   16.7. Current MAE: 24.22, RMSE: 71.83:  96% 1239/1286 [01:36<00:03, 14.16it/s]\n",
            "7155.jpg: actual-predicted:     69,   61.7, error:    7.3. Current MAE: 24.21, RMSE: 71.80:  96% 1239/1286 [01:36<00:03, 14.16it/s]\n",
            "7124.jpg: actual-predicted:     49,   46.5, error:    2.5. Current MAE: 24.19, RMSE: 71.77:  96% 1239/1286 [01:36<00:03, 14.16it/s]\n",
            "7549.jpg: actual-predicted:     76,   87.2, error:   11.2. Current MAE: 24.18, RMSE: 71.75:  97% 1242/1286 [01:36<00:02, 15.16it/s]\n",
            "7316.jpg: actual-predicted:     68,   49.8, error:   18.2. Current MAE: 24.18, RMSE: 71.72:  97% 1242/1286 [01:36<00:02, 15.16it/s]\n",
            "7346.jpg: actual-predicted:    144,  122.1, error:   21.9. Current MAE: 24.17, RMSE: 71.69:  97% 1244/1286 [01:36<00:02, 15.96it/s]\n",
            "6765.jpg: actual-predicted:    150,  140.6, error:    9.4. Current MAE: 24.16, RMSE: 71.66:  97% 1244/1286 [01:36<00:02, 15.96it/s]\n",
            "6924.jpg: actual-predicted:     30,   28.3, error:    1.7. Current MAE: 24.14, RMSE: 71.64:  97% 1244/1286 [01:36<00:02, 15.96it/s]\n",
            "6925.jpg: actual-predicted:     84,   70.6, error:   13.4. Current MAE: 24.14, RMSE: 71.61:  97% 1247/1286 [01:36<00:02, 15.32it/s]\n",
            "6835.jpg: actual-predicted:    138,  119.6, error:   18.4. Current MAE: 24.13, RMSE: 71.58:  97% 1247/1286 [01:36<00:02, 15.32it/s]\n",
            "7600.jpg: actual-predicted:    452,  340.6, error:  111.4. Current MAE: 24.20, RMSE: 71.62:  97% 1249/1286 [01:36<00:02, 15.35it/s]\n",
            "7593.jpg: actual-predicted:    274,  267.6, error:    6.4. Current MAE: 24.19, RMSE: 71.59:  97% 1249/1286 [01:36<00:02, 15.35it/s]\n",
            "7610.jpg: actual-predicted:     20,   27.6, error:    7.6. Current MAE: 24.17, RMSE: 71.57:  97% 1251/1286 [01:36<00:02, 16.24it/s]\n",
            "7247.jpg: actual-predicted:     18,   22.9, error:    4.9. Current MAE: 24.16, RMSE: 71.54:  97% 1251/1286 [01:36<00:02, 16.24it/s]\n",
            "7504.jpg: actual-predicted:     23,   42.4, error:   19.4. Current MAE: 24.15, RMSE: 71.51:  97% 1251/1286 [01:36<00:02, 16.24it/s]\n",
            "7181.jpg: actual-predicted:    135,  104.8, error:   30.2. Current MAE: 24.16, RMSE: 71.49:  98% 1254/1286 [01:36<00:01, 17.16it/s]\n",
            "7260.jpg: actual-predicted:    193,  211.6, error:   18.6. Current MAE: 24.16, RMSE: 71.46:  98% 1254/1286 [01:37<00:01, 17.16it/s]\n",
            "7013.jpg: actual-predicted:    139,  156.2, error:   17.2. Current MAE: 24.15, RMSE: 71.43:  98% 1256/1286 [01:37<00:01, 16.96it/s]\n",
            "7436.jpg: actual-predicted:    283,  282.4, error:    0.6. Current MAE: 24.13, RMSE: 71.41:  98% 1256/1286 [01:37<00:01, 16.96it/s]\n",
            "7659.jpg: actual-predicted:    198,  144.7, error:   53.3. Current MAE: 24.15, RMSE: 71.39:  98% 1258/1286 [01:37<00:01, 16.22it/s]\n",
            "6858.jpg: actual-predicted:     93,  109.0, error:   16.0. Current MAE: 24.15, RMSE: 71.37:  98% 1258/1286 [01:37<00:01, 16.22it/s]\n",
            "7100.jpg: actual-predicted:     27,   71.5, error:   44.5. Current MAE: 24.16, RMSE: 71.35:  98% 1260/1286 [01:37<00:01, 16.20it/s]\n",
            "7541.jpg: actual-predicted:     69,   66.8, error:    2.2. Current MAE: 24.15, RMSE: 71.32:  98% 1260/1286 [01:37<00:01, 16.20it/s]\n",
            "7315.jpg: actual-predicted:     71,   71.2, error:    0.2. Current MAE: 24.13, RMSE: 71.29:  98% 1262/1286 [01:37<00:01, 14.39it/s]\n",
            "7326.jpg: actual-predicted:    185,  140.4, error:   44.6. Current MAE: 24.14, RMSE: 71.27:  98% 1262/1286 [01:37<00:01, 14.39it/s]\n",
            "7388.jpg: actual-predicted:    134,  161.9, error:   27.9. Current MAE: 24.15, RMSE: 71.25:  98% 1264/1286 [01:37<00:01, 13.73it/s]\n",
            "6772.jpg: actual-predicted:     68,   51.3, error:   16.7. Current MAE: 24.14, RMSE: 71.22:  98% 1264/1286 [01:37<00:01, 13.73it/s]\n",
            "7266.jpg: actual-predicted:    118,   63.1, error:   54.9. Current MAE: 24.17, RMSE: 71.21:  98% 1266/1286 [01:37<00:01, 14.38it/s]\n",
            "7121.jpg: actual-predicted:    111,   52.2, error:   58.8. Current MAE: 24.19, RMSE: 71.20:  98% 1266/1286 [01:37<00:01, 14.38it/s]\n",
            "7226.jpg: actual-predicted:     74,   49.9, error:   24.1. Current MAE: 24.19, RMSE: 71.18:  99% 1268/1286 [01:38<00:01, 12.75it/s]\n",
            "7060.jpg: actual-predicted:     65,   56.3, error:    8.7. Current MAE: 24.18, RMSE: 71.15:  99% 1268/1286 [01:38<00:01, 12.75it/s]\n",
            "7481.jpg: actual-predicted:     27,   44.4, error:   17.4. Current MAE: 24.17, RMSE: 71.13:  99% 1270/1286 [01:38<00:01, 12.52it/s]\n",
            "7563.jpg: actual-predicted:     26,   41.9, error:   15.9. Current MAE: 24.17, RMSE: 71.10:  99% 1270/1286 [01:38<00:01, 12.52it/s]\n",
            "7338.jpg: actual-predicted:     80,   85.1, error:    5.1. Current MAE: 24.15, RMSE: 71.07:  99% 1272/1286 [01:38<00:01, 12.11it/s]\n",
            "7293.jpg: actual-predicted:     69,   40.4, error:   28.6. Current MAE: 24.16, RMSE: 71.05:  99% 1272/1286 [01:38<00:01, 12.11it/s]\n",
            "7466.jpg: actual-predicted:    116,   20.7, error:   95.3. Current MAE: 24.21, RMSE: 71.07:  99% 1274/1286 [01:38<00:00, 13.27it/s]\n",
            "6865.jpg: actual-predicted:    162,    7.8, error:  154.2. Current MAE: 24.31, RMSE: 71.17:  99% 1274/1286 [01:38<00:00, 13.27it/s]\n",
            "7002.jpg: actual-predicted:    100,   41.0, error:   59.0. Current MAE: 24.34, RMSE: 71.16:  99% 1276/1286 [01:38<00:00, 12.29it/s]\n",
            "7566.jpg: actual-predicted:     99,   61.8, error:   37.2. Current MAE: 24.35, RMSE: 71.14:  99% 1276/1286 [01:38<00:00, 12.29it/s]\n",
            "6932.jpg: actual-predicted:     49,   32.6, error:   16.4. Current MAE: 24.35, RMSE: 71.12:  99% 1278/1286 [01:38<00:00, 12.81it/s]\n",
            "6853.jpg: actual-predicted:     26,   23.3, error:    2.7. Current MAE: 24.33, RMSE: 71.09:  99% 1278/1286 [01:38<00:00, 12.81it/s]\n",
            "7413.jpg: actual-predicted:     83,   68.6, error:   14.4. Current MAE: 24.32, RMSE: 71.06: 100% 1280/1286 [01:38<00:00, 12.59it/s]\n",
            "6916.jpg: actual-predicted:     65,  101.1, error:   36.1. Current MAE: 24.33, RMSE: 71.04: 100% 1280/1286 [01:39<00:00, 12.59it/s]\n",
            "7122.jpg: actual-predicted:     21,    9.1, error:   11.9. Current MAE: 24.32, RMSE: 71.02: 100% 1280/1286 [01:39<00:00, 12.59it/s]\n",
            "6798.jpg: actual-predicted:     87,   77.6, error:    9.4. Current MAE: 24.31, RMSE: 70.99: 100% 1283/1286 [01:39<00:00, 13.69it/s]\n",
            "7011.jpg: actual-predicted:     44,   74.1, error:   30.1. Current MAE: 24.31, RMSE: 70.97: 100% 1283/1286 [01:39<00:00, 13.69it/s]\n",
            "7049.jpg: actual-predicted:     92,  119.2, error:   27.2. Current MAE: 24.32, RMSE: 70.94: 100% 1285/1286 [01:39<00:00, 14.64it/s]\n",
            "7049.jpg: actual-predicted:     92,  119.2, error:   27.2. Current MAE: 24.32, RMSE: 70.94: 100% 1286/1286 [01:39<00:00, 12.96it/s]\n",
            "[47.90774536  1.29107475 -2.07258415 ... -9.42782593 30.1383667\n",
            " 27.17940521]\n",
            "(1286,) [ 237 1140  229 ...  448  299  437]\n",
            "[-962.52035522 -962.3381958  -943.61645508 ...  156.24151611  205.88018799\n",
            "  257.7421875 ]\n",
            "347 94.35723876953125 407.35723876953125\n",
            "1186 123.7205810546875 183.7205810546875\n",
            "448 156.24151611328125 657.2415161132812\n",
            "299 205.88018798828125 706.8801879882812\n",
            "437 257.7421875 1142.7421875\n",
            "[-47.90774536  -1.29107475   2.07258415 ...   9.42782593 -30.1383667\n",
            " -27.17940521]\n",
            "(1286,) [ 437  299  448 ...  229 1140  237]\n",
            "[-257.7421875  -205.88018799 -156.24151611 ...  943.61645508  962.3381958\n",
            "  962.52035522]\n",
            "535 616.4561157226562 290.54388427734375\n",
            "203 828.5820007324219 193.41799926757812\n",
            "229 943.616455078125 1148.383544921875\n",
            "1140 962.3381958007812 268.66180419921875\n",
            "237 962.5203552246094 129.47964477539062\n",
            "On val data, MAE:  24.32, RMSE:  70.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAxImYu_TUGU"
      },
      "source": [
        "### Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QmhF5q1jPyt"
      },
      "source": [
        "# get ground truth and predicted counts and plot scatter plot\n",
        "count_file = 'count.csv'\n",
        "count = open(count_file, 'r')\n",
        "count_data = count.read()\n",
        "count_data = count_data.split('\\n')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWsDiApldKc_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d94c2586-d870-4952-96f2-5e177763d830"
      },
      "source": [
        "count_data = count_data[:-1]\n",
        "print(count_data)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Id,ground_truth_count,predicted_count', '190.jpg,13,60.907745361328125', '191.jpg,15,16.291074752807617', '192.jpg,19,16.92741584777832', '194.jpg,82,63.642303466796875', '195.jpg,10,9.924295425415039', '196.jpg,85,61.27728271484375', '197.jpg,77,81.02568054199219', '198.jpg,69,61.1616325378418', '214.jpg,64,36.648799896240234', '215.jpg,259,96.38662719726562', '216.jpg,46,27.58968734741211', '217.jpg,60,72.2542953491211', '218.jpg,58,50.70586013793945', '219.jpg,47,50.34369659423828', '220.jpg,59,41.16701889038086', '221.jpg,42,23.79133415222168', '222.jpg,65,70.08517456054688', '224.jpg,20,16.00101089477539', '226.jpg,78,66.87071990966797', '227.jpg,25,69.66957092285156', '228.jpg,44,21.79428482055664', '229.jpg,25,47.625877380371094', '231.jpg,24,30.34103775024414', '232.jpg,27,47.71561050415039', '233.jpg,126,107.17872619628906', '234.jpg,38,40.76728057861328', '236.jpg,11,33.71512985229492', '237.jpg,65,75.41116333007812', '238.jpg,20,15.453472137451172', '239.jpg,26,24.553207397460938', '240.jpg,37,26.92384910583496', '241.jpg,35,36.82303237915039', '243.jpg,33,71.31874084472656', '244.jpg,12,48.43233871459961', '245.jpg,55,58.64387893676758', '246.jpg,30,21.42306900024414', '248.jpg,48,22.86761474609375', '249.jpg,45,28.976985931396484', '250.jpg,50,27.546464920043945', '251.jpg,69,66.45320892333984', '252.jpg,22,29.990150451660156', '253.jpg,192,170.2755889892578', '254.jpg,74,54.14080810546875', '255.jpg,50,42.31401443481445', '256.jpg,38,40.897544860839844', '257.jpg,191,132.4605712890625', '271.jpg,9,11.464388847351074', '554.jpg,14,21.741369247436523', '555.jpg,12,18.437362670898438', '556.jpg,14,30.487262725830078', '557.jpg,18,33.86350631713867', '558.jpg,20,27.962661743164062', '559.jpg,20,34.07218551635742', '560.jpg,13,30.66064453125', '561.jpg,13,10.642972946166992', '562.jpg,13,43.719390869140625', '564.jpg,10,40.76389694213867', '565.jpg,18,16.369861602783203', '566.jpg,15,32.5947265625', '567.jpg,10,16.12178611755371', '568.jpg,9,17.575407028198242', '569.jpg,17,23.720218658447266', '570.jpg,19,12.645089149475098', '571.jpg,15,26.205177307128906', '572.jpg,31,46.31421661376953', '573.jpg,10,24.429969787597656', '574.jpg,25,20.225080490112305', '575.jpg,12,30.979446411132812', '576.jpg,19,20.99596405029297', '577.jpg,11,15.889833450317383', '578.jpg,12,66.38672637939453', '579.jpg,9,9.388496398925781', '580.jpg,10,50.056541442871094', '581.jpg,8,9.389833450317383', '582.jpg,14,28.208805084228516', '583.jpg,11,29.081941604614258', '584.jpg,13,11.487960815429688', '585.jpg,12,19.58950424194336', '586.jpg,11,25.524105072021484', '587.jpg,15,29.56108856201172', '588.jpg,9,36.39067840576172', '589.jpg,15,23.97614288330078', '590.jpg,16,84.48074340820312', '591.jpg,11,21.823463439941406', '592.jpg,10,24.394447326660156', '593.jpg,23,13.125703811645508', '595.jpg,9,54.67182922363281', '596.jpg,14,34.794708251953125', '597.jpg,54,63.61859893798828', '598.jpg,13,27.623210906982422', '599.jpg,15,28.720661163330078', '600.jpg,19,29.935585021972656', '601.jpg,9,22.166732788085938', '602.jpg,46,61.51061248779297', '603.jpg,25,56.39051818847656', '604.jpg,39,68.565185546875', '605.jpg,13,58.950748443603516', '606.jpg,27,63.38263702392578', '607.jpg,12,29.32754898071289', '609.jpg,12,38.046058654785156', '610.jpg,20,13.737020492553711', '611.jpg,14,28.99104118347168', '613.jpg,7,25.641843795776367', '614.jpg,10,19.20323944091797', '615.jpg,23,31.246803283691406', '616.jpg,119,153.98085021972656', '617.jpg,11,37.52969741821289', '618.jpg,20,27.899246215820312', '619.jpg,13,37.466552734375', '620.jpg,9,25.758174896240234', '621.jpg,12,29.88482666015625', '622.jpg,34,71.55231475830078', '623.jpg,9,17.5132999420166', '624.jpg,10,25.014780044555664', '625.jpg,14,65.92097473144531', '626.jpg,12,5.865091323852539', '734.jpg,20,37.000465393066406', '735.jpg,14,15.179627418518066', '736.jpg,44,32.11406707763672', '737.jpg,9,19.014238357543945', '738.jpg,13,22.02954864501953', '740.jpg,10,16.207340240478516', '741.jpg,13,1.8228487968444824', '742.jpg,13,2.3681480884552', '744.jpg,8,37.45746994018555', '745.jpg,60,60.93391418457031', '746.jpg,8,15.94568157196045', '747.jpg,16,25.312387466430664', '749.jpg,10,77.59315490722656', '750.jpg,8,16.651748657226562', '751.jpg,58,99.82698059082031', '752.jpg,36,34.42243194580078', '753.jpg,12,11.130842208862305', '754.jpg,9,25.28743553161621', '755.jpg,13,9.405447006225586', '756.jpg,15,18.279401779174805', '757.jpg,9,29.273164749145508', '758.jpg,14,8.926774978637695', '759.jpg,10,15.499225616455078', '760.jpg,21,37.95921325683594', '761.jpg,16,43.899070739746094', '762.jpg,77,156.6546630859375', '763.jpg,56,67.42402648925781', '764.jpg,85,60.26197052001953', '765.jpg,11,49.24738311767578', '766.jpg,50,64.9045181274414', '767.jpg,55,42.43619155883789', '768.jpg,16,9.436323165893555', '769.jpg,13,27.293720245361328', '770.jpg,83,49.084320068359375', '771.jpg,15,8.166375160217285', '772.jpg,28,85.09813690185547', '773.jpg,10,9.408100128173828', '774.jpg,8,10.236043930053711', '775.jpg,20,35.04792785644531', '776.jpg,15,26.4650821685791', '778.jpg,13,16.31125831604004', '807.jpg,36,32.53203582763672', '808.jpg,182,164.0223388671875', '809.jpg,323,331.898681640625', '810.jpg,22,32.44746017456055', '811.jpg,17,26.057979583740234', '812.jpg,51,73.24287414550781', '813.jpg,185,204.57032775878906', '814.jpg,21,26.3926944732666', '817.jpg,34,47.7752685546875', '819.jpg,40,38.20532989501953', '820.jpg,437,347.65643310546875', '822.jpg,53,52.396278381347656', '823.jpg,195,151.71237182617188', '824.jpg,9,20.256240844726562', '825.jpg,50,34.85361862182617', '826.jpg,70,54.702125549316406', '827.jpg,40,35.87331008911133', '828.jpg,87,65.27809143066406', '830.jpg,577,505.53546142578125', '831.jpg,117,87.58076477050781', '832.jpg,116,97.16722869873047', '833.jpg,54,56.33711242675781', '834.jpg,80,62.16204071044922', '835.jpg,22,52.44677734375', '836.jpg,230,148.7665557861328', '837.jpg,35,0.8782737851142883', '838.jpg,113,84.15689086914062', '840.jpg,637,240.72998046875', '841.jpg,11,13.879280090332031', '842.jpg,46,35.51810836791992', '844.jpg,191,123.52891540527344', '845.jpg,142,121.83245849609375', '846.jpg,35,16.646636962890625', '849.jpg,21,12.679926872253418', '850.jpg,183,78.53923034667969', '851.jpg,320,119.56938934326172', '852.jpg,41,48.338111877441406', '853.jpg,10,5.8899431228637695', '854.jpg,10,52.04336929321289', '856.jpg,44,30.974111557006836', '857.jpg,162,204.69287109375', '859.jpg,97,21.13344383239746', '860.jpg,240,190.67547607421875', '861.jpg,65,29.332809448242188', '862.jpg,15,21.856849670410156', '864.jpg,84,78.89572143554688', '865.jpg,1022,193.41799926757812', '866.jpg,230,44.62596893310547', '867.jpg,23,17.140533447265625', '868.jpg,8,1.7227766513824463', '869.jpg,250,94.39987182617188', '871.jpg,18,29.822925567626953', '873.jpg,21,22.28376007080078', '876.jpg,207,15.288930892944336', '913.jpg,9,24.067489624023438', '914.jpg,65,23.328210830688477', '915.jpg,11,0.8186169862747192', '916.jpg,9,16.31098175048828', '917.jpg,10,7.675209999084473', '918.jpg,47,43.23175048828125', '919.jpg,32,12.333170890808105', '920.jpg,12,6.400306701660156', '922.jpg,8,38.363487243652344', '923.jpg,122,112.4622802734375', '925.jpg,47,6.556412696838379', '926.jpg,39,111.03413391113281', '929.jpg,23,37.79259490966797', '930.jpg,15,22.13041877746582', '931.jpg,298,376.8294677734375', '932.jpg,53,59.52751541137695', '933.jpg,67,72.12144470214844', '934.jpg,13,13.058022499084473', '935.jpg,2092,1148.383544921875', '938.jpg,12,20.00788688659668', '941.jpg,13,19.665485382080078', '942.jpg,37,30.679691314697266', '943.jpg,97,87.48486328125', '945.jpg,122,152.5265655517578', '946.jpg,20,27.012226104736328', '948.jpg,24,31.59059715270996', '949.jpg,1092,129.47964477539062', '952.jpg,139,125.15036010742188', '955.jpg,86,23.144180297851562', '957.jpg,530,243.18258666992188', '959.jpg,18,25.645483016967773', '960.jpg,13,25.85331153869629', '961.jpg,48,28.243209838867188', '962.jpg,7,14.91987419128418', '963.jpg,63,54.317100524902344', '964.jpg,18,83.41580200195312', '965.jpg,10,26.90346908569336', '966.jpg,76,161.46095275878906', '969.jpg,38,56.02964782714844', '970.jpg,63,76.63447570800781', '972.jpg,485,557.9769287109375', '973.jpg,45,51.881797790527344', '975.jpg,718,276.1792297363281', '976.jpg,85,88.88983917236328', '977.jpg,165,174.57872009277344', '979.jpg,108,95.21354675292969', '982.jpg,50,81.76713562011719', '984.jpg,64,62.683265686035156', '1386.jpg,35,124.34437561035156', '1391.jpg,42,67.7984619140625', '1397.jpg,166,74.48407745361328', '1890.jpg,76,62.69525146484375', '1891.jpg,31,35.9332160949707', '1892.jpg,180,204.9020538330078', '1894.jpg,32,27.503253936767578', '1895.jpg,30,26.28912925720215', '1896.jpg,123,152.1803436279297', '1897.jpg,12,16.595298767089844', '1898.jpg,149,153.54312133789062', '1899.jpg,8,8.115029335021973', '1900.jpg,12,15.61505126953125', '1901.jpg,17,27.271747589111328', '1902.jpg,94,97.58260345458984', '1903.jpg,139,142.57156372070312', '1906.jpg,70,57.196067810058594', '1907.jpg,28,33.394630432128906', '1910.jpg,28,31.466876983642578', '1911.jpg,119,167.45986938476562', '1912.jpg,46,38.188968658447266', '1913.jpg,50,54.443180084228516', '1915.jpg,684,280.65240478515625', '1916.jpg,20,32.49003219604492', '1917.jpg,17,32.76860046386719', '1918.jpg,18,22.10611915588379', '1919.jpg,436,358.2619323730469', '1920.jpg,138,133.3861846923828', '1921.jpg,49,18.28961753845215', '1922.jpg,45,51.75133514404297', '1924.jpg,48,35.511512756347656', '1925.jpg,29,39.93077087402344', '1927.jpg,68,27.519372940063477', '1928.jpg,13,16.331777572631836', '1929.jpg,86,109.41790771484375', '1930.jpg,18,24.157001495361328', '1931.jpg,54,41.34644317626953', '1933.jpg,215,182.01370239257812', '1934.jpg,171,162.81784057617188', '1935.jpg,175,132.5617218017578', '1936.jpg,501,706.8801879882812', '1937.jpg,117,113.59788513183594', '1938.jpg,9,30.27635955810547', '1939.jpg,69,43.97318649291992', '1942.jpg,163,164.4848175048828', '1943.jpg,221,307.93011474609375', '1944.jpg,48,22.308101654052734', '1945.jpg,44,35.332923889160156', '1946.jpg,40,48.98816680908203', '1947.jpg,12,15.999870300292969', '1948.jpg,22,16.02057456970215', '1949.jpg,150,140.36520385742188', '1950.jpg,21,23.923254013061523', '1951.jpg,19,13.675931930541992', '1952.jpg,37,39.52014923095703', '1955.jpg,13,24.03331184387207', '1956.jpg,1229,760.308837890625', '1957.jpg,39,49.56197738647461', '1958.jpg,12,23.034503936767578', '1959.jpg,68,33.87250518798828', '1960.jpg,163,146.53878784179688', '1961.jpg,111,101.14239501953125', '1962.jpg,13,16.776050567626953', '1964.jpg,8,9.702657699584961', '1965.jpg,96,84.90609741210938', '1966.jpg,19,26.987716674804688', '1967.jpg,36,29.880401611328125', '1968.jpg,13,17.010517120361328', '1969.jpg,134,110.99267578125', '1971.jpg,19,14.883223533630371', '1972.jpg,8,9.174711227416992', '1973.jpg,12,17.435819625854492', '1976.jpg,32,15.008232116699219', '1977.jpg,132,114.53412628173828', '1978.jpg,35,30.659778594970703', '1979.jpg,40,38.79159164428711', '1981.jpg,159,181.16500854492188', '1982.jpg,8,7.918516635894775', '1983.jpg,172,141.5957489013672', '1984.jpg,35,42.73956298828125', '1986.jpg,248,123.21949005126953', '1987.jpg,95,48.392723083496094', '1988.jpg,20,27.6787109375', '1989.jpg,148,129.4559783935547', '1990.jpg,476,288.4289855957031', '1991.jpg,119,79.47018432617188', '1992.jpg,18,27.005653381347656', '1993.jpg,48,47.48698425292969', '1994.jpg,313,407.35723876953125', '1996.jpg,24,31.351530075073242', '1997.jpg,14,13.429305076599121', '1999.jpg,83,125.56767272949219', '2000.jpg,18,41.519954681396484', '2001.jpg,100,83.35763549804688', '2003.jpg,20,12.145344734191895', '2137.jpg,72,75.14796447753906', '2298.jpg,8,17.057828903198242', '2300.jpg,19,29.214786529541016', '2301.jpg,14,38.35624694824219', '2302.jpg,11,29.05559539794922', '2303.jpg,12,21.007335662841797', '2304.jpg,9,14.898730278015137', '2305.jpg,27,43.593807220458984', '2306.jpg,14,7.438762664794922', '2312.jpg,14,10.780113220214844', '2313.jpg,8,11.094751358032227', '2316.jpg,58,33.13294219970703', '2317.jpg,10,12.950626373291016', '2404.jpg,9,46.46284484863281', '2406.jpg,17,14.966407775878906', '2409.jpg,59,2.291970729827881', '2410.jpg,25,45.56584167480469', '2411.jpg,9,19.618776321411133', '2412.jpg,15,14.941316604614258', '2413.jpg,8,15.555987358093262', '2807.jpg,263,259.10858154296875', '2808.jpg,26,20.55878257751465', '2809.jpg,45,50.7177848815918', '2812.jpg,158,24.866363525390625', '2815.jpg,49,27.69082260131836', '2816.jpg,45,48.30046081542969', '2818.jpg,252,54.19112777709961', '2820.jpg,34,12.544073104858398', '2822.jpg,136,32.94709014892578', '2825.jpg,8,12.092708587646484', '2826.jpg,22,3.537313461303711', '2827.jpg,140,85.29829406738281', '2828.jpg,58,88.24520111083984', '2829.jpg,61,30.54218292236328', '2830.jpg,62,33.86808776855469', '2834.jpg,9,8.283519744873047', '2835.jpg,89,26.14820671081543', '2836.jpg,9,7.879821300506592', '2837.jpg,25,19.67417335510254', '2839.jpg,67,23.43225860595703', '2840.jpg,35,23.150299072265625', '2842.jpg,124,37.87162780761719', '2846.jpg,38,16.77646255493164', '2847.jpg,20,26.671133041381836', '2848.jpg,57,47.702430725097656', '2850.jpg,287,94.46644592285156', '2851.jpg,61,17.585205078125', '2854.jpg,16,3.8493449687957764', '2855.jpg,56,42.94892120361328', '2857.jpg,107,52.285011291503906', '2858.jpg,131,216.86492919921875', '2860.jpg,38,38.83329772949219', '2861.jpg,40,19.523780822753906', '2862.jpg,85,43.75941467285156', '2863.jpg,151,73.10014343261719', '2864.jpg,45,21.523401260375977', '2866.jpg,25,27.959278106689453', '2867.jpg,8,9.298407554626465', '2868.jpg,13,4.684917449951172', '2869.jpg,119,79.56639862060547', '2870.jpg,23,0.8659377098083496', '2871.jpg,48,31.893646240234375', '2872.jpg,10,3.637200355529785', '2873.jpg,11,19.939842224121094', '2875.jpg,60,72.17376708984375', '2877.jpg,111,46.54526901245117', '2878.jpg,301,170.63510131835938', '2879.jpg,150,122.15592956542969', '2880.jpg,158,38.847412109375', '2881.jpg,131,120.14837646484375', '2882.jpg,174,180.2288818359375', '2884.jpg,165,142.38418579101562', '2888.jpg,18,32.15492630004883', '2890.jpg,32,4.66653299331665', '2899.jpg,39,23.106016159057617', '2900.jpg,35,37.468048095703125', '2901.jpg,9,1.1306254863739014', '2902.jpg,14,40.78264236450195', '2903.jpg,69,53.687618255615234', '2906.jpg,16,28.41246795654297', '3265.jpg,35,34.662139892578125', '3266.jpg,20,29.758872985839844', '3267.jpg,25,24.855178833007812', '3425.jpg,885,1142.7421875', '3426.jpg,219,140.04678344726562', '3427.jpg,24,26.71108627319336', '3428.jpg,458,179.73028564453125', '3430.jpg,36,36.7695198059082', '3431.jpg,75,89.27108001708984', '3432.jpg,49,45.594932556152344', '3433.jpg,538,287.1370849609375', '3434.jpg,305,195.88275146484375', '3435.jpg,116,117.70780944824219', '3436.jpg,443,301.63189697265625', '3437.jpg,501,657.2415161132812', '3438.jpg,60,66.39402770996094', '3476.jpg,262,216.2451171875', '3477.jpg,344,316.6936340332031', '3478.jpg,41,31.437307357788086', '3481.jpg,431,275.9607238769531', '3482.jpg,315,281.0335693359375', '3483.jpg,261,96.44723510742188', '3484.jpg,356,65.38483428955078', '3485.jpg,174,121.35436248779297', '3486.jpg,81,106.68799591064453', '3487.jpg,321,199.60740661621094', '3488.jpg,431,269.9873962402344', '3489.jpg,278,146.78866577148438', '3490.jpg,64,65.01072692871094', '3491.jpg,69,53.95302963256836', '3492.jpg,25,47.895381927490234', '3518.jpg,8,9.783210754394531', '3519.jpg,30,29.475025177001953', '3520.jpg,10,5.957703590393066', '3521.jpg,27,45.395992279052734', '3522.jpg,27,34.35245895385742', '3524.jpg,42,16.094989776611328', '3525.jpg,11,23.625022888183594', '3526.jpg,18,20.360946655273438', '3527.jpg,12,31.696006774902344', '3528.jpg,29,22.74093246459961', '3529.jpg,30,23.36122703552246', '3530.jpg,8,5.616882801055908', '3531.jpg,11,14.580528259277344', '3532.jpg,20,4.96436071395874', '3533.jpg,23,50.23960876464844', '3534.jpg,11,15.785979270935059', '3535.jpg,24,18.76346206665039', '3536.jpg,18,31.850149154663086', '3538.jpg,19,4.474264144897461', '3539.jpg,11,11.204824447631836', '3540.jpg,28,43.89253234863281', '3541.jpg,10,4.05133581161499', '3542.jpg,11,16.442920684814453', '3543.jpg,30,14.539432525634766', '3544.jpg,9,1.3089864253997803', '3546.jpg,16,12.417264938354492', '3547.jpg,21,6.523398399353027', '3548.jpg,24,12.293085098266602', '3549.jpg,10,4.769460678100586', '3550.jpg,18,11.58420181274414', '3552.jpg,17,17.547616958618164', '3553.jpg,16,14.783760070800781', '3554.jpg,15,10.562776565551758', '3556.jpg,20,89.96026611328125', '3558.jpg,20,17.455360412597656', '3559.jpg,22,12.975296020507812', '3560.jpg,23,5.840721607208252', '3561.jpg,19,3.915432929992676', '3562.jpg,22,10.572397232055664', '3563.jpg,13,6.512539386749268', '3564.jpg,20,77.26182556152344', '3565.jpg,22,8.846122741699219', '3566.jpg,17,1.119474172592163', '3567.jpg,8,3.7504091262817383', '3568.jpg,23,4.768274307250977', '3569.jpg,10,22.686790466308594', '3570.jpg,12,10.61473560333252', '3571.jpg,25,35.34958267211914', '3572.jpg,30,24.356483459472656', '3573.jpg,9,1.5020625591278076', '3574.jpg,42,37.544273376464844', '3575.jpg,32,40.1793212890625', '3576.jpg,26,39.45348358154297', '3578.jpg,13,1.294926643371582', '3580.jpg,11,11.167306900024414', '3581.jpg,8,6.987907409667969', '3582.jpg,37,5.240686893463135', '3583.jpg,20,11.657054901123047', '3584.jpg,22,17.647083282470703', '3585.jpg,12,19.179229736328125', '3586.jpg,20,27.526905059814453', '3587.jpg,9,1.9130494594573975', '3588.jpg,22,13.422205924987793', '3591.jpg,9,11.33772087097168', '3592.jpg,12,5.5955657958984375', '3660.jpg,18,22.77722930908203', '3661.jpg,9,14.972143173217773', '3662.jpg,10,12.697052001953125', '3663.jpg,17,18.936912536621094', '3664.jpg,50,58.54262161254883', '3665.jpg,907,290.54388427734375', '3666.jpg,32,25.91250991821289', '3668.jpg,31,57.393062591552734', '3669.jpg,8,9.593841552734375', '3670.jpg,36,38.67475509643555', '3671.jpg,15,22.53990936279297', '3672.jpg,12,17.728824615478516', '3673.jpg,46,87.87248229980469', '3674.jpg,33,44.4759521484375', '3675.jpg,10,21.456809997558594', '3757.jpg,8,7.634852886199951', '3758.jpg,9,9.919356346130371', '3759.jpg,12,16.36278533935547', '3760.jpg,12,5.731661796569824', '3761.jpg,12,10.187480926513672', '3762.jpg,11,17.505491256713867', '3763.jpg,16,21.04723358154297', '3764.jpg,12,11.020220756530762', '3765.jpg,12,15.618951797485352', '3766.jpg,12,12.32642936706543', '3767.jpg,20,17.078330993652344', '3768.jpg,9,13.539490699768066', '3769.jpg,9,9.985763549804688', '3770.jpg,10,13.419279098510742', '3771.jpg,10,17.560256958007812', '3772.jpg,16,19.56812286376953', '3773.jpg,12,9.026449203491211', '3774.jpg,31,29.44419288635254', '3775.jpg,12,22.058731079101562', '3777.jpg,14,11.610891342163086', '3778.jpg,12,13.8925199508667', '3779.jpg,12,16.25390625', '3780.jpg,11,15.856082916259766', '3781.jpg,10,32.35699462890625', '3782.jpg,12,16.08645248413086', '3783.jpg,11,13.648386001586914', '3784.jpg,8,1.2778923511505127', '3785.jpg,9,22.574581146240234', '3870.jpg,17,20.94704246520996', '3871.jpg,31,26.040630340576172', '3872.jpg,20,32.00032424926758', '3873.jpg,7,2.9472317695617676', '3979.jpg,9,3.065300226211548', '3980.jpg,16,4.628664016723633', '3981.jpg,8,4.088919639587402', '4091.jpg,40,16.539161682128906', '4092.jpg,19,14.546745300292969', '4093.jpg,8,11.898725509643555', '4094.jpg,14,48.37023162841797', '4095.jpg,11,23.75696563720703', '4096.jpg,8,10.95438289642334', '4097.jpg,20,16.963706970214844', '4098.jpg,17,16.76197052001953', '4101.jpg,10,12.995834350585938', '4102.jpg,15,33.660499572753906', '4103.jpg,12,5.89868688583374', '4104.jpg,44,51.20661544799805', '4105.jpg,12,27.35610008239746', '4106.jpg,9,34.367130279541016', '4107.jpg,9,3.942369222640991', '4108.jpg,49,13.448586463928223', '4109.jpg,9,11.77573013305664', '4137.jpg,13,17.85893440246582', '4139.jpg,8,14.532356262207031', '4163.jpg,26,85.00770568847656', '4164.jpg,14,27.64826202392578', '4165.jpg,104,28.30217170715332', '4167.jpg,10,14.623456954956055', '4168.jpg,25,34.78429412841797', '4529.jpg,12,32.15861511230469', '4530.jpg,44,59.69394302368164', '4532.jpg,22,28.130495071411133', '4533.jpg,14,34.462989807128906', '4534.jpg,11,44.731529235839844', '4535.jpg,22,33.39765930175781', '4536.jpg,27,21.772350311279297', '4537.jpg,51,68.09392547607422', '4538.jpg,16,15.398416519165039', '4539.jpg,16,32.97231674194336', '4540.jpg,23,26.851940155029297', '4541.jpg,13,28.050987243652344', '4542.jpg,17,22.799951553344727', '4543.jpg,23,50.18031692504883', '4544.jpg,33,55.08739471435547', '4545.jpg,21,35.31120300292969', '4546.jpg,35,46.083587646484375', '4547.jpg,35,41.56527328491211', '4548.jpg,55,61.35389709472656', '4549.jpg,33,35.48780822753906', '4551.jpg,42,86.3131103515625', '4552.jpg,17,52.295623779296875', '4554.jpg,65,46.5618782043457', '4555.jpg,10,15.382017135620117', '4556.jpg,133,145.34622192382812', '4557.jpg,29,32.16396713256836', '4558.jpg,13,31.94736671447754', '4559.jpg,35,31.055641174316406', '4560.jpg,9,29.46417236328125', '4561.jpg,11,21.898059844970703', '4562.jpg,11,13.326509475708008', '4563.jpg,8,16.01523208618164', '4564.jpg,133,165.1064453125', '4565.jpg,24,23.488571166992188', '4566.jpg,37,48.172401428222656', '4567.jpg,13,26.60405921936035', '4568.jpg,9,27.556005477905273', '4569.jpg,21,44.51764678955078', '4570.jpg,11,25.349231719970703', '4571.jpg,47,44.22809600830078', '4572.jpg,141,147.46026611328125', '4573.jpg,36,111.69528198242188', '4574.jpg,402,287.89349365234375', '4575.jpg,22,53.85267639160156', '4576.jpg,38,47.72462463378906', '4577.jpg,37,33.17578887939453', '4578.jpg,24,27.253978729248047', '4579.jpg,34,71.48131561279297', '4580.jpg,165,168.8557586669922', '4581.jpg,42,38.21498107910156', '4582.jpg,16,32.11225128173828', '4583.jpg,15,22.587158203125', '4584.jpg,10,12.561637878417969', '4585.jpg,12,10.489200592041016', '4586.jpg,12,18.550870895385742', '4587.jpg,33,35.61734390258789', '4588.jpg,8,10.251080513000488', '4589.jpg,34,16.769939422607422', '4590.jpg,8,10.018990516662598', '4591.jpg,38,24.98220443725586', '4593.jpg,14,14.796247482299805', '4594.jpg,34,18.945043563842773', '4595.jpg,16,11.885458946228027', '4596.jpg,24,24.569114685058594', '4597.jpg,64,91.99085998535156', '4598.jpg,22,8.968971252441406', '4599.jpg,19,9.782794952392578', '4600.jpg,41,48.068138122558594', '4601.jpg,8,7.304481506347656', '4602.jpg,54,49.1492805480957', '4603.jpg,25,44.82233428955078', '4604.jpg,87,100.04161071777344', '4605.jpg,34,33.29656219482422', '4606.jpg,54,55.998558044433594', '4607.jpg,13,11.448909759521484', '4608.jpg,19,44.42245101928711', '4611.jpg,51,44.19203186035156', '4703.jpg,13,23.023250579833984', '4704.jpg,8,8.965604782104492', '4705.jpg,47,39.59828186035156', '4706.jpg,14,30.386146545410156', '4707.jpg,8,11.692651748657227', '4708.jpg,21,57.16949462890625', '4709.jpg,13,24.076549530029297', '4710.jpg,10,41.31730270385742', '4711.jpg,117,108.06416320800781', '4713.jpg,18,27.18780517578125', '4715.jpg,8,50.15785217285156', '4716.jpg,26,35.103736877441406', '4718.jpg,15,24.10902214050293', '4719.jpg,33,31.810298919677734', '4720.jpg,9,33.19467544555664', '4721.jpg,17,34.3393440246582', '4722.jpg,14,21.845041275024414', '4723.jpg,9,27.767383575439453', '4724.jpg,15,58.04070281982422', '4725.jpg,9,8.371502876281738', '4726.jpg,8,22.626182556152344', '4727.jpg,21,43.53218078613281', '4728.jpg,11,55.77100372314453', '4729.jpg,23,44.995689392089844', '4730.jpg,15,17.69194793701172', '4731.jpg,12,16.722076416015625', '4732.jpg,56,53.960208892822266', '4733.jpg,9,37.50761795043945', '4734.jpg,104,106.80580139160156', '4735.jpg,13,6.102323532104492', '4736.jpg,28,67.3808822631836', '4737.jpg,9,8.567148208618164', '4738.jpg,23,16.498414993286133', '4739.jpg,40,28.103805541992188', '4740.jpg,14,12.149110794067383', '4741.jpg,41,38.25628662109375', '4742.jpg,47,52.174720764160156', '4743.jpg,8,7.399862766265869', '4744.jpg,41,35.65009307861328', '4745.jpg,24,14.19522476196289', '4746.jpg,39,64.94278717041016', '4747.jpg,55,49.97956848144531', '4748.jpg,20,27.119123458862305', '4749.jpg,133,125.74229431152344', '4750.jpg,39,30.534650802612305', '4751.jpg,42,38.58475112915039', '4752.jpg,40,70.06929016113281', '4753.jpg,22,9.219759941101074', '4754.jpg,20,30.419336318969727', '4755.jpg,109,102.24588012695312', '4756.jpg,14,26.495243072509766', '4758.jpg,42,46.744693756103516', '4759.jpg,22,17.624113082885742', '4760.jpg,30,35.58549118041992', '4761.jpg,24,23.13424301147461', '4762.jpg,21,14.883293151855469', '4763.jpg,114,108.37911987304688', '4764.jpg,21,19.712360382080078', '4765.jpg,14,16.44866371154785', '4794.jpg,55,45.53961944580078', '4795.jpg,11,9.52037239074707', '4796.jpg,196,146.8548126220703', '4797.jpg,80,98.3541259765625', '4798.jpg,15,15.390926361083984', '4799.jpg,122,113.73975372314453', '4800.jpg,32,18.148761749267578', '4801.jpg,60,57.645023345947266', '4802.jpg,61,46.733619689941406', '4803.jpg,50,53.6146240234375', '4804.jpg,34,37.027103424072266', '4805.jpg,73,55.98794937133789', '4806.jpg,41,57.58988952636719', '4807.jpg,25,34.36381530761719', '4808.jpg,120,107.17012023925781', '4809.jpg,306,202.3080291748047', '4810.jpg,112,82.42072296142578', '4811.jpg,213,179.18209838867188', '4812.jpg,67,43.26876449584961', '4813.jpg,43,49.45640563964844', '4814.jpg,19,18.14459991455078', '4815.jpg,70,62.302310943603516', '4816.jpg,33,55.45609664916992', '4817.jpg,57,45.91251754760742', '4818.jpg,37,40.3765983581543', '4819.jpg,41,53.9463005065918', '4820.jpg,144,121.82811737060547', '4821.jpg,90,74.1341552734375', '4822.jpg,29,34.04404830932617', '4824.jpg,49,45.64595031738281', '4825.jpg,36,67.24038696289062', '4826.jpg,39,24.5743350982666', '4827.jpg,84,91.64219665527344', '4828.jpg,39,36.15058898925781', '4829.jpg,40,31.40066146850586', '4830.jpg,90,65.9043197631836', '4831.jpg,122,130.78585815429688', '4832.jpg,50,52.03740692138672', '4833.jpg,98,63.420291900634766', '4834.jpg,46,44.841064453125', '4835.jpg,65,63.66046142578125', '4836.jpg,42,39.04022979736328', '4837.jpg,26,25.273530960083008', '4839.jpg,46,41.88957977294922', '4840.jpg,46,64.37168884277344', '4841.jpg,57,43.55686950683594', '4842.jpg,122,98.19343566894531', '4844.jpg,43,36.2115478515625', '4845.jpg,21,24.041915893554688', '4846.jpg,55,53.19656753540039', '4847.jpg,61,51.94361877441406', '4848.jpg,80,87.07239532470703', '4849.jpg,121,90.58211517333984', '4850.jpg,101,100.10272216796875', '4851.jpg,32,37.394981384277344', '4852.jpg,31,16.16155433654785', '4853.jpg,50,45.63347244262695', '4854.jpg,36,70.17999267578125', '4855.jpg,22,35.338714599609375', '5043.jpg,134,123.30120849609375', '5044.jpg,100,73.50894165039062', '5045.jpg,131,197.1153564453125', '5046.jpg,215,136.70462036132812', '5047.jpg,30,44.134647369384766', '5048.jpg,39,39.19667053222656', '5059.jpg,286,254.7631378173828', '5060.jpg,98,73.83699035644531', '5061.jpg,9,22.500036239624023', '5062.jpg,32,36.32756423950195', '5063.jpg,72,65.84901428222656', '5064.jpg,19,2.353649139404297', '5065.jpg,24,14.12273120880127', '5066.jpg,10,10.556512832641602', '5068.jpg,16,13.78581428527832', '5069.jpg,20,84.38748931884766', '5071.jpg,11,14.925271987915039', '5072.jpg,10,1.0486927032470703', '5073.jpg,24,19.12327003479004', '5074.jpg,17,9.766458511352539', '5075.jpg,16,16.013134002685547', '5076.jpg,10,5.154757022857666', '5077.jpg,52,33.264503479003906', '5078.jpg,20,40.613525390625', '5079.jpg,27,38.4866943359375', '5080.jpg,51,31.685791015625', '5081.jpg,12,12.554895401000977', '5082.jpg,13,1.6941418647766113', '5083.jpg,24,16.708099365234375', '5084.jpg,28,47.31010818481445', '5085.jpg,9,1.145795226097107', '5086.jpg,12,9.526951789855957', '5087.jpg,31,17.407394409179688', '5088.jpg,24,5.028510093688965', '5089.jpg,11,14.774792671203613', '5090.jpg,14,7.631679534912109', '5091.jpg,15,8.443155288696289', '5092.jpg,15,8.997756958007812', '5093.jpg,11,12.887530326843262', '5094.jpg,14,13.291717529296875', '5095.jpg,16,21.593339920043945', '5096.jpg,11,19.244564056396484', '5097.jpg,27,31.09749412536621', '5098.jpg,30,28.740591049194336', '5099.jpg,22,16.944259643554688', '5100.jpg,9,6.4030680656433105', '5101.jpg,23,22.06216812133789', '5102.jpg,21,1.3116084337234497', '5103.jpg,20,8.86042594909668', '5104.jpg,13,9.92833423614502', '5105.jpg,17,6.054260730743408', '5106.jpg,23,21.831602096557617', '5107.jpg,12,12.896867752075195', '5108.jpg,12,14.41575813293457', '5110.jpg,9,2.517164945602417', '5111.jpg,12,5.749137878417969', '5112.jpg,22,11.945131301879883', '5113.jpg,14,10.890167236328125', '5114.jpg,22,7.815493583679199', '5115.jpg,22,14.905946731567383', '5116.jpg,17,15.322124481201172', '5117.jpg,13,1.1743360757827759', '5118.jpg,17,10.5670166015625', '5150.jpg,57,75.59233856201172', '5151.jpg,32,15.448004722595215', '5152.jpg,8,9.536331176757812', '5153.jpg,15,32.59104537963867', '5154.jpg,32,46.214996337890625', '5155.jpg,10,19.712087631225586', '5156.jpg,12,17.02189064025879', '5157.jpg,31,47.13116455078125', '5200.jpg,8,9.517141342163086', '5201.jpg,12,10.437561988830566', '5202.jpg,12,15.501877784729004', '5203.jpg,11,14.431896209716797', '5204.jpg,12,12.157073974609375', '5205.jpg,12,8.05935287475586', '5206.jpg,30,42.409114837646484', '5207.jpg,20,17.3077449798584', '5209.jpg,17,24.688213348388672', '5210.jpg,12,16.339599609375', '5211.jpg,9,13.038190841674805', '5212.jpg,12,13.00737190246582', '5213.jpg,16,19.35177993774414', '5214.jpg,9,14.378589630126953', '5215.jpg,12,21.268463134765625', '5216.jpg,9,8.89649486541748', '5217.jpg,10,11.685134887695312', '5219.jpg,13,16.362613677978516', '5220.jpg,9,19.242616653442383', '5221.jpg,12,8.829019546508789', '5222.jpg,12,12.541775703430176', '5223.jpg,9,12.474225997924805', '5225.jpg,38,24.791767120361328', '5227.jpg,54,32.65855407714844', '5228.jpg,20,31.837175369262695', '5229.jpg,12,15.417867660522461', '5654.jpg,10,4.675165176391602', '5655.jpg,9,11.042980194091797', '5656.jpg,16,23.23456382751465', '5658.jpg,9,11.530232429504395', '5659.jpg,16,18.593170166015625', '5660.jpg,19,19.923643112182617', '5661.jpg,12,13.921038627624512', '5662.jpg,12,14.27880859375', '5663.jpg,12,8.775090217590332', '5664.jpg,12,13.986528396606445', '5665.jpg,16,13.864656448364258', '5666.jpg,8,10.01017951965332', '5667.jpg,20,17.8404541015625', '5668.jpg,12,13.128890037536621', '5669.jpg,15,21.4510440826416', '5670.jpg,12,11.987287521362305', '5671.jpg,12,11.618972778320312', '5672.jpg,12,23.191347122192383', '5673.jpg,20,23.350502014160156', '5735.jpg,32,59.502010345458984', '5736.jpg,239,279.2413635253906', '5737.jpg,103,82.38911437988281', '5738.jpg,27,48.39350128173828', '5739.jpg,53,37.150062561035156', '5740.jpg,87,108.35487365722656', '5741.jpg,36,31.88345718383789', '5742.jpg,43,47.47890853881836', '5743.jpg,270,208.38214111328125', '5744.jpg,322,113.47040557861328', '5745.jpg,146,87.40928649902344', '5746.jpg,100,81.14518737792969', '5747.jpg,100,54.32456970214844', '5748.jpg,74,159.3638153076172', '5857.jpg,44,39.96034240722656', '5858.jpg,170,77.8930892944336', '5859.jpg,49,56.580406188964844', '5860.jpg,757,351.864990234375', '5861.jpg,67,65.40845489501953', '5862.jpg,58,59.81169891357422', '5863.jpg,76,51.40725326538086', '5864.jpg,81,72.946533203125', '5865.jpg,114,97.40478515625', '5866.jpg,267,236.76589965820312', '5867.jpg,83,59.497798919677734', '5868.jpg,54,48.38038635253906', '5869.jpg,32,31.097570419311523', '5870.jpg,47,26.50056266784668', '5871.jpg,53,65.79768371582031', '5872.jpg,116,90.12454986572266', '5873.jpg,69,62.09099578857422', '5874.jpg,124,125.07196807861328', '5875.jpg,74,61.18296813964844', '5876.jpg,216,186.3629913330078', '5877.jpg,32,21.99730110168457', '5878.jpg,44,45.41989517211914', '5879.jpg,36,30.638097763061523', '5880.jpg,30,33.21670150756836', '5881.jpg,99,89.20513916015625', '5882.jpg,47,42.688316345214844', '5883.jpg,69,78.62102508544922', '5884.jpg,41,50.12901306152344', '5885.jpg,115,114.78578186035156', '5886.jpg,25,76.19291687011719', '5887.jpg,49,41.1197509765625', '5888.jpg,84,55.3909797668457', '5889.jpg,27,31.0245304107666', '5890.jpg,33,33.533382415771484', '5891.jpg,89,63.44303894042969', '5892.jpg,103,64.1903076171875', '5893.jpg,73,64.60832214355469', '5894.jpg,62,75.18230438232422', '5895.jpg,43,38.063270568847656', '5896.jpg,55,48.1259765625', '5897.jpg,109,125.7547836303711', '5898.jpg,32,54.94309616088867', '5899.jpg,99,96.060546875', '5900.jpg,39,37.3669319152832', '5901.jpg,48,49.308406829833984', '5902.jpg,209,74.6890640258789', '5903.jpg,48,53.103172302246094', '5904.jpg,33,35.911659240722656', '5905.jpg,147,127.41142272949219', '5906.jpg,113,116.32862854003906', '5907.jpg,156,132.26954650878906', '5908.jpg,116,83.98359680175781', '5909.jpg,65,62.241580963134766', '5910.jpg,62,54.30005645751953', '5911.jpg,40,18.746978759765625', '5912.jpg,42,39.9803466796875', '5913.jpg,123,73.27230834960938', '5914.jpg,63,55.27687072753906', '5947.jpg,12,11.362712860107422', '5948.jpg,55,6.831634521484375', '5949.jpg,13,47.008880615234375', '5950.jpg,8,15.457091331481934', '5951.jpg,29,23.198434829711914', '5952.jpg,48,88.47097778320312', '6055.jpg,24,38.17919921875', '6056.jpg,11,52.638423919677734', '6057.jpg,49,39.13536071777344', '6058.jpg,12,6.334591865539551', '6059.jpg,10,26.028947830200195', '6060.jpg,11,20.014610290527344', '6061.jpg,104,86.33686828613281', '6062.jpg,11,4.876817226409912', '6063.jpg,23,25.260848999023438', '6064.jpg,33,21.634475708007812', '6065.jpg,12,37.85277557373047', '6066.jpg,36,23.34788703918457', '6067.jpg,53,39.616180419921875', '6068.jpg,10,12.974809646606445', '6069.jpg,16,25.0771484375', '6070.jpg,24,61.836246490478516', '6071.jpg,9,42.115234375', '6072.jpg,36,35.986083984375', '6073.jpg,18,20.431995391845703', '6074.jpg,25,17.644052505493164', '6075.jpg,98,49.545623779296875', '6076.jpg,16,23.72166633605957', '6077.jpg,27,19.25946807861328', '6078.jpg,37,55.656471252441406', '6079.jpg,10,14.095781326293945', '6080.jpg,277,266.9634094238281', '6081.jpg,9,19.52249526977539', '6082.jpg,31,53.694847106933594', '6083.jpg,8,3.887565851211548', '6084.jpg,30,44.26447296142578', '6085.jpg,18,5.669581413269043', '6086.jpg,11,7.660685062408447', '6087.jpg,11,5.572432518005371', '6088.jpg,32,26.746925354003906', '6089.jpg,19,17.893028259277344', '6090.jpg,21,17.768957138061523', '6091.jpg,11,2.93324613571167', '6092.jpg,12,8.810785293579102', '6093.jpg,28,35.174888610839844', '6094.jpg,9,8.729876518249512', '6095.jpg,29,50.89139175415039', '6096.jpg,18,11.96875286102295', '6097.jpg,21,31.480010986328125', '6098.jpg,13,12.361618995666504', '6099.jpg,26,13.7955322265625', '6100.jpg,12,14.1961088180542', '6101.jpg,8,6.3925323486328125', '6102.jpg,9,5.457157135009766', '6103.jpg,32,4.956672668457031', '6104.jpg,27,39.417198181152344', '6105.jpg,20,39.62385559082031', '6106.jpg,18,3.626178741455078', '6107.jpg,15,27.27752685546875', '6108.jpg,18,4.646505355834961', '6109.jpg,32,25.156112670898438', '6110.jpg,15,11.805017471313477', '6111.jpg,46,53.146080017089844', '6112.jpg,23,14.45721435546875', '6113.jpg,11,29.428319931030273', '6114.jpg,21,9.253726959228516', '6115.jpg,16,7.950057029724121', '6116.jpg,14,17.845294952392578', '6117.jpg,12,23.897647857666016', '6118.jpg,17,35.59408187866211', '6119.jpg,14,5.393790245056152', '6120.jpg,14,18.985313415527344', '6121.jpg,14,7.491898059844971', '6122.jpg,15,2.289294958114624', '6286.jpg,49,42.59249496459961', '6287.jpg,23,36.45075988769531', '6288.jpg,18,44.39863586425781', '6289.jpg,16,12.158267974853516', '6290.jpg,31,39.350738525390625', '6291.jpg,15,15.836725234985352', '6292.jpg,9,16.27352523803711', '6293.jpg,9,10.192049980163574', '6294.jpg,50,29.744125366210938', '6295.jpg,70,99.46896362304688', '6296.jpg,33,50.30036163330078', '6297.jpg,16,32.141143798828125', '6298.jpg,61,42.7457275390625', '6299.jpg,28,48.83782958984375', '6300.jpg,24,21.681947708129883', '6301.jpg,24,28.900671005249023', '6302.jpg,58,37.47029113769531', '6303.jpg,9,38.86963653564453', '6304.jpg,17,16.10433578491211', '6305.jpg,32,26.105884552001953', '6306.jpg,11,20.137189865112305', '6307.jpg,10,29.4954891204834', '7532.jpg,20,15.363058090209961', '6927.jpg,32,38.64384078979492', '6728.jpg,99,79.32096862792969', '7228.jpg,63,78.85270690917969', '7330.jpg,40,54.51966094970703', '6779.jpg,119,76.74072265625', '7540.jpg,64,81.5142822265625', '6885.jpg,167,139.78057861328125', '7428.jpg,66,69.85140991210938', '7334.jpg,53,34.10346984863281', '7390.jpg,177,111.03202819824219', '7012.jpg,66,66.10665893554688', '6877.jpg,66,58.65499496459961', '7461.jpg,22,13.914833068847656', '7143.jpg,121,110.67012023925781', '7537.jpg,39,52.805198669433594', '6897.jpg,59,32.31929397583008', '7169.jpg,34,40.89482879638672', '6872.jpg,49,75.43148803710938', '7088.jpg,110,65.4505615234375', '7371.jpg,136,168.4705810546875', '7545.jpg,106,117.32698059082031', '7269.jpg,73,13.449195861816406', '7148.jpg,67,11.312227249145508', '7501.jpg,218,153.91552734375', '7658.jpg,211,183.9183349609375', '7133.jpg,35,46.45439529418945', '7197.jpg,79,27.490554809570312', '7601.jpg,142,156.0804901123047', '7257.jpg,33,23.02716064453125', '7069.jpg,142,122.42647552490234', '7029.jpg,199,80.07183837890625', '7368.jpg,74,7.179171085357666', '7619.jpg,16,16.17082405090332', '6875.jpg,20,22.359182357788086', '7660.jpg,11,16.747411727905273', '7604.jpg,17,4.812332630157471', '7344.jpg,30,24.81015396118164', '7651.jpg,75,93.5054931640625', '6896.jpg,15,7.8219451904296875', '6944.jpg,26,19.000301361083984', '7558.jpg,37,39.85991668701172', '6866.jpg,207,84.30070495605469', '6784.jpg,52,55.576202392578125', '6778.jpg,47,49.90070724487305', '7077.jpg,140,113.48464965820312', '6801.jpg,29,29.788898468017578', '7280.jpg,116,95.28828430175781', '7003.jpg,182,166.95175170898438', '6836.jpg,15,12.383331298828125', '7317.jpg,11,9.683642387390137', '7063.jpg,17,11.107778549194336', '7304.jpg,12,17.189395904541016', '7434.jpg,169,117.22811889648438', '7107.jpg,19,9.059006690979004', '6939.jpg,62,77.62014770507812', '6729.jpg,251,210.35862731933594', '7656.jpg,1231,268.66180419921875', '6775.jpg,191,160.27337646484375', '6722.jpg,36,56.750770568847656', '7223.jpg,105,114.39562225341797', '7308.jpg,186,146.7376708984375', '6741.jpg,22,3.225646734237671', '7125.jpg,37,43.646995544433594', '7028.jpg,214,100.69633483886719', '7258.jpg,20,14.248502731323242', '6794.jpg,27,10.558723449707031', '7360.jpg,13,32.597686767578125', '7636.jpg,22,32.430320739746094', '7649.jpg,19,29.757143020629883', '7568.jpg,24,60.367149353027344', '7655.jpg,72,43.11027526855469', '6787.jpg,28,32.99769973754883', '7435.jpg,40,32.798683166503906', '7544.jpg,67,110.07371520996094', '6926.jpg,238,120.56736755371094', '7433.jpg,13,37.657073974609375', '6744.jpg,17,41.070167541503906', '7193.jpg,13,19.186504364013672', '7348.jpg,12,23.11965560913086', '6882.jpg,10,8.005857467651367', '6957.jpg,11,20.314237594604492', '7393.jpg,18,26.53486442565918', '6796.jpg,12,20.11155128479004', '7391.jpg,14,19.433170318603516', '6979.jpg,11,15.482964515686035', '7421.jpg,10,20.57001495361328', '7543.jpg,19,11.147960662841797', '7208.jpg,10,12.159866333007812', '6825.jpg,14,33.23339080810547', '7602.jpg,14,32.32855224609375', '7531.jpg,65,45.456390380859375', '6871.jpg,17,26.614885330200195', '6814.jpg,28,30.905391693115234', '6751.jpg,142,104.87104797363281', '7518.jpg,21,44.557098388671875', '7224.jpg,50,62.34545135498047', '6753.jpg,18,19.556217193603516', '6886.jpg,84,67.0481948852539', '7423.jpg,138,157.30545043945312', '7305.jpg,31,121.78398132324219', '7615.jpg,144,145.73643493652344', '6764.jpg,112,107.60005187988281', '7477.jpg,60,183.7205810546875', '6931.jpg,355,341.560546875', '6714.jpg,26,31.876508712768555', '6948.jpg,166,160.52157592773438', '7033.jpg,83,102.89590454101562', '6873.jpg,11,11.902958869934082', '6969.jpg,949,789.384033203125', '6981.jpg,57,61.865909576416016', '7301.jpg,36,47.20297622680664', '6783.jpg,17,28.9444637298584', '7561.jpg,20,25.185577392578125', '7510.jpg,61,63.80029296875', '7418.jpg,39,45.962562561035156', '7159.jpg,42,44.49066925048828', '7415.jpg,23,27.208999633789062', '7004.jpg,117,135.83779907226562', '7691.jpg,43,31.253009796142578', '7589.jpg,18,18.955419540405273', '7149.jpg,17,31.97856330871582', '7271.jpg,127,126.14874267578125', '7019.jpg,65,7.418901443481445', '7403.jpg,14,13.991220474243164', '7116.jpg,78,68.92327117919922', '7314.jpg,23,21.587743759155273', '7498.jpg,53,51.235538482666016', '7507.jpg,35,13.133721351623535', '6919.jpg,26,18.28277015686035', '7051.jpg,48,61.96866226196289', '6989.jpg,76,72.1773681640625', '7318.jpg,30,32.37638473510742', '7250.jpg,18,6.999089241027832', '7367.jpg,27,18.70232391357422', '6840.jpg,19,26.540863037109375', '7006.jpg,15,6.847691535949707', '7503.jpg,22,18.05243682861328', '6748.jpg,27,54.59521484375', '7164.jpg,83,91.89472961425781', '6782.jpg,17,14.468440055847168', '6983.jpg,40,47.21794891357422', '7673.jpg,15,23.562843322753906', '6911.jpg,39,45.2559700012207', '7249.jpg,61,28.886043548583984', '6767.jpg,28,40.3184700012207', '6721.jpg,11,15.152978897094727', '6988.jpg,24,18.955730438232422', '6846.jpg,28,34.49858856201172', '7582.jpg,25,48.60017395019531', '7233.jpg,24,28.096538543701172', '6955.jpg,25,24.748748779296875', '6725.jpg,20,20.876256942749023', '7265.jpg,42,61.67618179321289', '7487.jpg,18,19.360700607299805', '7024.jpg,68,65.18313598632812', '7209.jpg,40,56.73756790161133', '7155.jpg,69,61.66938400268555', '7124.jpg,49,46.536041259765625', '7549.jpg,76,87.24156188964844', '7316.jpg,68,49.819679260253906', '7346.jpg,144,122.13263702392578', '6765.jpg,150,140.61691284179688', '6924.jpg,30,28.272336959838867', '6925.jpg,84,70.55561828613281', '6835.jpg,138,119.58246612548828', '7600.jpg,452,340.563720703125', '7593.jpg,274,267.6275634765625', '7610.jpg,20,27.604684829711914', '7247.jpg,18,22.93277359008789', '7504.jpg,23,42.368167877197266', '7181.jpg,135,104.79517364501953', '7260.jpg,193,211.57046508789062', '7013.jpg,139,156.2393035888672', '7436.jpg,283,282.3998107910156', '7659.jpg,198,144.67556762695312', '6858.jpg,93,109.01429748535156', '7100.jpg,27,71.52494812011719', '7541.jpg,69,66.8427505493164', '7315.jpg,71,71.15617370605469', '7326.jpg,185,140.40093994140625', '7388.jpg,134,161.86000061035156', '6772.jpg,68,51.34646224975586', '7266.jpg,118,63.059268951416016', '7121.jpg,111,52.22307205200195', '7226.jpg,74,49.933631896972656', '7060.jpg,65,56.277671813964844', '7481.jpg,27,44.38777542114258', '7563.jpg,26,41.899532318115234', '7338.jpg,80,85.07649993896484', '7293.jpg,69,40.409332275390625', '7466.jpg,116,20.69546890258789', '6865.jpg,162,7.782961845397949', '7002.jpg,100,41.028717041015625', '7566.jpg,99,61.76434326171875', '6932.jpg,49,32.57304763793945', '6853.jpg,26,23.308635711669922', '7413.jpg,83,68.57839965820312', '6916.jpg,65,101.10028076171875', '7122.jpg,21,9.072157859802246', '6798.jpg,87,77.57217407226562', '7011.jpg,44,74.13836669921875', '7049.jpg,92,119.17940521240234']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdgFKHnNp2Ho"
      },
      "source": [
        "ground_truth_count = []\n",
        "predicted_count = []\n",
        "for i in range(1, len(count_data)):\n",
        "  temp = count_data[i].split(',')\n",
        "  ground_truth_count.append(int(temp[1]))\n",
        "  predicted_count.append(float(temp[2])) "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovR7bGbxqE_7"
      },
      "source": [
        "ground_truth_count = np.array(ground_truth_count)\n",
        "predicted_count = np.array(predicted_count)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A56i6hiotuT",
        "outputId": "8507d8dd-da7b-44db-95ba-9709725c95d6"
      },
      "source": [
        "ground_truth_count.shape, predicted_count.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1286,), (1286,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGI1eK0wr1XR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "75b1390f-b330-4c51-f445-18e1f593b585"
      },
      "source": [
        "plt.scatter(ground_truth_count, predicted_count)\n",
        "plt.xlabel(\"ground_truth\")\n",
        "plt.ylabel(\"predicted\")\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F7Wo1aIL46g"
      },
      "source": [
        "# 2.3 - with Test Time Adaptation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98pX9f27gHwM"
      },
      "source": [
        "### Run for val-partA with test time adaptation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxd1xyVML4XH",
        "outputId": "2b7b84ba-d219-4f10-dc79-c58534288cf0"
      },
      "source": [
        "!python test.py --data_path 'data/' -ts 'val_PartA' -a -gs 500 -wn 1e-2"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation on val_PartA data\n",
            "\r  0% 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/content/LearningToCountEverything/utils.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss += F.mse_loss(X, ones)\n",
            "/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17494, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2851.jpg: actual-predicted:     61,   26.8, error:   34.2. Current MAE: 34.18, RMSE: 34.18:   0% 0/100 [00:28<?, ?it/s]\n",
            "2851.jpg: actual-predicted:     61,   26.8, error:   34.2. Current MAE: 34.18, RMSE: 34.18:   1% 1/100 [00:28<47:14, 28.63s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([151596, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4167.jpg: actual-predicted:     10,   10.5, error:    0.5. Current MAE: 17.35, RMSE: 24.17:   1% 1/100 [01:00<47:14, 28.63s/it]\n",
            "4167.jpg: actual-predicted:     10,   10.5, error:    0.5. Current MAE: 17.35, RMSE: 24.17:   2% 2/100 [01:00<48:27, 29.67s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([167217, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4105.jpg: actual-predicted:     12,   25.3, error:   13.3. Current MAE: 15.99, RMSE: 21.17:   2% 2/100 [01:32<48:27, 29.67s/it]\n",
            "4105.jpg: actual-predicted:     12,   25.3, error:   13.3. Current MAE: 15.99, RMSE: 21.17:   3% 3/100 [01:32<48:53, 30.24s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([116452, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5890.jpg: actual-predicted:     33,   27.3, error:    5.7. Current MAE: 13.41, RMSE: 18.55:   3% 3/100 [02:00<48:53, 30.24s/it]\n",
            "5890.jpg: actual-predicted:     33,   27.3, error:    5.7. Current MAE: 13.41, RMSE: 18.55:   4% 4/100 [02:00<47:10, 29.49s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([2137, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "253.jpg : actual-predicted:    192,  141.9, error:   50.1. Current MAE: 20.74, RMSE: 27.87:   4% 4/100 [02:30<47:10, 29.49s/it]\n",
            "253.jpg : actual-predicted:    192,  141.9, error:   50.1. Current MAE: 20.74, RMSE: 27.87:   5% 5/100 [02:30<47:04, 29.73s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([103455, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5089.jpg: actual-predicted:     11,   11.9, error:    0.9. Current MAE: 17.44, RMSE: 25.45:   5% 5/100 [03:01<47:04, 29.73s/it]\n",
            "5089.jpg: actual-predicted:     11,   11.9, error:    0.9. Current MAE: 17.44, RMSE: 25.45:   6% 6/100 [03:01<47:05, 30.06s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([22536, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6722.jpg: actual-predicted:     36,   38.5, error:    2.5. Current MAE: 15.31, RMSE: 23.58:   6% 6/100 [03:31<47:05, 30.06s/it]\n",
            "6722.jpg: actual-predicted:     36,   38.5, error:    2.5. Current MAE: 15.31, RMSE: 23.58:   7% 7/100 [03:31<46:31, 30.02s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([51318, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3873.jpg: actual-predicted:      7,    5.0, error:    2.0. Current MAE: 13.65, RMSE: 22.07:   7% 7/100 [03:53<46:31, 30.02s/it]\n",
            "3873.jpg: actual-predicted:      7,    5.0, error:    2.0. Current MAE: 13.65, RMSE: 22.07:   8% 8/100 [03:53<42:28, 27.70s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([95198, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5898.jpg: actual-predicted:     32,   41.3, error:    9.3. Current MAE: 13.17, RMSE: 21.03:   8% 8/100 [04:14<42:28, 27.70s/it]\n",
            "5898.jpg: actual-predicted:     32,   41.3, error:    9.3. Current MAE: 13.17, RMSE: 21.03:   9% 9/100 [04:14<39:11, 25.84s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([0, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1929.jpg: actual-predicted:     86,  102.6, error:   16.6. Current MAE: 13.51, RMSE: 20.64:   9% 9/100 [04:37<39:11, 25.84s/it]\n",
            "1929.jpg: actual-predicted:     86,  102.6, error:   16.6. Current MAE: 13.51, RMSE: 20.64:  10% 10/100 [04:37<37:10, 24.79s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([106708, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1391.jpg: actual-predicted:     42,   49.1, error:    7.1. Current MAE: 12.93, RMSE: 19.79:  10% 10/100 [05:06<37:10, 24.79s/it]\n",
            "1391.jpg: actual-predicted:     42,   49.1, error:    7.1. Current MAE: 12.93, RMSE: 19.79:  11% 11/100 [05:06<38:36, 26.03s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([43639, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1900.jpg: actual-predicted:     12,   14.3, error:    2.3. Current MAE: 12.04, RMSE: 18.96:  11% 11/100 [05:37<38:36, 26.03s/it]\n",
            "1900.jpg: actual-predicted:     12,   14.3, error:    2.3. Current MAE: 12.04, RMSE: 18.96:  12% 12/100 [05:37<40:26, 27.58s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([39518, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2877.jpg: actual-predicted:    111,   63.2, error:   47.8. Current MAE: 14.79, RMSE: 22.52:  12% 12/100 [06:08<40:26, 27.58s/it]\n",
            "2877.jpg: actual-predicted:    111,   63.2, error:   47.8. Current MAE: 14.79, RMSE: 22.52:  13% 13/100 [06:08<41:23, 28.54s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([199720, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "761.jpg : actual-predicted:     16,   30.6, error:   14.6. Current MAE: 14.77, RMSE: 22.05:  13% 13/100 [06:40<41:23, 28.54s/it]\n",
            "761.jpg : actual-predicted:     16,   30.6, error:   14.6. Current MAE: 14.77, RMSE: 22.05:  14% 14/100 [06:40<42:32, 29.67s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([100892, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7247.jpg: actual-predicted:     18,   22.0, error:    4.0. Current MAE: 14.05, RMSE: 21.33:  14% 14/100 [07:03<42:32, 29.67s/it]\n",
            "7247.jpg: actual-predicted:     18,   22.0, error:    4.0. Current MAE: 14.05, RMSE: 21.33:  15% 15/100 [07:03<39:21, 27.79s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([29178, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4758.jpg: actual-predicted:     42,   37.9, error:    4.1. Current MAE: 13.43, RMSE: 20.67:  15% 15/100 [07:29<39:21, 27.79s/it]\n",
            "4758.jpg: actual-predicted:     42,   37.9, error:    4.1. Current MAE: 13.43, RMSE: 20.67:  16% 16/100 [07:29<38:09, 27.26s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([102813, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2826.jpg: actual-predicted:     22,    7.8, error:   14.2. Current MAE: 13.48, RMSE: 20.35:  16% 16/100 [08:02<38:09, 27.26s/it]\n",
            "2826.jpg: actual-predicted:     22,    7.8, error:   14.2. Current MAE: 13.48, RMSE: 20.35:  17% 17/100 [08:02<39:46, 28.75s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([92888, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4590.jpg: actual-predicted:      8,    8.8, error:    0.8. Current MAE: 12.77, RMSE: 19.78:  17% 17/100 [08:25<39:46, 28.75s/it]\n",
            "4590.jpg: actual-predicted:      8,    8.8, error:    0.8. Current MAE: 12.77, RMSE: 19.78:  18% 18/100 [08:25<37:08, 27.17s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([231048, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6721.jpg: actual-predicted:     11,   12.8, error:    1.8. Current MAE: 12.19, RMSE: 19.26:  18% 18/100 [09:02<37:08, 27.17s/it]\n",
            "6721.jpg: actual-predicted:     11,   12.8, error:    1.8. Current MAE: 12.19, RMSE: 19.26:  19% 19/100 [09:02<40:39, 30.12s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([116110, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3662.jpg: actual-predicted:     10,   11.0, error:    1.0. Current MAE: 11.64, RMSE: 18.77:  19% 19/100 [09:32<40:39, 30.12s/it]\n",
            "3662.jpg: actual-predicted:     10,   11.0, error:    1.0. Current MAE: 11.64, RMSE: 18.77:  20% 20/100 [09:32<40:02, 30.04s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([3773, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1981.jpg: actual-predicted:    159,  153.6, error:    5.4. Current MAE: 11.34, RMSE: 18.36:  20% 20/100 [10:03<40:02, 30.04s/it]\n",
            "1981.jpg: actual-predicted:    159,  153.6, error:    5.4. Current MAE: 11.34, RMSE: 18.36:  21% 21/100 [10:03<39:50, 30.25s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17952, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2003.jpg: actual-predicted:     20,   12.6, error:    7.4. Current MAE: 11.16, RMSE: 18.00:  21% 21/100 [10:31<39:50, 30.25s/it]\n",
            "2003.jpg: actual-predicted:     20,   12.6, error:    7.4. Current MAE: 11.16, RMSE: 18.00:  22% 22/100 [10:31<38:45, 29.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([61887, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3760.jpg: actual-predicted:     12,    8.2, error:    3.8. Current MAE: 10.84, RMSE: 17.62:  22% 22/100 [11:01<38:45, 29.82s/it]\n",
            "3760.jpg: actual-predicted:     12,    8.2, error:    3.8. Current MAE: 10.84, RMSE: 17.62:  23% 23/100 [11:01<38:00, 29.61s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([44709, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1902.jpg: actual-predicted:     94,   81.3, error:   12.7. Current MAE: 10.92, RMSE: 17.45:  23% 23/100 [11:29<38:00, 29.61s/it]\n",
            "1902.jpg: actual-predicted:     94,   81.3, error:   12.7. Current MAE: 10.92, RMSE: 17.45:  24% 24/100 [11:29<37:05, 29.28s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([51214, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1945.jpg: actual-predicted:     44,   34.0, error:   10.0. Current MAE: 10.88, RMSE: 17.21:  24% 24/100 [11:52<37:05, 29.28s/it]\n",
            "1945.jpg: actual-predicted:     44,   34.0, error:   10.0. Current MAE: 10.88, RMSE: 17.21:  25% 25/100 [11:52<34:13, 27.38s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([202005, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "824.jpg : actual-predicted:      9,   17.7, error:    8.7. Current MAE: 10.80, RMSE: 16.96:  25% 25/100 [12:24<34:13, 27.38s/it]\n",
            "824.jpg : actual-predicted:      9,   17.7, error:    8.7. Current MAE: 10.80, RMSE: 16.96:  26% 26/100 [12:24<35:17, 28.61s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([129228, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4824.jpg: actual-predicted:     49,   41.1, error:    7.9. Current MAE: 10.69, RMSE: 16.72:  26% 26/100 [12:47<35:17, 28.61s/it]\n",
            "4824.jpg: actual-predicted:     49,   41.1, error:    7.9. Current MAE: 10.69, RMSE: 16.72:  27% 27/100 [12:47<32:51, 27.01s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([203865, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "239.jpg : actual-predicted:     26,   22.9, error:    3.1. Current MAE: 10.42, RMSE: 16.42:  27% 27/100 [13:18<32:51, 27.01s/it]\n",
            "239.jpg : actual-predicted:     26,   22.9, error:    3.1. Current MAE: 10.42, RMSE: 16.42:  28% 28/100 [13:18<33:56, 28.29s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([153105, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "961.jpg : actual-predicted:     48,   30.1, error:   17.9. Current MAE: 10.68, RMSE: 16.48:  28% 28/100 [13:56<33:56, 28.29s/it]\n",
            "961.jpg : actual-predicted:     48,   30.1, error:   17.9. Current MAE: 10.68, RMSE: 16.48:  29% 29/100 [13:56<36:53, 31.17s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17761, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1984.jpg: actual-predicted:     35,   36.8, error:    1.8. Current MAE: 10.38, RMSE: 16.21:  29% 29/100 [14:25<36:53, 31.17s/it]\n",
            "1984.jpg: actual-predicted:     35,   36.8, error:    1.8. Current MAE: 10.38, RMSE: 16.21:  30% 30/100 [14:25<35:27, 30.39s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([69210, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2409.jpg: actual-predicted:     59,    5.7, error:   53.3. Current MAE: 11.77, RMSE: 18.59:  30% 30/100 [14:56<35:27, 30.39s/it]\n",
            "2409.jpg: actual-predicted:     59,    5.7, error:   53.3. Current MAE: 11.77, RMSE: 18.59:  31% 31/100 [14:56<35:11, 30.60s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([56398, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6120.jpg: actual-predicted:     14,   15.1, error:    1.1. Current MAE: 11.43, RMSE: 18.30:  31% 31/100 [15:24<35:11, 30.60s/it]\n",
            "6120.jpg: actual-predicted:     14,   15.1, error:    1.1. Current MAE: 11.43, RMSE: 18.30:  32% 32/100 [15:24<34:05, 30.08s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([27327, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6084.jpg: actual-predicted:     30,   34.4, error:    4.4. Current MAE: 11.22, RMSE: 18.04:  32% 32/100 [15:47<34:05, 30.08s/it]\n",
            "6084.jpg: actual-predicted:     30,   34.4, error:    4.4. Current MAE: 11.22, RMSE: 18.04:  33% 33/100 [15:47<31:06, 27.86s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([47327, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4831.jpg: actual-predicted:    122,  104.5, error:   17.5. Current MAE: 11.40, RMSE: 18.02:  33% 33/100 [16:16<31:06, 27.86s/it]\n",
            "4831.jpg: actual-predicted:    122,  104.5, error:   17.5. Current MAE: 11.40, RMSE: 18.02:  34% 34/100 [16:16<30:50, 28.04s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([85934, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3521.jpg: actual-predicted:     27,   42.2, error:   15.2. Current MAE: 11.51, RMSE: 17.95:  34% 34/100 [16:46<30:50, 28.04s/it]\n",
            "3521.jpg: actual-predicted:     27,   42.2, error:   15.2. Current MAE: 11.51, RMSE: 17.95:  35% 35/100 [16:46<31:13, 28.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([124204, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4534.jpg: actual-predicted:     11,   30.2, error:   19.2. Current MAE: 11.73, RMSE: 17.98:  35% 35/100 [17:18<31:13, 28.82s/it]\n",
            "4534.jpg: actual-predicted:     11,   30.2, error:   19.2. Current MAE: 11.73, RMSE: 17.98:  36% 36/100 [17:18<31:46, 29.79s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([67543, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2808.jpg: actual-predicted:     26,   18.4, error:    7.6. Current MAE: 11.61, RMSE: 17.78:  36% 36/100 [17:48<31:46, 29.79s/it]\n",
            "2808.jpg: actual-predicted:     26,   18.4, error:    7.6. Current MAE: 11.61, RMSE: 17.78:  37% 37/100 [17:48<31:08, 29.66s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([113202, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "226.jpg : actual-predicted:     78,   56.9, error:   21.1. Current MAE: 11.86, RMSE: 17.88:  37% 37/100 [18:11<31:08, 29.66s/it]\n",
            "1979.jpg: actual-predicted:     40,   41.1, error:    1.1. Current MAE: 11.59, RMSE: 17.65:  38% 38/100 [18:42<28:36, 27.68s/it]\n",
            "1979.jpg: actual-predicted:     40,   41.1, error:    1.1. Current MAE: 11.59, RMSE: 17.65:  39% 39/100 [18:42<29:14, 28.75s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([144239, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5879.jpg: actual-predicted:     36,   23.9, error:   12.1. Current MAE: 11.60, RMSE: 17.53:  39% 39/100 [19:19<29:14, 28.75s/it]\n",
            "5879.jpg: actual-predicted:     36,   23.9, error:   12.1. Current MAE: 11.60, RMSE: 17.53:  40% 40/100 [19:19<31:05, 31.09s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([65281, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "766.jpg : actual-predicted:     50,   56.9, error:    6.9. Current MAE: 11.48, RMSE: 17.35:  40% 40/100 [19:49<31:05, 31.09s/it]\n",
            "766.jpg : actual-predicted:     50,   56.9, error:    6.9. Current MAE: 11.48, RMSE: 17.35:  41% 41/100 [19:49<30:23, 30.91s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([120743, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7531.jpg: actual-predicted:     65,   36.5, error:   28.5. Current MAE: 11.89, RMSE: 17.70:  41% 41/100 [20:20<30:23, 30.91s/it]\n",
            "7531.jpg: actual-predicted:     65,   36.5, error:   28.5. Current MAE: 11.89, RMSE: 17.70:  42% 42/100 [20:20<29:52, 30.91s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([143857, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5214.jpg: actual-predicted:      9,   11.2, error:    2.2. Current MAE: 11.66, RMSE: 17.49:  42% 42/100 [20:51<29:52, 30.91s/it]\n",
            "5214.jpg: actual-predicted:      9,   11.2, error:    2.2. Current MAE: 11.66, RMSE: 17.49:  43% 43/100 [20:51<29:30, 31.06s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([194563, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "749.jpg : actual-predicted:     10,   54.5, error:   44.5. Current MAE: 12.41, RMSE: 18.55:  43% 43/100 [21:23<29:30, 31.06s/it]\n",
            "749.jpg : actual-predicted:     10,   54.5, error:   44.5. Current MAE: 12.41, RMSE: 18.55:  44% 44/100 [21:23<29:01, 31.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([148350, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2855.jpg: actual-predicted:     56,   45.4, error:   10.6. Current MAE: 12.37, RMSE: 18.41:  44% 44/100 [21:55<29:01, 31.10s/it]\n",
            "2855.jpg: actual-predicted:     56,   45.4, error:   10.6. Current MAE: 12.37, RMSE: 18.41:  45% 45/100 [21:55<28:47, 31.41s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([150224, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5658.jpg: actual-predicted:      9,   10.7, error:    1.7. Current MAE: 12.14, RMSE: 18.21:  45% 45/100 [22:26<28:47, 31.41s/it]\n",
            "5658.jpg: actual-predicted:      9,   10.7, error:    1.7. Current MAE: 12.14, RMSE: 18.21:  46% 46/100 [22:26<28:16, 31.42s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([103490, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "218.jpg : actual-predicted:     58,   50.4, error:    7.6. Current MAE: 12.04, RMSE: 18.05:  46% 46/100 [22:49<28:16, 31.42s/it]\n",
            "218.jpg : actual-predicted:     58,   50.4, error:    7.6. Current MAE: 12.04, RMSE: 18.05:  47% 47/100 [22:49<25:32, 28.91s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([142893, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "964.jpg : actual-predicted:     18,   51.8, error:   33.8. Current MAE: 12.49, RMSE: 18.51:  47% 47/100 [23:20<25:32, 28.91s/it]\n",
            "964.jpg : actual-predicted:     18,   51.8, error:   33.8. Current MAE: 12.49, RMSE: 18.51:  48% 48/100 [23:20<25:33, 29.48s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([52444, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5085.jpg: actual-predicted:      9,    3.8, error:    5.2. Current MAE: 12.35, RMSE: 18.34:  48% 48/100 [23:52<25:33, 29.48s/it]\n",
            "5085.jpg: actual-predicted:      9,    3.8, error:    5.2. Current MAE: 12.35, RMSE: 18.34:  49% 49/100 [23:52<25:47, 30.35s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([42718, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7293.jpg: actual-predicted:     69,   34.1, error:   34.9. Current MAE: 12.80, RMSE: 18.81:  49% 49/100 [24:15<25:47, 30.35s/it]\n",
            "7293.jpg: actual-predicted:     69,   34.1, error:   34.9. Current MAE: 12.80, RMSE: 18.81:  50% 50/100 [24:15<23:24, 28.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([41419, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3766.jpg: actual-predicted:     12,   13.2, error:    1.2. Current MAE: 12.57, RMSE: 18.63:  50% 50/100 [24:45<23:24, 28.10s/it]\n",
            "3766.jpg: actual-predicted:     12,   13.2, error:    1.2. Current MAE: 12.57, RMSE: 18.63:  51% 51/100 [24:45<23:18, 28.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([39274, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7012.jpg: actual-predicted:     66,   49.1, error:   16.9. Current MAE: 12.65, RMSE: 18.60:  51% 51/100 [25:15<23:18, 28.55s/it]\n",
            "7012.jpg: actual-predicted:     66,   49.1, error:   16.9. Current MAE: 12.65, RMSE: 18.60:  52% 52/100 [25:15<23:11, 28.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([70723, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2847.jpg: actual-predicted:     20,   19.7, error:    0.3. Current MAE: 12.42, RMSE: 18.42:  52% 52/100 [25:46<23:11, 28.99s/it]\n",
            "2847.jpg: actual-predicted:     20,   19.7, error:    0.3. Current MAE: 12.42, RMSE: 18.42:  53% 53/100 [25:46<23:07, 29.52s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([75835, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1911.jpg: actual-predicted:    119,  141.6, error:   22.6. Current MAE: 12.61, RMSE: 18.51:  53% 53/100 [26:14<23:07, 29.52s/it]\n",
            "1911.jpg: actual-predicted:    119,  141.6, error:   22.6. Current MAE: 12.61, RMSE: 18.51:  54% 54/100 [26:14<22:23, 29.22s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([19955, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6741.jpg: actual-predicted:     22,    6.0, error:   16.0. Current MAE: 12.67, RMSE: 18.47:  54% 54/100 [26:44<22:23, 29.22s/it]\n",
            "6741.jpg: actual-predicted:     22,    6.0, error:   16.0. Current MAE: 12.67, RMSE: 18.47:  55% 55/100 [26:44<22:10, 29.56s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([141163, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7107.jpg: actual-predicted:     19,   12.1, error:    6.9. Current MAE: 12.57, RMSE: 18.32:  55% 55/100 [27:29<22:10, 29.56s/it]\n",
            "7107.jpg: actual-predicted:     19,   12.1, error:    6.9. Current MAE: 12.57, RMSE: 18.32:  56% 56/100 [27:29<24:52, 33.92s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([121884, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4812.jpg: actual-predicted:     67,   42.2, error:   24.8. Current MAE: 12.78, RMSE: 18.46:  56% 56/100 [27:52<24:52, 33.92s/it]\n",
            "4812.jpg: actual-predicted:     67,   42.2, error:   24.8. Current MAE: 12.78, RMSE: 18.46:  57% 57/100 [27:52<21:59, 30.68s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([109599, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5858.jpg: actual-predicted:    170,   70.2, error:   99.8. Current MAE: 14.28, RMSE: 22.51:  57% 57/100 [28:15<21:59, 30.68s/it]\n",
            "5858.jpg: actual-predicted:    170,   70.2, error:   99.8. Current MAE: 14.28, RMSE: 22.51:  58% 58/100 [28:15<19:50, 28.35s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([129042, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5046.jpg: actual-predicted:    215,  165.4, error:   49.6. Current MAE: 14.88, RMSE: 23.23:  58% 58/100 [28:38<19:50, 28.35s/it]\n",
            "5046.jpg: actual-predicted:    215,  165.4, error:   49.6. Current MAE: 14.88, RMSE: 23.23:  59% 59/100 [28:38<18:19, 26.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([49236, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "976.jpg : actual-predicted:     85,   74.8, error:   10.2. Current MAE: 14.81, RMSE: 23.08:  59% 59/100 [29:11<18:19, 26.82s/it]\n",
            "976.jpg : actual-predicted:     85,   74.8, error:   10.2. Current MAE: 14.81, RMSE: 23.08:  60% 60/100 [29:11<19:10, 28.76s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([55040, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1952.jpg: actual-predicted:     37,   38.1, error:    1.1. Current MAE: 14.58, RMSE: 22.89:  60% 60/100 [29:34<19:10, 28.76s/it]\n",
            "1952.jpg: actual-predicted:     37,   38.1, error:    1.1. Current MAE: 14.58, RMSE: 22.89:  61% 61/100 [29:34<17:32, 26.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([144144, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "562.jpg : actual-predicted:     13,   30.0, error:   17.0. Current MAE: 14.62, RMSE: 22.80:  61% 61/100 [30:10<17:32, 26.99s/it]\n",
            "562.jpg : actual-predicted:     13,   30.0, error:   17.0. Current MAE: 14.62, RMSE: 22.80:  62% 62/100 [30:10<18:52, 29.80s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([73583, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6772.jpg: actual-predicted:     68,   43.0, error:   25.0. Current MAE: 14.78, RMSE: 22.84:  62% 62/100 [30:38<18:52, 29.80s/it]\n",
            "6772.jpg: actual-predicted:     68,   43.0, error:   25.0. Current MAE: 14.78, RMSE: 22.84:  63% 63/100 [30:38<17:56, 29.09s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([72174, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7600.jpg: actual-predicted:    452,  263.3, error:  188.7. Current MAE: 17.50, RMSE: 32.71:  63% 63/100 [31:05<17:56, 29.09s/it]\n",
            "7600.jpg: actual-predicted:    452,  263.3, error:  188.7. Current MAE: 17.50, RMSE: 32.71:  64% 64/100 [31:05<17:02, 28.41s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([131096, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "740.jpg : actual-predicted:     10,   15.3, error:    5.3. Current MAE: 17.31, RMSE: 32.47:  64% 64/100 [31:28<17:02, 28.41s/it]\n",
            "740.jpg : actual-predicted:     10,   15.3, error:    5.3. Current MAE: 17.31, RMSE: 32.47:  65% 65/100 [31:28<15:39, 26.84s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([38347, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6896.jpg: actual-predicted:     15,   10.9, error:    4.1. Current MAE: 17.11, RMSE: 32.22:  65% 65/100 [31:51<15:39, 26.84s/it]\n",
            "6896.jpg: actual-predicted:     15,   10.9, error:    4.1. Current MAE: 17.11, RMSE: 32.22:  66% 66/100 [31:51<14:35, 25.76s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([100187, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5104.jpg: actual-predicted:     13,    8.8, error:    4.2. Current MAE: 16.92, RMSE: 31.99:  66% 66/100 [32:22<14:35, 25.76s/it]\n",
            "5104.jpg: actual-predicted:     13,    8.8, error:    4.2. Current MAE: 16.92, RMSE: 31.99:  67% 67/100 [32:22<15:01, 27.32s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([50136, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3768.jpg: actual-predicted:      9,   11.1, error:    2.1. Current MAE: 16.70, RMSE: 31.75:  67% 67/100 [32:45<15:01, 27.32s/it]\n",
            "3768.jpg: actual-predicted:      9,   11.1, error:    2.1. Current MAE: 16.70, RMSE: 31.75:  68% 68/100 [32:45<13:55, 26.11s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([125867, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "753.jpg : actual-predicted:     12,   13.6, error:    1.6. Current MAE: 16.48, RMSE: 31.52:  68% 68/100 [33:16<13:55, 26.11s/it]\n",
            "2809.jpg: actual-predicted:     45,   40.6, error:    4.4. Current MAE: 16.31, RMSE: 31.30:  69% 69/100 [33:46<14:14, 27.58s/it]\n",
            "2809.jpg: actual-predicted:     45,   40.6, error:    4.4. Current MAE: 16.31, RMSE: 31.30:  70% 70/100 [33:46<14:09, 28.32s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([106202, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1907.jpg: actual-predicted:     28,   26.7, error:    1.3. Current MAE: 16.10, RMSE: 31.08:  70% 70/100 [34:15<14:09, 28.32s/it]\n",
            "1907.jpg: actual-predicted:     28,   26.7, error:    1.3. Current MAE: 16.10, RMSE: 31.08:  71% 71/100 [34:15<13:45, 28.45s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([182056, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7602.jpg: actual-predicted:     14,   29.3, error:   15.3. Current MAE: 16.09, RMSE: 30.92:  71% 71/100 [34:51<13:45, 28.45s/it]\n",
            "7602.jpg: actual-predicted:     14,   29.3, error:   15.3. Current MAE: 16.09, RMSE: 30.92:  72% 72/100 [34:51<14:20, 30.74s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([176393, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "221.jpg : actual-predicted:     42,   26.3, error:   15.7. Current MAE: 16.08, RMSE: 30.76:  72% 72/100 [35:22<14:20, 30.74s/it]\n",
            "221.jpg : actual-predicted:     42,   26.3, error:   15.7. Current MAE: 16.08, RMSE: 30.76:  73% 73/100 [35:22<13:51, 30.81s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([95061, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5043.jpg: actual-predicted:    134,  129.9, error:    4.1. Current MAE: 15.92, RMSE: 30.55:  73% 73/100 [35:45<13:51, 30.81s/it]\n",
            "7133.jpg: actual-predicted:     35,   42.8, error:    7.8. Current MAE: 15.81, RMSE: 30.36:  74% 74/100 [36:37<12:20, 28.48s/it]\n",
            "7133.jpg: actual-predicted:     35,   42.8, error:    7.8. Current MAE: 15.81, RMSE: 30.36:  75% 75/100 [36:37<14:46, 35.44s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([132084, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7159.jpg: actual-predicted:     42,   41.2, error:    0.8. Current MAE: 15.62, RMSE: 30.16:  75% 75/100 [37:22<14:46, 35.44s/it]\n",
            "7159.jpg: actual-predicted:     42,   41.2, error:    0.8. Current MAE: 15.62, RMSE: 30.16:  76% 76/100 [37:22<15:22, 38.45s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([109892, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5862.jpg: actual-predicted:     58,   49.7, error:    8.3. Current MAE: 15.52, RMSE: 29.98:  76% 76/100 [37:49<15:22, 38.45s/it]\n",
            "5862.jpg: actual-predicted:     58,   49.7, error:    8.3. Current MAE: 15.52, RMSE: 29.98:  77% 77/100 [37:49<13:22, 34.89s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([99369, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3774.jpg: actual-predicted:     31,   25.3, error:    5.7. Current MAE: 15.39, RMSE: 29.79:  77% 77/100 [38:20<13:22, 34.89s/it]\n",
            "3774.jpg: actual-predicted:     31,   25.3, error:    5.7. Current MAE: 15.39, RMSE: 29.79:  78% 78/100 [38:20<12:19, 33.63s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([151204, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6287.jpg: actual-predicted:     23,   30.3, error:    7.3. Current MAE: 15.29, RMSE: 29.62:  78% 78/100 [38:47<12:19, 33.63s/it]\n",
            "6287.jpg: actual-predicted:     23,   30.3, error:    7.3. Current MAE: 15.29, RMSE: 29.62:  79% 79/100 [38:47<11:08, 31.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([26815, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4596.jpg: actual-predicted:     24,   19.8, error:    4.2. Current MAE: 15.15, RMSE: 29.43:  79% 79/100 [39:10<11:08, 31.82s/it]\n",
            "4596.jpg: actual-predicted:     24,   19.8, error:    4.2. Current MAE: 15.15, RMSE: 29.43:  80% 80/100 [39:10<09:41, 29.06s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([52413, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4539.jpg: actual-predicted:     16,   23.6, error:    7.6. Current MAE: 15.06, RMSE: 29.26:  80% 80/100 [39:33<09:41, 29.06s/it]\n",
            "4539.jpg: actual-predicted:     16,   23.6, error:    7.6. Current MAE: 15.06, RMSE: 29.26:  81% 81/100 [39:33<08:40, 27.42s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([151338, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7318.jpg: actual-predicted:     30,   28.5, error:    1.5. Current MAE: 14.89, RMSE: 29.09:  81% 81/100 [40:03<08:40, 27.42s/it]\n",
            "7318.jpg: actual-predicted:     30,   28.5, error:    1.5. Current MAE: 14.89, RMSE: 29.09:  82% 82/100 [40:03<08:23, 27.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([140330, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3581.jpg: actual-predicted:      8,    6.8, error:    1.2. Current MAE: 14.73, RMSE: 28.91:  82% 82/100 [40:32<08:23, 27.99s/it]\n",
            "3581.jpg: actual-predicted:      8,    6.8, error:    1.2. Current MAE: 14.73, RMSE: 28.91:  83% 83/100 [40:32<07:59, 28.22s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([116701, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3540.jpg: actual-predicted:     28,   39.3, error:   11.3. Current MAE: 14.69, RMSE: 28.76:  83% 83/100 [41:02<07:59, 28.22s/it]\n",
            "3540.jpg: actual-predicted:     28,   39.3, error:   11.3. Current MAE: 14.69, RMSE: 28.76:  84% 84/100 [41:02<07:42, 28.90s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([217144, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "560.jpg : actual-predicted:     13,   25.4, error:   12.4. Current MAE: 14.66, RMSE: 28.63:  84% 84/100 [41:39<07:42, 28.90s/it]\n",
            "560.jpg : actual-predicted:     13,   25.4, error:   12.4. Current MAE: 14.66, RMSE: 28.63:  85% 85/100 [41:39<07:50, 31.40s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([129407, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1933.jpg: actual-predicted:    215,  133.1, error:   81.9. Current MAE: 15.44, RMSE: 29.80:  85% 85/100 [42:15<07:50, 31.40s/it]\n",
            "1933.jpg: actual-predicted:    215,  133.1, error:   81.9. Current MAE: 15.44, RMSE: 29.80:  86% 86/100 [42:15<07:39, 32.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([125321, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6117.jpg: actual-predicted:     12,   20.3, error:    8.3. Current MAE: 15.36, RMSE: 29.64:  86% 86/100 [42:43<07:39, 32.82s/it]\n",
            "6117.jpg: actual-predicted:     12,   20.3, error:    8.3. Current MAE: 15.36, RMSE: 29.64:  87% 87/100 [42:43<06:45, 31.21s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([79363, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5899.jpg: actual-predicted:     99,   75.8, error:   23.2. Current MAE: 15.45, RMSE: 29.57:  87% 87/100 [43:08<06:45, 31.21s/it]\n",
            "5899.jpg: actual-predicted:     99,   75.8, error:   23.2. Current MAE: 15.45, RMSE: 29.57:  88% 88/100 [43:08<05:52, 29.40s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([8620, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1991.jpg: actual-predicted:    119,   72.4, error:   46.6. Current MAE: 15.80, RMSE: 29.82:  88% 88/100 [43:34<05:52, 29.40s/it]\n",
            "1991.jpg: actual-predicted:    119,   72.4, error:   46.6. Current MAE: 15.80, RMSE: 29.82:  89% 89/100 [43:34<05:12, 28.41s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([8199, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6119.jpg: actual-predicted:     14,    7.6, error:    6.4. Current MAE: 15.70, RMSE: 29.66:  89% 89/100 [43:57<05:12, 28.41s/it]\n",
            "6119.jpg: actual-predicted:     14,    7.6, error:    6.4. Current MAE: 15.70, RMSE: 29.66:  90% 90/100 [43:57<04:27, 26.77s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([4671, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1892.jpg: actual-predicted:    180,  177.9, error:    2.1. Current MAE: 15.55, RMSE: 29.50:  90% 90/100 [44:25<04:27, 26.77s/it]\n",
            "1892.jpg: actual-predicted:    180,  177.9, error:    2.1. Current MAE: 15.55, RMSE: 29.50:  91% 91/100 [44:25<04:04, 27.21s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([158879, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4713.jpg: actual-predicted:     18,   31.1, error:   13.1. Current MAE: 15.52, RMSE: 29.37:  91% 91/100 [44:56<04:04, 27.21s/it]\n",
            "4713.jpg: actual-predicted:     18,   31.1, error:   13.1. Current MAE: 15.52, RMSE: 29.37:  92% 92/100 [44:56<03:46, 28.25s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([144329, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4817.jpg: actual-predicted:     57,   35.1, error:   21.9. Current MAE: 15.59, RMSE: 29.30:  92% 92/100 [45:25<03:46, 28.25s/it]\n",
            "4817.jpg: actual-predicted:     57,   35.1, error:   21.9. Current MAE: 15.59, RMSE: 29.30:  93% 93/100 [45:25<03:19, 28.46s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([162817, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "600.jpg : actual-predicted:     19,   27.3, error:    8.3. Current MAE: 15.51, RMSE: 29.15:  93% 93/100 [45:56<03:19, 28.46s/it]\n",
            "600.jpg : actual-predicted:     19,   27.3, error:    8.3. Current MAE: 15.51, RMSE: 29.15:  94% 94/100 [45:56<02:55, 29.18s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([250813, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "585.jpg : actual-predicted:     12,   17.5, error:    5.5. Current MAE: 15.41, RMSE: 29.01:  94% 94/100 [46:43<02:55, 29.18s/it]\n",
            "585.jpg : actual-predicted:     12,   17.5, error:    5.5. Current MAE: 15.41, RMSE: 29.01:  95% 95/100 [46:43<02:53, 34.67s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([52375, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5092.jpg: actual-predicted:     15,   13.1, error:    1.9. Current MAE: 15.26, RMSE: 28.86:  95% 95/100 [47:06<02:53, 34.67s/it]\n",
            "5092.jpg: actual-predicted:     15,   13.1, error:    1.9. Current MAE: 15.26, RMSE: 28.86:  96% 96/100 [47:06<02:04, 31.18s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([199259, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "582.jpg : actual-predicted:     14,   23.3, error:    9.3. Current MAE: 15.20, RMSE: 28.72:  96% 96/100 [47:38<02:04, 31.18s/it]\n",
            "582.jpg : actual-predicted:     14,   23.3, error:    9.3. Current MAE: 15.20, RMSE: 28.72:  97% 97/100 [47:38<01:34, 31.42s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([146575, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "240.jpg : actual-predicted:     37,   22.8, error:   14.2. Current MAE: 15.19, RMSE: 28.61:  97% 97/100 [48:07<01:34, 31.42s/it]\n",
            "240.jpg : actual-predicted:     37,   22.8, error:   14.2. Current MAE: 15.19, RMSE: 28.61:  98% 98/100 [48:07<01:01, 30.77s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([74407, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5655.jpg: actual-predicted:      9,    9.6, error:    0.6. Current MAE: 15.04, RMSE: 28.47:  98% 98/100 [48:36<01:01, 30.77s/it]\n",
            "5655.jpg: actual-predicted:      9,    9.6, error:    0.6. Current MAE: 15.04, RMSE: 28.47:  99% 99/100 [48:36<00:30, 30.20s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([49557, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6927.jpg: actual-predicted:     32,   34.2, error:    2.2. Current MAE: 14.92, RMSE: 28.32:  99% 99/100 [49:16<00:30, 30.20s/it]\n",
            "6927.jpg: actual-predicted:     32,   34.2, error:    2.2. Current MAE: 14.92, RMSE: 28.32: 100% 100/100 [49:16<00:00, 29.56s/it]\n",
            "On val_PartA data, MAE:  14.92, RMSE:  28.32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpRfq2S7RA_O"
      },
      "source": [
        "### Vadilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQUAUH_RRA_O"
      },
      "source": [
        "# get ground truth and predicted counts and plot scatter plot\n",
        "count_file = 'count.csv'\n",
        "count = open(count_file, 'r')\n",
        "count_data = count.read()\n",
        "count_data = count_data.split('\\n')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFKyes75RA_Y",
        "outputId": "77279114-1af6-4460-c742-b6d231577a89"
      },
      "source": [
        "count_data = count_data[:-1]\n",
        "print(count_data)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Id,ground_truth_count,predicted_count', '2851.jpg,61,26.820907592773438', '4167.jpg,10,10.515422821044922', '4105.jpg,12,25.260976791381836', '5890.jpg,33,27.331195831298828', '253.jpg,192,141.9206085205078', '5089.jpg,11,11.928040504455566', '6722.jpg,36,38.53025817871094', '3873.jpg,7,4.955296993255615', '5898.jpg,32,41.29182052612305', '1929.jpg,86,102.62657928466797', '1391.jpg,42,49.09038162231445', '1900.jpg,12,14.298606872558594', '2877.jpg,111,63.246559143066406', '761.jpg,16,30.56096839904785', '7247.jpg,18,21.970027923583984', '4758.jpg,42,37.89552688598633', '2826.jpg,22,7.7957987785339355', '4590.jpg,8,8.776276588439941', '6721.jpg,11,12.816295623779297', '3662.jpg,10,11.003122329711914', '1981.jpg,159,153.59547424316406', '2003.jpg,20,12.64177131652832', '3760.jpg,12,8.16051197052002', '1902.jpg,94,81.25189971923828', '1945.jpg,44,34.01950454711914', '824.jpg,9,17.655254364013672', '4824.jpg,49,41.052772521972656', '239.jpg,26,22.93158531188965', '961.jpg,48,30.057514190673828', '1984.jpg,35,36.8184700012207', '2409.jpg,59,5.728867053985596', '6120.jpg,14,15.105937957763672', '6084.jpg,30,34.384788513183594', '4831.jpg,122,104.484130859375', '3521.jpg,27,42.21917724609375', '4534.jpg,11,30.156415939331055', '2808.jpg,26,18.43799591064453', '226.jpg,78,56.880615234375', '1979.jpg,40,41.061737060546875', '5879.jpg,36,23.91820526123047', '766.jpg,50,56.91596603393555', '7531.jpg,65,36.51024627685547', '5214.jpg,9,11.206918716430664', '749.jpg,10,54.481178283691406', '2855.jpg,56,45.4210205078125', '5658.jpg,9,10.7057523727417', '218.jpg,58,50.41294479370117', '964.jpg,18,51.83982849121094', '5085.jpg,9,3.830596446990967', '7293.jpg,69,34.081871032714844', '3766.jpg,12,13.223400115966797', '7012.jpg,66,49.0933952331543', '2847.jpg,20,19.684471130371094', '1911.jpg,119,141.62716674804688', '6741.jpg,22,6.0048675537109375', '7107.jpg,19,12.05192756652832', '4812.jpg,67,42.15653991699219', '5858.jpg,170,70.16841888427734', '5046.jpg,215,165.3636932373047', '976.jpg,85,74.77774047851562', '1952.jpg,37,38.063114166259766', '562.jpg,13,29.972660064697266', '6772.jpg,68,43.02288055419922', '7600.jpg,452,263.25457763671875', '740.jpg,10,15.284900665283203', '6896.jpg,15,10.922513008117676', '5104.jpg,13,8.777853965759277', '3768.jpg,9,11.091686248779297', '753.jpg,12,13.62666130065918', '2809.jpg,45,40.595703125', '1907.jpg,28,26.711669921875', '7602.jpg,14,29.301759719848633', '221.jpg,42,26.344362258911133', '5043.jpg,134,129.85340881347656', '7133.jpg,35,42.751914978027344', '7159.jpg,42,41.1854248046875', '5862.jpg,58,49.73300552368164', '3774.jpg,31,25.300704956054688', '6287.jpg,23,30.288681030273438', '4596.jpg,24,19.81083106994629', '4539.jpg,16,23.58626365661621', '7318.jpg,30,28.481201171875', '3581.jpg,8,6.7509307861328125', '3540.jpg,28,39.25459671020508', '560.jpg,13,25.432903289794922', '1933.jpg,215,133.13607788085938', '6117.jpg,12,20.296737670898438', '5899.jpg,99,75.84507751464844', '1991.jpg,119,72.42893981933594', '6119.jpg,14,7.61577033996582', '1892.jpg,180,177.90756225585938', '4713.jpg,18,31.13117027282715', '4817.jpg,57,35.067832946777344', '600.jpg,19,27.325328826904297', '585.jpg,12,17.463340759277344', '5092.jpg,15,13.09716796875', '582.jpg,14,23.285938262939453', '240.jpg,37,22.840435028076172', '5655.jpg,9,9.553967475891113', '6927.jpg,32,34.20940399169922']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZUGWYOmRA_Z"
      },
      "source": [
        "ground_truth_count = []\n",
        "predicted_count = []\n",
        "for i in range(1, len(count_data)):\n",
        "  temp = count_data[i].split(',')\n",
        "  ground_truth_count.append(int(temp[1]))\n",
        "  predicted_count.append(float(temp[2])) "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcruuzB8RA_Z"
      },
      "source": [
        "ground_truth_count = np.array(ground_truth_count)\n",
        "predicted_count = np.array(predicted_count)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeQAT7SJRA_Z",
        "outputId": "14a320ee-a37c-4065-bbd3-1319f2e49877"
      },
      "source": [
        "ground_truth_count.shape, predicted_count.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100,), (100,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "lXHfTx40RA_a",
        "outputId": "eb332c4d-202d-4cbe-ed17-f91277be8871"
      },
      "source": [
        "plt.scatter(ground_truth_count, predicted_count)\n",
        "plt.xlabel(\"ground_truth\")\n",
        "plt.ylabel(\"predicted\")\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmczA8QKfMNh"
      },
      "source": [
        "### Run for val-partA without test time adaptaion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFe1iKpnfNsA",
        "outputId": "9b750504-aedd-40c6-ac02-c40fc74bf811"
      },
      "source": [
        "!python test.py --data_path 'data/' -ts 'val_PartA'"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation on val_PartA data\n",
            "\r  0% 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "\r2851.jpg: actual-predicted:     61,   17.6, error:   43.4. Current MAE: 43.41, RMSE: 43.41:   0% 0/100 [00:00<?, ?it/s]\n",
            "4167.jpg: actual-predicted:     10,   14.6, error:    4.6. Current MAE: 24.02, RMSE: 30.87:   0% 0/100 [00:00<?, ?it/s]\n",
            "4105.jpg: actual-predicted:     12,   27.4, error:   15.4. Current MAE: 21.13, RMSE: 26.72:   2% 2/100 [00:00<00:10,  9.40it/s]\n",
            "5890.jpg: actual-predicted:     33,   33.5, error:    0.5. Current MAE: 15.98, RMSE: 23.14:   2% 2/100 [00:00<00:10,  9.40it/s]\n",
            "253.jpg : actual-predicted:    192,  170.3, error:   21.7. Current MAE: 17.13, RMSE: 22.87:   4% 4/100 [00:00<00:09, 10.54it/s]\n",
            "5089.jpg: actual-predicted:     11,   14.8, error:    3.8. Current MAE: 14.90, RMSE: 20.93:   4% 4/100 [00:00<00:09, 10.54it/s]\n",
            "6722.jpg: actual-predicted:     36,   56.8, error:   20.8. Current MAE: 15.74, RMSE: 20.90:   6% 6/100 [00:00<00:08, 10.46it/s]\n",
            "3873.jpg: actual-predicted:      7,    2.9, error:    4.1. Current MAE: 14.28, RMSE: 19.61:   6% 6/100 [00:00<00:08, 10.46it/s]\n",
            "5898.jpg: actual-predicted:     32,   54.9, error:   22.9. Current MAE: 15.24, RMSE: 20.01:   8% 8/100 [00:00<00:09,  9.97it/s]\n",
            "1929.jpg: actual-predicted:     86,  109.4, error:   23.4. Current MAE: 16.06, RMSE: 20.37:   8% 8/100 [00:00<00:09,  9.97it/s]\n",
            "1391.jpg: actual-predicted:     42,   67.8, error:   25.8. Current MAE: 16.94, RMSE: 20.92:  10% 10/100 [00:00<00:07, 11.69it/s]\n",
            "1900.jpg: actual-predicted:     12,   15.6, error:    3.6. Current MAE: 15.83, RMSE: 20.06:  10% 10/100 [00:01<00:07, 11.69it/s]\n",
            "2877.jpg: actual-predicted:    111,   46.5, error:   64.5. Current MAE: 19.57, RMSE: 26.29:  12% 12/100 [00:01<00:07, 11.58it/s]\n",
            "761.jpg : actual-predicted:     16,   43.9, error:   27.9. Current MAE: 20.17, RMSE: 26.41:  12% 12/100 [00:01<00:07, 11.58it/s]\n",
            "7247.jpg: actual-predicted:     18,   22.9, error:    4.9. Current MAE: 19.15, RMSE: 25.54:  14% 14/100 [00:01<00:06, 12.66it/s]\n",
            "4758.jpg: actual-predicted:     42,   46.7, error:    4.7. Current MAE: 18.25, RMSE: 24.76:  14% 14/100 [00:01<00:06, 12.66it/s]\n",
            "2826.jpg: actual-predicted:     22,    3.5, error:   18.5. Current MAE: 18.26, RMSE: 24.43:  16% 16/100 [00:01<00:06, 13.70it/s]\n",
            "4590.jpg: actual-predicted:      8,   10.0, error:    2.0. Current MAE: 17.36, RMSE: 23.75:  16% 16/100 [00:01<00:06, 13.70it/s]\n",
            "6721.jpg: actual-predicted:     11,   15.2, error:    4.2. Current MAE: 16.67, RMSE: 23.14:  18% 18/100 [00:01<00:06, 12.21it/s]\n",
            "3662.jpg: actual-predicted:     10,   12.7, error:    2.7. Current MAE: 15.97, RMSE: 22.56:  18% 18/100 [00:01<00:06, 12.21it/s]\n",
            "1981.jpg: actual-predicted:    159,  181.2, error:   22.2. Current MAE: 16.26, RMSE: 22.54:  20% 20/100 [00:01<00:06, 12.47it/s]\n",
            "2003.jpg: actual-predicted:     20,   12.1, error:    7.9. Current MAE: 15.88, RMSE: 22.09:  20% 20/100 [00:01<00:06, 12.47it/s]\n",
            "3760.jpg: actual-predicted:     12,    5.7, error:    6.3. Current MAE: 15.46, RMSE: 21.64:  22% 22/100 [00:01<00:06, 11.83it/s]\n",
            "1902.jpg: actual-predicted:     94,   97.6, error:    3.6. Current MAE: 14.97, RMSE: 21.20:  22% 22/100 [00:01<00:06, 11.83it/s]\n",
            "1945.jpg: actual-predicted:     44,   35.3, error:    8.7. Current MAE: 14.72, RMSE: 20.84:  24% 24/100 [00:02<00:06, 11.90it/s]\n",
            "824.jpg : actual-predicted:      9,   20.3, error:   11.3. Current MAE: 14.58, RMSE: 20.55:  24% 24/100 [00:02<00:06, 11.90it/s]\n",
            "4824.jpg: actual-predicted:     49,   45.6, error:    3.4. Current MAE: 14.17, RMSE: 20.18:  26% 26/100 [00:02<00:05, 12.92it/s]\n",
            "239.jpg : actual-predicted:     26,   24.6, error:    1.4. Current MAE: 13.71, RMSE: 19.82:  26% 26/100 [00:02<00:05, 12.92it/s]\n",
            "961.jpg : actual-predicted:     48,   28.2, error:   19.8. Current MAE: 13.92, RMSE: 19.82:  26% 26/100 [00:02<00:05, 12.92it/s]\n",
            "1984.jpg: actual-predicted:     35,   42.7, error:    7.7. Current MAE: 13.72, RMSE: 19.54:  29% 29/100 [00:02<00:05, 14.04it/s]\n",
            "2409.jpg: actual-predicted:     59,    2.3, error:   56.7. Current MAE: 15.10, RMSE: 21.75:  29% 29/100 [00:02<00:05, 14.04it/s]\n",
            "6120.jpg: actual-predicted:     14,   19.0, error:    5.0. Current MAE: 14.79, RMSE: 21.43:  31% 31/100 [00:02<00:05, 12.37it/s]\n",
            "6084.jpg: actual-predicted:     30,   44.3, error:   14.3. Current MAE: 14.77, RMSE: 21.24:  31% 31/100 [00:02<00:05, 12.37it/s]\n",
            "4831.jpg: actual-predicted:    122,  130.8, error:    8.8. Current MAE: 14.59, RMSE: 20.98:  33% 33/100 [00:02<00:05, 12.48it/s]\n",
            "3521.jpg: actual-predicted:     27,   45.4, error:   18.4. Current MAE: 14.70, RMSE: 20.91:  33% 33/100 [00:02<00:05, 12.48it/s]\n",
            "4534.jpg: actual-predicted:     11,   44.7, error:   33.7. Current MAE: 15.23, RMSE: 21.37:  35% 35/100 [00:02<00:04, 13.40it/s]\n",
            "2808.jpg: actual-predicted:     26,   20.6, error:    5.4. Current MAE: 14.97, RMSE: 21.10:  35% 35/100 [00:02<00:04, 13.40it/s]\n",
            "226.jpg : actual-predicted:     78,   66.9, error:   11.1. Current MAE: 14.87, RMSE: 20.90:  37% 37/100 [00:03<00:05, 12.43it/s]\n",
            "1979.jpg: actual-predicted:     40,   38.8, error:    1.2. Current MAE: 14.52, RMSE: 20.63:  37% 37/100 [00:03<00:05, 12.43it/s]\n",
            "5879.jpg: actual-predicted:     36,   30.6, error:    5.4. Current MAE: 14.29, RMSE: 20.39:  39% 39/100 [00:03<00:04, 13.33it/s]\n",
            "766.jpg : actual-predicted:     50,   64.9, error:   14.9. Current MAE: 14.30, RMSE: 20.27:  39% 39/100 [00:03<00:04, 13.33it/s]\n",
            "7531.jpg: actual-predicted:     65,   45.5, error:   19.5. Current MAE: 14.43, RMSE: 20.26:  41% 41/100 [00:03<00:04, 13.45it/s]\n",
            "5214.jpg: actual-predicted:      9,   14.4, error:    5.4. Current MAE: 14.22, RMSE: 20.04:  41% 41/100 [00:03<00:04, 13.45it/s]\n",
            "749.jpg : actual-predicted:     10,   77.6, error:   67.6. Current MAE: 15.43, RMSE: 22.27:  43% 43/100 [00:03<00:04, 13.62it/s]\n",
            "2855.jpg: actual-predicted:     56,   42.9, error:   13.1. Current MAE: 15.38, RMSE: 22.11:  43% 43/100 [00:03<00:04, 13.62it/s]\n",
            "5658.jpg: actual-predicted:      9,   11.5, error:    2.5. Current MAE: 15.10, RMSE: 21.87:  45% 45/100 [00:03<00:03, 14.55it/s]\n",
            "218.jpg : actual-predicted:     58,   50.7, error:    7.3. Current MAE: 14.93, RMSE: 21.67:  45% 45/100 [00:03<00:03, 14.55it/s]\n",
            "964.jpg : actual-predicted:     18,   83.4, error:   65.4. Current MAE: 15.98, RMSE: 23.43:  47% 47/100 [00:03<00:03, 14.46it/s]\n",
            "5085.jpg: actual-predicted:      9,    1.1, error:    7.9. Current MAE: 15.82, RMSE: 23.21:  47% 47/100 [00:04<00:03, 14.46it/s]\n",
            "7293.jpg: actual-predicted:     69,   40.4, error:   28.6. Current MAE: 16.07, RMSE: 23.33:  49% 49/100 [00:04<00:07,  6.48it/s]\n",
            "3766.jpg: actual-predicted:     12,   12.3, error:    0.3. Current MAE: 15.76, RMSE: 23.10:  49% 49/100 [00:04<00:07,  6.48it/s]\n",
            "7012.jpg: actual-predicted:     66,   66.1, error:    0.1. Current MAE: 15.46, RMSE: 22.88:  51% 51/100 [00:04<00:06,  7.39it/s]\n",
            "2847.jpg: actual-predicted:     20,   26.7, error:    6.7. Current MAE: 15.30, RMSE: 22.68:  51% 51/100 [00:04<00:06,  7.39it/s]\n",
            "1911.jpg: actual-predicted:    119,  167.5, error:   48.5. Current MAE: 15.91, RMSE: 23.42:  53% 53/100 [00:04<00:05,  8.36it/s]\n",
            "6741.jpg: actual-predicted:     22,    3.2, error:   18.8. Current MAE: 15.96, RMSE: 23.34:  53% 53/100 [00:04<00:05,  8.36it/s]\n",
            "7107.jpg: actual-predicted:     19,    9.1, error:    9.9. Current MAE: 15.86, RMSE: 23.17:  55% 55/100 [00:05<00:05,  8.95it/s]\n",
            "4812.jpg: actual-predicted:     67,   43.3, error:   23.7. Current MAE: 15.99, RMSE: 23.18:  55% 55/100 [00:05<00:05,  8.95it/s]\n",
            "5858.jpg: actual-predicted:    170,   77.9, error:   92.1. Current MAE: 17.31, RMSE: 25.97:  57% 57/100 [00:05<00:04,  8.95it/s]\n",
            "5046.jpg: actual-predicted:    215,  136.7, error:   78.3. Current MAE: 18.34, RMSE: 27.69:  57% 57/100 [00:05<00:04,  8.95it/s]\n",
            "976.jpg : actual-predicted:     85,   88.9, error:    3.9. Current MAE: 18.10, RMSE: 27.46:  57% 57/100 [00:05<00:04,  8.95it/s]\n",
            "1952.jpg: actual-predicted:     37,   39.5, error:    2.5. Current MAE: 17.84, RMSE: 27.24:  60% 60/100 [00:05<00:03, 10.91it/s]\n",
            "562.jpg : actual-predicted:     13,   43.7, error:   30.7. Current MAE: 18.05, RMSE: 27.30:  60% 60/100 [00:05<00:03, 10.91it/s]\n",
            "6772.jpg: actual-predicted:     68,   51.3, error:   16.7. Current MAE: 18.03, RMSE: 27.16:  62% 62/100 [00:05<00:03, 11.67it/s]\n",
            "7600.jpg: actual-predicted:    452,  340.6, error:  111.4. Current MAE: 19.49, RMSE: 30.34:  62% 62/100 [00:05<00:03, 11.67it/s]\n",
            "740.jpg : actual-predicted:     10,   16.2, error:    6.2. Current MAE: 19.28, RMSE: 30.11:  64% 64/100 [00:05<00:02, 13.17it/s]\n",
            "6896.jpg: actual-predicted:     15,    7.8, error:    7.2. Current MAE: 19.10, RMSE: 29.90:  64% 64/100 [00:05<00:02, 13.17it/s]\n",
            "5104.jpg: actual-predicted:     13,    9.9, error:    3.1. Current MAE: 18.86, RMSE: 29.68:  66% 66/100 [00:05<00:02, 12.55it/s]\n",
            "3768.jpg: actual-predicted:      9,   13.5, error:    4.5. Current MAE: 18.65, RMSE: 29.46:  66% 66/100 [00:05<00:02, 12.55it/s]\n",
            "753.jpg : actual-predicted:     12,   11.1, error:    0.9. Current MAE: 18.39, RMSE: 29.25:  68% 68/100 [00:05<00:02, 11.29it/s]\n",
            "2809.jpg: actual-predicted:     45,   50.7, error:    5.7. Current MAE: 18.21, RMSE: 29.05:  68% 68/100 [00:06<00:02, 11.29it/s]\n",
            "1907.jpg: actual-predicted:     28,   33.4, error:    5.4. Current MAE: 18.03, RMSE: 28.85:  70% 70/100 [00:06<00:02, 11.44it/s]\n",
            "7602.jpg: actual-predicted:     14,   32.3, error:   18.3. Current MAE: 18.04, RMSE: 28.73:  70% 70/100 [00:06<00:02, 11.44it/s]\n",
            "221.jpg : actual-predicted:     42,   23.8, error:   18.2. Current MAE: 18.04, RMSE: 28.61:  72% 72/100 [00:06<00:02, 12.35it/s]\n",
            "5043.jpg: actual-predicted:    134,  123.3, error:   10.7. Current MAE: 17.94, RMSE: 28.44:  72% 72/100 [00:06<00:02, 12.35it/s]\n",
            "7133.jpg: actual-predicted:     35,   46.5, error:   11.5. Current MAE: 17.85, RMSE: 28.28:  72% 72/100 [00:06<00:02, 12.35it/s]\n",
            "7159.jpg: actual-predicted:     42,   44.5, error:    2.5. Current MAE: 17.65, RMSE: 28.10:  75% 75/100 [00:06<00:02, 12.46it/s]\n",
            "5862.jpg: actual-predicted:     58,   59.8, error:    1.8. Current MAE: 17.44, RMSE: 27.92:  75% 75/100 [00:06<00:02, 12.46it/s]\n",
            "3774.jpg: actual-predicted:     31,   29.4, error:    1.6. Current MAE: 17.24, RMSE: 27.74:  77% 77/100 [00:06<00:01, 13.67it/s]\n",
            "6287.jpg: actual-predicted:     23,   36.5, error:   13.5. Current MAE: 17.19, RMSE: 27.60:  77% 77/100 [00:06<00:01, 13.67it/s]\n",
            "4596.jpg: actual-predicted:     24,   24.6, error:    0.6. Current MAE: 16.99, RMSE: 27.43:  79% 79/100 [00:06<00:01, 13.79it/s]\n",
            "4539.jpg: actual-predicted:     16,   33.0, error:   17.0. Current MAE: 16.98, RMSE: 27.32:  79% 79/100 [00:06<00:01, 13.79it/s]\n",
            "7318.jpg: actual-predicted:     30,   32.4, error:    2.4. Current MAE: 16.81, RMSE: 27.16:  81% 81/100 [00:06<00:01, 13.19it/s]\n",
            "3581.jpg: actual-predicted:      8,    7.0, error:    1.0. Current MAE: 16.62, RMSE: 27.00:  81% 81/100 [00:06<00:01, 13.19it/s]\n",
            "3540.jpg: actual-predicted:     28,   43.9, error:   15.9. Current MAE: 16.61, RMSE: 26.89:  83% 83/100 [00:07<00:01, 13.42it/s]\n",
            "560.jpg : actual-predicted:     13,   30.7, error:   17.7. Current MAE: 16.62, RMSE: 26.80:  83% 83/100 [00:07<00:01, 13.42it/s]\n",
            "1933.jpg: actual-predicted:    215,  182.0, error:   33.0. Current MAE: 16.81, RMSE: 26.88:  85% 85/100 [00:07<00:01, 13.59it/s]\n",
            "6117.jpg: actual-predicted:     12,   23.9, error:   11.9. Current MAE: 16.75, RMSE: 26.76:  85% 85/100 [00:07<00:01, 13.59it/s]\n",
            "5899.jpg: actual-predicted:     99,   96.1, error:    2.9. Current MAE: 16.60, RMSE: 26.60:  87% 87/100 [00:07<00:00, 14.02it/s]\n",
            "1991.jpg: actual-predicted:    119,   79.5, error:   39.5. Current MAE: 16.85, RMSE: 26.78:  87% 87/100 [00:07<00:00, 14.02it/s]\n",
            "6119.jpg: actual-predicted:     14,    5.4, error:    8.6. Current MAE: 16.76, RMSE: 26.65:  89% 89/100 [00:07<00:00, 15.04it/s]\n",
            "1892.jpg: actual-predicted:    180,  204.9, error:   24.9. Current MAE: 16.85, RMSE: 26.63:  89% 89/100 [00:07<00:00, 15.04it/s]\n",
            "4713.jpg: actual-predicted:     18,   27.2, error:    9.2. Current MAE: 16.77, RMSE: 26.50:  91% 91/100 [00:07<00:00, 13.13it/s]\n",
            "4817.jpg: actual-predicted:     57,   45.9, error:   11.1. Current MAE: 16.71, RMSE: 26.39:  91% 91/100 [00:07<00:00, 13.13it/s]\n",
            "600.jpg : actual-predicted:     19,   29.9, error:   10.9. Current MAE: 16.65, RMSE: 26.27:  93% 93/100 [00:07<00:00, 14.28it/s]\n",
            "585.jpg : actual-predicted:     12,   19.6, error:    7.6. Current MAE: 16.55, RMSE: 26.14:  93% 93/100 [00:07<00:00, 14.28it/s]\n",
            "5092.jpg: actual-predicted:     15,    9.0, error:    6.0. Current MAE: 16.44, RMSE: 26.01:  95% 95/100 [00:07<00:00, 14.64it/s]\n",
            "582.jpg : actual-predicted:     14,   28.2, error:   14.2. Current MAE: 16.42, RMSE: 25.92:  95% 95/100 [00:07<00:00, 14.64it/s]\n",
            "240.jpg : actual-predicted:     37,   26.9, error:   10.1. Current MAE: 16.35, RMSE: 25.81:  97% 97/100 [00:08<00:00, 14.09it/s]\n",
            "5655.jpg: actual-predicted:      9,   11.0, error:    2.0. Current MAE: 16.21, RMSE: 25.68:  97% 97/100 [00:08<00:00, 14.09it/s]\n",
            "6927.jpg: actual-predicted:     32,   38.6, error:    6.6. Current MAE: 16.11, RMSE: 25.56:  99% 99/100 [00:08<00:00, 13.80it/s]\n",
            "6927.jpg: actual-predicted:     32,   38.6, error:    6.6. Current MAE: 16.11, RMSE: 25.56: 100% 100/100 [00:08<00:00, 12.15it/s]\n",
            "On val_PartA data, MAE:  16.11, RMSE:  25.56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yZyptMrfkOS"
      },
      "source": [
        "### Vadilation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPxjTjjofkOf"
      },
      "source": [
        "# get ground truth and predicted counts and plot scatter plot\n",
        "count_file = 'count.csv'\n",
        "count = open(count_file, 'r')\n",
        "count_data = count.read()\n",
        "count_data = count_data.split('\\n')"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_Ds3rY9fkOg",
        "outputId": "9be71b35-ba26-4853-b34f-21326860c80b"
      },
      "source": [
        "count_data = count_data[:-1]\n",
        "print(count_data)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Id,ground_truth_count,predicted_count', '2851.jpg,61,17.585205078125', '4167.jpg,10,14.623456954956055', '4105.jpg,12,27.35610008239746', '5890.jpg,33,33.533382415771484', '253.jpg,192,170.2755889892578', '5089.jpg,11,14.774792671203613', '6722.jpg,36,56.750770568847656', '3873.jpg,7,2.9472317695617676', '5898.jpg,32,54.94309616088867', '1929.jpg,86,109.41790771484375', '1391.jpg,42,67.7984619140625', '1900.jpg,12,15.61505126953125', '2877.jpg,111,46.54526901245117', '761.jpg,16,43.899070739746094', '7247.jpg,18,22.93277359008789', '4758.jpg,42,46.744693756103516', '2826.jpg,22,3.537313461303711', '4590.jpg,8,10.018990516662598', '6721.jpg,11,15.152978897094727', '3662.jpg,10,12.697052001953125', '1981.jpg,159,181.16500854492188', '2003.jpg,20,12.145344734191895', '3760.jpg,12,5.731661796569824', '1902.jpg,94,97.58260345458984', '1945.jpg,44,35.332923889160156', '824.jpg,9,20.256240844726562', '4824.jpg,49,45.64595031738281', '239.jpg,26,24.553207397460938', '961.jpg,48,28.243209838867188', '1984.jpg,35,42.73956298828125', '2409.jpg,59,2.291970729827881', '6120.jpg,14,18.985313415527344', '6084.jpg,30,44.26447296142578', '4831.jpg,122,130.78585815429688', '3521.jpg,27,45.395992279052734', '4534.jpg,11,44.731529235839844', '2808.jpg,26,20.55878257751465', '226.jpg,78,66.87071990966797', '1979.jpg,40,38.79159164428711', '5879.jpg,36,30.638097763061523', '766.jpg,50,64.9045181274414', '7531.jpg,65,45.456390380859375', '5214.jpg,9,14.378589630126953', '749.jpg,10,77.59315490722656', '2855.jpg,56,42.94892120361328', '5658.jpg,9,11.530232429504395', '218.jpg,58,50.70586013793945', '964.jpg,18,83.41580200195312', '5085.jpg,9,1.145795226097107', '7293.jpg,69,40.409332275390625', '3766.jpg,12,12.32642936706543', '7012.jpg,66,66.10665893554688', '2847.jpg,20,26.671133041381836', '1911.jpg,119,167.45986938476562', '6741.jpg,22,3.225646734237671', '7107.jpg,19,9.059006690979004', '4812.jpg,67,43.26876449584961', '5858.jpg,170,77.8930892944336', '5046.jpg,215,136.70462036132812', '976.jpg,85,88.88983917236328', '1952.jpg,37,39.52014923095703', '562.jpg,13,43.719390869140625', '6772.jpg,68,51.34646224975586', '7600.jpg,452,340.563720703125', '740.jpg,10,16.207340240478516', '6896.jpg,15,7.8219451904296875', '5104.jpg,13,9.92833423614502', '3768.jpg,9,13.539490699768066', '753.jpg,12,11.130842208862305', '2809.jpg,45,50.7177848815918', '1907.jpg,28,33.394630432128906', '7602.jpg,14,32.32855224609375', '221.jpg,42,23.79133415222168', '5043.jpg,134,123.30120849609375', '7133.jpg,35,46.45439529418945', '7159.jpg,42,44.49066925048828', '5862.jpg,58,59.81169891357422', '3774.jpg,31,29.44419288635254', '6287.jpg,23,36.45075988769531', '4596.jpg,24,24.569114685058594', '4539.jpg,16,32.97231674194336', '7318.jpg,30,32.37638473510742', '3581.jpg,8,6.987907409667969', '3540.jpg,28,43.89253234863281', '560.jpg,13,30.66064453125', '1933.jpg,215,182.01370239257812', '6117.jpg,12,23.897647857666016', '5899.jpg,99,96.060546875', '1991.jpg,119,79.47018432617188', '6119.jpg,14,5.393790245056152', '1892.jpg,180,204.9020538330078', '4713.jpg,18,27.18780517578125', '4817.jpg,57,45.91251754760742', '600.jpg,19,29.935585021972656', '585.jpg,12,19.58950424194336', '5092.jpg,15,8.997756958007812', '582.jpg,14,28.208805084228516', '240.jpg,37,26.92384910583496', '5655.jpg,9,11.042980194091797', '6927.jpg,32,38.64384078979492']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAW1EomZfkOg"
      },
      "source": [
        "ground_truth_count = []\n",
        "predicted_count = []\n",
        "for i in range(1, len(count_data)):\n",
        "  temp = count_data[i].split(',')\n",
        "  ground_truth_count.append(int(temp[1]))\n",
        "  predicted_count.append(float(temp[2])) "
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7N63iwZ3fkOg"
      },
      "source": [
        "ground_truth_count = np.array(ground_truth_count)\n",
        "predicted_count = np.array(predicted_count)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUTNiRk9fkOh",
        "outputId": "5b19ede2-0136-4cff-e8c6-44d2902dd773"
      },
      "source": [
        "ground_truth_count.shape, predicted_count.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((100,), (100,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "sJN-VEOifkOh",
        "outputId": "c2370bc0-9c52-4ab4-e186-37f53f9e00aa"
      },
      "source": [
        "plt.scatter(ground_truth_count, predicted_count)\n",
        "plt.xlabel(\"ground_truth\")\n",
        "plt.ylabel(\"predicted\")\n",
        "plt.show()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA_ZX0RF305B"
      },
      "source": [
        "# 2.4 - Test Time With Adaptaion, kaggle submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTBiq_F6331j",
        "outputId": "7362c94f-4dc6-4743-a9be-3a3e670f06ca"
      },
      "source": [
        "!python test.py --data_path 'data/' -ts 'test' -a -gs 1000 -wn 1e-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation on test data\n",
            "  0% 0/1190 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode)\n",
            "/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([173170, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "/content/LearningToCountEverything/utils.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss += F.mse_loss(X, ones)\n",
            "2.jpg   : actual-predicted:      0,    8.4, error:    8.4. Current MAE:  8.42, RMSE:  8.42:   0% 0/1190 [00:37<?, ?it/s]\n",
            "2.jpg   : actual-predicted:      0,    8.4, error:    8.4. Current MAE:  8.42, RMSE:  8.42:   0% 1/1190 [00:37<12:22:47, 37.48s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([154652, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3.jpg   : actual-predicted:      0,   22.0, error:   22.0. Current MAE: 15.20, RMSE: 16.64:   0% 1/1190 [01:08<12:22:47, 37.48s/it]\n",
            "3.jpg   : actual-predicted:      0,   22.0, error:   22.0. Current MAE: 15.20, RMSE: 16.64:   0% 2/1190 [01:08<11:45:59, 35.66s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([194525, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4.jpg   : actual-predicted:      0,   21.0, error:   21.0. Current MAE: 17.14, RMSE: 18.22:   0% 2/1190 [01:44<11:45:59, 35.66s/it]\n",
            "4.jpg   : actual-predicted:      0,   21.0, error:   21.0. Current MAE: 17.14, RMSE: 18.22:   0% 3/1190 [01:44<11:46:26, 35.71s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([95202, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5.jpg   : actual-predicted:      0,   95.8, error:   95.8. Current MAE: 36.80, RMSE: 50.42:   0% 3/1190 [02:17<11:46:26, 35.71s/it]\n",
            "5.jpg   : actual-predicted:      0,   95.8, error:   95.8. Current MAE: 36.80, RMSE: 50.42:   0% 4/1190 [02:17<11:28:30, 34.83s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([106642, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6.jpg   : actual-predicted:      0,   22.0, error:   22.0. Current MAE: 33.83, RMSE: 46.16:   0% 4/1190 [02:52<11:28:30, 34.83s/it]\n",
            "6.jpg   : actual-predicted:      0,   22.0, error:   22.0. Current MAE: 33.83, RMSE: 46.16:   0% 5/1190 [02:52<11:27:22, 34.80s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([8833, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "285.jpg : actual-predicted:      0,   12.1, error:   12.1. Current MAE: 30.21, RMSE: 42.42:   0% 5/1190 [03:46<11:27:22, 34.80s/it]\n",
            "285.jpg : actual-predicted:      0,   12.1, error:   12.1. Current MAE: 30.21, RMSE: 42.42:   1% 6/1190 [03:46<13:22:51, 40.69s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([132144, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "286.jpg : actual-predicted:      0,   12.3, error:   12.3. Current MAE: 27.66, RMSE: 39.55:   1% 6/1190 [04:21<13:22:51, 40.69s/it]\n",
            "286.jpg : actual-predicted:      0,   12.3, error:   12.3. Current MAE: 27.66, RMSE: 39.55:   1% 7/1190 [04:21<12:47:42, 38.94s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([110936, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "287.jpg : actual-predicted:      0,   17.5, error:   17.5. Current MAE: 26.39, RMSE: 37.51:   1% 7/1190 [04:47<12:47:42, 38.94s/it]\n",
            "287.jpg : actual-predicted:      0,   17.5, error:   17.5. Current MAE: 26.39, RMSE: 37.51:   1% 8/1190 [04:47<11:29:19, 34.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([104202, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "288.jpg : actual-predicted:      0,   19.7, error:   19.7. Current MAE: 25.64, RMSE: 35.97:   1% 8/1190 [05:21<11:29:19, 34.99s/it]\n",
            "288.jpg : actual-predicted:      0,   19.7, error:   19.7. Current MAE: 25.64, RMSE: 35.97:   1% 9/1190 [05:21<11:24:48, 34.79s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([121984, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "289.jpg : actual-predicted:      0,   25.8, error:   25.8. Current MAE: 25.66, RMSE: 35.08:   1% 9/1190 [05:52<11:24:48, 34.79s/it]\n",
            "289.jpg : actual-predicted:      0,   25.8, error:   25.8. Current MAE: 25.66, RMSE: 35.08:   1% 10/1190 [05:52<11:01:43, 33.65s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([110664, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "290.jpg : actual-predicted:      0,    7.8, error:    7.8. Current MAE: 24.04, RMSE: 33.53:   1% 10/1190 [06:23<11:01:43, 33.65s/it]\n",
            "290.jpg : actual-predicted:      0,    7.8, error:    7.8. Current MAE: 24.04, RMSE: 33.53:   1% 11/1190 [06:23<10:47:11, 32.94s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64903, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "291.jpg : actual-predicted:      0,   16.2, error:   16.2. Current MAE: 23.39, RMSE: 32.45:   1% 11/1190 [06:57<10:47:11, 32.94s/it]\n",
            "291.jpg : actual-predicted:      0,   16.2, error:   16.2. Current MAE: 23.39, RMSE: 32.45:   1% 12/1190 [06:57<10:53:04, 33.26s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([37888, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "292.jpg : actual-predicted:      0,   26.6, error:   26.6. Current MAE: 23.63, RMSE: 32.04:   1% 12/1190 [07:24<10:53:04, 33.26s/it]\n",
            "292.jpg : actual-predicted:      0,   26.6, error:   26.6. Current MAE: 23.63, RMSE: 32.04:   1% 13/1190 [07:24<10:10:45, 31.14s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([37059, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "293.jpg : actual-predicted:      0,   25.1, error:   25.1. Current MAE: 23.74, RMSE: 31.59:   1% 13/1190 [07:56<10:10:45, 31.14s/it]\n",
            "293.jpg : actual-predicted:      0,   25.1, error:   25.1. Current MAE: 23.74, RMSE: 31.59:   1% 14/1190 [07:56<10:18:23, 31.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([21822, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "294.jpg : actual-predicted:      0,  116.9, error:  116.9. Current MAE: 29.95, RMSE: 42.92:   1% 14/1190 [08:20<10:18:23, 31.55s/it]\n",
            "294.jpg : actual-predicted:      0,  116.9, error:  116.9. Current MAE: 29.95, RMSE: 42.92:   1% 15/1190 [08:20<9:31:51, 29.20s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([19056, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "295.jpg : actual-predicted:      0,   48.9, error:   48.9. Current MAE: 31.13, RMSE: 43.32:   1% 15/1190 [08:53<9:31:51, 29.20s/it]\n",
            "295.jpg : actual-predicted:      0,   48.9, error:   48.9. Current MAE: 31.13, RMSE: 43.32:   1% 16/1190 [08:53<9:57:19, 30.53s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([116160, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "296.jpg : actual-predicted:      0,   34.7, error:   34.7. Current MAE: 31.34, RMSE: 42.86:   1% 16/1190 [09:18<9:57:19, 30.53s/it]\n",
            "296.jpg : actual-predicted:      0,   34.7, error:   34.7. Current MAE: 31.34, RMSE: 42.86:   1% 17/1190 [09:18<9:23:47, 28.84s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([66504, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "297.jpg : actual-predicted:      0,   11.5, error:   11.5. Current MAE: 30.24, RMSE: 41.74:   1% 17/1190 [09:51<9:23:47, 28.84s/it]\n",
            "297.jpg : actual-predicted:      0,   11.5, error:   11.5. Current MAE: 30.24, RMSE: 41.74:   2% 18/1190 [09:51<9:44:06, 29.90s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([106117, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "298.jpg : actual-predicted:      0,   53.1, error:   53.1. Current MAE: 31.44, RMSE: 42.41:   2% 18/1190 [10:25<9:44:06, 29.90s/it]\n",
            "298.jpg : actual-predicted:      0,   53.1, error:   53.1. Current MAE: 31.44, RMSE: 42.41:   2% 19/1190 [10:25<10:10:57, 31.30s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([165387, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "299.jpg : actual-predicted:      0,   13.7, error:   13.7. Current MAE: 30.55, RMSE: 41.45:   2% 19/1190 [11:00<10:10:57, 31.30s/it]\n",
            "299.jpg : actual-predicted:      0,   13.7, error:   13.7. Current MAE: 30.55, RMSE: 41.45:   2% 20/1190 [11:00<10:32:43, 32.45s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([77146, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "300.jpg : actual-predicted:      0,   25.6, error:   25.6. Current MAE: 30.32, RMSE: 40.84:   2% 20/1190 [11:38<10:32:43, 32.45s/it]\n",
            "300.jpg : actual-predicted:      0,   25.6, error:   25.6. Current MAE: 30.32, RMSE: 40.84:   2% 21/1190 [11:38<10:59:38, 33.86s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([81751, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "301.jpg : actual-predicted:      0,   17.8, error:   17.8. Current MAE: 29.75, RMSE: 40.08:   2% 21/1190 [12:08<10:59:38, 33.86s/it]\n",
            "301.jpg : actual-predicted:      0,   17.8, error:   17.8. Current MAE: 29.75, RMSE: 40.08:   2% 22/1190 [12:08<10:41:29, 32.95s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([134334, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "302.jpg : actual-predicted:      0,   12.7, error:   12.7. Current MAE: 29.00, RMSE: 39.29:   2% 22/1190 [12:43<10:41:29, 32.95s/it]\n",
            "302.jpg : actual-predicted:      0,   12.7, error:   12.7. Current MAE: 29.00, RMSE: 39.29:   2% 23/1190 [12:43<10:52:39, 33.56s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([157494, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "303.jpg : actual-predicted:      0,   31.6, error:   31.6. Current MAE: 29.11, RMSE: 39.00:   2% 23/1190 [13:18<10:52:39, 33.56s/it]\n",
            "303.jpg : actual-predicted:      0,   31.6, error:   31.6. Current MAE: 29.11, RMSE: 39.00:   2% 24/1190 [13:18<10:58:38, 33.89s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([139288, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "305.jpg : actual-predicted:      0,   12.7, error:   12.7. Current MAE: 28.46, RMSE: 38.29:   2% 24/1190 [13:53<10:58:38, 33.89s/it]\n",
            "305.jpg : actual-predicted:      0,   12.7, error:   12.7. Current MAE: 28.46, RMSE: 38.29:   2% 25/1190 [13:53<11:06:42, 34.34s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([5701, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "306.jpg : actual-predicted:      0,   20.0, error:   20.0. Current MAE: 28.13, RMSE: 37.75:   2% 25/1190 [14:24<11:06:42, 34.34s/it]\n",
            "306.jpg : actual-predicted:      0,   20.0, error:   20.0. Current MAE: 28.13, RMSE: 37.75:   2% 26/1190 [14:24<10:47:14, 33.36s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([93287, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "307.jpg : actual-predicted:      0,   11.4, error:   11.4. Current MAE: 27.51, RMSE: 37.11:   2% 26/1190 [14:51<10:47:14, 33.36s/it]\n",
            "307.jpg : actual-predicted:      0,   11.4, error:   11.4. Current MAE: 27.51, RMSE: 37.11:   2% 27/1190 [14:51<10:08:51, 31.41s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([150947, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "308.jpg : actual-predicted:      0,   11.3, error:   11.3. Current MAE: 26.93, RMSE: 36.51:   2% 27/1190 [15:32<10:08:51, 31.41s/it]\n",
            "308.jpg : actual-predicted:      0,   11.3, error:   11.3. Current MAE: 26.93, RMSE: 36.51:   2% 28/1190 [15:32<11:01:50, 34.17s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([11291, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "309.jpg : actual-predicted:      0,   56.0, error:   56.0. Current MAE: 27.93, RMSE: 37.35:   2% 28/1190 [15:58<11:01:50, 34.17s/it]\n",
            "309.jpg : actual-predicted:      0,   56.0, error:   56.0. Current MAE: 27.93, RMSE: 37.35:   2% 29/1190 [15:58<10:12:19, 31.64s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([55867, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "310.jpg : actual-predicted:      0,   22.5, error:   22.5. Current MAE: 27.75, RMSE: 36.95:   2% 29/1190 [16:29<10:12:19, 31.64s/it]\n",
            "310.jpg : actual-predicted:      0,   22.5, error:   22.5. Current MAE: 27.75, RMSE: 36.95:   3% 30/1190 [16:29<10:08:29, 31.47s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([0, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "311.jpg : actual-predicted:      0,   35.2, error:   35.2. Current MAE: 28.00, RMSE: 36.90:   3% 30/1190 [16:53<10:08:29, 31.47s/it]\n",
            "311.jpg : actual-predicted:      0,   35.2, error:   35.2. Current MAE: 28.00, RMSE: 36.90:   3% 31/1190 [16:53<9:28:04, 29.41s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([6074, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "312.jpg : actual-predicted:      0,   26.5, error:   26.5. Current MAE: 27.95, RMSE: 36.62:   3% 31/1190 [17:23<9:28:04, 29.41s/it]\n",
            "313.jpg : actual-predicted:      0,   18.8, error:   18.8. Current MAE: 27.67, RMSE: 36.20:   3% 32/1190 [17:57<9:31:01, 29.59s/it]\n",
            "315.jpg : actual-predicted:      0,   33.5, error:   33.5. Current MAE: 27.84, RMSE: 36.13:   3% 33/1190 [18:30<9:53:11, 30.76s/it]\n",
            "316.jpg : actual-predicted:      0,   21.3, error:   21.3. Current MAE: 27.66, RMSE: 35.79:   3% 34/1190 [19:10<10:09:06, 31.61s/it]\n",
            "316.jpg : actual-predicted:      0,   21.3, error:   21.3. Current MAE: 27.66, RMSE: 35.79:   3% 35/1190 [19:10<10:56:16, 34.09s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([165294, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "317.jpg : actual-predicted:      0,   22.1, error:   22.1. Current MAE: 27.50, RMSE: 35.48:   3% 35/1190 [19:47<10:56:16, 34.09s/it]\n",
            "317.jpg : actual-predicted:      0,   22.1, error:   22.1. Current MAE: 27.50, RMSE: 35.48:   3% 36/1190 [19:47<11:10:15, 34.85s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([158769, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "319.jpg : actual-predicted:      0,    9.6, error:    9.6. Current MAE: 27.02, RMSE: 35.03:   3% 36/1190 [20:22<11:10:15, 34.85s/it]\n",
            "319.jpg : actual-predicted:      0,    9.6, error:    9.6. Current MAE: 27.02, RMSE: 35.03:   3% 37/1190 [20:22<11:10:49, 34.91s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([58401, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "320.jpg : actual-predicted:      0,   11.6, error:   11.6. Current MAE: 26.61, RMSE: 34.62:   3% 37/1190 [20:54<11:10:49, 34.91s/it]\n",
            "320.jpg : actual-predicted:      0,   11.6, error:   11.6. Current MAE: 26.61, RMSE: 34.62:   3% 38/1190 [20:54<10:55:43, 34.15s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([77169, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "321.jpg : actual-predicted:      0,   20.4, error:   20.4. Current MAE: 26.45, RMSE: 34.33:   3% 38/1190 [21:26<10:55:43, 34.15s/it]\n",
            "321.jpg : actual-predicted:      0,   20.4, error:   20.4. Current MAE: 26.45, RMSE: 34.33:   3% 39/1190 [21:26<10:38:05, 33.26s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([26016, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "322.jpg : actual-predicted:      0,   14.2, error:   14.2. Current MAE: 26.14, RMSE: 33.97:   3% 39/1190 [21:51<10:38:05, 33.26s/it]\n",
            "322.jpg : actual-predicted:      0,   14.2, error:   14.2. Current MAE: 26.14, RMSE: 33.97:   3% 40/1190 [21:51<9:53:32, 30.97s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([152318, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "323.jpg : actual-predicted:      0,   32.7, error:   32.7. Current MAE: 26.30, RMSE: 33.94:   3% 40/1190 [22:27<9:53:32, 30.97s/it]\n",
            "323.jpg : actual-predicted:      0,   32.7, error:   32.7. Current MAE: 26.30, RMSE: 33.94:   3% 41/1190 [22:27<10:17:58, 32.27s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([89635, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "324.jpg : actual-predicted:      0,    8.4, error:    8.4. Current MAE: 25.88, RMSE: 33.56:   3% 41/1190 [22:53<10:17:58, 32.27s/it]\n",
            "325.jpg : actual-predicted:      0,    8.7, error:    8.7. Current MAE: 25.48, RMSE: 33.19:   4% 42/1190 [23:23<9:42:27, 30.44s/it]\n",
            "325.jpg : actual-predicted:      0,    8.7, error:    8.7. Current MAE: 25.48, RMSE: 33.19:   4% 43/1190 [23:23<9:41:28, 30.42s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([79184, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "326.jpg : actual-predicted:      0,   12.0, error:   12.0. Current MAE: 25.17, RMSE: 32.86:   4% 43/1190 [24:00<9:41:28, 30.42s/it]\n",
            "326.jpg : actual-predicted:      0,   12.0, error:   12.0. Current MAE: 25.17, RMSE: 32.86:   4% 44/1190 [24:00<10:21:13, 32.52s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([137454, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "327.jpg : actual-predicted:      0,   10.1, error:   10.1. Current MAE: 24.84, RMSE: 32.53:   4% 44/1190 [24:32<10:21:13, 32.52s/it]\n",
            "327.jpg : actual-predicted:      0,   10.1, error:   10.1. Current MAE: 24.84, RMSE: 32.53:   4% 45/1190 [24:32<10:15:57, 32.28s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([101699, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "328.jpg : actual-predicted:      0,   26.9, error:   26.9. Current MAE: 24.88, RMSE: 32.42:   4% 45/1190 [25:06<10:15:57, 32.28s/it]\n",
            "328.jpg : actual-predicted:      0,   26.9, error:   26.9. Current MAE: 24.88, RMSE: 32.42:   4% 46/1190 [25:06<10:21:49, 32.61s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([56956, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "329.jpg : actual-predicted:      0,   18.3, error:   18.3. Current MAE: 24.74, RMSE: 32.18:   4% 46/1190 [25:36<10:21:49, 32.61s/it]\n",
            "330.jpg : actual-predicted:      0,   22.6, error:   22.6. Current MAE: 24.70, RMSE: 32.01:   4% 47/1190 [26:07<10:10:40, 32.06s/it]\n",
            "330.jpg : actual-predicted:      0,   22.6, error:   22.6. Current MAE: 24.70, RMSE: 32.01:   4% 48/1190 [26:07<9:59:27, 31.49s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([132203, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "331.jpg : actual-predicted:      0,   27.9, error:   27.9. Current MAE: 24.76, RMSE: 31.93:   4% 48/1190 [26:38<9:59:27, 31.49s/it]\n",
            "331.jpg : actual-predicted:      0,   27.9, error:   27.9. Current MAE: 24.76, RMSE: 31.93:   4% 49/1190 [26:38<9:56:53, 31.39s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([128967, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "332.jpg : actual-predicted:      0,    9.0, error:    9.0. Current MAE: 24.45, RMSE: 31.64:   4% 49/1190 [27:11<9:56:53, 31.39s/it]\n",
            "332.jpg : actual-predicted:      0,    9.0, error:    9.0. Current MAE: 24.45, RMSE: 31.64:   4% 50/1190 [27:11<10:07:54, 31.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([134196, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "333.jpg : actual-predicted:      0,   48.2, error:   48.2. Current MAE: 24.91, RMSE: 32.05:   4% 50/1190 [27:46<10:07:54, 31.99s/it]\n",
            "333.jpg : actual-predicted:      0,   48.2, error:   48.2. Current MAE: 24.91, RMSE: 32.05:   4% 51/1190 [27:46<10:24:23, 32.89s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([78291, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "334.jpg : actual-predicted:      0,   13.0, error:   13.0. Current MAE: 24.69, RMSE: 31.79:   4% 51/1190 [28:21<10:24:23, 32.89s/it]\n",
            "334.jpg : actual-predicted:      0,   13.0, error:   13.0. Current MAE: 24.69, RMSE: 31.79:   4% 52/1190 [28:21<10:35:55, 33.53s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([177390, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "335.jpg : actual-predicted:      0,   13.4, error:   13.4. Current MAE: 24.47, RMSE: 31.54:   4% 52/1190 [28:56<10:35:55, 33.53s/it]\n",
            "335.jpg : actual-predicted:      0,   13.4, error:   13.4. Current MAE: 24.47, RMSE: 31.54:   4% 53/1190 [28:56<10:45:35, 34.07s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([142129, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "336.jpg : actual-predicted:      0,   20.1, error:   20.1. Current MAE: 24.39, RMSE: 31.37:   4% 53/1190 [29:26<10:45:35, 34.07s/it]\n",
            "336.jpg : actual-predicted:      0,   20.1, error:   20.1. Current MAE: 24.39, RMSE: 31.37:   5% 54/1190 [29:26<10:19:18, 32.71s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([91366, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "337.jpg : actual-predicted:      0,   10.5, error:   10.5. Current MAE: 24.14, RMSE: 31.11:   5% 54/1190 [29:58<10:19:18, 32.71s/it]\n",
            "337.jpg : actual-predicted:      0,   10.5, error:   10.5. Current MAE: 24.14, RMSE: 31.11:   5% 55/1190 [29:58<10:12:58, 32.40s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([42132, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "339.jpg : actual-predicted:      0,   18.6, error:   18.6. Current MAE: 24.04, RMSE: 30.93:   5% 55/1190 [30:23<10:12:58, 32.40s/it]\n",
            "339.jpg : actual-predicted:      0,   18.6, error:   18.6. Current MAE: 24.04, RMSE: 30.93:   5% 56/1190 [30:23<9:31:58, 30.26s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([49162, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "340.jpg : actual-predicted:      0,    7.8, error:    7.8. Current MAE: 23.76, RMSE: 30.68:   5% 56/1190 [30:54<9:31:58, 30.26s/it]\n",
            "340.jpg : actual-predicted:      0,    7.8, error:    7.8. Current MAE: 23.76, RMSE: 30.68:   5% 57/1190 [30:54<9:36:46, 30.54s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([127198, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "341.jpg : actual-predicted:      0,   13.5, error:   13.5. Current MAE: 23.58, RMSE: 30.46:   5% 57/1190 [31:26<9:36:46, 30.54s/it]\n",
            "341.jpg : actual-predicted:      0,   13.5, error:   13.5. Current MAE: 23.58, RMSE: 30.46:   5% 58/1190 [31:26<9:45:58, 31.06s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([10827, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "342.jpg : actual-predicted:      0,   22.3, error:   22.3. Current MAE: 23.56, RMSE: 30.34:   5% 58/1190 [31:57<9:45:58, 31.06s/it]\n",
            "342.jpg : actual-predicted:      0,   22.3, error:   22.3. Current MAE: 23.56, RMSE: 30.34:   5% 59/1190 [31:57<9:45:52, 31.08s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([113379, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "343.jpg : actual-predicted:      0,   11.9, error:   11.9. Current MAE: 23.36, RMSE: 30.13:   5% 59/1190 [32:25<9:45:52, 31.08s/it]\n",
            "343.jpg : actual-predicted:      0,   11.9, error:   11.9. Current MAE: 23.36, RMSE: 30.13:   5% 60/1190 [32:25<9:25:12, 30.01s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([168569, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "344.jpg : actual-predicted:      0,   28.1, error:   28.1. Current MAE: 23.44, RMSE: 30.10:   5% 60/1190 [33:01<9:25:12, 30.01s/it]\n",
            "344.jpg : actual-predicted:      0,   28.1, error:   28.1. Current MAE: 23.44, RMSE: 30.10:   5% 61/1190 [33:01<10:00:51, 31.93s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([823, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "345.jpg : actual-predicted:      0,   36.2, error:   36.2. Current MAE: 23.64, RMSE: 30.20:   5% 61/1190 [33:35<10:00:51, 31.93s/it]\n",
            "345.jpg : actual-predicted:      0,   36.2, error:   36.2. Current MAE: 23.64, RMSE: 30.20:   5% 62/1190 [33:35<10:10:13, 32.46s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([137801, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "346.jpg : actual-predicted:      0,    7.1, error:    7.1. Current MAE: 23.38, RMSE: 29.98:   5% 62/1190 [34:11<10:10:13, 32.46s/it]\n",
            "346.jpg : actual-predicted:      0,    7.1, error:    7.1. Current MAE: 23.38, RMSE: 29.98:   5% 63/1190 [34:11<10:30:36, 33.57s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([43245, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "347.jpg : actual-predicted:      0,   41.6, error:   41.6. Current MAE: 23.67, RMSE: 30.19:   5% 63/1190 [34:35<10:30:36, 33.57s/it]\n",
            "347.jpg : actual-predicted:      0,   41.6, error:   41.6. Current MAE: 23.67, RMSE: 30.19:   5% 64/1190 [34:35<9:36:31, 30.72s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([131182, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "348.jpg : actual-predicted:      0,   28.5, error:   28.5. Current MAE: 23.74, RMSE: 30.17:   5% 64/1190 [35:05<9:36:31, 30.72s/it]\n",
            "348.jpg : actual-predicted:      0,   28.5, error:   28.5. Current MAE: 23.74, RMSE: 30.17:   5% 65/1190 [35:05<9:29:03, 30.35s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([6660, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "349.jpg : actual-predicted:      0,   20.2, error:   20.2. Current MAE: 23.69, RMSE: 30.04:   5% 65/1190 [35:39<9:29:03, 30.35s/it]\n",
            "349.jpg : actual-predicted:      0,   20.2, error:   20.2. Current MAE: 23.69, RMSE: 30.04:   6% 66/1190 [35:39<9:48:05, 31.39s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([143728, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "350.jpg : actual-predicted:      0,   11.3, error:   11.3. Current MAE: 23.50, RMSE: 29.85:   6% 66/1190 [36:10<9:48:05, 31.39s/it]\n",
            "351.jpg : actual-predicted:      0,   22.6, error:   22.6. Current MAE: 23.49, RMSE: 29.75:   6% 67/1190 [36:35<9:47:48, 31.41s/it]\n",
            "351.jpg : actual-predicted:      0,   22.6, error:   22.6. Current MAE: 23.49, RMSE: 29.75:   6% 68/1190 [36:35<9:08:08, 29.31s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([78139, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "680.jpg : actual-predicted:      0,   14.7, error:   14.7. Current MAE: 23.36, RMSE: 29.59:   6% 68/1190 [37:37<9:08:08, 29.31s/it]\n",
            "680.jpg : actual-predicted:      0,   14.7, error:   14.7. Current MAE: 23.36, RMSE: 29.59:   6% 69/1190 [37:37<12:14:34, 39.32s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([113340, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "681.jpg : actual-predicted:      0,   30.6, error:   30.6. Current MAE: 23.47, RMSE: 29.61:   6% 69/1190 [38:12<12:14:34, 39.32s/it]\n",
            "681.jpg : actual-predicted:      0,   30.6, error:   30.6. Current MAE: 23.47, RMSE: 29.61:   6% 70/1190 [38:12<11:46:33, 37.85s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([46159, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "682.jpg : actual-predicted:      0,   14.8, error:   14.8. Current MAE: 23.34, RMSE: 29.45:   6% 70/1190 [38:42<11:46:33, 37.85s/it]\n",
            "682.jpg : actual-predicted:      0,   14.8, error:   14.8. Current MAE: 23.34, RMSE: 29.45:   6% 71/1190 [38:42<11:05:21, 35.68s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([54299, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "685.jpg : actual-predicted:      0,  107.1, error:  107.1. Current MAE: 24.51, RMSE: 31.85:   6% 71/1190 [39:13<11:05:21, 35.68s/it]\n",
            "685.jpg : actual-predicted:      0,  107.1, error:  107.1. Current MAE: 24.51, RMSE: 31.85:   6% 72/1190 [39:13<10:37:01, 34.19s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([174430, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "686.jpg : actual-predicted:      0,   47.4, error:   47.4. Current MAE: 24.82, RMSE: 32.12:   6% 72/1190 [39:48<10:37:01, 34.19s/it]\n",
            "687.jpg : actual-predicted:      0,  266.3, error:  266.3. Current MAE: 28.08, RMSE: 44.45:   6% 73/1190 [40:11<10:43:29, 34.57s/it]\n",
            "687.jpg : actual-predicted:      0,  266.3, error:  266.3. Current MAE: 28.08, RMSE: 44.45:   6% 74/1190 [40:11<9:38:33, 31.11s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([139404, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "689.jpg : actual-predicted:      0,   65.0, error:   65.0. Current MAE: 28.58, RMSE: 44.78:   6% 74/1190 [40:46<9:38:33, 31.11s/it]\n",
            "689.jpg : actual-predicted:      0,   65.0, error:   65.0. Current MAE: 28.58, RMSE: 44.78:   6% 75/1190 [40:46<9:58:50, 32.22s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([109141, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "691.jpg : actual-predicted:      0,   69.6, error:   69.6. Current MAE: 29.12, RMSE: 45.20:   6% 75/1190 [41:21<9:58:50, 32.22s/it]\n",
            "691.jpg : actual-predicted:      0,   69.6, error:   69.6. Current MAE: 29.12, RMSE: 45.20:   6% 76/1190 [41:21<10:11:23, 32.93s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([76342, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "692.jpg : actual-predicted:      0,   12.0, error:   12.0. Current MAE: 28.89, RMSE: 44.93:   6% 76/1190 [41:47<10:11:23, 32.93s/it]\n",
            "692.jpg : actual-predicted:      0,   12.0, error:   12.0. Current MAE: 28.89, RMSE: 44.93:   6% 77/1190 [41:47<9:32:48, 30.88s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([82753, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "693.jpg : actual-predicted:      0,   16.7, error:   16.7. Current MAE: 28.74, RMSE: 44.68:   6% 77/1190 [42:22<9:32:48, 30.88s/it]\n",
            "693.jpg : actual-predicted:      0,   16.7, error:   16.7. Current MAE: 28.74, RMSE: 44.68:   7% 78/1190 [42:22<9:55:52, 32.15s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([90683, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "694.jpg : actual-predicted:      0,   60.6, error:   60.6. Current MAE: 29.14, RMSE: 44.91:   7% 78/1190 [43:09<9:55:52, 32.15s/it]\n",
            "694.jpg : actual-predicted:      0,   60.6, error:   60.6. Current MAE: 29.14, RMSE: 44.91:   7% 79/1190 [43:09<11:18:34, 36.65s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([171121, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "695.jpg : actual-predicted:      0,   10.7, error:   10.7. Current MAE: 28.91, RMSE: 44.65:   7% 79/1190 [43:39<11:18:34, 36.65s/it]\n",
            "697.jpg : actual-predicted:      0,   60.5, error:   60.5. Current MAE: 29.30, RMSE: 44.88:   7% 80/1190 [44:03<10:37:40, 34.47s/it]\n",
            "697.jpg : actual-predicted:      0,   60.5, error:   60.5. Current MAE: 29.30, RMSE: 44.88:   7% 81/1190 [44:03<9:41:05, 31.44s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([156820, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "698.jpg : actual-predicted:      0,   97.9, error:   97.9. Current MAE: 30.14, RMSE: 45.90:   7% 81/1190 [44:38<9:41:05, 31.44s/it]\n",
            "701.jpg : actual-predicted:      0,   61.7, error:   61.7. Current MAE: 30.52, RMSE: 46.12:   7% 82/1190 [45:19<10:01:00, 32.55s/it]\n",
            "701.jpg : actual-predicted:      0,   61.7, error:   61.7. Current MAE: 30.52, RMSE: 46.12:   7% 83/1190 [45:19<10:48:53, 35.17s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([2365, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "702.jpg : actual-predicted:      0,   57.0, error:   57.0. Current MAE: 30.83, RMSE: 46.26:   7% 83/1190 [45:44<10:48:53, 35.17s/it]\n",
            "702.jpg : actual-predicted:      0,   57.0, error:   57.0. Current MAE: 30.83, RMSE: 46.26:   7% 84/1190 [45:44<9:49:33, 31.98s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([86071, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "703.jpg : actual-predicted:      0,   36.5, error:   36.5. Current MAE: 30.90, RMSE: 46.16:   7% 84/1190 [46:18<9:49:33, 31.98s/it]\n",
            "704.jpg : actual-predicted:      0,   56.6, error:   56.6. Current MAE: 31.20, RMSE: 46.29:   7% 85/1190 [46:48<10:01:56, 32.68s/it]\n",
            "704.jpg : actual-predicted:      0,   56.6, error:   56.6. Current MAE: 31.20, RMSE: 46.29:   7% 86/1190 [46:48<9:45:21, 31.81s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([128135, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "705.jpg : actual-predicted:      0,   52.7, error:   52.7. Current MAE: 31.44, RMSE: 46.37:   7% 86/1190 [47:20<9:45:21, 31.81s/it]\n",
            "705.jpg : actual-predicted:      0,   52.7, error:   52.7. Current MAE: 31.44, RMSE: 46.37:   7% 87/1190 [47:20<9:43:07, 31.72s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([118610, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "706.jpg : actual-predicted:      0,   31.2, error:   31.2. Current MAE: 31.44, RMSE: 46.23:   7% 87/1190 [47:44<9:43:07, 31.72s/it]\n",
            "706.jpg : actual-predicted:      0,   31.2, error:   31.2. Current MAE: 31.44, RMSE: 46.23:   7% 88/1190 [47:44<9:03:57, 29.62s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([146138, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "708.jpg : actual-predicted:      0,   13.3, error:   13.3. Current MAE: 31.24, RMSE: 45.99:   7% 88/1190 [48:11<9:03:57, 29.62s/it]\n",
            "708.jpg : actual-predicted:      0,   13.3, error:   13.3. Current MAE: 31.24, RMSE: 45.99:   7% 89/1190 [48:11<8:46:52, 28.71s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([126855, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "709.jpg : actual-predicted:      0,   87.4, error:   87.4. Current MAE: 31.86, RMSE: 46.65:   7% 89/1190 [48:55<8:46:52, 28.71s/it]\n",
            "709.jpg : actual-predicted:      0,   87.4, error:   87.4. Current MAE: 31.86, RMSE: 46.65:   8% 90/1190 [48:55<10:10:30, 33.30s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([142609, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "710.jpg : actual-predicted:      0,   22.3, error:   22.3. Current MAE: 31.76, RMSE: 46.45:   8% 90/1190 [49:34<10:10:30, 33.30s/it]\n",
            "710.jpg : actual-predicted:      0,   22.3, error:   22.3. Current MAE: 31.76, RMSE: 46.45:   8% 91/1190 [49:34<10:44:15, 35.17s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([177212, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "711.jpg : actual-predicted:      0,   18.8, error:   18.8. Current MAE: 31.62, RMSE: 46.24:   8% 91/1190 [50:10<10:44:15, 35.17s/it]\n",
            "711.jpg : actual-predicted:      0,   18.8, error:   18.8. Current MAE: 31.62, RMSE: 46.24:   8% 92/1190 [50:10<10:48:52, 35.46s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([34483, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "712.jpg : actual-predicted:      0,   51.7, error:   51.7. Current MAE: 31.83, RMSE: 46.31:   8% 92/1190 [50:41<10:48:52, 35.46s/it]\n",
            "712.jpg : actual-predicted:      0,   51.7, error:   51.7. Current MAE: 31.83, RMSE: 46.31:   8% 93/1190 [50:41<10:20:24, 33.93s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([89384, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "713.jpg : actual-predicted:      0,   18.5, error:   18.5. Current MAE: 31.69, RMSE: 46.10:   8% 93/1190 [51:06<10:20:24, 33.93s/it]\n",
            "714.jpg : actual-predicted:      0,   85.9, error:   85.9. Current MAE: 32.26, RMSE: 46.69:   8% 94/1190 [51:40<9:33:34, 31.40s/it]\n",
            "714.jpg : actual-predicted:      0,   85.9, error:   85.9. Current MAE: 32.26, RMSE: 46.69:   8% 95/1190 [51:40<9:47:19, 32.18s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([181529, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "715.jpg : actual-predicted:      0,   21.9, error:   21.9. Current MAE: 32.15, RMSE: 46.50:   8% 95/1190 [52:15<9:47:19, 32.18s/it]\n",
            "715.jpg : actual-predicted:      0,   21.9, error:   21.9. Current MAE: 32.15, RMSE: 46.50:   8% 96/1190 [52:15<10:02:24, 33.04s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([82455, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "716.jpg : actual-predicted:      0,   80.6, error:   80.6. Current MAE: 32.65, RMSE: 46.98:   8% 96/1190 [52:40<10:02:24, 33.04s/it]\n",
            "716.jpg : actual-predicted:      0,   80.6, error:   80.6. Current MAE: 32.65, RMSE: 46.98:   8% 97/1190 [52:40<9:15:02, 30.47s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([196889, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "717.jpg : actual-predicted:      0,   15.9, error:   15.9. Current MAE: 32.48, RMSE: 46.77:   8% 97/1190 [53:15<9:15:02, 30.47s/it]\n",
            "717.jpg : actual-predicted:      0,   15.9, error:   15.9. Current MAE: 32.48, RMSE: 46.77:   8% 98/1190 [53:15<9:42:23, 32.00s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([168564, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "719.jpg : actual-predicted:      0,   24.0, error:   24.0. Current MAE: 32.40, RMSE: 46.59:   8% 98/1190 [53:50<9:42:23, 32.00s/it]\n",
            "719.jpg : actual-predicted:      0,   24.0, error:   24.0. Current MAE: 32.40, RMSE: 46.59:   8% 99/1190 [53:50<9:57:56, 32.88s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([52709, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "904.jpg : actual-predicted:      0,    5.1, error:    5.1. Current MAE: 32.12, RMSE: 46.36:   8% 99/1190 [54:25<9:57:56, 32.88s/it]\n",
            "904.jpg : actual-predicted:      0,    5.1, error:    5.1. Current MAE: 32.12, RMSE: 46.36:   8% 100/1190 [54:25<10:06:13, 33.37s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1184, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "905.jpg : actual-predicted:      0,   24.2, error:   24.2. Current MAE: 32.04, RMSE: 46.20:   8% 100/1190 [54:50<10:06:13, 33.37s/it]\n",
            "905.jpg : actual-predicted:      0,   24.2, error:   24.2. Current MAE: 32.04, RMSE: 46.20:   8% 101/1190 [54:50<9:19:22, 30.82s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([55418, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "906.jpg : actual-predicted:      0,   95.7, error:   95.7. Current MAE: 32.67, RMSE: 46.94:   8% 101/1190 [55:19<9:19:22, 30.82s/it]\n",
            "906.jpg : actual-predicted:      0,   95.7, error:   95.7. Current MAE: 32.67, RMSE: 46.94:   9% 102/1190 [55:19<9:09:46, 30.32s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([6425, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "907.jpg : actual-predicted:      0,   14.4, error:   14.4. Current MAE: 32.49, RMSE: 46.73:   9% 102/1190 [56:07<9:09:46, 30.32s/it]\n",
            "907.jpg : actual-predicted:      0,   14.4, error:   14.4. Current MAE: 32.49, RMSE: 46.73:   9% 103/1190 [56:07<10:45:13, 35.62s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([98522, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "909.jpg : actual-predicted:      0,   32.3, error:   32.3. Current MAE: 32.49, RMSE: 46.61:   9% 103/1190 [56:38<10:45:13, 35.62s/it]\n",
            "909.jpg : actual-predicted:      0,   32.3, error:   32.3. Current MAE: 32.49, RMSE: 46.61:   9% 104/1190 [56:38<10:21:39, 34.35s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([109144, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "910.jpg : actual-predicted:      0,   20.8, error:   20.8. Current MAE: 32.38, RMSE: 46.43:   9% 104/1190 [57:09<10:21:39, 34.35s/it]\n",
            "910.jpg : actual-predicted:      0,   20.8, error:   20.8. Current MAE: 32.38, RMSE: 46.43:   9% 105/1190 [57:09<10:03:53, 33.40s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([118223, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "911.jpg : actual-predicted:      0,   56.2, error:   56.2. Current MAE: 32.60, RMSE: 46.53:   9% 105/1190 [57:41<10:03:53, 33.40s/it]\n",
            "911.jpg : actual-predicted:      0,   56.2, error:   56.2. Current MAE: 32.60, RMSE: 46.53:   9% 106/1190 [57:41<9:52:45, 32.81s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([23214, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "985.jpg : actual-predicted:      0,   81.0, error:   81.0. Current MAE: 33.06, RMSE: 46.97:   9% 106/1190 [58:17<9:52:45, 32.81s/it]\n",
            "985.jpg : actual-predicted:      0,   81.0, error:   81.0. Current MAE: 33.06, RMSE: 46.97:   9% 107/1190 [58:17<10:09:56, 33.79s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([93735, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "988.jpg : actual-predicted:      0,   13.8, error:   13.8. Current MAE: 32.88, RMSE: 46.77:   9% 107/1190 [58:48<10:09:56, 33.79s/it]\n",
            "989.jpg : actual-predicted:      0,   64.4, error:   64.4. Current MAE: 33.17, RMSE: 46.97:   9% 108/1190 [59:51<9:55:49, 33.04s/it]\n",
            "989.jpg : actual-predicted:      0,   64.4, error:   64.4. Current MAE: 33.17, RMSE: 46.97:   9% 109/1190 [59:51<12:37:16, 42.03s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([57117, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "990.jpg : actual-predicted:      0,  109.2, error:  109.2. Current MAE: 33.86, RMSE: 47.90:   9% 109/1190 [1:00:25<12:37:16, 42.03s/it]\n",
            "990.jpg : actual-predicted:      0,  109.2, error:  109.2. Current MAE: 33.86, RMSE: 47.90:   9% 110/1190 [1:00:25<11:49:18, 39.41s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([58360, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "991.jpg : actual-predicted:      0,   98.6, error:   98.6. Current MAE: 34.44, RMSE: 48.59:   9% 110/1190 [1:00:58<11:49:18, 39.41s/it]\n",
            "991.jpg : actual-predicted:      0,   98.6, error:   98.6. Current MAE: 34.44, RMSE: 48.59:   9% 111/1190 [1:00:58<11:14:27, 37.50s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([66339, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "993.jpg : actual-predicted:      0,   15.3, error:   15.3. Current MAE: 34.27, RMSE: 48.40:   9% 111/1190 [1:01:30<11:14:27, 37.50s/it]\n",
            "993.jpg : actual-predicted:      0,   15.3, error:   15.3. Current MAE: 34.27, RMSE: 48.40:   9% 112/1190 [1:01:30<10:44:08, 35.85s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64119, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "995.jpg : actual-predicted:      0,   14.0, error:   14.0. Current MAE: 34.09, RMSE: 48.20:   9% 112/1190 [1:02:02<10:44:08, 35.85s/it]\n",
            "995.jpg : actual-predicted:      0,   14.0, error:   14.0. Current MAE: 34.09, RMSE: 48.20:   9% 113/1190 [1:02:02<10:22:52, 34.70s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([53633, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "996.jpg : actual-predicted:      0,   18.9, error:   18.9. Current MAE: 33.96, RMSE: 48.02:   9% 113/1190 [1:02:32<10:22:52, 34.70s/it]\n",
            "996.jpg : actual-predicted:      0,   18.9, error:   18.9. Current MAE: 33.96, RMSE: 48.02:  10% 114/1190 [1:02:32<10:00:46, 33.50s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([79373, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "998.jpg : actual-predicted:      0,   23.6, error:   23.6. Current MAE: 33.87, RMSE: 47.86:  10% 114/1190 [1:03:04<10:00:46, 33.50s/it]\n",
            "998.jpg : actual-predicted:      0,   23.6, error:   23.6. Current MAE: 33.87, RMSE: 47.86:  10% 115/1190 [1:03:04<9:51:31, 33.02s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([45497, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "999.jpg : actual-predicted:      0,   22.6, error:   22.6. Current MAE: 33.77, RMSE: 47.70:  10% 115/1190 [1:03:29<9:51:31, 33.02s/it]\n",
            "999.jpg : actual-predicted:      0,   22.6, error:   22.6. Current MAE: 33.77, RMSE: 47.70:  10% 116/1190 [1:03:29<9:08:35, 30.65s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([34556, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1050.jpg: actual-predicted:      0,   40.8, error:   40.8. Current MAE: 33.83, RMSE: 47.65:  10% 116/1190 [1:03:58<9:08:35, 30.65s/it]\n",
            "1050.jpg: actual-predicted:      0,   40.8, error:   40.8. Current MAE: 33.83, RMSE: 47.65:  10% 117/1190 [1:03:58<8:58:06, 30.09s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([54563, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1053.jpg: actual-predicted:      0,   68.6, error:   68.6. Current MAE: 34.12, RMSE: 47.86:  10% 117/1190 [1:04:31<8:58:06, 30.09s/it]\n",
            "1053.jpg: actual-predicted:      0,   68.6, error:   68.6. Current MAE: 34.12, RMSE: 47.86:  10% 118/1190 [1:04:31<9:10:51, 30.83s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([91922, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1061.jpg: actual-predicted:      0,    5.3, error:    5.3. Current MAE: 33.88, RMSE: 47.66:  10% 118/1190 [1:04:55<9:10:51, 30.83s/it]\n",
            "1061.jpg: actual-predicted:      0,    5.3, error:    5.3. Current MAE: 33.88, RMSE: 47.66:  10% 119/1190 [1:04:55<8:35:29, 28.88s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([82531, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1106.jpg: actual-predicted:      0,   40.3, error:   40.3. Current MAE: 33.94, RMSE: 47.61:  10% 119/1190 [1:05:19<8:35:29, 28.88s/it]\n",
            "1106.jpg: actual-predicted:      0,   40.3, error:   40.3. Current MAE: 33.94, RMSE: 47.61:  10% 120/1190 [1:05:19<8:11:17, 27.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([94693, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1123.jpg: actual-predicted:      0,  769.3, error:  769.3. Current MAE: 40.01, RMSE: 84.49:  10% 120/1190 [1:05:51<8:11:17, 27.55s/it]\n",
            "1123.jpg: actual-predicted:      0,  769.3, error:  769.3. Current MAE: 40.01, RMSE: 84.49:  10% 121/1190 [1:05:51<8:33:04, 28.80s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([39896, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1130.jpg: actual-predicted:      0,  125.8, error:  125.8. Current MAE: 40.72, RMSE: 84.91:  10% 121/1190 [1:06:15<8:33:04, 28.80s/it]\n",
            "1130.jpg: actual-predicted:      0,  125.8, error:  125.8. Current MAE: 40.72, RMSE: 84.91:  10% 122/1190 [1:06:15<8:06:43, 27.34s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([140658, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1455.jpg: actual-predicted:      0,   54.8, error:   54.8. Current MAE: 40.83, RMSE: 84.71:  10% 122/1190 [1:06:51<8:06:43, 27.34s/it]\n",
            "1455.jpg: actual-predicted:      0,   54.8, error:   54.8. Current MAE: 40.83, RMSE: 84.71:  10% 123/1190 [1:06:51<8:52:59, 29.97s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([82447, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1456.jpg: actual-predicted:      0,  180.3, error:  180.3. Current MAE: 41.96, RMSE: 85.91:  10% 123/1190 [1:07:26<8:52:59, 29.97s/it]\n",
            "1456.jpg: actual-predicted:      0,  180.3, error:  180.3. Current MAE: 41.96, RMSE: 85.91:  10% 124/1190 [1:07:26<9:15:29, 31.27s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([71218, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1458.jpg: actual-predicted:      0,  156.7, error:  156.7. Current MAE: 42.87, RMSE: 86.70:  10% 124/1190 [1:07:50<9:15:29, 31.27s/it]\n",
            "1458.jpg: actual-predicted:      0,  156.7, error:  156.7. Current MAE: 42.87, RMSE: 86.70:  11% 125/1190 [1:07:50<8:38:04, 29.19s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([143124, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1461.jpg: actual-predicted:      0,  104.4, error:  104.4. Current MAE: 43.36, RMSE: 86.86:  11% 125/1190 [1:08:25<8:38:04, 29.19s/it]\n",
            "1461.jpg: actual-predicted:      0,  104.4, error:  104.4. Current MAE: 43.36, RMSE: 86.86:  11% 126/1190 [1:08:25<9:08:05, 30.91s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([15203, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1462.jpg: actual-predicted:      0,  264.8, error:  264.8. Current MAE: 45.11, RMSE: 89.65:  11% 126/1190 [1:08:50<9:08:05, 30.91s/it]\n",
            "1462.jpg: actual-predicted:      0,  264.8, error:  264.8. Current MAE: 45.11, RMSE: 89.65:  11% 127/1190 [1:08:50<8:37:40, 29.22s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([157797, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1463.jpg: actual-predicted:      0,   56.9, error:   56.9. Current MAE: 45.20, RMSE: 89.44:  11% 127/1190 [1:09:33<8:37:40, 29.22s/it]\n",
            "1463.jpg: actual-predicted:      0,   56.9, error:   56.9. Current MAE: 45.20, RMSE: 89.44:  11% 128/1190 [1:09:33<9:52:35, 33.48s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([164065, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1464.jpg: actual-predicted:      0,   70.1, error:   70.1. Current MAE: 45.39, RMSE: 89.30:  11% 128/1190 [1:10:05<9:52:35, 33.48s/it]\n",
            "1464.jpg: actual-predicted:      0,   70.1, error:   70.1. Current MAE: 45.39, RMSE: 89.30:  11% 129/1190 [1:10:05<9:42:50, 32.96s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([200726, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1467.jpg: actual-predicted:      0,   45.5, error:   45.5. Current MAE: 45.39, RMSE: 89.05:  11% 129/1190 [1:10:41<9:42:50, 32.96s/it]\n",
            "1467.jpg: actual-predicted:      0,   45.5, error:   45.5. Current MAE: 45.39, RMSE: 89.05:  11% 130/1190 [1:10:41<9:55:51, 33.73s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([203793, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1493.jpg: actual-predicted:      0,   74.1, error:   74.1. Current MAE: 45.61, RMSE: 88.95:  11% 130/1190 [1:11:23<9:55:51, 33.73s/it]\n",
            "1493.jpg: actual-predicted:      0,   74.1, error:   74.1. Current MAE: 45.61, RMSE: 88.95:  11% 131/1190 [1:11:23<10:40:32, 36.29s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([90948, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1497.jpg: actual-predicted:      0,  147.4, error:  147.4. Current MAE: 46.38, RMSE: 89.53:  11% 131/1190 [1:11:54<10:40:32, 36.29s/it]\n",
            "1497.jpg: actual-predicted:      0,  147.4, error:  147.4. Current MAE: 46.38, RMSE: 89.53:  11% 132/1190 [1:11:54<10:12:20, 34.73s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([195728, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1509.jpg: actual-predicted:      0,   35.7, error:   35.7. Current MAE: 46.30, RMSE: 89.25:  11% 132/1190 [1:12:29<10:12:20, 34.73s/it]\n",
            "1509.jpg: actual-predicted:      0,   35.7, error:   35.7. Current MAE: 46.30, RMSE: 89.25:  11% 133/1190 [1:12:29<10:15:13, 34.92s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([205069, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1537.jpg: actual-predicted:      0,   40.8, error:   40.8. Current MAE: 46.26, RMSE: 88.98:  11% 133/1190 [1:13:15<10:15:13, 34.92s/it]\n",
            "1537.jpg: actual-predicted:      0,   40.8, error:   40.8. Current MAE: 46.26, RMSE: 88.98:  11% 134/1190 [1:13:15<11:11:13, 38.14s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([211965, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1572.jpg: actual-predicted:      0,   38.7, error:   38.7. Current MAE: 46.20, RMSE: 88.72:  11% 134/1190 [1:14:06<11:11:13, 38.14s/it]\n",
            "1572.jpg: actual-predicted:      0,   38.7, error:   38.7. Current MAE: 46.20, RMSE: 88.72:  11% 135/1190 [1:14:06<12:15:30, 41.83s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([132891, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1873.jpg: actual-predicted:      0,   17.7, error:   17.7. Current MAE: 45.99, RMSE: 88.40:  11% 135/1190 [1:14:43<12:15:30, 41.83s/it]\n",
            "1873.jpg: actual-predicted:      0,   17.7, error:   17.7. Current MAE: 45.99, RMSE: 88.40:  11% 136/1190 [1:14:43<11:52:10, 40.54s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([167807, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1874.jpg: actual-predicted:      0,    7.6, error:    7.6. Current MAE: 45.71, RMSE: 88.08:  11% 136/1190 [1:15:37<11:52:10, 40.54s/it]\n",
            "1874.jpg: actual-predicted:      0,    7.6, error:    7.6. Current MAE: 45.71, RMSE: 88.08:  12% 137/1190 [1:15:37<13:00:09, 44.45s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([183049, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1875.jpg: actual-predicted:      0,   34.7, error:   34.7. Current MAE: 45.63, RMSE: 87.81:  12% 137/1190 [1:16:18<13:00:09, 44.45s/it]\n",
            "1875.jpg: actual-predicted:      0,   34.7, error:   34.7. Current MAE: 45.63, RMSE: 87.81:  12% 138/1190 [1:16:18<12:42:37, 43.50s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([117266, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1881.jpg: actual-predicted:      0,   18.2, error:   18.2. Current MAE: 45.44, RMSE: 87.51:  12% 138/1190 [1:16:43<12:42:37, 43.50s/it]\n",
            "1881.jpg: actual-predicted:      0,   18.2, error:   18.2. Current MAE: 45.44, RMSE: 87.51:  12% 139/1190 [1:16:43<11:04:32, 37.94s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([133630, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1884.jpg: actual-predicted:      0,   15.3, error:   15.3. Current MAE: 45.22, RMSE: 87.21:  12% 139/1190 [1:17:16<11:04:32, 37.94s/it]\n",
            "1884.jpg: actual-predicted:      0,   15.3, error:   15.3. Current MAE: 45.22, RMSE: 87.21:  12% 140/1190 [1:17:16<10:37:11, 36.41s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([169655, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1886.jpg: actual-predicted:      0,   16.6, error:   16.6. Current MAE: 45.02, RMSE: 86.91:  12% 140/1190 [1:17:57<10:37:11, 36.41s/it]\n",
            "1886.jpg: actual-predicted:      0,   16.6, error:   16.6. Current MAE: 45.02, RMSE: 86.91:  12% 141/1190 [1:17:57<11:01:15, 37.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([142279, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1887.jpg: actual-predicted:      0,   12.0, error:   12.0. Current MAE: 44.79, RMSE: 86.61:  12% 141/1190 [1:18:30<11:01:15, 37.82s/it]\n",
            "1887.jpg: actual-predicted:      0,   12.0, error:   12.0. Current MAE: 44.79, RMSE: 86.61:  12% 142/1190 [1:18:30<10:34:07, 36.30s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([150962, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1888.jpg: actual-predicted:      0,   15.9, error:   15.9. Current MAE: 44.58, RMSE: 86.31:  12% 142/1190 [1:19:01<10:34:07, 36.30s/it]\n",
            "1888.jpg: actual-predicted:      0,   15.9, error:   15.9. Current MAE: 44.58, RMSE: 86.31:  12% 143/1190 [1:19:01<10:07:47, 34.83s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([173238, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "1889.jpg: actual-predicted:      0,   22.2, error:   22.2. Current MAE: 44.43, RMSE: 86.03:  12% 143/1190 [1:19:42<10:07:47, 34.83s/it]\n",
            "2004.jpg: actual-predicted:      0,  270.6, error:  270.6. Current MAE: 45.99, RMSE: 88.63:  12% 144/1190 [1:20:16<10:39:35, 36.69s/it]\n",
            "2004.jpg: actual-predicted:      0,  270.6, error:  270.6. Current MAE: 45.99, RMSE: 88.63:  12% 145/1190 [1:20:16<10:23:25, 35.80s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([31432, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2005.jpg: actual-predicted:      0,  165.6, error:  165.6. Current MAE: 46.81, RMSE: 89.38:  12% 145/1190 [1:20:54<10:23:25, 35.80s/it]\n",
            "2005.jpg: actual-predicted:      0,  165.6, error:  165.6. Current MAE: 46.81, RMSE: 89.38:  12% 146/1190 [1:20:54<10:33:22, 36.40s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([16132, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2007.jpg: actual-predicted:      0,   89.6, error:   89.6. Current MAE: 47.10, RMSE: 89.38:  12% 146/1190 [1:21:25<10:33:22, 36.40s/it]\n",
            "2007.jpg: actual-predicted:      0,   89.6, error:   89.6. Current MAE: 47.10, RMSE: 89.38:  12% 147/1190 [1:21:25<10:04:56, 34.80s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([56562, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2008.jpg: actual-predicted:      0,   46.0, error:   46.0. Current MAE: 47.09, RMSE: 89.16:  12% 147/1190 [1:22:00<10:04:56, 34.80s/it]\n",
            "2008.jpg: actual-predicted:      0,   46.0, error:   46.0. Current MAE: 47.09, RMSE: 89.16:  12% 148/1190 [1:22:00<10:08:36, 35.04s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([9399, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2009.jpg: actual-predicted:      0,  225.7, error:  225.7. Current MAE: 48.29, RMSE: 90.77:  12% 148/1190 [1:22:34<10:08:36, 35.04s/it]\n",
            "2009.jpg: actual-predicted:      0,  225.7, error:  225.7. Current MAE: 48.29, RMSE: 90.77:  13% 149/1190 [1:22:34<9:59:32, 34.56s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([154116, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2010.jpg: actual-predicted:      0,   20.7, error:   20.7. Current MAE: 48.11, RMSE: 90.48:  13% 149/1190 [1:23:06<9:59:32, 34.56s/it]\n",
            "2010.jpg: actual-predicted:      0,   20.7, error:   20.7. Current MAE: 48.11, RMSE: 90.48:  13% 150/1190 [1:23:06<9:47:00, 33.87s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([15617, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2011.jpg: actual-predicted:      0,   77.2, error:   77.2. Current MAE: 48.30, RMSE: 90.40:  13% 150/1190 [1:23:37<9:47:00, 33.87s/it]\n",
            "2011.jpg: actual-predicted:      0,   77.2, error:   77.2. Current MAE: 48.30, RMSE: 90.40:  13% 151/1190 [1:23:37<9:32:03, 33.04s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([4495, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2012.jpg: actual-predicted:      0,   40.3, error:   40.3. Current MAE: 48.25, RMSE: 90.16:  13% 151/1190 [1:24:02<9:32:03, 33.04s/it]\n",
            "2012.jpg: actual-predicted:      0,   40.3, error:   40.3. Current MAE: 48.25, RMSE: 90.16:  13% 152/1190 [1:24:02<8:50:42, 30.68s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([77510, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2013.jpg: actual-predicted:      0,   27.1, error:   27.1. Current MAE: 48.11, RMSE: 89.89:  13% 152/1190 [1:24:28<8:50:42, 30.68s/it]\n",
            "2013.jpg: actual-predicted:      0,   27.1, error:   27.1. Current MAE: 48.11, RMSE: 89.89:  13% 153/1190 [1:24:28<8:26:40, 29.32s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([118290, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2014.jpg: actual-predicted:      0,   12.3, error:   12.3. Current MAE: 47.87, RMSE: 89.60:  13% 153/1190 [1:25:03<8:26:40, 29.32s/it]\n",
            "2014.jpg: actual-predicted:      0,   12.3, error:   12.3. Current MAE: 47.87, RMSE: 89.60:  13% 154/1190 [1:25:03<8:56:19, 31.06s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([13117, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2015.jpg: actual-predicted:      0,   20.2, error:   20.2. Current MAE: 47.70, RMSE: 89.33:  13% 154/1190 [1:25:43<8:56:19, 31.06s/it]\n",
            "2015.jpg: actual-predicted:      0,   20.2, error:   20.2. Current MAE: 47.70, RMSE: 89.33:  13% 155/1190 [1:25:43<9:38:49, 33.56s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([158670, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2016.jpg: actual-predicted:      0,   31.6, error:   31.6. Current MAE: 47.59, RMSE: 89.08:  13% 155/1190 [1:26:26<9:38:49, 33.56s/it]\n",
            "2016.jpg: actual-predicted:      0,   31.6, error:   31.6. Current MAE: 47.59, RMSE: 89.08:  13% 156/1190 [1:26:26<10:28:58, 36.50s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([16410, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2017.jpg: actual-predicted:      0,   80.3, error:   80.3. Current MAE: 47.80, RMSE: 89.02:  13% 156/1190 [1:26:57<10:28:58, 36.50s/it]\n",
            "2017.jpg: actual-predicted:      0,   80.3, error:   80.3. Current MAE: 47.80, RMSE: 89.02:  13% 157/1190 [1:26:57<10:00:55, 34.90s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([5301, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2018.jpg: actual-predicted:      0,   38.4, error:   38.4. Current MAE: 47.74, RMSE: 88.80:  13% 157/1190 [1:27:23<10:00:55, 34.90s/it]\n",
            "2018.jpg: actual-predicted:      0,   38.4, error:   38.4. Current MAE: 47.74, RMSE: 88.80:  13% 158/1190 [1:27:23<9:11:15, 32.05s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([18220, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2019.jpg: actual-predicted:      0,   16.1, error:   16.1. Current MAE: 47.54, RMSE: 88.52:  13% 158/1190 [1:27:54<9:11:15, 32.05s/it]\n",
            "2019.jpg: actual-predicted:      0,   16.1, error:   16.1. Current MAE: 47.54, RMSE: 88.52:  13% 159/1190 [1:27:54<9:06:56, 31.83s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([56367, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2020.jpg: actual-predicted:      0,   25.7, error:   25.7. Current MAE: 47.41, RMSE: 88.27:  13% 159/1190 [1:28:20<9:06:56, 31.83s/it]\n",
            "2020.jpg: actual-predicted:      0,   25.7, error:   25.7. Current MAE: 47.41, RMSE: 88.27:  13% 160/1190 [1:28:20<8:34:38, 29.98s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([27055, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2021.jpg: actual-predicted:      0,   30.3, error:   30.3. Current MAE: 47.30, RMSE: 88.03:  13% 160/1190 [1:28:55<8:34:38, 29.98s/it]\n",
            "2021.jpg: actual-predicted:      0,   30.3, error:   30.3. Current MAE: 47.30, RMSE: 88.03:  14% 161/1190 [1:28:55<9:01:05, 31.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([30606, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2025.jpg: actual-predicted:      0,   54.8, error:   54.8. Current MAE: 47.35, RMSE: 87.86:  14% 161/1190 [1:29:20<9:01:05, 31.55s/it]\n",
            "2025.jpg: actual-predicted:      0,   54.8, error:   54.8. Current MAE: 47.35, RMSE: 87.86:  14% 162/1190 [1:29:20<8:28:25, 29.67s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([94590, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2026.jpg: actual-predicted:      0,   20.2, error:   20.2. Current MAE: 47.18, RMSE: 87.61:  14% 162/1190 [1:29:55<8:28:25, 29.67s/it]\n",
            "2026.jpg: actual-predicted:      0,   20.2, error:   20.2. Current MAE: 47.18, RMSE: 87.61:  14% 163/1190 [1:29:55<8:52:22, 31.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([25307, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2027.jpg: actual-predicted:      0,   33.4, error:   33.4. Current MAE: 47.10, RMSE: 87.38:  14% 163/1190 [1:30:28<8:52:22, 31.10s/it]\n",
            "2027.jpg: actual-predicted:      0,   33.4, error:   33.4. Current MAE: 47.10, RMSE: 87.38:  14% 164/1190 [1:30:28<9:04:17, 31.83s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([42408, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2028.jpg: actual-predicted:      0,   15.3, error:   15.3. Current MAE: 46.90, RMSE: 87.12:  14% 164/1190 [1:31:04<9:04:17, 31.83s/it]\n",
            "2028.jpg: actual-predicted:      0,   15.3, error:   15.3. Current MAE: 46.90, RMSE: 87.12:  14% 165/1190 [1:31:04<9:22:54, 32.95s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([25811, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2029.jpg: actual-predicted:      0,   76.4, error:   76.4. Current MAE: 47.08, RMSE: 87.06:  14% 165/1190 [1:31:35<9:22:54, 32.95s/it]\n",
            "2029.jpg: actual-predicted:      0,   76.4, error:   76.4. Current MAE: 47.08, RMSE: 87.06:  14% 166/1190 [1:31:35<9:13:40, 32.44s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17264, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2030.jpg: actual-predicted:      0,   21.5, error:   21.5. Current MAE: 46.93, RMSE: 86.82:  14% 166/1190 [1:32:07<9:13:40, 32.44s/it]\n",
            "2030.jpg: actual-predicted:      0,   21.5, error:   21.5. Current MAE: 46.93, RMSE: 86.82:  14% 167/1190 [1:32:07<9:08:29, 32.17s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([62895, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2031.jpg: actual-predicted:      0,   17.0, error:   17.0. Current MAE: 46.75, RMSE: 86.57:  14% 167/1190 [1:32:38<9:08:29, 32.17s/it]\n",
            "2031.jpg: actual-predicted:      0,   17.0, error:   17.0. Current MAE: 46.75, RMSE: 86.57:  14% 168/1190 [1:32:38<9:05:55, 32.05s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([14664, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2032.jpg: actual-predicted:      0,   14.8, error:   14.8. Current MAE: 46.56, RMSE: 86.32:  14% 168/1190 [1:33:03<9:05:55, 32.05s/it]\n",
            "2032.jpg: actual-predicted:      0,   14.8, error:   14.8. Current MAE: 46.56, RMSE: 86.32:  14% 169/1190 [1:33:03<8:29:10, 29.92s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([42064, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2033.jpg: actual-predicted:      0,   27.1, error:   27.1. Current MAE: 46.45, RMSE: 86.09:  14% 169/1190 [1:33:41<8:29:10, 29.92s/it]\n",
            "2033.jpg: actual-predicted:      0,   27.1, error:   27.1. Current MAE: 46.45, RMSE: 86.09:  14% 170/1190 [1:33:41<9:06:41, 32.16s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([22801, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2035.jpg: actual-predicted:      0,   37.0, error:   37.0. Current MAE: 46.39, RMSE: 85.88:  14% 170/1190 [1:34:05<9:06:41, 32.16s/it]\n",
            "2035.jpg: actual-predicted:      0,   37.0, error:   37.0. Current MAE: 46.39, RMSE: 85.88:  14% 171/1190 [1:34:05<8:27:30, 29.88s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([18883, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2036.jpg: actual-predicted:      0,   33.1, error:   33.1. Current MAE: 46.31, RMSE: 85.67:  14% 171/1190 [1:34:37<8:27:30, 29.88s/it]\n",
            "2036.jpg: actual-predicted:      0,   33.1, error:   33.1. Current MAE: 46.31, RMSE: 85.67:  14% 172/1190 [1:34:37<8:38:27, 30.56s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([12719, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2037.jpg: actual-predicted:      0,  119.2, error:  119.2. Current MAE: 46.73, RMSE: 85.90:  14% 172/1190 [1:35:09<8:38:27, 30.56s/it]\n",
            "2037.jpg: actual-predicted:      0,  119.2, error:  119.2. Current MAE: 46.73, RMSE: 85.90:  15% 173/1190 [1:35:09<8:40:52, 30.73s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([8791, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2038.jpg: actual-predicted:      0,  226.5, error:  226.5. Current MAE: 47.77, RMSE: 87.36:  15% 173/1190 [1:35:42<8:40:52, 30.73s/it]\n",
            "2038.jpg: actual-predicted:      0,  226.5, error:  226.5. Current MAE: 47.77, RMSE: 87.36:  15% 174/1190 [1:35:42<8:54:16, 31.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([5349, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2039.jpg: actual-predicted:      0,   69.3, error:   69.3. Current MAE: 47.89, RMSE: 87.27:  15% 174/1190 [1:36:15<8:54:16, 31.55s/it]\n",
            "2039.jpg: actual-predicted:      0,   69.3, error:   69.3. Current MAE: 47.89, RMSE: 87.27:  15% 175/1190 [1:36:15<9:03:30, 32.13s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([28132, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2040.jpg: actual-predicted:      0,   22.0, error:   22.0. Current MAE: 47.74, RMSE: 87.03:  15% 175/1190 [1:36:55<9:03:30, 32.13s/it]\n",
            "2040.jpg: actual-predicted:      0,   22.0, error:   22.0. Current MAE: 47.74, RMSE: 87.03:  15% 176/1190 [1:36:55<9:40:59, 34.38s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([20411, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2041.jpg: actual-predicted:      0,   60.1, error:   60.1. Current MAE: 47.81, RMSE: 86.91:  15% 176/1190 [1:37:28<9:40:59, 34.38s/it]\n",
            "2041.jpg: actual-predicted:      0,   60.1, error:   60.1. Current MAE: 47.81, RMSE: 86.91:  15% 177/1190 [1:37:28<9:35:21, 34.08s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([120803, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2042.jpg: actual-predicted:      0,   46.0, error:   46.0. Current MAE: 47.80, RMSE: 86.73:  15% 177/1190 [1:38:06<9:35:21, 34.08s/it]\n",
            "2043.jpg: actual-predicted:      0,   77.6, error:   77.6. Current MAE: 47.97, RMSE: 86.68:  15% 178/1190 [1:38:36<9:52:32, 35.13s/it]\n",
            "2043.jpg: actual-predicted:      0,   77.6, error:   77.6. Current MAE: 47.97, RMSE: 86.68:  15% 179/1190 [1:38:36<9:25:38, 33.57s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([19493, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2044.jpg: actual-predicted:      0,   24.2, error:   24.2. Current MAE: 47.84, RMSE: 86.46:  15% 179/1190 [1:39:01<9:25:38, 33.57s/it]\n",
            "2044.jpg: actual-predicted:      0,   24.2, error:   24.2. Current MAE: 47.84, RMSE: 86.46:  15% 180/1190 [1:39:01<8:43:14, 31.08s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([107115, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2045.jpg: actual-predicted:      0,   13.1, error:   13.1. Current MAE: 47.65, RMSE: 86.23:  15% 180/1190 [1:39:34<8:43:14, 31.08s/it]\n",
            "2045.jpg: actual-predicted:      0,   13.1, error:   13.1. Current MAE: 47.65, RMSE: 86.23:  15% 181/1190 [1:39:34<8:49:42, 31.50s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([49934, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2046.jpg: actual-predicted:      0,   16.5, error:   16.5. Current MAE: 47.47, RMSE: 86.00:  15% 181/1190 [1:40:09<8:49:42, 31.50s/it]\n",
            "2046.jpg: actual-predicted:      0,   16.5, error:   16.5. Current MAE: 47.47, RMSE: 86.00:  15% 182/1190 [1:40:09<9:08:23, 32.64s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([111924, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2047.jpg: actual-predicted:      0,   25.3, error:   25.3. Current MAE: 47.35, RMSE: 85.78:  15% 182/1190 [1:40:35<9:08:23, 32.64s/it]\n",
            "2047.jpg: actual-predicted:      0,   25.3, error:   25.3. Current MAE: 47.35, RMSE: 85.78:  15% 183/1190 [1:40:35<8:34:55, 30.68s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([63273, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2048.jpg: actual-predicted:      0,   36.4, error:   36.4. Current MAE: 47.29, RMSE: 85.59:  15% 183/1190 [1:41:12<8:34:55, 30.68s/it]\n",
            "2048.jpg: actual-predicted:      0,   36.4, error:   36.4. Current MAE: 47.29, RMSE: 85.59:  15% 184/1190 [1:41:12<9:04:44, 32.49s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([9636, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2049.jpg: actual-predicted:      0,   96.4, error:   96.4. Current MAE: 47.56, RMSE: 85.65:  15% 184/1190 [1:41:37<9:04:44, 32.49s/it]\n",
            "2049.jpg: actual-predicted:      0,   96.4, error:   96.4. Current MAE: 47.56, RMSE: 85.65:  16% 185/1190 [1:41:37<8:26:23, 30.23s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([104049, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2051.jpg: actual-predicted:      0,   16.0, error:   16.0. Current MAE: 47.39, RMSE: 85.43:  16% 185/1190 [1:42:06<8:26:23, 30.23s/it]\n",
            "2051.jpg: actual-predicted:      0,   16.0, error:   16.0. Current MAE: 47.39, RMSE: 85.43:  16% 186/1190 [1:42:06<8:19:24, 29.85s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([79937, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2052.jpg: actual-predicted:      0,   10.4, error:   10.4. Current MAE: 47.19, RMSE: 85.20:  16% 186/1190 [1:42:30<8:19:24, 29.85s/it]\n",
            "2052.jpg: actual-predicted:      0,   10.4, error:   10.4. Current MAE: 47.19, RMSE: 85.20:  16% 187/1190 [1:42:30<7:50:22, 28.14s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([165206, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2053.jpg: actual-predicted:      0,   46.9, error:   46.9. Current MAE: 47.19, RMSE: 85.05:  16% 187/1190 [1:43:09<7:50:22, 28.14s/it]\n",
            "2053.jpg: actual-predicted:      0,   46.9, error:   46.9. Current MAE: 47.19, RMSE: 85.05:  16% 188/1190 [1:43:09<8:45:51, 31.49s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17442, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2054.jpg: actual-predicted:      0,   21.2, error:   21.2. Current MAE: 47.05, RMSE: 84.84:  16% 188/1190 [1:43:41<8:45:51, 31.49s/it]\n",
            "2054.jpg: actual-predicted:      0,   21.2, error:   21.2. Current MAE: 47.05, RMSE: 84.84:  16% 189/1190 [1:43:41<8:44:44, 31.45s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([44034, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2138.jpg: actual-predicted:      0,   34.1, error:   34.1. Current MAE: 46.98, RMSE: 84.65:  16% 189/1190 [1:44:12<8:44:44, 31.45s/it]\n",
            "2138.jpg: actual-predicted:      0,   34.1, error:   34.1. Current MAE: 46.98, RMSE: 84.65:  16% 190/1190 [1:44:12<8:45:29, 31.53s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([148532, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2139.jpg: actual-predicted:      0,   29.8, error:   29.8. Current MAE: 46.89, RMSE: 84.45:  16% 190/1190 [1:44:47<8:45:29, 31.53s/it]\n",
            "2139.jpg: actual-predicted:      0,   29.8, error:   29.8. Current MAE: 46.89, RMSE: 84.45:  16% 191/1190 [1:44:47<9:02:33, 32.59s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([54480, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2140.jpg: actual-predicted:      0,   16.3, error:   16.3. Current MAE: 46.74, RMSE: 84.24:  16% 191/1190 [1:45:13<9:02:33, 32.59s/it]\n",
            "2140.jpg: actual-predicted:      0,   16.3, error:   16.3. Current MAE: 46.74, RMSE: 84.24:  16% 192/1190 [1:45:13<8:28:11, 30.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([73364, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2141.jpg: actual-predicted:      0,    9.4, error:    9.4. Current MAE: 46.54, RMSE: 84.03:  16% 192/1190 [1:45:46<8:28:11, 30.55s/it]\n",
            "2142.jpg: actual-predicted:      0,   22.7, error:   22.7. Current MAE: 46.42, RMSE: 83.82:  16% 193/1190 [1:46:19<8:37:47, 31.16s/it]\n",
            "2142.jpg: actual-predicted:      0,   22.7, error:   22.7. Current MAE: 46.42, RMSE: 83.82:  16% 194/1190 [1:46:19<8:47:01, 31.75s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([129370, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2143.jpg: actual-predicted:      0,   19.2, error:   19.2. Current MAE: 46.28, RMSE: 83.62:  16% 194/1190 [1:46:45<8:47:01, 31.75s/it]\n",
            "2143.jpg: actual-predicted:      0,   19.2, error:   19.2. Current MAE: 46.28, RMSE: 83.62:  16% 195/1190 [1:46:45<8:19:57, 30.15s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([168107, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2145.jpg: actual-predicted:      0,   11.8, error:   11.8. Current MAE: 46.10, RMSE: 83.41:  16% 195/1190 [1:47:18<8:19:57, 30.15s/it]\n",
            "2145.jpg: actual-predicted:      0,   11.8, error:   11.8. Current MAE: 46.10, RMSE: 83.41:  16% 196/1190 [1:47:18<8:32:19, 30.92s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([8538, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2146.jpg: actual-predicted:      0,   14.0, error:   14.0. Current MAE: 45.94, RMSE: 83.21:  16% 196/1190 [1:47:43<8:32:19, 30.92s/it]\n",
            "2146.jpg: actual-predicted:      0,   14.0, error:   14.0. Current MAE: 45.94, RMSE: 83.21:  17% 197/1190 [1:47:43<8:02:56, 29.18s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([13437, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2147.jpg: actual-predicted:      0,   13.3, error:   13.3. Current MAE: 45.78, RMSE: 83.00:  17% 197/1190 [1:48:12<8:02:56, 29.18s/it]\n",
            "2147.jpg: actual-predicted:      0,   13.3, error:   13.3. Current MAE: 45.78, RMSE: 83.00:  17% 198/1190 [1:48:12<7:59:09, 28.98s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([63210, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2150.jpg: actual-predicted:      0,   10.0, error:   10.0. Current MAE: 45.60, RMSE: 82.79:  17% 198/1190 [1:48:47<7:59:09, 28.98s/it]\n",
            "2150.jpg: actual-predicted:      0,   10.0, error:   10.0. Current MAE: 45.60, RMSE: 82.79:  17% 199/1190 [1:48:47<8:27:51, 30.75s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([112764, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2151.jpg: actual-predicted:      0,    9.7, error:    9.7. Current MAE: 45.42, RMSE: 82.59:  17% 199/1190 [1:49:18<8:27:51, 30.75s/it]\n",
            "2151.jpg: actual-predicted:      0,    9.7, error:    9.7. Current MAE: 45.42, RMSE: 82.59:  17% 200/1190 [1:49:18<8:32:17, 31.05s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([53304, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2152.jpg: actual-predicted:      0,    9.8, error:    9.8. Current MAE: 45.24, RMSE: 82.39:  17% 200/1190 [1:49:57<8:32:17, 31.05s/it]\n",
            "2152.jpg: actual-predicted:      0,    9.8, error:    9.8. Current MAE: 45.24, RMSE: 82.39:  17% 201/1190 [1:49:57<9:10:59, 33.43s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([95186, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2153.jpg: actual-predicted:      0,   16.0, error:   16.0. Current MAE: 45.10, RMSE: 82.19:  17% 201/1190 [1:50:23<9:10:59, 33.43s/it]\n",
            "2153.jpg: actual-predicted:      0,   16.0, error:   16.0. Current MAE: 45.10, RMSE: 82.19:  17% 202/1190 [1:50:23<8:32:16, 31.11s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([10089, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2155.jpg: actual-predicted:      0,   15.5, error:   15.5. Current MAE: 44.95, RMSE: 82.00:  17% 202/1190 [1:50:48<8:32:16, 31.11s/it]\n",
            "2156.jpg: actual-predicted:      0,   40.5, error:   40.5. Current MAE: 44.93, RMSE: 81.84:  17% 203/1190 [1:51:12<8:02:30, 29.33s/it]\n",
            "2156.jpg: actual-predicted:      0,   40.5, error:   40.5. Current MAE: 44.93, RMSE: 81.84:  17% 204/1190 [1:51:12<7:37:34, 27.84s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([77805, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2157.jpg: actual-predicted:      0,   82.7, error:   82.7. Current MAE: 45.11, RMSE: 81.85:  17% 204/1190 [1:51:47<7:37:34, 27.84s/it]\n",
            "2157.jpg: actual-predicted:      0,   82.7, error:   82.7. Current MAE: 45.11, RMSE: 81.85:  17% 205/1190 [1:51:47<8:07:55, 29.72s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([16080, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2159.jpg: actual-predicted:      0,  180.1, error:  180.1. Current MAE: 45.77, RMSE: 82.61:  17% 205/1190 [1:52:10<8:07:55, 29.72s/it]\n",
            "2159.jpg: actual-predicted:      0,  180.1, error:  180.1. Current MAE: 45.77, RMSE: 82.61:  17% 206/1190 [1:52:10<7:38:05, 27.93s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([74787, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2162.jpg: actual-predicted:      0,   24.2, error:   24.2. Current MAE: 45.66, RMSE: 82.42:  17% 206/1190 [1:52:35<7:38:05, 27.93s/it]\n",
            "2162.jpg: actual-predicted:      0,   24.2, error:   24.2. Current MAE: 45.66, RMSE: 82.42:  17% 207/1190 [1:52:35<7:19:33, 26.83s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([125087, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2163.jpg: actual-predicted:      0,    6.6, error:    6.6. Current MAE: 45.48, RMSE: 82.23:  17% 207/1190 [1:53:07<7:19:33, 26.83s/it]\n",
            "2163.jpg: actual-predicted:      0,    6.6, error:    6.6. Current MAE: 45.48, RMSE: 82.23:  17% 208/1190 [1:53:07<7:48:12, 28.61s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([15394, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2164.jpg: actual-predicted:      0,    9.8, error:    9.8. Current MAE: 45.30, RMSE: 82.03:  17% 208/1190 [1:53:50<7:48:12, 28.61s/it]\n",
            "2164.jpg: actual-predicted:      0,    9.8, error:    9.8. Current MAE: 45.30, RMSE: 82.03:  18% 209/1190 [1:53:50<8:57:10, 32.85s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([14185, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2165.jpg: actual-predicted:      0,   16.1, error:   16.1. Current MAE: 45.17, RMSE: 81.85:  18% 209/1190 [1:54:18<8:57:10, 32.85s/it]\n",
            "2165.jpg: actual-predicted:      0,   16.1, error:   16.1. Current MAE: 45.17, RMSE: 81.85:  18% 210/1190 [1:54:18<8:33:52, 31.46s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([125123, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2166.jpg: actual-predicted:      0,   84.5, error:   84.5. Current MAE: 45.35, RMSE: 81.86:  18% 210/1190 [1:54:53<8:33:52, 31.46s/it]\n",
            "2166.jpg: actual-predicted:      0,   84.5, error:   84.5. Current MAE: 45.35, RMSE: 81.86:  18% 211/1190 [1:54:53<8:50:17, 32.50s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([49905, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2168.jpg: actual-predicted:      0,   45.0, error:   45.0. Current MAE: 45.35, RMSE: 81.72:  18% 211/1190 [1:55:17<8:50:17, 32.50s/it]\n",
            "2168.jpg: actual-predicted:      0,   45.0, error:   45.0. Current MAE: 45.35, RMSE: 81.72:  18% 212/1190 [1:55:17<8:08:08, 29.95s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([143406, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2170.jpg: actual-predicted:      0,   55.3, error:   55.3. Current MAE: 45.40, RMSE: 81.62:  18% 212/1190 [1:56:01<8:08:08, 29.95s/it]\n",
            "2170.jpg: actual-predicted:      0,   55.3, error:   55.3. Current MAE: 45.40, RMSE: 81.62:  18% 213/1190 [1:56:01<9:13:09, 33.97s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([63516, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2171.jpg: actual-predicted:      0,   20.6, error:   20.6. Current MAE: 45.28, RMSE: 81.44:  18% 213/1190 [1:56:26<9:13:09, 33.97s/it]\n",
            "2171.jpg: actual-predicted:      0,   20.6, error:   20.6. Current MAE: 45.28, RMSE: 81.44:  18% 214/1190 [1:56:26<8:31:55, 31.47s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([121808, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2172.jpg: actual-predicted:      0,   45.3, error:   45.3. Current MAE: 45.28, RMSE: 81.31:  18% 214/1190 [1:56:51<8:31:55, 31.47s/it]\n",
            "2172.jpg: actual-predicted:      0,   45.3, error:   45.3. Current MAE: 45.28, RMSE: 81.31:  18% 215/1190 [1:56:51<7:57:41, 29.40s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([113616, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2173.jpg: actual-predicted:      0,  107.8, error:  107.8. Current MAE: 45.57, RMSE: 81.45:  18% 215/1190 [1:57:24<7:57:41, 29.40s/it]\n",
            "2173.jpg: actual-predicted:      0,  107.8, error:  107.8. Current MAE: 45.57, RMSE: 81.45:  18% 216/1190 [1:57:24<8:17:23, 30.64s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([18745, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2174.jpg: actual-predicted:      0,   16.0, error:   16.0. Current MAE: 45.43, RMSE: 81.27:  18% 216/1190 [1:57:56<8:17:23, 30.64s/it]\n",
            "2174.jpg: actual-predicted:      0,   16.0, error:   16.0. Current MAE: 45.43, RMSE: 81.27:  18% 217/1190 [1:57:56<8:21:05, 30.90s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([96930, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2175.jpg: actual-predicted:      0,   29.9, error:   29.9. Current MAE: 45.36, RMSE: 81.11:  18% 217/1190 [1:58:32<8:21:05, 30.90s/it]\n",
            "2175.jpg: actual-predicted:      0,   29.9, error:   29.9. Current MAE: 45.36, RMSE: 81.11:  18% 218/1190 [1:58:32<8:46:47, 32.52s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([76372, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2176.jpg: actual-predicted:      0,   46.2, error:   46.2. Current MAE: 45.37, RMSE: 80.99:  18% 218/1190 [1:58:58<8:46:47, 32.52s/it]\n",
            "2177.jpg: actual-predicted:      0,   15.0, error:   15.0. Current MAE: 45.23, RMSE: 80.81:  18% 219/1190 [1:59:32<8:14:04, 30.53s/it]\n",
            "2177.jpg: actual-predicted:      0,   15.0, error:   15.0. Current MAE: 45.23, RMSE: 80.81:  18% 220/1190 [1:59:32<8:31:22, 31.63s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([162457, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2178.jpg: actual-predicted:      0,   13.7, error:   13.7. Current MAE: 45.09, RMSE: 80.63:  18% 220/1190 [2:00:09<8:31:22, 31.63s/it]\n",
            "2178.jpg: actual-predicted:      0,   13.7, error:   13.7. Current MAE: 45.09, RMSE: 80.63:  19% 221/1190 [2:00:09<8:55:39, 33.17s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([94971, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2179.jpg: actual-predicted:      0,   11.3, error:   11.3. Current MAE: 44.93, RMSE: 80.45:  19% 221/1190 [2:00:42<8:55:39, 33.17s/it]\n",
            "2180.jpg: actual-predicted:      0,  176.5, error:  176.5. Current MAE: 45.52, RMSE: 81.14:  19% 222/1190 [2:01:14<8:52:08, 32.98s/it]\n",
            "2180.jpg: actual-predicted:      0,  176.5, error:  176.5. Current MAE: 45.52, RMSE: 81.14:  19% 223/1190 [2:01:14<8:50:31, 32.92s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([106887, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2181.jpg: actual-predicted:      0,   14.2, error:   14.2. Current MAE: 45.38, RMSE: 80.96:  19% 223/1190 [2:01:39<8:50:31, 32.92s/it]\n",
            "2181.jpg: actual-predicted:      0,   14.2, error:   14.2. Current MAE: 45.38, RMSE: 80.96:  19% 224/1190 [2:01:39<8:09:08, 30.38s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([55570, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2182.jpg: actual-predicted:      0,   16.4, error:   16.4. Current MAE: 45.26, RMSE: 80.79:  19% 224/1190 [2:02:11<8:09:08, 30.38s/it]\n",
            "2182.jpg: actual-predicted:      0,   16.4, error:   16.4. Current MAE: 45.26, RMSE: 80.79:  19% 225/1190 [2:02:11<8:15:10, 30.79s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([192098, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2184.jpg: actual-predicted:      0,   25.4, error:   25.4. Current MAE: 45.17, RMSE: 80.63:  19% 225/1190 [2:02:45<8:15:10, 30.79s/it]\n",
            "2184.jpg: actual-predicted:      0,   25.4, error:   25.4. Current MAE: 45.17, RMSE: 80.63:  19% 226/1190 [2:02:45<8:32:50, 31.92s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([56611, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2189.jpg: actual-predicted:      0,    3.2, error:    3.2. Current MAE: 44.98, RMSE: 80.45:  19% 226/1190 [2:03:11<8:32:50, 31.92s/it]\n",
            "2189.jpg: actual-predicted:      0,    3.2, error:    3.2. Current MAE: 44.98, RMSE: 80.45:  19% 227/1190 [2:03:11<8:05:20, 30.24s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([15388, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2190.jpg: actual-predicted:      0,   13.0, error:   13.0. Current MAE: 44.84, RMSE: 80.28:  19% 227/1190 [2:03:44<8:05:20, 30.24s/it]\n",
            "2191.jpg: actual-predicted:      0,   14.0, error:   14.0. Current MAE: 44.71, RMSE: 80.11:  19% 228/1190 [2:04:24<8:18:27, 31.09s/it]\n",
            "2191.jpg: actual-predicted:      0,   14.0, error:   14.0. Current MAE: 44.71, RMSE: 80.11:  19% 229/1190 [2:04:24<8:56:33, 33.50s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17896, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2192.jpg: actual-predicted:      0,    9.8, error:    9.8. Current MAE: 44.56, RMSE: 79.93:  19% 229/1190 [2:04:56<8:56:33, 33.50s/it]\n",
            "2193.jpg: actual-predicted:      0,   31.7, error:   31.7. Current MAE: 44.50, RMSE: 79.79:  19% 230/1190 [2:05:26<8:51:21, 33.21s/it]\n",
            "2193.jpg: actual-predicted:      0,   31.7, error:   31.7. Current MAE: 44.50, RMSE: 79.79:  19% 231/1190 [2:05:26<8:34:57, 32.22s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([147612, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2194.jpg: actual-predicted:      0,   54.2, error:   54.2. Current MAE: 44.54, RMSE: 79.70:  19% 231/1190 [2:06:01<8:34:57, 32.22s/it]\n",
            "2194.jpg: actual-predicted:      0,   54.2, error:   54.2. Current MAE: 44.54, RMSE: 79.70:  19% 232/1190 [2:06:01<8:46:49, 32.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([25539, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2195.jpg: actual-predicted:      0,    9.6, error:    9.6. Current MAE: 44.39, RMSE: 79.53:  19% 232/1190 [2:06:37<8:46:49, 32.99s/it]\n",
            "2195.jpg: actual-predicted:      0,    9.6, error:    9.6. Current MAE: 44.39, RMSE: 79.53:  20% 233/1190 [2:06:37<9:03:30, 34.08s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17292, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2197.jpg: actual-predicted:      0,   55.1, error:   55.1. Current MAE: 44.44, RMSE: 79.44:  20% 233/1190 [2:07:09<9:03:30, 34.08s/it]\n",
            "2197.jpg: actual-predicted:      0,   55.1, error:   55.1. Current MAE: 44.44, RMSE: 79.44:  20% 234/1190 [2:07:09<8:49:24, 33.23s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([84705, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2198.jpg: actual-predicted:      0,   17.8, error:   17.8. Current MAE: 44.32, RMSE: 79.28:  20% 234/1190 [2:07:49<8:49:24, 33.23s/it]\n",
            "2199.jpg: actual-predicted:      0,    8.1, error:    8.1. Current MAE: 44.17, RMSE: 79.11:  20% 235/1190 [2:08:29<9:20:27, 35.21s/it]\n",
            "2199.jpg: actual-predicted:      0,    8.1, error:    8.1. Current MAE: 44.17, RMSE: 79.11:  20% 236/1190 [2:08:29<9:43:44, 36.71s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([11765, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2202.jpg: actual-predicted:      0,   99.5, error:   99.5. Current MAE: 44.40, RMSE: 79.21:  20% 236/1190 [2:08:59<9:43:44, 36.71s/it]\n",
            "2202.jpg: actual-predicted:      0,   99.5, error:   99.5. Current MAE: 44.40, RMSE: 79.21:  20% 237/1190 [2:08:59<9:11:11, 34.70s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([39383, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2203.jpg: actual-predicted:      0,   23.9, error:   23.9. Current MAE: 44.32, RMSE: 79.06:  20% 237/1190 [2:09:34<9:11:11, 34.70s/it]\n",
            "2203.jpg: actual-predicted:      0,   23.9, error:   23.9. Current MAE: 44.32, RMSE: 79.06:  20% 238/1190 [2:09:34<9:12:32, 34.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([40516, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2204.jpg: actual-predicted:      0,    6.6, error:    6.6. Current MAE: 44.16, RMSE: 78.89:  20% 238/1190 [2:10:05<9:12:32, 34.82s/it]\n",
            "2204.jpg: actual-predicted:      0,    6.6, error:    6.6. Current MAE: 44.16, RMSE: 78.89:  20% 239/1190 [2:10:05<8:55:52, 33.81s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1547, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2206.jpg: actual-predicted:      0,   58.6, error:   58.6. Current MAE: 44.22, RMSE: 78.82:  20% 239/1190 [2:10:39<8:55:52, 33.81s/it]\n",
            "2206.jpg: actual-predicted:      0,   58.6, error:   58.6. Current MAE: 44.22, RMSE: 78.82:  20% 240/1190 [2:10:39<8:52:51, 33.65s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([145671, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2207.jpg: actual-predicted:      0,   17.3, error:   17.3. Current MAE: 44.11, RMSE: 78.66:  20% 240/1190 [2:11:11<8:52:51, 33.65s/it]\n",
            "2207.jpg: actual-predicted:      0,   17.3, error:   17.3. Current MAE: 44.11, RMSE: 78.66:  20% 241/1190 [2:11:11<8:46:49, 33.31s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([58702, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2208.jpg: actual-predicted:      0,    5.6, error:    5.6. Current MAE: 43.95, RMSE: 78.50:  20% 241/1190 [2:11:47<8:46:49, 33.31s/it]\n",
            "2208.jpg: actual-predicted:      0,    5.6, error:    5.6. Current MAE: 43.95, RMSE: 78.50:  20% 242/1190 [2:11:47<8:57:46, 34.04s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([34297, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2209.jpg: actual-predicted:      0,    7.4, error:    7.4. Current MAE: 43.80, RMSE: 78.34:  20% 242/1190 [2:12:23<8:57:46, 34.04s/it]\n",
            "2209.jpg: actual-predicted:      0,    7.4, error:    7.4. Current MAE: 43.80, RMSE: 78.34:  20% 243/1190 [2:12:23<9:05:18, 34.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([20623, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2210.jpg: actual-predicted:      0,   16.7, error:   16.7. Current MAE: 43.69, RMSE: 78.19:  20% 243/1190 [2:12:58<9:05:18, 34.55s/it]\n",
            "2210.jpg: actual-predicted:      0,   16.7, error:   16.7. Current MAE: 43.69, RMSE: 78.19:  21% 244/1190 [2:12:58<9:09:15, 34.84s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([15252, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2211.jpg: actual-predicted:      0,   25.3, error:   25.3. Current MAE: 43.61, RMSE: 78.05:  21% 244/1190 [2:13:26<9:09:15, 34.84s/it]\n",
            "2211.jpg: actual-predicted:      0,   25.3, error:   25.3. Current MAE: 43.61, RMSE: 78.05:  21% 245/1190 [2:13:26<8:35:30, 32.73s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([118063, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2213.jpg: actual-predicted:      0,   17.1, error:   17.1. Current MAE: 43.51, RMSE: 77.89:  21% 245/1190 [2:13:57<8:35:30, 32.73s/it]\n",
            "2213.jpg: actual-predicted:      0,   17.1, error:   17.1. Current MAE: 43.51, RMSE: 77.89:  21% 246/1190 [2:13:57<8:28:56, 32.35s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([9851, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2215.jpg: actual-predicted:      0,   27.9, error:   27.9. Current MAE: 43.44, RMSE: 77.76:  21% 246/1190 [2:14:25<8:28:56, 32.35s/it]\n",
            "2215.jpg: actual-predicted:      0,   27.9, error:   27.9. Current MAE: 43.44, RMSE: 77.76:  21% 247/1190 [2:14:25<8:07:53, 31.04s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([162825, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2216.jpg: actual-predicted:      0,   21.8, error:   21.8. Current MAE: 43.36, RMSE: 77.61:  21% 247/1190 [2:15:29<8:07:53, 31.04s/it]\n",
            "2217.jpg: actual-predicted:      0,    7.6, error:    7.6. Current MAE: 43.21, RMSE: 77.46:  21% 248/1190 [2:15:59<10:40:00, 40.76s/it]\n",
            "2217.jpg: actual-predicted:      0,    7.6, error:    7.6. Current MAE: 43.21, RMSE: 77.46:  21% 249/1190 [2:15:59<9:50:26, 37.65s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([16355, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2218.jpg: actual-predicted:      0,    8.7, error:    8.7. Current MAE: 43.07, RMSE: 77.30:  21% 249/1190 [2:16:31<9:50:26, 37.65s/it]\n",
            "2218.jpg: actual-predicted:      0,    8.7, error:    8.7. Current MAE: 43.07, RMSE: 77.30:  21% 250/1190 [2:16:31<9:21:38, 35.85s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([61623, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2219.jpg: actual-predicted:      0,  192.4, error:  192.4. Current MAE: 43.67, RMSE: 78.10:  21% 250/1190 [2:17:02<9:21:38, 35.85s/it]\n",
            "2219.jpg: actual-predicted:      0,  192.4, error:  192.4. Current MAE: 43.67, RMSE: 78.10:  21% 251/1190 [2:17:02<9:00:14, 34.52s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([13409, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2220.jpg: actual-predicted:      0,    4.4, error:    4.4. Current MAE: 43.51, RMSE: 77.95:  21% 251/1190 [2:17:35<9:00:14, 34.52s/it]\n",
            "2220.jpg: actual-predicted:      0,    4.4, error:    4.4. Current MAE: 43.51, RMSE: 77.95:  21% 252/1190 [2:17:35<8:51:55, 34.02s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([8747, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2223.jpg: actual-predicted:      0,   14.9, error:   14.9. Current MAE: 43.40, RMSE: 77.80:  21% 252/1190 [2:18:00<8:51:55, 34.02s/it]\n",
            "2225.jpg: actual-predicted:      0,   14.0, error:   14.0. Current MAE: 43.28, RMSE: 77.65:  21% 253/1190 [2:18:26<8:10:26, 31.41s/it]\n",
            "2225.jpg: actual-predicted:      0,   14.0, error:   14.0. Current MAE: 43.28, RMSE: 77.65:  21% 254/1190 [2:18:26<7:44:38, 29.79s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([25878, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2226.jpg: actual-predicted:      0,   25.4, error:   25.4. Current MAE: 43.21, RMSE: 77.51:  21% 254/1190 [2:18:58<7:44:38, 29.79s/it]\n",
            "2226.jpg: actual-predicted:      0,   25.4, error:   25.4. Current MAE: 43.21, RMSE: 77.51:  21% 255/1190 [2:18:58<7:51:29, 30.26s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([97213, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2227.jpg: actual-predicted:      0,    7.0, error:    7.0. Current MAE: 43.07, RMSE: 77.36:  21% 255/1190 [2:19:24<7:51:29, 30.26s/it]\n",
            "2227.jpg: actual-predicted:      0,    7.0, error:    7.0. Current MAE: 43.07, RMSE: 77.36:  22% 256/1190 [2:19:24<7:30:46, 28.96s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([38185, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2229.jpg: actual-predicted:      0,   43.1, error:   43.1. Current MAE: 43.07, RMSE: 77.26:  22% 256/1190 [2:19:49<7:30:46, 28.96s/it]\n",
            "2229.jpg: actual-predicted:      0,   43.1, error:   43.1. Current MAE: 43.07, RMSE: 77.26:  22% 257/1190 [2:19:49<7:13:12, 27.86s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([9640, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2232.jpg: actual-predicted:      0,   56.9, error:   56.9. Current MAE: 43.13, RMSE: 77.19:  22% 257/1190 [2:20:14<7:13:12, 27.86s/it]\n",
            "2232.jpg: actual-predicted:      0,   56.9, error:   56.9. Current MAE: 43.13, RMSE: 77.19:  22% 258/1190 [2:20:14<6:57:24, 26.87s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([14648, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2233.jpg: actual-predicted:      0,   35.2, error:   35.2. Current MAE: 43.10, RMSE: 77.07:  22% 258/1190 [2:20:45<6:57:24, 26.87s/it]\n",
            "2233.jpg: actual-predicted:      0,   35.2, error:   35.2. Current MAE: 43.10, RMSE: 77.07:  22% 259/1190 [2:20:45<7:17:29, 28.20s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([90432, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2234.jpg: actual-predicted:      0,    9.8, error:    9.8. Current MAE: 42.97, RMSE: 76.93:  22% 259/1190 [2:21:18<7:17:29, 28.20s/it]\n",
            "2234.jpg: actual-predicted:      0,    9.8, error:    9.8. Current MAE: 42.97, RMSE: 76.93:  22% 260/1190 [2:21:18<7:41:04, 29.75s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([177763, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2235.jpg: actual-predicted:      0,   15.1, error:   15.1. Current MAE: 42.86, RMSE: 76.78:  22% 260/1190 [2:22:06<7:41:04, 29.75s/it]\n",
            "2235.jpg: actual-predicted:      0,   15.1, error:   15.1. Current MAE: 42.86, RMSE: 76.78:  22% 261/1190 [2:22:06<9:03:41, 35.11s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([98796, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2236.jpg: actual-predicted:      0,   50.1, error:   50.1. Current MAE: 42.89, RMSE: 76.70:  22% 261/1190 [2:22:41<9:03:41, 35.11s/it]\n",
            "2236.jpg: actual-predicted:      0,   50.1, error:   50.1. Current MAE: 42.89, RMSE: 76.70:  22% 262/1190 [2:22:41<9:03:54, 35.17s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([122633, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2237.jpg: actual-predicted:      0,   10.7, error:   10.7. Current MAE: 42.77, RMSE: 76.56:  22% 262/1190 [2:23:22<9:03:54, 35.17s/it]\n",
            "2237.jpg: actual-predicted:      0,   10.7, error:   10.7. Current MAE: 42.77, RMSE: 76.56:  22% 263/1190 [2:23:22<9:28:32, 36.80s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17668, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2238.jpg: actual-predicted:      0,   13.1, error:   13.1. Current MAE: 42.65, RMSE: 76.42:  22% 263/1190 [2:23:52<9:28:32, 36.80s/it]\n",
            "2238.jpg: actual-predicted:      0,   13.1, error:   13.1. Current MAE: 42.65, RMSE: 76.42:  22% 264/1190 [2:23:52<8:57:31, 34.83s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([97270, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2239.jpg: actual-predicted:      0,   12.1, error:   12.1. Current MAE: 42.54, RMSE: 76.28:  22% 264/1190 [2:24:24<8:57:31, 34.83s/it]\n",
            "2239.jpg: actual-predicted:      0,   12.1, error:   12.1. Current MAE: 42.54, RMSE: 76.28:  22% 265/1190 [2:24:24<8:44:44, 34.04s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([37372, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2240.jpg: actual-predicted:      0,   27.0, error:   27.0. Current MAE: 42.48, RMSE: 76.15:  22% 265/1190 [2:24:49<8:44:44, 34.04s/it]\n",
            "2240.jpg: actual-predicted:      0,   27.0, error:   27.0. Current MAE: 42.48, RMSE: 76.15:  22% 266/1190 [2:24:49<8:02:59, 31.36s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([27289, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2241.jpg: actual-predicted:      0,   20.2, error:   20.2. Current MAE: 42.40, RMSE: 76.02:  22% 266/1190 [2:25:14<8:02:59, 31.36s/it]\n",
            "2241.jpg: actual-predicted:      0,   20.2, error:   20.2. Current MAE: 42.40, RMSE: 76.02:  22% 267/1190 [2:25:14<7:33:58, 29.51s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([7559, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2243.jpg: actual-predicted:      0,  216.3, error:  216.3. Current MAE: 43.05, RMSE: 77.02:  22% 267/1190 [2:25:39<7:33:58, 29.51s/it]\n",
            "2243.jpg: actual-predicted:      0,  216.3, error:  216.3. Current MAE: 43.05, RMSE: 77.02:  23% 268/1190 [2:25:39<7:11:07, 28.06s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([121472, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2244.jpg: actual-predicted:      0,    7.2, error:    7.2. Current MAE: 42.91, RMSE: 76.88:  23% 268/1190 [2:26:06<7:11:07, 28.06s/it]\n",
            "2244.jpg: actual-predicted:      0,    7.2, error:    7.2. Current MAE: 42.91, RMSE: 76.88:  23% 269/1190 [2:26:06<7:02:52, 27.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([138502, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2245.jpg: actual-predicted:      0,   29.5, error:   29.5. Current MAE: 42.86, RMSE: 76.75:  23% 269/1190 [2:26:46<7:02:52, 27.55s/it]\n",
            "2246.jpg: actual-predicted:      0,   25.3, error:   25.3. Current MAE: 42.80, RMSE: 76.63:  23% 270/1190 [2:27:16<8:01:41, 31.41s/it]\n",
            "2246.jpg: actual-predicted:      0,   25.3, error:   25.3. Current MAE: 42.80, RMSE: 76.63:  23% 271/1190 [2:27:16<7:54:17, 30.97s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([19548, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2247.jpg: actual-predicted:      0,   24.8, error:   24.8. Current MAE: 42.73, RMSE: 76.50:  23% 271/1190 [2:27:47<7:54:17, 30.97s/it]\n",
            "2247.jpg: actual-predicted:      0,   24.8, error:   24.8. Current MAE: 42.73, RMSE: 76.50:  23% 272/1190 [2:27:47<7:56:40, 31.15s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([29429, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2248.jpg: actual-predicted:      0,   47.7, error:   47.7. Current MAE: 42.75, RMSE: 76.42:  23% 272/1190 [2:28:19<7:56:40, 31.15s/it]\n",
            "2252.jpg: actual-predicted:      0,   70.2, error:   70.2. Current MAE: 42.85, RMSE: 76.39:  23% 273/1190 [2:28:52<7:57:10, 31.22s/it]\n",
            "2252.jpg: actual-predicted:      0,   70.2, error:   70.2. Current MAE: 42.85, RMSE: 76.39:  23% 274/1190 [2:28:52<8:04:36, 31.74s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([57892, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2255.jpg: actual-predicted:      0,   12.8, error:   12.8. Current MAE: 42.74, RMSE: 76.26:  23% 274/1190 [2:29:23<8:04:36, 31.74s/it]\n",
            "2255.jpg: actual-predicted:      0,   12.8, error:   12.8. Current MAE: 42.74, RMSE: 76.26:  23% 275/1190 [2:29:23<8:03:32, 31.71s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17177, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2256.jpg: actual-predicted:      0,   54.2, error:   54.2. Current MAE: 42.78, RMSE: 76.19:  23% 275/1190 [2:29:55<8:03:32, 31.71s/it]\n",
            "2256.jpg: actual-predicted:      0,   54.2, error:   54.2. Current MAE: 42.78, RMSE: 76.19:  23% 276/1190 [2:29:55<8:02:54, 31.70s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([19597, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2257.jpg: actual-predicted:      0,    9.7, error:    9.7. Current MAE: 42.66, RMSE: 76.05:  23% 276/1190 [2:30:27<8:02:54, 31.70s/it]\n",
            "2257.jpg: actual-predicted:      0,    9.7, error:    9.7. Current MAE: 42.66, RMSE: 76.05:  23% 277/1190 [2:30:27<8:01:42, 31.66s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([14408, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2258.jpg: actual-predicted:      0,   46.2, error:   46.2. Current MAE: 42.68, RMSE: 75.97:  23% 277/1190 [2:31:00<8:01:42, 31.66s/it]\n",
            "2258.jpg: actual-predicted:      0,   46.2, error:   46.2. Current MAE: 42.68, RMSE: 75.97:  23% 278/1190 [2:31:00<8:09:50, 32.23s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([78568, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2259.jpg: actual-predicted:      0,  112.9, error:  112.9. Current MAE: 42.93, RMSE: 76.13:  23% 278/1190 [2:31:37<8:09:50, 32.23s/it]\n",
            "2259.jpg: actual-predicted:      0,  112.9, error:  112.9. Current MAE: 42.93, RMSE: 76.13:  23% 279/1190 [2:31:37<8:29:01, 33.53s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([123603, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2260.jpg: actual-predicted:      0,    8.1, error:    8.1. Current MAE: 42.80, RMSE: 76.00:  23% 279/1190 [2:32:08<8:29:01, 33.53s/it]\n",
            "2260.jpg: actual-predicted:      0,    8.1, error:    8.1. Current MAE: 42.80, RMSE: 76.00:  24% 280/1190 [2:32:08<8:17:33, 32.81s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([157605, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2261.jpg: actual-predicted:      0,   90.3, error:   90.3. Current MAE: 42.97, RMSE: 76.05:  24% 280/1190 [2:32:45<8:17:33, 32.81s/it]\n",
            "2261.jpg: actual-predicted:      0,   90.3, error:   90.3. Current MAE: 42.97, RMSE: 76.05:  24% 281/1190 [2:32:45<8:36:53, 34.12s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([39590, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2262.jpg: actual-predicted:      0,    5.8, error:    5.8. Current MAE: 42.84, RMSE: 75.92:  24% 281/1190 [2:33:11<8:36:53, 34.12s/it]\n",
            "2262.jpg: actual-predicted:      0,    5.8, error:    5.8. Current MAE: 42.84, RMSE: 75.92:  24% 282/1190 [2:33:11<7:59:23, 31.68s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([49572, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2264.jpg: actual-predicted:      0,    4.2, error:    4.2. Current MAE: 42.70, RMSE: 75.79:  24% 282/1190 [2:33:44<7:59:23, 31.68s/it]\n",
            "2265.jpg: actual-predicted:      0,   33.1, error:   33.1. Current MAE: 42.67, RMSE: 75.68:  24% 283/1190 [2:34:13<8:03:35, 31.99s/it]\n",
            "2265.jpg: actual-predicted:      0,   33.1, error:   33.1. Current MAE: 42.67, RMSE: 75.68:  24% 284/1190 [2:34:13<7:50:45, 31.18s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([70590, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2267.jpg: actual-predicted:      0,    9.0, error:    9.0. Current MAE: 42.55, RMSE: 75.55:  24% 284/1190 [2:34:37<7:50:45, 31.18s/it]\n",
            "2267.jpg: actual-predicted:      0,    9.0, error:    9.0. Current MAE: 42.55, RMSE: 75.55:  24% 285/1190 [2:34:37<7:18:48, 29.09s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([39876, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2268.jpg: actual-predicted:      0,   32.4, error:   32.4. Current MAE: 42.52, RMSE: 75.44:  24% 285/1190 [2:35:01<7:18:48, 29.09s/it]\n",
            "2268.jpg: actual-predicted:      0,   32.4, error:   32.4. Current MAE: 42.52, RMSE: 75.44:  24% 286/1190 [2:35:01<6:53:08, 27.42s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([19161, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2269.jpg: actual-predicted:      0,   10.2, error:   10.2. Current MAE: 42.40, RMSE: 75.31:  24% 286/1190 [2:35:32<6:53:08, 27.42s/it]\n",
            "2269.jpg: actual-predicted:      0,   10.2, error:   10.2. Current MAE: 42.40, RMSE: 75.31:  24% 287/1190 [2:35:32<7:11:56, 28.70s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([15895, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2270.jpg: actual-predicted:      0,   42.7, error:   42.7. Current MAE: 42.41, RMSE: 75.22:  24% 287/1190 [2:36:06<7:11:56, 28.70s/it]\n",
            "2270.jpg: actual-predicted:      0,   42.7, error:   42.7. Current MAE: 42.41, RMSE: 75.22:  24% 288/1190 [2:36:06<7:33:06, 30.14s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([90723, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2271.jpg: actual-predicted:      0,   19.5, error:   19.5. Current MAE: 42.33, RMSE: 75.10:  24% 288/1190 [2:36:37<7:33:06, 30.14s/it]\n",
            "2272.jpg: actual-predicted:      0,    6.7, error:    6.7. Current MAE: 42.20, RMSE: 74.97:  24% 289/1190 [2:37:11<7:35:11, 30.31s/it]\n",
            "2272.jpg: actual-predicted:      0,    6.7, error:    6.7. Current MAE: 42.20, RMSE: 74.97:  24% 290/1190 [2:37:11<7:52:19, 31.49s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([46290, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2273.jpg: actual-predicted:      0,  153.9, error:  153.9. Current MAE: 42.59, RMSE: 75.38:  24% 290/1190 [2:37:36<7:52:19, 31.49s/it]\n",
            "2273.jpg: actual-predicted:      0,  153.9, error:  153.9. Current MAE: 42.59, RMSE: 75.38:  24% 291/1190 [2:37:36<7:23:18, 29.59s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([5903, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2274.jpg: actual-predicted:      0,   36.9, error:   36.9. Current MAE: 42.57, RMSE: 75.29:  24% 291/1190 [2:38:06<7:23:18, 29.59s/it]\n",
            "2275.jpg: actual-predicted:      0,   19.4, error:   19.4. Current MAE: 42.49, RMSE: 75.17:  25% 292/1190 [2:38:30<7:23:27, 29.63s/it]\n",
            "2275.jpg: actual-predicted:      0,   19.4, error:   19.4. Current MAE: 42.49, RMSE: 75.17:  25% 293/1190 [2:38:30<7:00:11, 28.11s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64618, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2276.jpg: actual-predicted:      0,   16.9, error:   16.9. Current MAE: 42.40, RMSE: 75.04:  25% 293/1190 [2:39:10<7:00:11, 28.11s/it]\n",
            "2276.jpg: actual-predicted:      0,   16.9, error:   16.9. Current MAE: 42.40, RMSE: 75.04:  25% 294/1190 [2:39:10<7:52:06, 31.61s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([23509, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2277.jpg: actual-predicted:      0,   24.1, error:   24.1. Current MAE: 42.34, RMSE: 74.93:  25% 294/1190 [2:39:41<7:52:06, 31.61s/it]\n",
            "2277.jpg: actual-predicted:      0,   24.1, error:   24.1. Current MAE: 42.34, RMSE: 74.93:  25% 295/1190 [2:39:41<7:49:24, 31.47s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1465, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2279.jpg: actual-predicted:      0,   14.0, error:   14.0. Current MAE: 42.24, RMSE: 74.81:  25% 295/1190 [2:40:14<7:49:24, 31.47s/it]\n",
            "2279.jpg: actual-predicted:      0,   14.0, error:   14.0. Current MAE: 42.24, RMSE: 74.81:  25% 296/1190 [2:40:14<7:52:49, 31.73s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([87485, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2280.jpg: actual-predicted:      0,   66.8, error:   66.8. Current MAE: 42.33, RMSE: 74.78:  25% 296/1190 [2:40:47<7:52:49, 31.73s/it]\n",
            "2280.jpg: actual-predicted:      0,   66.8, error:   66.8. Current MAE: 42.33, RMSE: 74.78:  25% 297/1190 [2:40:47<7:58:56, 32.18s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([24985, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2281.jpg: actual-predicted:      0,   10.1, error:   10.1. Current MAE: 42.22, RMSE: 74.66:  25% 297/1190 [2:41:27<7:58:56, 32.18s/it]\n",
            "2281.jpg: actual-predicted:      0,   10.1, error:   10.1. Current MAE: 42.22, RMSE: 74.66:  25% 298/1190 [2:41:27<8:35:19, 34.66s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([172199, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2282.jpg: actual-predicted:      0,   60.7, error:   60.7. Current MAE: 42.28, RMSE: 74.62:  25% 298/1190 [2:42:02<8:35:19, 34.66s/it]\n",
            "2282.jpg: actual-predicted:      0,   60.7, error:   60.7. Current MAE: 42.28, RMSE: 74.62:  25% 299/1190 [2:42:02<8:36:18, 34.77s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([60759, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2284.jpg: actual-predicted:      0,   12.3, error:   12.3. Current MAE: 42.18, RMSE: 74.50:  25% 299/1190 [2:42:33<8:36:18, 34.77s/it]\n",
            "2284.jpg: actual-predicted:      0,   12.3, error:   12.3. Current MAE: 42.18, RMSE: 74.50:  25% 300/1190 [2:42:33<8:17:06, 33.51s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([16099, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2285.jpg: actual-predicted:      0,   29.0, error:   29.0. Current MAE: 42.14, RMSE: 74.39:  25% 300/1190 [2:42:58<8:17:06, 33.51s/it]\n",
            "2285.jpg: actual-predicted:      0,   29.0, error:   29.0. Current MAE: 42.14, RMSE: 74.39:  25% 301/1190 [2:42:58<7:38:05, 30.92s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([20459, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2286.jpg: actual-predicted:      0,    8.4, error:    8.4. Current MAE: 42.02, RMSE: 74.27:  25% 301/1190 [2:43:29<7:38:05, 30.92s/it]\n",
            "2286.jpg: actual-predicted:      0,    8.4, error:    8.4. Current MAE: 42.02, RMSE: 74.27:  25% 302/1190 [2:43:29<7:40:50, 31.14s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([108379, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2287.jpg: actual-predicted:      0,  125.6, error:  125.6. Current MAE: 42.30, RMSE: 74.50:  25% 302/1190 [2:44:00<7:40:50, 31.14s/it]\n",
            "2287.jpg: actual-predicted:      0,  125.6, error:  125.6. Current MAE: 42.30, RMSE: 74.50:  25% 303/1190 [2:44:00<7:39:22, 31.07s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([15075, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2288.jpg: actual-predicted:      0,   16.3, error:   16.3. Current MAE: 42.21, RMSE: 74.38:  25% 303/1190 [2:44:32<7:39:22, 31.07s/it]\n",
            "2288.jpg: actual-predicted:      0,   16.3, error:   16.3. Current MAE: 42.21, RMSE: 74.38:  26% 304/1190 [2:44:32<7:43:12, 31.37s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([239064, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2607.jpg: actual-predicted:      0,   37.5, error:   37.5. Current MAE: 42.20, RMSE: 74.29:  26% 304/1190 [2:45:43<7:43:12, 31.37s/it]\n",
            "2607.jpg: actual-predicted:      0,   37.5, error:   37.5. Current MAE: 42.20, RMSE: 74.29:  26% 305/1190 [2:45:43<10:38:08, 43.26s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([65239, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2611.jpg: actual-predicted:      0,   12.0, error:   12.0. Current MAE: 42.10, RMSE: 74.17:  26% 305/1190 [2:46:09<10:38:08, 43.26s/it]\n",
            "2611.jpg: actual-predicted:      0,   12.0, error:   12.0. Current MAE: 42.10, RMSE: 74.17:  26% 306/1190 [2:46:09<9:19:03, 37.94s/it] /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([124703, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2612.jpg: actual-predicted:      0,   35.3, error:   35.3. Current MAE: 42.08, RMSE: 74.08:  26% 306/1190 [2:46:51<9:19:03, 37.94s/it]\n",
            "2612.jpg: actual-predicted:      0,   35.3, error:   35.3. Current MAE: 42.08, RMSE: 74.08:  26% 307/1190 [2:46:51<9:37:40, 39.25s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([143897, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2613.jpg: actual-predicted:      0,   14.6, error:   14.6. Current MAE: 41.99, RMSE: 73.96:  26% 307/1190 [2:47:32<9:37:40, 39.25s/it]\n",
            "2613.jpg: actual-predicted:      0,   14.6, error:   14.6. Current MAE: 41.99, RMSE: 73.96:  26% 308/1190 [2:47:32<9:41:50, 39.58s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([141901, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2614.jpg: actual-predicted:      0,   15.8, error:   15.8. Current MAE: 41.90, RMSE: 73.85:  26% 308/1190 [2:48:08<9:41:50, 39.58s/it]\n",
            "2614.jpg: actual-predicted:      0,   15.8, error:   15.8. Current MAE: 41.90, RMSE: 73.85:  26% 309/1190 [2:48:08<9:25:58, 38.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([107821, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2615.jpg: actual-predicted:      0,    3.4, error:    3.4. Current MAE: 41.78, RMSE: 73.73:  26% 309/1190 [2:48:40<9:25:58, 38.55s/it]\n",
            "2615.jpg: actual-predicted:      0,    3.4, error:    3.4. Current MAE: 41.78, RMSE: 73.73:  26% 310/1190 [2:48:40<8:55:57, 36.54s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([162924, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2617.jpg: actual-predicted:      0,   37.2, error:   37.2. Current MAE: 41.77, RMSE: 73.64:  26% 310/1190 [2:49:12<8:55:57, 36.54s/it]\n",
            "2617.jpg: actual-predicted:      0,   37.2, error:   37.2. Current MAE: 41.77, RMSE: 73.64:  26% 311/1190 [2:49:12<8:37:59, 35.36s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([77572, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2619.jpg: actual-predicted:      0,   17.2, error:   17.2. Current MAE: 41.69, RMSE: 73.53:  26% 311/1190 [2:49:43<8:37:59, 35.36s/it]\n",
            "2619.jpg: actual-predicted:      0,   17.2, error:   17.2. Current MAE: 41.69, RMSE: 73.53:  26% 312/1190 [2:49:43<8:18:00, 34.03s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([124519, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2907.jpg: actual-predicted:      0,   27.7, error:   27.7. Current MAE: 41.64, RMSE: 73.43:  26% 312/1190 [2:50:16<8:18:00, 34.03s/it]\n",
            "2907.jpg: actual-predicted:      0,   27.7, error:   27.7. Current MAE: 41.64, RMSE: 73.43:  26% 313/1190 [2:50:16<8:11:00, 33.59s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([16389, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2908.jpg: actual-predicted:      0,   37.7, error:   37.7. Current MAE: 41.63, RMSE: 73.34:  26% 313/1190 [2:50:41<8:11:00, 33.59s/it]\n",
            "2910.jpg: actual-predicted:      0,   17.4, error:   17.4. Current MAE: 41.55, RMSE: 73.23:  26% 314/1190 [2:51:43<7:34:10, 31.11s/it]\n",
            "2910.jpg: actual-predicted:      0,   17.4, error:   17.4. Current MAE: 41.55, RMSE: 73.23:  26% 315/1190 [2:51:43<9:49:40, 40.44s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([8345, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2912.jpg: actual-predicted:      0,   68.1, error:   68.1. Current MAE: 41.64, RMSE: 73.22:  26% 315/1190 [2:52:09<9:49:40, 40.44s/it]\n",
            "2912.jpg: actual-predicted:      0,   68.1, error:   68.1. Current MAE: 41.64, RMSE: 73.22:  27% 316/1190 [2:52:09<8:43:28, 35.94s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([60515, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2913.jpg: actual-predicted:      0,   17.9, error:   17.9. Current MAE: 41.56, RMSE: 73.11:  27% 316/1190 [2:52:33<8:43:28, 35.94s/it]\n",
            "2913.jpg: actual-predicted:      0,   17.9, error:   17.9. Current MAE: 41.56, RMSE: 73.11:  27% 317/1190 [2:52:33<7:51:26, 32.40s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([116524, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2914.jpg: actual-predicted:      0,   23.9, error:   23.9. Current MAE: 41.51, RMSE: 73.00:  27% 317/1190 [2:53:15<7:51:26, 32.40s/it]\n",
            "2914.jpg: actual-predicted:      0,   23.9, error:   23.9. Current MAE: 41.51, RMSE: 73.00:  27% 318/1190 [2:53:15<8:35:34, 35.48s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([10030, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2915.jpg: actual-predicted:      0,   68.0, error:   68.0. Current MAE: 41.59, RMSE: 72.99:  27% 318/1190 [2:53:40<8:35:34, 35.48s/it]\n",
            "2915.jpg: actual-predicted:      0,   68.0, error:   68.0. Current MAE: 41.59, RMSE: 72.99:  27% 319/1190 [2:53:40<7:48:21, 32.26s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([41748, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2916.jpg: actual-predicted:      0,  237.9, error:  237.9. Current MAE: 42.20, RMSE: 74.08:  27% 319/1190 [2:54:11<7:48:21, 32.26s/it]\n",
            "2916.jpg: actual-predicted:      0,  237.9, error:  237.9. Current MAE: 42.20, RMSE: 74.08:  27% 320/1190 [2:54:11<7:41:47, 31.85s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([141422, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2917.jpg: actual-predicted:      0,   20.5, error:   20.5. Current MAE: 42.13, RMSE: 73.97:  27% 320/1190 [2:54:49<7:41:47, 31.85s/it]\n",
            "2917.jpg: actual-predicted:      0,   20.5, error:   20.5. Current MAE: 42.13, RMSE: 73.97:  27% 321/1190 [2:54:49<8:08:19, 33.72s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([47085, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2918.jpg: actual-predicted:      0,   32.2, error:   32.2. Current MAE: 42.10, RMSE: 73.88:  27% 321/1190 [2:55:15<8:08:19, 33.72s/it]\n",
            "2918.jpg: actual-predicted:      0,   32.2, error:   32.2. Current MAE: 42.10, RMSE: 73.88:  27% 322/1190 [2:55:15<7:34:33, 31.42s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([153796, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2920.jpg: actual-predicted:      0,   20.5, error:   20.5. Current MAE: 42.04, RMSE: 73.77:  27% 322/1190 [2:55:52<7:34:33, 31.42s/it]\n",
            "2920.jpg: actual-predicted:      0,   20.5, error:   20.5. Current MAE: 42.04, RMSE: 73.77:  27% 323/1190 [2:55:52<7:56:42, 32.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([2846, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2921.jpg: actual-predicted:      0,   24.0, error:   24.0. Current MAE: 41.98, RMSE: 73.67:  27% 323/1190 [2:56:17<7:56:42, 32.99s/it]\n",
            "2921.jpg: actual-predicted:      0,   24.0, error:   24.0. Current MAE: 41.98, RMSE: 73.67:  27% 324/1190 [2:56:17<7:23:03, 30.70s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([41209, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2922.jpg: actual-predicted:      0,   24.4, error:   24.4. Current MAE: 41.93, RMSE: 73.57:  27% 324/1190 [2:56:43<7:23:03, 30.70s/it]\n",
            "2922.jpg: actual-predicted:      0,   24.4, error:   24.4. Current MAE: 41.93, RMSE: 73.57:  27% 325/1190 [2:56:43<6:59:45, 29.12s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([18418, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2923.jpg: actual-predicted:      0,   45.9, error:   45.9. Current MAE: 41.94, RMSE: 73.50:  27% 325/1190 [2:57:08<6:59:45, 29.12s/it]\n",
            "2923.jpg: actual-predicted:      0,   45.9, error:   45.9. Current MAE: 41.94, RMSE: 73.50:  27% 326/1190 [2:57:08<6:44:34, 28.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([6473, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2924.jpg: actual-predicted:      0,   57.7, error:   57.7. Current MAE: 41.99, RMSE: 73.46:  27% 326/1190 [2:57:34<6:44:34, 28.10s/it]\n",
            "2924.jpg: actual-predicted:      0,   57.7, error:   57.7. Current MAE: 41.99, RMSE: 73.46:  27% 327/1190 [2:57:34<6:33:05, 27.33s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([125471, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2925.jpg: actual-predicted:      0,   51.1, error:   51.1. Current MAE: 42.02, RMSE: 73.40:  27% 327/1190 [2:58:12<6:33:05, 27.33s/it]\n",
            "2926.jpg: actual-predicted:      0,   32.7, error:   32.7. Current MAE: 41.99, RMSE: 73.31:  28% 328/1190 [2:58:37<7:17:28, 30.45s/it]\n",
            "2926.jpg: actual-predicted:      0,   32.7, error:   32.7. Current MAE: 41.99, RMSE: 73.31:  28% 329/1190 [2:58:37<6:53:21, 28.81s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([66332, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2927.jpg: actual-predicted:      0,   44.7, error:   44.7. Current MAE: 41.99, RMSE: 73.24:  28% 329/1190 [2:59:13<6:53:21, 28.81s/it]\n",
            "2927.jpg: actual-predicted:      0,   44.7, error:   44.7. Current MAE: 41.99, RMSE: 73.24:  28% 330/1190 [2:59:13<7:25:43, 31.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([39559, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2928.jpg: actual-predicted:      0,   29.6, error:   29.6. Current MAE: 41.96, RMSE: 73.15:  28% 330/1190 [2:59:39<7:25:43, 31.10s/it]\n",
            "2928.jpg: actual-predicted:      0,   29.6, error:   29.6. Current MAE: 41.96, RMSE: 73.15:  28% 331/1190 [2:59:39<7:02:02, 29.48s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([28483, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2929.jpg: actual-predicted:      0,   86.4, error:   86.4. Current MAE: 42.09, RMSE: 73.19:  28% 331/1190 [3:00:04<7:02:02, 29.48s/it]\n",
            "2929.jpg: actual-predicted:      0,   86.4, error:   86.4. Current MAE: 42.09, RMSE: 73.19:  28% 332/1190 [3:00:04<6:44:43, 28.30s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([35377, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2930.jpg: actual-predicted:      0,   68.9, error:   68.9. Current MAE: 42.17, RMSE: 73.18:  28% 332/1190 [3:00:35<6:44:43, 28.30s/it]\n",
            "2930.jpg: actual-predicted:      0,   68.9, error:   68.9. Current MAE: 42.17, RMSE: 73.18:  28% 333/1190 [3:00:35<6:53:09, 28.93s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([36690, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2931.jpg: actual-predicted:      0,   13.8, error:   13.8. Current MAE: 42.09, RMSE: 73.07:  28% 333/1190 [3:01:01<6:53:09, 28.93s/it]\n",
            "2932.jpg: actual-predicted:      0,   37.0, error:   37.0. Current MAE: 42.07, RMSE: 72.99:  28% 334/1190 [3:01:26<6:40:05, 28.04s/it]\n",
            "2933.jpg: actual-predicted:      0,   59.6, error:   59.6. Current MAE: 42.12, RMSE: 72.96:  28% 335/1190 [3:01:50<6:25:58, 27.09s/it]\n",
            "2933.jpg: actual-predicted:      0,   59.6, error:   59.6. Current MAE: 42.12, RMSE: 72.96:  28% 336/1190 [3:01:50<6:14:24, 26.31s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([72743, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2934.jpg: actual-predicted:      0,   66.2, error:   66.2. Current MAE: 42.20, RMSE: 72.94:  28% 336/1190 [3:02:16<6:14:24, 26.31s/it]\n",
            "2934.jpg: actual-predicted:      0,   66.2, error:   66.2. Current MAE: 42.20, RMSE: 72.94:  28% 337/1190 [3:02:16<6:12:48, 26.22s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([83356, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2935.jpg: actual-predicted:      0,   28.3, error:   28.3. Current MAE: 42.15, RMSE: 72.85:  28% 337/1190 [3:02:42<6:12:48, 26.22s/it]\n",
            "2935.jpg: actual-predicted:      0,   28.3, error:   28.3. Current MAE: 42.15, RMSE: 72.85:  28% 338/1190 [3:02:42<6:10:31, 26.09s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([15775, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2936.jpg: actual-predicted:      0,   23.1, error:   23.1. Current MAE: 42.10, RMSE: 72.75:  28% 338/1190 [3:03:07<6:10:31, 26.09s/it]\n",
            "2936.jpg: actual-predicted:      0,   23.1, error:   23.1. Current MAE: 42.10, RMSE: 72.75:  28% 339/1190 [3:03:07<6:07:49, 25.93s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([16847, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2937.jpg: actual-predicted:      0,   48.1, error:   48.1. Current MAE: 42.12, RMSE: 72.69:  28% 339/1190 [3:03:33<6:07:49, 25.93s/it]\n",
            "2937.jpg: actual-predicted:      0,   48.1, error:   48.1. Current MAE: 42.12, RMSE: 72.69:  29% 340/1190 [3:03:33<6:05:37, 25.81s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([79160, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2938.jpg: actual-predicted:      0,   15.5, error:   15.5. Current MAE: 42.04, RMSE: 72.59:  29% 340/1190 [3:03:59<6:05:37, 25.81s/it]\n",
            "2938.jpg: actual-predicted:      0,   15.5, error:   15.5. Current MAE: 42.04, RMSE: 72.59:  29% 341/1190 [3:03:59<6:05:29, 25.83s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([112893, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2939.jpg: actual-predicted:      0,   40.2, error:   40.2. Current MAE: 42.03, RMSE: 72.51:  29% 341/1190 [3:04:31<6:05:29, 25.83s/it]\n",
            "2939.jpg: actual-predicted:      0,   40.2, error:   40.2. Current MAE: 42.03, RMSE: 72.51:  29% 342/1190 [3:04:31<6:30:40, 27.64s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([5036, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2941.jpg: actual-predicted:      0,   11.8, error:   11.8. Current MAE: 41.94, RMSE: 72.41:  29% 342/1190 [3:05:01<6:30:40, 27.64s/it]\n",
            "2941.jpg: actual-predicted:      0,   11.8, error:   11.8. Current MAE: 41.94, RMSE: 72.41:  29% 343/1190 [3:05:01<6:42:13, 28.49s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([82592, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2942.jpg: actual-predicted:      0,   28.7, error:   28.7. Current MAE: 41.91, RMSE: 72.32:  29% 343/1190 [3:05:28<6:42:13, 28.49s/it]\n",
            "2943.jpg: actual-predicted:      0,   35.1, error:   35.1. Current MAE: 41.89, RMSE: 72.24:  29% 344/1190 [3:06:00<6:33:15, 27.89s/it]\n",
            "2943.jpg: actual-predicted:      0,   35.1, error:   35.1. Current MAE: 41.89, RMSE: 72.24:  29% 345/1190 [3:06:00<6:49:43, 29.09s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([9434, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2944.jpg: actual-predicted:      0,   37.9, error:   37.9. Current MAE: 41.87, RMSE: 72.17:  29% 345/1190 [3:06:34<6:49:43, 29.09s/it]\n",
            "2944.jpg: actual-predicted:      0,   37.9, error:   37.9. Current MAE: 41.87, RMSE: 72.17:  29% 346/1190 [3:06:34<7:11:18, 30.66s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([76856, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2945.jpg: actual-predicted:      0,   17.1, error:   17.1. Current MAE: 41.80, RMSE: 72.07:  29% 346/1190 [3:07:00<7:11:18, 30.66s/it]\n",
            "2945.jpg: actual-predicted:      0,   17.1, error:   17.1. Current MAE: 41.80, RMSE: 72.07:  29% 347/1190 [3:07:00<6:53:25, 29.43s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([73408, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2946.jpg: actual-predicted:      0,   16.7, error:   16.7. Current MAE: 41.73, RMSE: 71.97:  29% 347/1190 [3:07:26<6:53:25, 29.43s/it]\n",
            "2946.jpg: actual-predicted:      0,   16.7, error:   16.7. Current MAE: 41.73, RMSE: 71.97:  29% 348/1190 [3:07:26<6:38:12, 28.38s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([7712, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2947.jpg: actual-predicted:      0,   44.8, error:   44.8. Current MAE: 41.74, RMSE: 71.91:  29% 348/1190 [3:07:52<6:38:12, 28.38s/it]\n",
            "2947.jpg: actual-predicted:      0,   44.8, error:   44.8. Current MAE: 41.74, RMSE: 71.91:  29% 349/1190 [3:07:52<6:25:24, 27.50s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([75292, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2948.jpg: actual-predicted:      0,   15.2, error:   15.2. Current MAE: 41.66, RMSE: 71.81:  29% 349/1190 [3:08:18<6:25:24, 27.50s/it]\n",
            "2948.jpg: actual-predicted:      0,   15.2, error:   15.2. Current MAE: 41.66, RMSE: 71.81:  29% 350/1190 [3:08:18<6:19:23, 27.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64670, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2949.jpg: actual-predicted:      0,   28.4, error:   28.4. Current MAE: 41.63, RMSE: 71.72:  29% 350/1190 [3:08:44<6:19:23, 27.10s/it]\n",
            "2949.jpg: actual-predicted:      0,   28.4, error:   28.4. Current MAE: 41.63, RMSE: 71.72:  29% 351/1190 [3:08:44<6:15:02, 26.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([151549, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2951.jpg: actual-predicted:      0,   25.0, error:   25.0. Current MAE: 41.58, RMSE: 71.63:  29% 351/1190 [3:09:19<6:15:02, 26.82s/it]\n",
            "2951.jpg: actual-predicted:      0,   25.0, error:   25.0. Current MAE: 41.58, RMSE: 71.63:  30% 352/1190 [3:09:19<6:47:52, 29.20s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([3989, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2952.jpg: actual-predicted:      0,   55.7, error:   55.7. Current MAE: 41.62, RMSE: 71.59:  30% 352/1190 [3:09:52<6:47:52, 29.20s/it]\n",
            "2952.jpg: actual-predicted:      0,   55.7, error:   55.7. Current MAE: 41.62, RMSE: 71.59:  30% 353/1190 [3:09:52<7:02:26, 30.28s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([83906, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2953.jpg: actual-predicted:      0,   32.3, error:   32.3. Current MAE: 41.59, RMSE: 71.51:  30% 353/1190 [3:10:18<7:02:26, 30.28s/it]\n",
            "2953.jpg: actual-predicted:      0,   32.3, error:   32.3. Current MAE: 41.59, RMSE: 71.51:  30% 354/1190 [3:10:18<6:45:19, 29.09s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([14743, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2954.jpg: actual-predicted:      0,   30.5, error:   30.5. Current MAE: 41.56, RMSE: 71.43:  30% 354/1190 [3:10:52<6:45:19, 29.09s/it]\n",
            "2954.jpg: actual-predicted:      0,   30.5, error:   30.5. Current MAE: 41.56, RMSE: 71.43:  30% 355/1190 [3:10:52<7:06:55, 30.68s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([20626, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2955.jpg: actual-predicted:      0,   93.5, error:   93.5. Current MAE: 41.71, RMSE: 71.50:  30% 355/1190 [3:11:18<7:06:55, 30.68s/it]\n",
            "2955.jpg: actual-predicted:      0,   93.5, error:   93.5. Current MAE: 41.71, RMSE: 71.50:  30% 356/1190 [3:11:18<6:44:57, 29.13s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([18262, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "2956.jpg: actual-predicted:      0,   38.2, error:   38.2. Current MAE: 41.70, RMSE: 71.43:  30% 356/1190 [3:11:43<6:44:57, 29.13s/it]\n",
            "2956.jpg: actual-predicted:      0,   38.2, error:   38.2. Current MAE: 41.70, RMSE: 71.43:  30% 357/1190 [3:11:43<6:27:39, 27.92s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([136089, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3111.jpg: actual-predicted:      0,   16.4, error:   16.4. Current MAE: 41.63, RMSE: 71.33:  30% 357/1190 [3:12:10<6:27:39, 27.92s/it]\n",
            "3111.jpg: actual-predicted:      0,   16.4, error:   16.4. Current MAE: 41.63, RMSE: 71.33:  30% 358/1190 [3:12:10<6:22:25, 27.58s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([142333, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3112.jpg: actual-predicted:      0,   10.0, error:   10.0. Current MAE: 41.54, RMSE: 71.24:  30% 358/1190 [3:12:46<6:22:25, 27.58s/it]\n",
            "3112.jpg: actual-predicted:      0,   10.0, error:   10.0. Current MAE: 41.54, RMSE: 71.24:  30% 359/1190 [3:12:46<6:59:35, 30.30s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([174670, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3114.jpg: actual-predicted:      0,   24.3, error:   24.3. Current MAE: 41.49, RMSE: 71.15:  30% 359/1190 [3:13:23<6:59:35, 30.30s/it]\n",
            "3114.jpg: actual-predicted:      0,   24.3, error:   24.3. Current MAE: 41.49, RMSE: 71.15:  30% 360/1190 [3:13:23<7:25:35, 32.21s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([40783, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3153.jpg: actual-predicted:      0,   10.5, error:   10.5. Current MAE: 41.40, RMSE: 71.05:  30% 360/1190 [3:13:58<7:25:35, 32.21s/it]\n",
            "3153.jpg: actual-predicted:      0,   10.5, error:   10.5. Current MAE: 41.40, RMSE: 71.05:  30% 361/1190 [3:13:58<7:34:36, 32.90s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([135388, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3154.jpg: actual-predicted:      0,   25.8, error:   25.8. Current MAE: 41.36, RMSE: 70.97:  30% 361/1190 [3:14:25<7:34:36, 32.90s/it]\n",
            "3154.jpg: actual-predicted:      0,   25.8, error:   25.8. Current MAE: 41.36, RMSE: 70.97:  30% 362/1190 [3:14:25<7:09:09, 31.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([69325, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3155.jpg: actual-predicted:      0,   32.6, error:   32.6. Current MAE: 41.34, RMSE: 70.89:  30% 362/1190 [3:14:50<7:09:09, 31.10s/it]\n",
            "3155.jpg: actual-predicted:      0,   32.6, error:   32.6. Current MAE: 41.34, RMSE: 70.89:  31% 363/1190 [3:14:50<6:46:57, 29.53s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([102782, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3156.jpg: actual-predicted:      0,   23.2, error:   23.2. Current MAE: 41.29, RMSE: 70.80:  31% 363/1190 [3:15:17<6:46:57, 29.53s/it]\n",
            "3156.jpg: actual-predicted:      0,   23.2, error:   23.2. Current MAE: 41.29, RMSE: 70.80:  31% 364/1190 [3:15:17<6:32:59, 28.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([105976, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3157.jpg: actual-predicted:      0,   31.7, error:   31.7. Current MAE: 41.26, RMSE: 70.73:  31% 364/1190 [3:15:43<6:32:59, 28.55s/it]\n",
            "3157.jpg: actual-predicted:      0,   31.7, error:   31.7. Current MAE: 41.26, RMSE: 70.73:  31% 365/1190 [3:15:43<6:22:31, 27.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([168664, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3158.jpg: actual-predicted:      0,   31.5, error:   31.5. Current MAE: 41.23, RMSE: 70.65:  31% 365/1190 [3:16:18<6:22:31, 27.82s/it]\n",
            "3158.jpg: actual-predicted:      0,   31.5, error:   31.5. Current MAE: 41.23, RMSE: 70.65:  31% 366/1190 [3:16:18<6:53:51, 30.14s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([120490, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3159.jpg: actual-predicted:      0,   18.6, error:   18.6. Current MAE: 41.17, RMSE: 70.56:  31% 366/1190 [3:16:54<6:53:51, 30.14s/it]\n",
            "3159.jpg: actual-predicted:      0,   18.6, error:   18.6. Current MAE: 41.17, RMSE: 70.56:  31% 367/1190 [3:16:54<7:16:41, 31.84s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([76552, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3160.jpg: actual-predicted:      0,   10.4, error:   10.4. Current MAE: 41.09, RMSE: 70.46:  31% 367/1190 [3:17:31<7:16:41, 31.84s/it]\n",
            "3160.jpg: actual-predicted:      0,   10.4, error:   10.4. Current MAE: 41.09, RMSE: 70.46:  31% 368/1190 [3:17:31<7:35:53, 33.28s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([72567, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3268.jpg: actual-predicted:      0,   13.9, error:   13.9. Current MAE: 41.02, RMSE: 70.37:  31% 368/1190 [3:18:02<7:35:53, 33.28s/it]\n",
            "3268.jpg: actual-predicted:      0,   13.9, error:   13.9. Current MAE: 41.02, RMSE: 70.37:  31% 369/1190 [3:18:02<7:27:10, 32.68s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([138070, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3269.jpg: actual-predicted:      0,   27.5, error:   27.5. Current MAE: 40.98, RMSE: 70.29:  31% 369/1190 [3:18:29<7:27:10, 32.68s/it]\n",
            "3269.jpg: actual-predicted:      0,   27.5, error:   27.5. Current MAE: 40.98, RMSE: 70.29:  31% 370/1190 [3:18:29<7:02:39, 30.93s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([95558, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3270.jpg: actual-predicted:      0,   17.2, error:   17.2. Current MAE: 40.91, RMSE: 70.20:  31% 370/1190 [3:19:00<7:02:39, 30.93s/it]\n",
            "3270.jpg: actual-predicted:      0,   17.2, error:   17.2. Current MAE: 40.91, RMSE: 70.20:  31% 371/1190 [3:19:00<7:04:45, 31.12s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([5130, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3271.jpg: actual-predicted:      0,   21.2, error:   21.2. Current MAE: 40.86, RMSE: 70.12:  31% 371/1190 [3:19:31<7:04:45, 31.12s/it]\n",
            "3271.jpg: actual-predicted:      0,   21.2, error:   21.2. Current MAE: 40.86, RMSE: 70.12:  31% 372/1190 [3:19:31<7:02:30, 30.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([109178, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3274.jpg: actual-predicted:      0,    9.3, error:    9.3. Current MAE: 40.78, RMSE: 70.02:  31% 372/1190 [3:20:03<7:02:30, 30.99s/it]\n",
            "3274.jpg: actual-predicted:      0,    9.3, error:    9.3. Current MAE: 40.78, RMSE: 70.02:  31% 373/1190 [3:20:03<7:04:54, 31.20s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([125373, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3275.jpg: actual-predicted:      0,   15.0, error:   15.0. Current MAE: 40.71, RMSE: 69.94:  31% 373/1190 [3:20:35<7:04:54, 31.20s/it]\n",
            "3275.jpg: actual-predicted:      0,   15.0, error:   15.0. Current MAE: 40.71, RMSE: 69.94:  31% 374/1190 [3:20:35<7:07:28, 31.43s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([86404, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3276.jpg: actual-predicted:      0,   14.3, error:   14.3. Current MAE: 40.64, RMSE: 69.85:  31% 374/1190 [3:21:07<7:07:28, 31.43s/it]\n",
            "3276.jpg: actual-predicted:      0,   14.3, error:   14.3. Current MAE: 40.64, RMSE: 69.85:  32% 375/1190 [3:21:07<7:08:10, 31.52s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([77293, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3278.jpg: actual-predicted:      0,   41.6, error:   41.6. Current MAE: 40.64, RMSE: 69.79:  32% 375/1190 [3:21:37<7:08:10, 31.52s/it]\n",
            "3278.jpg: actual-predicted:      0,   41.6, error:   41.6. Current MAE: 40.64, RMSE: 69.79:  32% 376/1190 [3:21:37<7:05:11, 31.34s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([105492, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3279.jpg: actual-predicted:      0,   22.8, error:   22.8. Current MAE: 40.59, RMSE: 69.70:  32% 376/1190 [3:22:13<7:05:11, 31.34s/it]\n",
            "3279.jpg: actual-predicted:      0,   22.8, error:   22.8. Current MAE: 40.59, RMSE: 69.70:  32% 377/1190 [3:22:13<7:19:57, 32.47s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([58262, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3281.jpg: actual-predicted:      0,   17.2, error:   17.2. Current MAE: 40.53, RMSE: 69.62:  32% 377/1190 [3:22:38<7:19:57, 32.47s/it]\n",
            "3281.jpg: actual-predicted:      0,   17.2, error:   17.2. Current MAE: 40.53, RMSE: 69.62:  32% 378/1190 [3:22:38<6:52:46, 30.50s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([38354, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3282.jpg: actual-predicted:      0,   31.4, error:   31.4. Current MAE: 40.51, RMSE: 69.54:  32% 378/1190 [3:23:10<6:52:46, 30.50s/it]\n",
            "3282.jpg: actual-predicted:      0,   31.4, error:   31.4. Current MAE: 40.51, RMSE: 69.54:  32% 379/1190 [3:23:10<6:54:48, 30.69s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([85198, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3283.jpg: actual-predicted:      0,   47.6, error:   47.6. Current MAE: 40.53, RMSE: 69.49:  32% 379/1190 [3:23:41<6:54:48, 30.69s/it]\n",
            "3283.jpg: actual-predicted:      0,   47.6, error:   47.6. Current MAE: 40.53, RMSE: 69.49:  32% 380/1190 [3:23:41<6:57:31, 30.93s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([49321, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3284.jpg: actual-predicted:      0,   16.2, error:   16.2. Current MAE: 40.46, RMSE: 69.41:  32% 380/1190 [3:24:12<6:57:31, 30.93s/it]\n",
            "3284.jpg: actual-predicted:      0,   16.2, error:   16.2. Current MAE: 40.46, RMSE: 69.41:  32% 381/1190 [3:24:12<6:58:11, 31.02s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([37344, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3285.jpg: actual-predicted:      0,   30.7, error:   30.7. Current MAE: 40.44, RMSE: 69.34:  32% 381/1190 [3:24:43<6:58:11, 31.02s/it]\n",
            "3285.jpg: actual-predicted:      0,   30.7, error:   30.7. Current MAE: 40.44, RMSE: 69.34:  32% 382/1190 [3:24:43<6:58:28, 31.08s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([157257, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3308.jpg: actual-predicted:      0,   40.5, error:   40.5. Current MAE: 40.44, RMSE: 69.28:  32% 382/1190 [3:25:20<6:58:28, 31.08s/it]\n",
            "3308.jpg: actual-predicted:      0,   40.5, error:   40.5. Current MAE: 40.44, RMSE: 69.28:  32% 383/1190 [3:25:20<7:20:50, 32.78s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([131420, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3309.jpg: actual-predicted:      0,   13.7, error:   13.7. Current MAE: 40.37, RMSE: 69.19:  32% 383/1190 [3:25:56<7:20:50, 32.78s/it]\n",
            "3309.jpg: actual-predicted:      0,   13.7, error:   13.7. Current MAE: 40.37, RMSE: 69.19:  32% 384/1190 [3:25:56<7:30:31, 33.54s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64734, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3310.jpg: actual-predicted:      0,   29.2, error:   29.2. Current MAE: 40.34, RMSE: 69.11:  32% 384/1190 [3:26:23<7:30:31, 33.54s/it]\n",
            "3311.jpg: actual-predicted:      0,  131.4, error:  131.4. Current MAE: 40.57, RMSE: 69.35:  32% 385/1190 [3:26:56<7:05:33, 31.72s/it]\n",
            "3311.jpg: actual-predicted:      0,  131.4, error:  131.4. Current MAE: 40.57, RMSE: 69.35:  32% 386/1190 [3:26:56<7:11:21, 32.19s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([77206, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3312.jpg: actual-predicted:      0,   81.3, error:   81.3. Current MAE: 40.68, RMSE: 69.38:  32% 386/1190 [3:27:23<7:11:21, 32.19s/it]\n",
            "3312.jpg: actual-predicted:      0,   81.3, error:   81.3. Current MAE: 40.68, RMSE: 69.38:  33% 387/1190 [3:27:23<6:47:00, 30.41s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([142796, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3313.jpg: actual-predicted:      0,   32.5, error:   32.5. Current MAE: 40.66, RMSE: 69.31:  33% 387/1190 [3:27:50<6:47:00, 30.41s/it]\n",
            "3313.jpg: actual-predicted:      0,   32.5, error:   32.5. Current MAE: 40.66, RMSE: 69.31:  33% 388/1190 [3:27:50<6:32:43, 29.38s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([129156, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3314.jpg: actual-predicted:      0,   45.0, error:   45.0. Current MAE: 40.67, RMSE: 69.26:  33% 388/1190 [3:28:16<6:32:43, 29.38s/it]\n",
            "3315.jpg: actual-predicted:      0,  166.2, error:  166.2. Current MAE: 40.99, RMSE: 69.68:  33% 389/1190 [3:28:43<6:19:34, 28.43s/it]\n",
            "3315.jpg: actual-predicted:      0,  166.2, error:  166.2. Current MAE: 40.99, RMSE: 69.68:  33% 390/1190 [3:28:43<6:15:54, 28.19s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([19476, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3317.jpg: actual-predicted:      0,   30.5, error:   30.5. Current MAE: 40.96, RMSE: 69.61:  33% 390/1190 [3:29:14<6:15:54, 28.19s/it]\n",
            "3318.jpg: actual-predicted:      0,  151.8, error:  151.8. Current MAE: 41.25, RMSE: 69.94:  33% 391/1190 [3:29:44<6:25:45, 28.97s/it]\n",
            "3318.jpg: actual-predicted:      0,  151.8, error:  151.8. Current MAE: 41.25, RMSE: 69.94:  33% 392/1190 [3:29:44<6:28:11, 29.19s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([135330, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3319.jpg: actual-predicted:      0,   31.1, error:   31.1. Current MAE: 41.22, RMSE: 69.87:  33% 392/1190 [3:30:11<6:28:11, 29.19s/it]\n",
            "3319.jpg: actual-predicted:      0,   31.1, error:   31.1. Current MAE: 41.22, RMSE: 69.87:  33% 393/1190 [3:30:11<6:18:29, 28.49s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([56727, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3320.jpg: actual-predicted:      0,  125.1, error:  125.1. Current MAE: 41.43, RMSE: 70.07:  33% 393/1190 [3:30:36<6:18:29, 28.49s/it]\n",
            "3320.jpg: actual-predicted:      0,  125.1, error:  125.1. Current MAE: 41.43, RMSE: 70.07:  33% 394/1190 [3:30:36<6:06:29, 27.63s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([173598, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3321.jpg: actual-predicted:      0,   52.9, error:   52.9. Current MAE: 41.46, RMSE: 70.03:  33% 394/1190 [3:31:12<6:06:29, 27.63s/it]\n",
            "3322.jpg: actual-predicted:      0,  440.7, error:  440.7. Current MAE: 42.47, RMSE: 73.36:  33% 395/1190 [3:31:42<6:38:08, 30.05s/it]\n",
            "3322.jpg: actual-predicted:      0,  440.7, error:  440.7. Current MAE: 42.47, RMSE: 73.36:  33% 396/1190 [3:31:42<6:36:29, 29.96s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([202370, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3323.jpg: actual-predicted:      0,   13.6, error:   13.6. Current MAE: 42.40, RMSE: 73.27:  33% 396/1190 [3:32:19<6:36:29, 29.96s/it]\n",
            "3323.jpg: actual-predicted:      0,   13.6, error:   13.6. Current MAE: 42.40, RMSE: 73.27:  33% 397/1190 [3:32:19<7:04:31, 32.12s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([20492, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3324.jpg: actual-predicted:      0,   14.9, error:   14.9. Current MAE: 42.33, RMSE: 73.19:  33% 397/1190 [3:32:48<7:04:31, 32.12s/it]\n",
            "3324.jpg: actual-predicted:      0,   14.9, error:   14.9. Current MAE: 42.33, RMSE: 73.19:  33% 398/1190 [3:32:48<6:50:19, 31.09s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([41776, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3326.jpg: actual-predicted:      0,   73.6, error:   73.6. Current MAE: 42.41, RMSE: 73.19:  33% 398/1190 [3:33:22<6:50:19, 31.09s/it]\n",
            "3326.jpg: actual-predicted:      0,   73.6, error:   73.6. Current MAE: 42.41, RMSE: 73.19:  34% 399/1190 [3:33:22<7:02:09, 32.02s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([123348, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3327.jpg: actual-predicted:      0,   35.7, error:   35.7. Current MAE: 42.39, RMSE: 73.12:  34% 399/1190 [3:33:48<7:02:09, 32.02s/it]\n",
            "3327.jpg: actual-predicted:      0,   35.7, error:   35.7. Current MAE: 42.39, RMSE: 73.12:  34% 400/1190 [3:33:48<6:39:35, 30.35s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([157690, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3328.jpg: actual-predicted:      0,   81.3, error:   81.3. Current MAE: 42.49, RMSE: 73.14:  34% 400/1190 [3:34:24<6:39:35, 30.35s/it]\n",
            "3328.jpg: actual-predicted:      0,   81.3, error:   81.3. Current MAE: 42.49, RMSE: 73.14:  34% 401/1190 [3:34:24<6:59:02, 31.87s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([117117, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3329.jpg: actual-predicted:      0,  128.4, error:  128.4. Current MAE: 42.70, RMSE: 73.33:  34% 401/1190 [3:34:51<6:59:02, 31.87s/it]\n",
            "3329.jpg: actual-predicted:      0,  128.4, error:  128.4. Current MAE: 42.70, RMSE: 73.33:  34% 402/1190 [3:34:51<6:38:37, 30.35s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([127398, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3330.jpg: actual-predicted:      0,   54.0, error:   54.0. Current MAE: 42.73, RMSE: 73.29:  34% 402/1190 [3:35:26<6:38:37, 30.35s/it]\n",
            "3330.jpg: actual-predicted:      0,   54.0, error:   54.0. Current MAE: 42.73, RMSE: 73.29:  34% 403/1190 [3:35:26<6:56:32, 31.76s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([170312, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3331.jpg: actual-predicted:      0,   94.0, error:   94.0. Current MAE: 42.86, RMSE: 73.34:  34% 403/1190 [3:36:01<6:56:32, 31.76s/it]\n",
            "3331.jpg: actual-predicted:      0,   94.0, error:   94.0. Current MAE: 42.86, RMSE: 73.34:  34% 404/1190 [3:36:01<7:11:07, 32.91s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([140088, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3332.jpg: actual-predicted:      0,   35.5, error:   35.5. Current MAE: 42.84, RMSE: 73.27:  34% 404/1190 [3:36:33<7:11:07, 32.91s/it]\n",
            "3333.jpg: actual-predicted:      0,  110.6, error:  110.6. Current MAE: 43.01, RMSE: 73.39:  34% 405/1190 [3:37:03<7:08:06, 32.72s/it]\n",
            "3333.jpg: actual-predicted:      0,  110.6, error:  110.6. Current MAE: 43.01, RMSE: 73.39:  34% 406/1190 [3:37:03<6:56:52, 31.90s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([189278, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3334.jpg: actual-predicted:      0,   92.3, error:   92.3. Current MAE: 43.13, RMSE: 73.44:  34% 406/1190 [3:37:45<6:56:52, 31.90s/it]\n",
            "3334.jpg: actual-predicted:      0,   92.3, error:   92.3. Current MAE: 43.13, RMSE: 73.44:  34% 407/1190 [3:37:45<7:33:31, 34.75s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([83680, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3335.jpg: actual-predicted:      0,   38.6, error:   38.6. Current MAE: 43.12, RMSE: 73.38:  34% 407/1190 [3:38:14<7:33:31, 34.75s/it]\n",
            "3335.jpg: actual-predicted:      0,   38.6, error:   38.6. Current MAE: 43.12, RMSE: 73.38:  34% 408/1190 [3:38:14<7:11:28, 33.11s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([172946, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3336.jpg: actual-predicted:      0,   45.2, error:   45.2. Current MAE: 43.12, RMSE: 73.32:  34% 408/1190 [3:38:51<7:11:28, 33.11s/it]\n",
            "3336.jpg: actual-predicted:      0,   45.2, error:   45.2. Current MAE: 43.12, RMSE: 73.32:  34% 409/1190 [3:38:51<7:24:59, 34.19s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([189852, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3337.jpg: actual-predicted:      0,  123.6, error:  123.6. Current MAE: 43.32, RMSE: 73.49:  34% 409/1190 [3:39:27<7:24:59, 34.19s/it]\n",
            "3337.jpg: actual-predicted:      0,  123.6, error:  123.6. Current MAE: 43.32, RMSE: 73.49:  34% 410/1190 [3:39:27<7:31:48, 34.75s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([118735, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3338.jpg: actual-predicted:      0,  168.5, error:  168.5. Current MAE: 43.62, RMSE: 73.87:  34% 410/1190 [3:39:54<7:31:48, 34.75s/it]\n",
            "3339.jpg: actual-predicted:      0,   34.4, error:   34.4. Current MAE: 43.60, RMSE: 73.80:  35% 411/1190 [3:40:28<7:00:17, 32.37s/it]\n",
            "3341.jpg: actual-predicted:      0,   47.0, error:   47.0. Current MAE: 43.61, RMSE: 73.74:  35% 412/1190 [3:40:57<7:08:20, 33.03s/it]\n",
            "3341.jpg: actual-predicted:      0,   47.0, error:   47.0. Current MAE: 43.61, RMSE: 73.74:  35% 413/1190 [3:40:57<6:49:14, 31.60s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([26288, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3342.jpg: actual-predicted:      0,   11.1, error:   11.1. Current MAE: 43.53, RMSE: 73.65:  35% 413/1190 [3:41:36<6:49:14, 31.60s/it]\n",
            "3342.jpg: actual-predicted:      0,   11.1, error:   11.1. Current MAE: 43.53, RMSE: 73.65:  35% 414/1190 [3:41:36<7:18:11, 33.88s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([127762, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3424.jpg: actual-predicted:      0,    8.2, error:    8.2. Current MAE: 43.44, RMSE: 73.57:  35% 414/1190 [3:42:17<7:18:11, 33.88s/it]\n",
            "3493.jpg: actual-predicted:      0,   17.9, error:   17.9. Current MAE: 43.38, RMSE: 73.48:  35% 415/1190 [3:42:51<7:46:36, 36.12s/it]\n",
            "3493.jpg: actual-predicted:      0,   17.9, error:   17.9. Current MAE: 43.38, RMSE: 73.48:  35% 416/1190 [3:42:51<7:37:27, 35.46s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([24928, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3494.jpg: actual-predicted:      0,   18.9, error:   18.9. Current MAE: 43.32, RMSE: 73.40:  35% 416/1190 [3:43:16<7:37:27, 35.46s/it]\n",
            "3494.jpg: actual-predicted:      0,   18.9, error:   18.9. Current MAE: 43.32, RMSE: 73.40:  35% 417/1190 [3:43:16<6:57:50, 32.43s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([16471, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3495.jpg: actual-predicted:      0,   49.9, error:   49.9. Current MAE: 43.34, RMSE: 73.35:  35% 417/1190 [3:43:48<6:57:50, 32.43s/it]\n",
            "3495.jpg: actual-predicted:      0,   49.9, error:   49.9. Current MAE: 43.34, RMSE: 73.35:  35% 418/1190 [3:43:48<6:54:05, 32.18s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([55599, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3496.jpg: actual-predicted:      0,   73.4, error:   73.4. Current MAE: 43.41, RMSE: 73.35:  35% 418/1190 [3:44:14<6:54:05, 32.18s/it]\n",
            "3496.jpg: actual-predicted:      0,   73.4, error:   73.4. Current MAE: 43.41, RMSE: 73.35:  35% 419/1190 [3:44:14<6:27:55, 30.19s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([80249, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3497.jpg: actual-predicted:      0,   28.0, error:   28.0. Current MAE: 43.37, RMSE: 73.28:  35% 419/1190 [3:44:49<6:27:55, 30.19s/it]\n",
            "3497.jpg: actual-predicted:      0,   28.0, error:   28.0. Current MAE: 43.37, RMSE: 73.28:  35% 420/1190 [3:44:49<6:49:21, 31.90s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([59923, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3498.jpg: actual-predicted:      0,   78.9, error:   78.9. Current MAE: 43.46, RMSE: 73.29:  35% 420/1190 [3:45:20<6:49:21, 31.90s/it]\n",
            "3499.jpg: actual-predicted:      0,   49.1, error:   49.1. Current MAE: 43.47, RMSE: 73.25:  35% 421/1190 [3:45:54<6:44:19, 31.55s/it]\n",
            "3499.jpg: actual-predicted:      0,   49.1, error:   49.1. Current MAE: 43.47, RMSE: 73.25:  35% 422/1190 [3:45:54<6:51:27, 32.15s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([139974, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3500.jpg: actual-predicted:      0,   14.8, error:   14.8. Current MAE: 43.40, RMSE: 73.16:  35% 422/1190 [3:46:32<6:51:27, 32.15s/it]\n",
            "3500.jpg: actual-predicted:      0,   14.8, error:   14.8. Current MAE: 43.40, RMSE: 73.16:  36% 423/1190 [3:46:32<7:12:48, 33.86s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([130206, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3501.jpg: actual-predicted:      0,   38.5, error:   38.5. Current MAE: 43.39, RMSE: 73.10:  36% 423/1190 [3:47:05<7:12:48, 33.86s/it]\n",
            "3501.jpg: actual-predicted:      0,   38.5, error:   38.5. Current MAE: 43.39, RMSE: 73.10:  36% 424/1190 [3:47:05<7:09:28, 33.64s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([103534, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3502.jpg: actual-predicted:      0,   34.7, error:   34.7. Current MAE: 43.37, RMSE: 73.03:  36% 424/1190 [3:47:31<7:09:28, 33.64s/it]\n",
            "3502.jpg: actual-predicted:      0,   34.7, error:   34.7. Current MAE: 43.37, RMSE: 73.03:  36% 425/1190 [3:47:31<6:40:38, 31.42s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([114082, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3643.jpg: actual-predicted:      0,   29.6, error:   29.6. Current MAE: 43.34, RMSE: 72.96:  36% 425/1190 [3:48:07<6:40:38, 31.42s/it]\n",
            "3643.jpg: actual-predicted:      0,   29.6, error:   29.6. Current MAE: 43.34, RMSE: 72.96:  36% 426/1190 [3:48:07<6:57:43, 32.81s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([129451, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3644.jpg: actual-predicted:      0,   13.6, error:   13.6. Current MAE: 43.27, RMSE: 72.88:  36% 426/1190 [3:48:43<6:57:43, 32.81s/it]\n",
            "3644.jpg: actual-predicted:      0,   13.6, error:   13.6. Current MAE: 43.27, RMSE: 72.88:  36% 427/1190 [3:48:43<7:11:25, 33.93s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([41871, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3645.jpg: actual-predicted:      0,   29.9, error:   29.9. Current MAE: 43.24, RMSE: 72.81:  36% 427/1190 [3:49:13<7:11:25, 33.93s/it]\n",
            "3645.jpg: actual-predicted:      0,   29.9, error:   29.9. Current MAE: 43.24, RMSE: 72.81:  36% 428/1190 [3:49:13<6:52:16, 32.46s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([114046, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3646.jpg: actual-predicted:      0,   19.4, error:   19.4. Current MAE: 43.18, RMSE: 72.73:  36% 428/1190 [3:49:39<6:52:16, 32.46s/it]\n",
            "3646.jpg: actual-predicted:      0,   19.4, error:   19.4. Current MAE: 43.18, RMSE: 72.73:  36% 429/1190 [3:49:39<6:28:58, 30.67s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([82077, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3647.jpg: actual-predicted:      0,   58.6, error:   58.6. Current MAE: 43.22, RMSE: 72.70:  36% 429/1190 [3:50:14<6:28:58, 30.67s/it]\n",
            "3647.jpg: actual-predicted:      0,   58.6, error:   58.6. Current MAE: 43.22, RMSE: 72.70:  36% 430/1190 [3:50:14<6:43:22, 31.85s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([78005, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3648.jpg: actual-predicted:      0,   14.7, error:   14.7. Current MAE: 43.15, RMSE: 72.62:  36% 430/1190 [3:50:40<6:43:22, 31.85s/it]\n",
            "3648.jpg: actual-predicted:      0,   14.7, error:   14.7. Current MAE: 43.15, RMSE: 72.62:  36% 431/1190 [3:50:40<6:21:08, 30.13s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([97921, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3649.jpg: actual-predicted:      0,   17.1, error:   17.1. Current MAE: 43.09, RMSE: 72.54:  36% 431/1190 [3:51:15<6:21:08, 30.13s/it]\n",
            "3649.jpg: actual-predicted:      0,   17.1, error:   17.1. Current MAE: 43.09, RMSE: 72.54:  36% 432/1190 [3:51:15<6:38:45, 31.56s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([115130, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3650.jpg: actual-predicted:      0,   20.3, error:   20.3. Current MAE: 43.04, RMSE: 72.46:  36% 432/1190 [3:51:46<6:38:45, 31.56s/it]\n",
            "3650.jpg: actual-predicted:      0,   20.3, error:   20.3. Current MAE: 43.04, RMSE: 72.46:  36% 433/1190 [3:51:46<6:38:57, 31.62s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([57580, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3651.jpg: actual-predicted:      0,    9.6, error:    9.6. Current MAE: 42.96, RMSE: 72.38:  36% 433/1190 [3:52:11<6:38:57, 31.62s/it]\n",
            "3651.jpg: actual-predicted:      0,    9.6, error:    9.6. Current MAE: 42.96, RMSE: 72.38:  36% 434/1190 [3:52:11<6:12:48, 29.59s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([129989, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3652.jpg: actual-predicted:      0,   24.6, error:   24.6. Current MAE: 42.92, RMSE: 72.31:  36% 434/1190 [3:52:52<6:12:48, 29.59s/it]\n",
            "3652.jpg: actual-predicted:      0,   24.6, error:   24.6. Current MAE: 42.92, RMSE: 72.31:  37% 435/1190 [3:52:52<6:55:32, 33.02s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([102678, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3653.jpg: actual-predicted:      0,   39.7, error:   39.7. Current MAE: 42.91, RMSE: 72.25:  37% 435/1190 [3:53:20<6:55:32, 33.02s/it]\n",
            "3653.jpg: actual-predicted:      0,   39.7, error:   39.7. Current MAE: 42.91, RMSE: 72.25:  37% 436/1190 [3:53:20<6:33:57, 31.35s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([47906, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3655.jpg: actual-predicted:      0,    8.1, error:    8.1. Current MAE: 42.83, RMSE: 72.17:  37% 436/1190 [3:53:44<6:33:57, 31.35s/it]\n",
            "3655.jpg: actual-predicted:      0,    8.1, error:    8.1. Current MAE: 42.83, RMSE: 72.17:  37% 437/1190 [3:53:44<6:08:16, 29.34s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([168129, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3656.jpg: actual-predicted:      0,   49.6, error:   49.6. Current MAE: 42.85, RMSE: 72.12:  37% 437/1190 [3:54:20<6:08:16, 29.34s/it]\n",
            "3656.jpg: actual-predicted:      0,   49.6, error:   49.6. Current MAE: 42.85, RMSE: 72.12:  37% 438/1190 [3:54:20<6:30:34, 31.16s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([69667, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3657.jpg: actual-predicted:      0,   23.3, error:   23.3. Current MAE: 42.80, RMSE: 72.05:  37% 438/1190 [3:54:44<6:30:34, 31.16s/it]\n",
            "3657.jpg: actual-predicted:      0,   23.3, error:   23.3. Current MAE: 42.80, RMSE: 72.05:  37% 439/1190 [3:54:44<6:05:33, 29.21s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([155746, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3658.jpg: actual-predicted:      0,   14.2, error:   14.2. Current MAE: 42.74, RMSE: 71.97:  37% 439/1190 [3:55:20<6:05:33, 29.21s/it]\n",
            "3659.jpg: actual-predicted:      0,   15.6, error:   15.6. Current MAE: 42.68, RMSE: 71.89:  37% 440/1190 [3:55:43<6:27:29, 31.00s/it]\n",
            "3659.jpg: actual-predicted:      0,   15.6, error:   15.6. Current MAE: 42.68, RMSE: 71.89:  37% 441/1190 [3:55:43<5:58:00, 28.68s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([71675, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3693.jpg: actual-predicted:      0,   42.8, error:   42.8. Current MAE: 42.68, RMSE: 71.84:  37% 441/1190 [3:56:22<5:58:00, 28.68s/it]\n",
            "3693.jpg: actual-predicted:      0,   42.8, error:   42.8. Current MAE: 42.68, RMSE: 71.84:  37% 442/1190 [3:56:22<6:34:59, 31.68s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([25009, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3694.jpg: actual-predicted:      0,   25.5, error:   25.5. Current MAE: 42.64, RMSE: 71.77:  37% 442/1190 [3:56:55<6:34:59, 31.68s/it]\n",
            "3694.jpg: actual-predicted:      0,   25.5, error:   25.5. Current MAE: 42.64, RMSE: 71.77:  37% 443/1190 [3:56:55<6:42:46, 32.35s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([70832, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3695.jpg: actual-predicted:      0,   19.9, error:   19.9. Current MAE: 42.59, RMSE: 71.70:  37% 443/1190 [3:57:21<6:42:46, 32.35s/it]\n",
            "3695.jpg: actual-predicted:      0,   19.9, error:   19.9. Current MAE: 42.59, RMSE: 71.70:  37% 444/1190 [3:57:21<6:17:43, 30.38s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([20573, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3696.jpg: actual-predicted:      0,   10.3, error:   10.3. Current MAE: 42.52, RMSE: 71.62:  37% 444/1190 [3:57:47<6:17:43, 30.38s/it]\n",
            "3696.jpg: actual-predicted:      0,   10.3, error:   10.3. Current MAE: 42.52, RMSE: 71.62:  37% 445/1190 [3:57:47<6:00:24, 29.03s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([14368, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "3697.jpg: actual-predicted:      0,    8.3, error:    8.3. Current MAE: 42.44, RMSE: 71.54:  37% 445/1190 [3:58:13<6:00:24, 29.03s/it]\n",
            "3698.jpg: actual-predicted:      0,   90.0, error:   90.0. Current MAE: 42.54, RMSE: 71.58:  37% 446/1190 [3:58:42<5:47:10, 28.00s/it]\n",
            "3698.jpg: actual-predicted:      0,   90.0, error:   90.0. Current MAE: 42.54, RMSE: 71.58:  38% 447/1190 [3:58:42<5:52:38, 28.48s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([115439, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4061.jpg: actual-predicted:      0,   85.5, error:   85.5. Current MAE: 42.64, RMSE: 71.62:  38% 447/1190 [3:59:14<5:52:38, 28.48s/it]\n",
            "4061.jpg: actual-predicted:      0,   85.5, error:   85.5. Current MAE: 42.64, RMSE: 71.62:  38% 448/1190 [3:59:14<6:03:13, 29.37s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([65915, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4062.jpg: actual-predicted:      0,  234.8, error:  234.8. Current MAE: 43.07, RMSE: 72.39:  38% 448/1190 [3:59:45<6:03:13, 29.37s/it]\n",
            "4062.jpg: actual-predicted:      0,  234.8, error:  234.8. Current MAE: 43.07, RMSE: 72.39:  38% 449/1190 [3:59:45<6:09:23, 29.91s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([101349, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4063.jpg: actual-predicted:      0,   12.7, error:   12.7. Current MAE: 43.00, RMSE: 72.31:  38% 449/1190 [4:00:10<6:09:23, 29.91s/it]\n",
            "4064.jpg: actual-predicted:      0,  137.0, error:  137.0. Current MAE: 43.21, RMSE: 72.52:  38% 450/1190 [4:00:40<5:50:38, 28.43s/it]\n",
            "4064.jpg: actual-predicted:      0,  137.0, error:  137.0. Current MAE: 43.21, RMSE: 72.52:  38% 451/1190 [4:00:40<5:55:17, 28.85s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([53671, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4065.jpg: actual-predicted:      0,   44.8, error:   44.8. Current MAE: 43.21, RMSE: 72.47:  38% 451/1190 [4:01:05<5:55:17, 28.85s/it]\n",
            "4065.jpg: actual-predicted:      0,   44.8, error:   44.8. Current MAE: 43.21, RMSE: 72.47:  38% 452/1190 [4:01:05<5:42:20, 27.83s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([101151, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4066.jpg: actual-predicted:      0,   10.0, error:   10.0. Current MAE: 43.14, RMSE: 72.39:  38% 452/1190 [4:01:38<5:42:20, 27.83s/it]\n",
            "4066.jpg: actual-predicted:      0,   10.0, error:   10.0. Current MAE: 43.14, RMSE: 72.39:  38% 453/1190 [4:01:38<6:01:57, 29.47s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([85160, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4067.jpg: actual-predicted:      0,   38.4, error:   38.4. Current MAE: 43.13, RMSE: 72.34:  38% 453/1190 [4:02:11<6:01:57, 29.47s/it]\n",
            "4067.jpg: actual-predicted:      0,   38.4, error:   38.4. Current MAE: 43.13, RMSE: 72.34:  38% 454/1190 [4:02:11<6:11:22, 30.28s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([108361, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4068.jpg: actual-predicted:      0,   12.6, error:   12.6. Current MAE: 43.06, RMSE: 72.26:  38% 454/1190 [4:02:42<6:11:22, 30.28s/it]\n",
            "4068.jpg: actual-predicted:      0,   12.6, error:   12.6. Current MAE: 43.06, RMSE: 72.26:  38% 455/1190 [4:02:42<6:15:42, 30.67s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([27333, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4069.jpg: actual-predicted:      0,  135.4, error:  135.4. Current MAE: 43.27, RMSE: 72.46:  38% 455/1190 [4:03:07<6:15:42, 30.67s/it]\n",
            "4069.jpg: actual-predicted:      0,  135.4, error:  135.4. Current MAE: 43.27, RMSE: 72.46:  38% 456/1190 [4:03:07<5:54:48, 29.00s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([106230, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4070.jpg: actual-predicted:      0,   53.5, error:   53.5. Current MAE: 43.29, RMSE: 72.42:  38% 456/1190 [4:03:48<5:54:48, 29.00s/it]\n",
            "4070.jpg: actual-predicted:      0,   53.5, error:   53.5. Current MAE: 43.29, RMSE: 72.42:  38% 457/1190 [4:03:48<6:35:49, 32.40s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([95452, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4071.jpg: actual-predicted:      0,   63.1, error:   63.1. Current MAE: 43.33, RMSE: 72.40:  38% 457/1190 [4:04:14<6:35:49, 32.40s/it]\n",
            "4071.jpg: actual-predicted:      0,   63.1, error:   63.1. Current MAE: 43.33, RMSE: 72.40:  38% 458/1190 [4:04:14<6:12:18, 30.52s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([110665, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4072.jpg: actual-predicted:      0,   11.2, error:   11.2. Current MAE: 43.26, RMSE: 72.32:  38% 458/1190 [4:04:46<6:12:18, 30.52s/it]\n",
            "4072.jpg: actual-predicted:      0,   11.2, error:   11.2. Current MAE: 43.26, RMSE: 72.32:  39% 459/1190 [4:04:46<6:17:31, 30.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([42183, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4073.jpg: actual-predicted:      0,   29.5, error:   29.5. Current MAE: 43.23, RMSE: 72.26:  39% 459/1190 [4:05:12<6:17:31, 30.99s/it]\n",
            "4073.jpg: actual-predicted:      0,   29.5, error:   29.5. Current MAE: 43.23, RMSE: 72.26:  39% 460/1190 [4:05:12<5:58:31, 29.47s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([80125, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4074.jpg: actual-predicted:      0,   28.4, error:   28.4. Current MAE: 43.20, RMSE: 72.19:  39% 460/1190 [4:05:43<5:58:31, 29.47s/it]\n",
            "4074.jpg: actual-predicted:      0,   28.4, error:   28.4. Current MAE: 43.20, RMSE: 72.19:  39% 461/1190 [4:05:43<6:04:03, 29.96s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([72441, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4077.jpg: actual-predicted:      0,  126.9, error:  126.9. Current MAE: 43.38, RMSE: 72.36:  39% 461/1190 [4:06:24<6:04:03, 29.96s/it]\n",
            "4077.jpg: actual-predicted:      0,  126.9, error:  126.9. Current MAE: 43.38, RMSE: 72.36:  39% 462/1190 [4:06:24<6:43:10, 33.23s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([112995, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4078.jpg: actual-predicted:      0,   59.0, error:   59.0. Current MAE: 43.41, RMSE: 72.33:  39% 462/1190 [4:07:00<6:43:10, 33.23s/it]\n",
            "4078.jpg: actual-predicted:      0,   59.0, error:   59.0. Current MAE: 43.41, RMSE: 72.33:  39% 463/1190 [4:07:00<6:52:39, 34.06s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([76666, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4079.jpg: actual-predicted:      0,   29.1, error:   29.1. Current MAE: 43.38, RMSE: 72.26:  39% 463/1190 [4:07:31<6:52:39, 34.06s/it]\n",
            "4079.jpg: actual-predicted:      0,   29.1, error:   29.1. Current MAE: 43.38, RMSE: 72.26:  39% 464/1190 [4:07:31<6:41:32, 33.19s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([84464, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4080.jpg: actual-predicted:      0,   48.0, error:   48.0. Current MAE: 43.39, RMSE: 72.22:  39% 464/1190 [4:07:57<6:41:32, 33.19s/it]\n",
            "4080.jpg: actual-predicted:      0,   48.0, error:   48.0. Current MAE: 43.39, RMSE: 72.22:  39% 465/1190 [4:07:57<6:14:18, 30.98s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([60245, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4082.jpg: actual-predicted:      0,   94.5, error:   94.5. Current MAE: 43.50, RMSE: 72.28:  39% 465/1190 [4:08:22<6:14:18, 30.98s/it]\n",
            "4082.jpg: actual-predicted:      0,   94.5, error:   94.5. Current MAE: 43.50, RMSE: 72.28:  39% 466/1190 [4:08:22<5:53:58, 29.34s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([6543, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4083.jpg: actual-predicted:      0,   71.6, error:   71.6. Current MAE: 43.56, RMSE: 72.27:  39% 466/1190 [4:08:47<5:53:58, 29.34s/it]\n",
            "4083.jpg: actual-predicted:      0,   71.6, error:   71.6. Current MAE: 43.56, RMSE: 72.27:  39% 467/1190 [4:08:47<5:37:32, 28.01s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([184713, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4084.jpg: actual-predicted:      0,   13.5, error:   13.5. Current MAE: 43.50, RMSE: 72.20:  39% 467/1190 [4:09:25<5:37:32, 28.01s/it]\n",
            "4084.jpg: actual-predicted:      0,   13.5, error:   13.5. Current MAE: 43.50, RMSE: 72.20:  39% 468/1190 [4:09:25<6:14:12, 31.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([85354, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4085.jpg: actual-predicted:      0,   81.1, error:   81.1. Current MAE: 43.58, RMSE: 72.22:  39% 468/1190 [4:09:58<6:14:12, 31.10s/it]\n",
            "4085.jpg: actual-predicted:      0,   81.1, error:   81.1. Current MAE: 43.58, RMSE: 72.22:  39% 469/1190 [4:09:58<6:18:23, 31.49s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([89475, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4086.jpg: actual-predicted:      0,   13.5, error:   13.5. Current MAE: 43.51, RMSE: 72.15:  39% 469/1190 [4:10:23<6:18:23, 31.49s/it]\n",
            "4086.jpg: actual-predicted:      0,   13.5, error:   13.5. Current MAE: 43.51, RMSE: 72.15:  39% 470/1190 [4:10:23<5:53:39, 29.47s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17763, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4087.jpg: actual-predicted:      0,  116.3, error:  116.3. Current MAE: 43.67, RMSE: 72.27:  39% 470/1190 [4:10:48<5:53:39, 29.47s/it]\n",
            "4087.jpg: actual-predicted:      0,  116.3, error:  116.3. Current MAE: 43.67, RMSE: 72.27:  40% 471/1190 [4:10:48<5:38:09, 28.22s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([108707, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4088.jpg: actual-predicted:      0,   21.3, error:   21.3. Current MAE: 43.62, RMSE: 72.20:  40% 471/1190 [4:11:21<5:38:09, 28.22s/it]\n",
            "4088.jpg: actual-predicted:      0,   21.3, error:   21.3. Current MAE: 43.62, RMSE: 72.20:  40% 472/1190 [4:11:21<5:54:03, 29.59s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([73927, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4089.jpg: actual-predicted:      0,   54.0, error:   54.0. Current MAE: 43.64, RMSE: 72.16:  40% 472/1190 [4:12:04<5:54:03, 29.59s/it]\n",
            "4089.jpg: actual-predicted:      0,   54.0, error:   54.0. Current MAE: 43.64, RMSE: 72.16:  40% 473/1190 [4:12:04<6:41:43, 33.62s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([63296, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4110.jpg: actual-predicted:      0,   11.9, error:   11.9. Current MAE: 43.58, RMSE: 72.09:  40% 473/1190 [4:12:30<6:41:43, 33.62s/it]\n",
            "4110.jpg: actual-predicted:      0,   11.9, error:   11.9. Current MAE: 43.58, RMSE: 72.09:  40% 474/1190 [4:12:30<6:13:14, 31.28s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([105617, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4111.jpg: actual-predicted:      0,   23.8, error:   23.8. Current MAE: 43.53, RMSE: 72.02:  40% 474/1190 [4:12:56<6:13:14, 31.28s/it]\n",
            "4111.jpg: actual-predicted:      0,   23.8, error:   23.8. Current MAE: 43.53, RMSE: 72.02:  40% 475/1190 [4:12:56<5:54:44, 29.77s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([78706, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4112.jpg: actual-predicted:      0,   15.0, error:   15.0. Current MAE: 43.47, RMSE: 71.95:  40% 475/1190 [4:13:31<5:54:44, 29.77s/it]\n",
            "4112.jpg: actual-predicted:      0,   15.0, error:   15.0. Current MAE: 43.47, RMSE: 71.95:  40% 476/1190 [4:13:31<6:12:25, 31.30s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([52584, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4113.jpg: actual-predicted:      0,   29.2, error:   29.2. Current MAE: 43.44, RMSE: 71.89:  40% 476/1190 [4:14:02<6:12:25, 31.30s/it]\n",
            "4113.jpg: actual-predicted:      0,   29.2, error:   29.2. Current MAE: 43.44, RMSE: 71.89:  40% 477/1190 [4:14:02<6:13:13, 31.41s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([131705, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4114.jpg: actual-predicted:      0,   14.0, error:   14.0. Current MAE: 43.38, RMSE: 71.82:  40% 477/1190 [4:14:38<6:13:13, 31.41s/it]\n",
            "4114.jpg: actual-predicted:      0,   14.0, error:   14.0. Current MAE: 43.38, RMSE: 71.82:  40% 478/1190 [4:14:38<6:26:06, 32.54s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([189043, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4115.jpg: actual-predicted:      0,   12.2, error:   12.2. Current MAE: 43.32, RMSE: 71.74:  40% 478/1190 [4:15:13<6:26:06, 32.54s/it]\n",
            "4115.jpg: actual-predicted:      0,   12.2, error:   12.2. Current MAE: 43.32, RMSE: 71.74:  40% 479/1190 [4:15:13<6:36:10, 33.43s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([135940, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4116.jpg: actual-predicted:      0,   10.3, error:   10.3. Current MAE: 43.25, RMSE: 71.67:  40% 479/1190 [4:15:46<6:36:10, 33.43s/it]\n",
            "4116.jpg: actual-predicted:      0,   10.3, error:   10.3. Current MAE: 43.25, RMSE: 71.67:  40% 480/1190 [4:15:46<6:34:59, 33.38s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([174599, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4118.jpg: actual-predicted:      0,   13.2, error:   13.2. Current MAE: 43.19, RMSE: 71.60:  40% 480/1190 [4:16:22<6:34:59, 33.38s/it]\n",
            "4118.jpg: actual-predicted:      0,   13.2, error:   13.2. Current MAE: 43.19, RMSE: 71.60:  40% 481/1190 [4:16:22<6:41:43, 34.00s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([63954, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4119.jpg: actual-predicted:      0,   13.4, error:   13.4. Current MAE: 43.13, RMSE: 71.53:  40% 481/1190 [4:16:57<6:41:43, 34.00s/it]\n",
            "4119.jpg: actual-predicted:      0,   13.4, error:   13.4. Current MAE: 43.13, RMSE: 71.53:  41% 482/1190 [4:16:57<6:44:01, 34.24s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([57367, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4120.jpg: actual-predicted:      0,   29.0, error:   29.0. Current MAE: 43.10, RMSE: 71.46:  41% 482/1190 [4:17:29<6:44:01, 34.24s/it]\n",
            "4120.jpg: actual-predicted:      0,   29.0, error:   29.0. Current MAE: 43.10, RMSE: 71.46:  41% 483/1190 [4:17:29<6:38:28, 33.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([115007, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4121.jpg: actual-predicted:      0,    9.2, error:    9.2. Current MAE: 43.03, RMSE: 71.39:  41% 483/1190 [4:18:10<6:38:28, 33.82s/it]\n",
            "4121.jpg: actual-predicted:      0,    9.2, error:    9.2. Current MAE: 43.03, RMSE: 71.39:  41% 484/1190 [4:18:10<7:03:05, 35.96s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([93624, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4122.jpg: actual-predicted:      0,    9.4, error:    9.4. Current MAE: 42.96, RMSE: 71.32:  41% 484/1190 [4:18:45<7:03:05, 35.96s/it]\n",
            "4122.jpg: actual-predicted:      0,    9.4, error:    9.4. Current MAE: 42.96, RMSE: 71.32:  41% 485/1190 [4:18:45<6:59:47, 35.73s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([159923, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4123.jpg: actual-predicted:      0,   17.8, error:   17.8. Current MAE: 42.90, RMSE: 71.25:  41% 485/1190 [4:19:25<6:59:47, 35.73s/it]\n",
            "4123.jpg: actual-predicted:      0,   17.8, error:   17.8. Current MAE: 42.90, RMSE: 71.25:  41% 486/1190 [4:19:25<7:11:31, 36.78s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([57883, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4170.jpg: actual-predicted:      0,   38.5, error:   38.5. Current MAE: 42.90, RMSE: 71.20:  41% 486/1190 [4:19:59<7:11:31, 36.78s/it]\n",
            "4170.jpg: actual-predicted:      0,   38.5, error:   38.5. Current MAE: 42.90, RMSE: 71.20:  41% 487/1190 [4:19:59<7:02:31, 36.06s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([90746, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4173.jpg: actual-predicted:      0,    5.7, error:    5.7. Current MAE: 42.82, RMSE: 71.13:  41% 487/1190 [4:20:31<7:02:31, 36.06s/it]\n",
            "4173.jpg: actual-predicted:      0,    5.7, error:    5.7. Current MAE: 42.82, RMSE: 71.13:  41% 488/1190 [4:20:31<6:46:38, 34.76s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([132132, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4174.jpg: actual-predicted:      0,   14.6, error:   14.6. Current MAE: 42.76, RMSE: 71.06:  41% 488/1190 [4:21:02<6:46:38, 34.76s/it]\n",
            "4174.jpg: actual-predicted:      0,   14.6, error:   14.6. Current MAE: 42.76, RMSE: 71.06:  41% 489/1190 [4:21:02<6:34:43, 33.79s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([9214, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4175.jpg: actual-predicted:      0,   10.6, error:   10.6. Current MAE: 42.70, RMSE: 70.98:  41% 489/1190 [4:21:29<6:34:43, 33.79s/it]\n",
            "4175.jpg: actual-predicted:      0,   10.6, error:   10.6. Current MAE: 42.70, RMSE: 70.98:  41% 490/1190 [4:21:29<6:07:44, 31.52s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([96802, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4283.jpg: actual-predicted:      0,   69.6, error:   69.6. Current MAE: 42.75, RMSE: 70.98:  41% 490/1190 [4:21:55<6:07:44, 31.52s/it]\n",
            "4283.jpg: actual-predicted:      0,   69.6, error:   69.6. Current MAE: 42.75, RMSE: 70.98:  41% 491/1190 [4:21:55<5:47:45, 29.85s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([42118, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4284.jpg: actual-predicted:      0,   80.8, error:   80.8. Current MAE: 42.83, RMSE: 71.00:  41% 491/1190 [4:22:18<5:47:45, 29.85s/it]\n",
            "4284.jpg: actual-predicted:      0,   80.8, error:   80.8. Current MAE: 42.83, RMSE: 71.00:  41% 492/1190 [4:22:18<5:26:28, 28.06s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([134754, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4285.jpg: actual-predicted:      0,   84.6, error:   84.6. Current MAE: 42.91, RMSE: 71.03:  41% 492/1190 [4:22:45<5:26:28, 28.06s/it]\n",
            "4285.jpg: actual-predicted:      0,   84.6, error:   84.6. Current MAE: 42.91, RMSE: 71.03:  41% 493/1190 [4:22:45<5:19:50, 27.53s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1022, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4286.jpg: actual-predicted:      0,  292.6, error:  292.6. Current MAE: 43.42, RMSE: 72.17:  41% 493/1190 [4:23:18<5:19:50, 27.53s/it]\n",
            "4286.jpg: actual-predicted:      0,  292.6, error:  292.6. Current MAE: 43.42, RMSE: 72.17:  42% 494/1190 [4:23:18<5:40:32, 29.36s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([100151, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4287.jpg: actual-predicted:      0,   28.4, error:   28.4. Current MAE: 43.39, RMSE: 72.11:  42% 494/1190 [4:23:43<5:40:32, 29.36s/it]\n",
            "4287.jpg: actual-predicted:      0,   28.4, error:   28.4. Current MAE: 43.39, RMSE: 72.11:  42% 495/1190 [4:23:43<5:24:34, 28.02s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([15164, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4288.jpg: actual-predicted:      0,   66.5, error:   66.5. Current MAE: 43.43, RMSE: 72.10:  42% 495/1190 [4:24:11<5:24:34, 28.02s/it]\n",
            "4288.jpg: actual-predicted:      0,   66.5, error:   66.5. Current MAE: 43.43, RMSE: 72.10:  42% 496/1190 [4:24:11<5:23:21, 27.96s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17198, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4289.jpg: actual-predicted:      0,   21.7, error:   21.7. Current MAE: 43.39, RMSE: 72.03:  42% 496/1190 [4:24:43<5:23:21, 27.96s/it]\n",
            "4289.jpg: actual-predicted:      0,   21.7, error:   21.7. Current MAE: 43.39, RMSE: 72.03:  42% 497/1190 [4:24:43<5:37:55, 29.26s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([76185, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4290.jpg: actual-predicted:      0,   39.1, error:   39.1. Current MAE: 43.38, RMSE: 71.98:  42% 497/1190 [4:25:09<5:37:55, 29.26s/it]\n",
            "4290.jpg: actual-predicted:      0,   39.1, error:   39.1. Current MAE: 43.38, RMSE: 71.98:  42% 498/1190 [4:25:09<5:26:04, 28.27s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([136174, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4291.jpg: actual-predicted:      0,  271.9, error:  271.9. Current MAE: 43.84, RMSE: 72.93:  42% 498/1190 [4:25:44<5:26:04, 28.27s/it]\n",
            "4291.jpg: actual-predicted:      0,  271.9, error:  271.9. Current MAE: 43.84, RMSE: 72.93:  42% 499/1190 [4:25:44<5:48:59, 30.30s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([137428, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4292.jpg: actual-predicted:      0,   12.4, error:   12.4. Current MAE: 43.78, RMSE: 72.86:  42% 499/1190 [4:26:21<5:48:59, 30.30s/it]\n",
            "4292.jpg: actual-predicted:      0,   12.4, error:   12.4. Current MAE: 43.78, RMSE: 72.86:  42% 500/1190 [4:26:21<6:09:11, 32.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17182, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4294.jpg: actual-predicted:      0,  136.1, error:  136.1. Current MAE: 43.96, RMSE: 73.04:  42% 500/1190 [4:26:48<6:09:11, 32.10s/it]\n",
            "4294.jpg: actual-predicted:      0,  136.1, error:  136.1. Current MAE: 43.96, RMSE: 73.04:  42% 501/1190 [4:26:48<5:53:28, 30.78s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([82965, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4295.jpg: actual-predicted:      0,   84.1, error:   84.1. Current MAE: 44.04, RMSE: 73.07:  42% 501/1190 [4:27:13<5:53:28, 30.78s/it]\n",
            "4295.jpg: actual-predicted:      0,   84.1, error:   84.1. Current MAE: 44.04, RMSE: 73.07:  42% 502/1190 [4:27:13<5:30:30, 28.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([22728, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4296.jpg: actual-predicted:      0,   29.9, error:   29.9. Current MAE: 44.01, RMSE: 73.01:  42% 502/1190 [4:27:44<5:30:30, 28.82s/it]\n",
            "4296.jpg: actual-predicted:      0,   29.9, error:   29.9. Current MAE: 44.01, RMSE: 73.01:  42% 503/1190 [4:27:44<5:39:29, 29.65s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([18999, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4297.jpg: actual-predicted:      0,   78.2, error:   78.2. Current MAE: 44.08, RMSE: 73.02:  42% 503/1190 [4:28:15<5:39:29, 29.65s/it]\n",
            "4297.jpg: actual-predicted:      0,   78.2, error:   78.2. Current MAE: 44.08, RMSE: 73.02:  42% 504/1190 [4:28:15<5:44:09, 30.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([38994, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4298.jpg: actual-predicted:      0,   31.3, error:   31.3. Current MAE: 44.06, RMSE: 72.96:  42% 504/1190 [4:28:49<5:44:09, 30.10s/it]\n",
            "4298.jpg: actual-predicted:      0,   31.3, error:   31.3. Current MAE: 44.06, RMSE: 72.96:  42% 505/1190 [4:28:49<5:55:03, 31.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([115111, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4300.jpg: actual-predicted:      0,   40.2, error:   40.2. Current MAE: 44.05, RMSE: 72.91:  42% 505/1190 [4:29:18<5:55:03, 31.10s/it]\n",
            "4300.jpg: actual-predicted:      0,   40.2, error:   40.2. Current MAE: 44.05, RMSE: 72.91:  43% 506/1190 [4:29:18<5:48:22, 30.56s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([136496, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4301.jpg: actual-predicted:      0,   25.3, error:   25.3. Current MAE: 44.01, RMSE: 72.84:  43% 506/1190 [4:29:45<5:48:22, 30.56s/it]\n",
            "4302.jpg: actual-predicted:      0,  146.3, error:  146.3. Current MAE: 44.21, RMSE: 73.06:  43% 507/1190 [4:30:24<5:35:10, 29.44s/it]\n",
            "4302.jpg: actual-predicted:      0,  146.3, error:  146.3. Current MAE: 44.21, RMSE: 73.06:  43% 508/1190 [4:30:24<6:07:25, 32.32s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([108070, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4303.jpg: actual-predicted:      0,  162.2, error:  162.2. Current MAE: 44.44, RMSE: 73.34:  43% 508/1190 [4:30:56<6:07:25, 32.32s/it]\n",
            "4303.jpg: actual-predicted:      0,  162.2, error:  162.2. Current MAE: 44.44, RMSE: 73.34:  43% 509/1190 [4:30:56<6:05:30, 32.20s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([161076, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4304.jpg: actual-predicted:      0,   21.2, error:   21.2. Current MAE: 44.40, RMSE: 73.28:  43% 509/1190 [4:31:28<6:05:30, 32.20s/it]\n",
            "4304.jpg: actual-predicted:      0,   21.2, error:   21.2. Current MAE: 44.40, RMSE: 73.28:  43% 510/1190 [4:31:28<6:05:00, 32.21s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([80876, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4305.jpg: actual-predicted:      0,   51.2, error:   51.2. Current MAE: 44.41, RMSE: 73.24:  43% 510/1190 [4:31:52<6:05:00, 32.21s/it]\n",
            "4305.jpg: actual-predicted:      0,   51.2, error:   51.2. Current MAE: 44.41, RMSE: 73.24:  43% 511/1190 [4:31:52<5:37:41, 29.84s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([201338, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4405.jpg: actual-predicted:      0,   11.7, error:   11.7. Current MAE: 44.35, RMSE: 73.17:  43% 511/1190 [4:32:30<5:37:41, 29.84s/it]\n",
            "4405.jpg: actual-predicted:      0,   11.7, error:   11.7. Current MAE: 44.35, RMSE: 73.17:  43% 512/1190 [4:32:30<6:03:20, 32.15s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([185218, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4406.jpg: actual-predicted:      0,   27.8, error:   27.8. Current MAE: 44.32, RMSE: 73.11:  43% 512/1190 [4:33:07<6:03:20, 32.15s/it]\n",
            "4406.jpg: actual-predicted:      0,   27.8, error:   27.8. Current MAE: 44.32, RMSE: 73.11:  43% 513/1190 [4:33:07<6:20:21, 33.71s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([79518, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4407.jpg: actual-predicted:      0,   53.8, error:   53.8. Current MAE: 44.33, RMSE: 73.08:  43% 513/1190 [4:33:43<6:20:21, 33.71s/it]\n",
            "4407.jpg: actual-predicted:      0,   53.8, error:   53.8. Current MAE: 44.33, RMSE: 73.08:  43% 514/1190 [4:33:43<6:26:36, 34.31s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([142422, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4408.jpg: actual-predicted:      0,   25.5, error:   25.5. Current MAE: 44.30, RMSE: 73.01:  43% 514/1190 [4:34:18<6:26:36, 34.31s/it]\n",
            "4408.jpg: actual-predicted:      0,   25.5, error:   25.5. Current MAE: 44.30, RMSE: 73.01:  43% 515/1190 [4:34:18<6:27:42, 34.46s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([124602, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4409.jpg: actual-predicted:      0,    9.5, error:    9.5. Current MAE: 44.23, RMSE: 72.95:  43% 515/1190 [4:34:48<6:27:42, 34.46s/it]\n",
            "4409.jpg: actual-predicted:      0,    9.5, error:    9.5. Current MAE: 44.23, RMSE: 72.95:  43% 516/1190 [4:34:48<6:11:08, 33.04s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([173130, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4412.jpg: actual-predicted:      0,   26.1, error:   26.1. Current MAE: 44.20, RMSE: 72.88:  43% 516/1190 [4:35:23<6:11:08, 33.04s/it]\n",
            "4412.jpg: actual-predicted:      0,   26.1, error:   26.1. Current MAE: 44.20, RMSE: 72.88:  43% 517/1190 [4:35:23<6:18:31, 33.75s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([213176, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4413.jpg: actual-predicted:      0,   14.8, error:   14.8. Current MAE: 44.14, RMSE: 72.82:  43% 517/1190 [4:36:06<6:18:31, 33.75s/it]\n",
            "4413.jpg: actual-predicted:      0,   14.8, error:   14.8. Current MAE: 44.14, RMSE: 72.82:  44% 518/1190 [4:36:06<6:50:26, 36.65s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([205739, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4414.jpg: actual-predicted:      0,   17.4, error:   17.4. Current MAE: 44.09, RMSE: 72.75:  44% 518/1190 [4:36:45<6:50:26, 36.65s/it]\n",
            "4414.jpg: actual-predicted:      0,   17.4, error:   17.4. Current MAE: 44.09, RMSE: 72.75:  44% 519/1190 [4:36:45<6:55:38, 37.17s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([123444, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4415.jpg: actual-predicted:      0,   34.3, error:   34.3. Current MAE: 44.07, RMSE: 72.70:  44% 519/1190 [4:37:11<6:55:38, 37.17s/it]\n",
            "4415.jpg: actual-predicted:      0,   34.3, error:   34.3. Current MAE: 44.07, RMSE: 72.70:  44% 520/1190 [4:37:11<6:19:41, 34.00s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([155590, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4416.jpg: actual-predicted:      0,   25.5, error:   25.5. Current MAE: 44.03, RMSE: 72.63:  44% 520/1190 [4:37:41<6:19:41, 34.00s/it]\n",
            "4416.jpg: actual-predicted:      0,   25.5, error:   25.5. Current MAE: 44.03, RMSE: 72.63:  44% 521/1190 [4:37:41<6:04:42, 32.71s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([78536, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4417.jpg: actual-predicted:      0,   34.5, error:   34.5. Current MAE: 44.01, RMSE: 72.58:  44% 521/1190 [4:38:17<6:04:42, 32.71s/it]\n",
            "4417.jpg: actual-predicted:      0,   34.5, error:   34.5. Current MAE: 44.01, RMSE: 72.58:  44% 522/1190 [4:38:17<6:14:21, 33.63s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([155227, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4418.jpg: actual-predicted:      0,   25.2, error:   25.2. Current MAE: 43.98, RMSE: 72.52:  44% 522/1190 [4:38:52<6:14:21, 33.63s/it]\n",
            "4418.jpg: actual-predicted:      0,   25.2, error:   25.2. Current MAE: 43.98, RMSE: 72.52:  44% 523/1190 [4:38:52<6:19:30, 34.14s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([154601, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4419.jpg: actual-predicted:      0,   39.9, error:   39.9. Current MAE: 43.97, RMSE: 72.47:  44% 523/1190 [4:39:27<6:19:30, 34.14s/it]\n",
            "4419.jpg: actual-predicted:      0,   39.9, error:   39.9. Current MAE: 43.97, RMSE: 72.47:  44% 524/1190 [4:39:27<6:22:28, 34.46s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([180792, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4421.jpg: actual-predicted:      0,   19.0, error:   19.0. Current MAE: 43.92, RMSE: 72.41:  44% 524/1190 [4:40:03<6:22:28, 34.46s/it]\n",
            "4421.jpg: actual-predicted:      0,   19.0, error:   19.0. Current MAE: 43.92, RMSE: 72.41:  44% 525/1190 [4:40:03<6:25:19, 34.77s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([170352, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4422.jpg: actual-predicted:      0,   21.8, error:   21.8. Current MAE: 43.88, RMSE: 72.34:  44% 525/1190 [4:40:38<6:25:19, 34.77s/it]\n",
            "4422.jpg: actual-predicted:      0,   21.8, error:   21.8. Current MAE: 43.88, RMSE: 72.34:  44% 526/1190 [4:40:38<6:26:32, 34.93s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([116330, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4423.jpg: actual-predicted:      0,   16.1, error:   16.1. Current MAE: 43.83, RMSE: 72.28:  44% 526/1190 [4:41:13<6:26:32, 34.93s/it]\n",
            "4423.jpg: actual-predicted:      0,   16.1, error:   16.1. Current MAE: 43.83, RMSE: 72.28:  44% 527/1190 [4:41:13<6:25:45, 34.91s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([59466, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4492.jpg: actual-predicted:      0,   15.0, error:   15.0. Current MAE: 43.77, RMSE: 72.21:  44% 527/1190 [4:41:39<6:25:45, 34.91s/it]\n",
            "4493.jpg: actual-predicted:      0,   15.0, error:   15.0. Current MAE: 43.72, RMSE: 72.15:  44% 528/1190 [4:42:14<5:55:32, 32.22s/it]\n",
            "4493.jpg: actual-predicted:      0,   15.0, error:   15.0. Current MAE: 43.72, RMSE: 72.15:  44% 529/1190 [4:42:14<6:03:11, 32.97s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([61406, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4494.jpg: actual-predicted:      0,   23.7, error:   23.7. Current MAE: 43.68, RMSE: 72.09:  44% 529/1190 [4:42:49<6:03:11, 32.97s/it]\n",
            "4494.jpg: actual-predicted:      0,   23.7, error:   23.7. Current MAE: 43.68, RMSE: 72.09:  45% 530/1190 [4:42:49<6:11:23, 33.76s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([164286, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4495.jpg: actual-predicted:      0,   12.0, error:   12.0. Current MAE: 43.62, RMSE: 72.02:  45% 530/1190 [4:43:25<6:11:23, 33.76s/it]\n",
            "4495.jpg: actual-predicted:      0,   12.0, error:   12.0. Current MAE: 43.62, RMSE: 72.02:  45% 531/1190 [4:43:25<6:15:47, 34.22s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([66138, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4496.jpg: actual-predicted:      0,   10.0, error:   10.0. Current MAE: 43.56, RMSE: 71.96:  45% 531/1190 [4:43:57<6:15:47, 34.22s/it]\n",
            "4496.jpg: actual-predicted:      0,   10.0, error:   10.0. Current MAE: 43.56, RMSE: 71.96:  45% 532/1190 [4:43:57<6:09:35, 33.70s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([33456, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4497.jpg: actual-predicted:      0,   19.1, error:   19.1. Current MAE: 43.51, RMSE: 71.89:  45% 532/1190 [4:44:31<6:09:35, 33.70s/it]\n",
            "4497.jpg: actual-predicted:      0,   19.1, error:   19.1. Current MAE: 43.51, RMSE: 71.89:  45% 533/1190 [4:44:31<6:11:22, 33.92s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([146106, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4498.jpg: actual-predicted:      0,   11.7, error:   11.7. Current MAE: 43.45, RMSE: 71.83:  45% 533/1190 [4:45:03<6:11:22, 33.92s/it]\n",
            "4498.jpg: actual-predicted:      0,   11.7, error:   11.7. Current MAE: 43.45, RMSE: 71.83:  45% 534/1190 [4:45:03<6:03:41, 33.26s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([136709, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4499.jpg: actual-predicted:      0,    6.6, error:    6.6. Current MAE: 43.38, RMSE: 71.76:  45% 534/1190 [4:45:30<6:03:41, 33.26s/it]\n",
            "4499.jpg: actual-predicted:      0,    6.6, error:    6.6. Current MAE: 43.38, RMSE: 71.76:  45% 535/1190 [4:45:30<5:41:44, 31.31s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([25057, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4500.jpg: actual-predicted:      0,    8.3, error:    8.3. Current MAE: 43.32, RMSE: 71.69:  45% 535/1190 [4:45:56<5:41:44, 31.31s/it]\n",
            "4500.jpg: actual-predicted:      0,    8.3, error:    8.3. Current MAE: 43.32, RMSE: 71.69:  45% 536/1190 [4:45:56<5:23:09, 29.65s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([32896, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4501.jpg: actual-predicted:      0,   22.1, error:   22.1. Current MAE: 43.28, RMSE: 71.63:  45% 536/1190 [4:46:26<5:23:09, 29.65s/it]\n",
            "4501.jpg: actual-predicted:      0,   22.1, error:   22.1. Current MAE: 43.28, RMSE: 71.63:  45% 537/1190 [4:46:26<5:26:16, 29.98s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([35763, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4502.jpg: actual-predicted:      0,   14.3, error:   14.3. Current MAE: 43.23, RMSE: 71.57:  45% 537/1190 [4:46:57<5:26:16, 29.98s/it]\n",
            "4502.jpg: actual-predicted:      0,   14.3, error:   14.3. Current MAE: 43.23, RMSE: 71.57:  45% 538/1190 [4:46:57<5:29:01, 30.28s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1335, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4874.jpg: actual-predicted:      0,   52.1, error:   52.1. Current MAE: 43.24, RMSE: 71.54:  45% 538/1190 [4:47:35<5:29:01, 30.28s/it]\n",
            "4874.jpg: actual-predicted:      0,   52.1, error:   52.1. Current MAE: 43.24, RMSE: 71.54:  45% 539/1190 [4:47:35<5:51:17, 32.38s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([15030, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4875.jpg: actual-predicted:      0,   29.4, error:   29.4. Current MAE: 43.22, RMSE: 71.48:  45% 539/1190 [4:48:06<5:51:17, 32.38s/it]\n",
            "4875.jpg: actual-predicted:      0,   29.4, error:   29.4. Current MAE: 43.22, RMSE: 71.48:  45% 540/1190 [4:48:06<5:47:09, 32.05s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([72714, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4876.jpg: actual-predicted:      0,   35.1, error:   35.1. Current MAE: 43.20, RMSE: 71.43:  45% 540/1190 [4:48:30<5:47:09, 32.05s/it]\n",
            "4877.jpg: actual-predicted:      0,   26.7, error:   26.7. Current MAE: 43.17, RMSE: 71.38:  45% 541/1190 [4:49:03<5:20:19, 29.61s/it]\n",
            "4878.jpg: actual-predicted:      0,  122.3, error:  122.3. Current MAE: 43.32, RMSE: 71.50:  46% 542/1190 [4:49:33<5:31:58, 30.74s/it]\n",
            "4878.jpg: actual-predicted:      0,  122.3, error:  122.3. Current MAE: 43.32, RMSE: 71.50:  46% 543/1190 [4:49:33<5:28:20, 30.45s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([15720, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4879.jpg: actual-predicted:      0,   98.1, error:   98.1. Current MAE: 43.42, RMSE: 71.56:  46% 543/1190 [4:50:05<5:28:20, 30.45s/it]\n",
            "4879.jpg: actual-predicted:      0,   98.1, error:   98.1. Current MAE: 43.42, RMSE: 71.56:  46% 544/1190 [4:50:05<5:32:51, 30.92s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([42299, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4880.jpg: actual-predicted:      0,   26.6, error:   26.6. Current MAE: 43.39, RMSE: 71.51:  46% 544/1190 [4:50:45<5:32:51, 30.92s/it]\n",
            "4880.jpg: actual-predicted:      0,   26.6, error:   26.6. Current MAE: 43.39, RMSE: 71.51:  46% 545/1190 [4:50:45<6:01:38, 33.64s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([33385, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4881.jpg: actual-predicted:      0,   28.2, error:   28.2. Current MAE: 43.36, RMSE: 71.45:  46% 545/1190 [4:51:10<6:01:38, 33.64s/it]\n",
            "4881.jpg: actual-predicted:      0,   28.2, error:   28.2. Current MAE: 43.36, RMSE: 71.45:  46% 546/1190 [4:51:10<5:33:54, 31.11s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([117714, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4882.jpg: actual-predicted:      0,   33.7, error:   33.7. Current MAE: 43.34, RMSE: 71.40:  46% 546/1190 [4:51:45<5:33:54, 31.11s/it]\n",
            "4882.jpg: actual-predicted:      0,   33.7, error:   33.7. Current MAE: 43.34, RMSE: 71.40:  46% 547/1190 [4:51:45<5:45:35, 32.25s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([42838, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4883.jpg: actual-predicted:      0,   10.1, error:   10.1. Current MAE: 43.28, RMSE: 71.34:  46% 547/1190 [4:52:10<5:45:35, 32.25s/it]\n",
            "4883.jpg: actual-predicted:      0,   10.1, error:   10.1. Current MAE: 43.28, RMSE: 71.34:  46% 548/1190 [4:52:10<5:19:51, 29.89s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([3042, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4884.jpg: actual-predicted:      0,   87.7, error:   87.7. Current MAE: 43.36, RMSE: 71.37:  46% 548/1190 [4:52:33<5:19:51, 29.89s/it]\n",
            "4884.jpg: actual-predicted:      0,   87.7, error:   87.7. Current MAE: 43.36, RMSE: 71.37:  46% 549/1190 [4:52:33<4:57:26, 27.84s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([123750, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4885.jpg: actual-predicted:      0,   23.0, error:   23.0. Current MAE: 43.32, RMSE: 71.31:  46% 549/1190 [4:52:59<4:57:26, 27.84s/it]\n",
            "4885.jpg: actual-predicted:      0,   23.0, error:   23.0. Current MAE: 43.32, RMSE: 71.31:  46% 550/1190 [4:52:59<4:51:32, 27.33s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([116536, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4886.jpg: actual-predicted:      0,   30.3, error:   30.3. Current MAE: 43.30, RMSE: 71.26:  46% 550/1190 [4:53:30<4:51:32, 27.33s/it]\n",
            "4886.jpg: actual-predicted:      0,   30.3, error:   30.3. Current MAE: 43.30, RMSE: 71.26:  46% 551/1190 [4:53:30<5:03:27, 28.49s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([102334, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4887.jpg: actual-predicted:      0,   25.7, error:   25.7. Current MAE: 43.27, RMSE: 71.20:  46% 551/1190 [4:53:55<5:03:27, 28.49s/it]\n",
            "4887.jpg: actual-predicted:      0,   25.7, error:   25.7. Current MAE: 43.27, RMSE: 71.20:  46% 552/1190 [4:53:55<4:52:22, 27.50s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([63618, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4888.jpg: actual-predicted:      0,   11.7, error:   11.7. Current MAE: 43.21, RMSE: 71.14:  46% 552/1190 [4:54:28<4:52:22, 27.50s/it]\n",
            "4889.jpg: actual-predicted:      0,   26.5, error:   26.5. Current MAE: 43.18, RMSE: 71.08:  46% 553/1190 [4:55:08<5:08:16, 29.04s/it]\n",
            "4889.jpg: actual-predicted:      0,   26.5, error:   26.5. Current MAE: 43.18, RMSE: 71.08:  47% 554/1190 [4:55:08<5:43:22, 32.39s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17055, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4890.jpg: actual-predicted:      0,   70.3, error:   70.3. Current MAE: 43.23, RMSE: 71.08:  47% 554/1190 [4:55:39<5:43:22, 32.39s/it]\n",
            "4890.jpg: actual-predicted:      0,   70.3, error:   70.3. Current MAE: 43.23, RMSE: 71.08:  47% 555/1190 [4:55:39<5:39:29, 32.08s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([40053, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4891.jpg: actual-predicted:      0,   12.2, error:   12.2. Current MAE: 43.18, RMSE: 71.02:  47% 555/1190 [4:56:11<5:39:29, 32.08s/it]\n",
            "4891.jpg: actual-predicted:      0,   12.2, error:   12.2. Current MAE: 43.18, RMSE: 71.02:  47% 556/1190 [4:56:11<5:37:16, 31.92s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([135261, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4892.jpg: actual-predicted:      0,   32.1, error:   32.1. Current MAE: 43.16, RMSE: 70.97:  47% 556/1190 [4:56:44<5:37:16, 31.92s/it]\n",
            "4892.jpg: actual-predicted:      0,   32.1, error:   32.1. Current MAE: 43.16, RMSE: 70.97:  47% 557/1190 [4:56:44<5:40:35, 32.28s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([27978, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4893.jpg: actual-predicted:      0,   26.3, error:   26.3. Current MAE: 43.12, RMSE: 70.91:  47% 557/1190 [4:57:18<5:40:35, 32.28s/it]\n",
            "4893.jpg: actual-predicted:      0,   26.3, error:   26.3. Current MAE: 43.12, RMSE: 70.91:  47% 558/1190 [4:57:18<5:45:37, 32.81s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([110618, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4894.jpg: actual-predicted:      0,    5.4, error:    5.4. Current MAE: 43.06, RMSE: 70.85:  47% 558/1190 [4:57:51<5:45:37, 32.81s/it]\n",
            "4894.jpg: actual-predicted:      0,    5.4, error:    5.4. Current MAE: 43.06, RMSE: 70.85:  47% 559/1190 [4:57:51<5:46:06, 32.91s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([126762, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4895.jpg: actual-predicted:      0,    8.3, error:    8.3. Current MAE: 43.00, RMSE: 70.79:  47% 559/1190 [4:58:25<5:46:06, 32.91s/it]\n",
            "4896.jpg: actual-predicted:      0,   67.0, error:   67.0. Current MAE: 43.04, RMSE: 70.78:  47% 560/1190 [4:58:58<5:46:42, 33.02s/it]\n",
            "4896.jpg: actual-predicted:      0,   67.0, error:   67.0. Current MAE: 43.04, RMSE: 70.78:  47% 561/1190 [4:58:58<5:46:45, 33.08s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([53973, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4897.jpg: actual-predicted:      0,   36.7, error:   36.7. Current MAE: 43.03, RMSE: 70.74:  47% 561/1190 [4:59:24<5:46:45, 33.08s/it]\n",
            "4897.jpg: actual-predicted:      0,   36.7, error:   36.7. Current MAE: 43.03, RMSE: 70.74:  47% 562/1190 [4:59:24<5:24:04, 30.96s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([120467, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4898.jpg: actual-predicted:      0,   34.9, error:   34.9. Current MAE: 43.01, RMSE: 70.69:  47% 562/1190 [5:00:01<5:24:04, 30.96s/it]\n",
            "4898.jpg: actual-predicted:      0,   34.9, error:   34.9. Current MAE: 43.01, RMSE: 70.69:  47% 563/1190 [5:00:01<5:44:39, 32.98s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([131545, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4900.jpg: actual-predicted:      0,    9.6, error:    9.6. Current MAE: 42.95, RMSE: 70.63:  47% 563/1190 [5:00:35<5:44:39, 32.98s/it]\n",
            "4900.jpg: actual-predicted:      0,    9.6, error:    9.6. Current MAE: 42.95, RMSE: 70.63:  47% 564/1190 [5:00:35<5:45:25, 33.11s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([131564, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4901.jpg: actual-predicted:      0,   17.1, error:   17.1. Current MAE: 42.91, RMSE: 70.57:  47% 564/1190 [5:01:07<5:45:25, 33.11s/it]\n",
            "4901.jpg: actual-predicted:      0,   17.1, error:   17.1. Current MAE: 42.91, RMSE: 70.57:  47% 565/1190 [5:01:07<5:41:03, 32.74s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([126591, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4903.jpg: actual-predicted:      0,   18.9, error:   18.9. Current MAE: 42.86, RMSE: 70.51:  47% 565/1190 [5:01:42<5:41:03, 32.74s/it]\n",
            "4903.jpg: actual-predicted:      0,   18.9, error:   18.9. Current MAE: 42.86, RMSE: 70.51:  48% 566/1190 [5:01:42<5:47:35, 33.42s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([77426, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4904.jpg: actual-predicted:      0,   11.2, error:   11.2. Current MAE: 42.81, RMSE: 70.45:  48% 566/1190 [5:02:14<5:47:35, 33.42s/it]\n",
            "4904.jpg: actual-predicted:      0,   11.2, error:   11.2. Current MAE: 42.81, RMSE: 70.45:  48% 567/1190 [5:02:14<5:43:12, 33.05s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17680, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4905.jpg: actual-predicted:      0,  174.6, error:  174.6. Current MAE: 43.04, RMSE: 70.77:  48% 567/1190 [5:02:45<5:43:12, 33.05s/it]\n",
            "4905.jpg: actual-predicted:      0,  174.6, error:  174.6. Current MAE: 43.04, RMSE: 70.77:  48% 568/1190 [5:02:45<5:37:07, 32.52s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([103095, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4906.jpg: actual-predicted:      0,   65.0, error:   65.0. Current MAE: 43.08, RMSE: 70.76:  48% 568/1190 [5:03:20<5:37:07, 32.52s/it]\n",
            "4906.jpg: actual-predicted:      0,   65.0, error:   65.0. Current MAE: 43.08, RMSE: 70.76:  48% 569/1190 [5:03:20<5:42:14, 33.07s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([54422, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4908.jpg: actual-predicted:      0,   24.4, error:   24.4. Current MAE: 43.05, RMSE: 70.70:  48% 569/1190 [5:03:59<5:42:14, 33.07s/it]\n",
            "4908.jpg: actual-predicted:      0,   24.4, error:   24.4. Current MAE: 43.05, RMSE: 70.70:  48% 570/1190 [5:03:59<6:02:52, 35.12s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([49975, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4909.jpg: actual-predicted:      0,    9.6, error:    9.6. Current MAE: 42.99, RMSE: 70.64:  48% 570/1190 [5:04:30<6:02:52, 35.12s/it]\n",
            "4909.jpg: actual-predicted:      0,    9.6, error:    9.6. Current MAE: 42.99, RMSE: 70.64:  48% 571/1190 [5:04:30<5:49:28, 33.87s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([121985, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4910.jpg: actual-predicted:      0,   19.7, error:   19.7. Current MAE: 42.95, RMSE: 70.59:  48% 571/1190 [5:04:57<5:49:28, 33.87s/it]\n",
            "4910.jpg: actual-predicted:      0,   19.7, error:   19.7. Current MAE: 42.95, RMSE: 70.59:  48% 572/1190 [5:04:57<5:24:59, 31.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([15306, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4911.jpg: actual-predicted:      0,   16.0, error:   16.0. Current MAE: 42.90, RMSE: 70.53:  48% 572/1190 [5:05:28<5:24:59, 31.55s/it]\n",
            "4911.jpg: actual-predicted:      0,   16.0, error:   16.0. Current MAE: 42.90, RMSE: 70.53:  48% 573/1190 [5:05:28<5:25:09, 31.62s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([16800, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4912.jpg: actual-predicted:      0,   26.3, error:   26.3. Current MAE: 42.87, RMSE: 70.47:  48% 573/1190 [5:06:00<5:25:09, 31.62s/it]\n",
            "4912.jpg: actual-predicted:      0,   26.3, error:   26.3. Current MAE: 42.87, RMSE: 70.47:  48% 574/1190 [5:06:00<5:23:38, 31.52s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([113685, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4913.jpg: actual-predicted:      0,   13.0, error:   13.0. Current MAE: 42.82, RMSE: 70.41:  48% 574/1190 [5:06:26<5:23:38, 31.52s/it]\n",
            "4915.jpg: actual-predicted:      0,   86.0, error:   86.0. Current MAE: 42.89, RMSE: 70.44:  48% 575/1190 [5:06:50<5:06:33, 29.91s/it]\n",
            "4915.jpg: actual-predicted:      0,   86.0, error:   86.0. Current MAE: 42.89, RMSE: 70.44:  48% 576/1190 [5:06:50<4:49:07, 28.25s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([82198, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4916.jpg: actual-predicted:      0,   60.6, error:   60.6. Current MAE: 42.93, RMSE: 70.43:  48% 576/1190 [5:07:16<4:49:07, 28.25s/it]\n",
            "4916.jpg: actual-predicted:      0,   60.6, error:   60.6. Current MAE: 42.93, RMSE: 70.43:  48% 577/1190 [5:07:16<4:40:07, 27.42s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([42461, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4917.jpg: actual-predicted:      0,   40.1, error:   40.1. Current MAE: 42.92, RMSE: 70.39:  48% 577/1190 [5:07:41<4:40:07, 27.42s/it]\n",
            "4917.jpg: actual-predicted:      0,   40.1, error:   40.1. Current MAE: 42.92, RMSE: 70.39:  49% 578/1190 [5:07:41<4:33:29, 26.81s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([31087, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4918.jpg: actual-predicted:      0,   67.5, error:   67.5. Current MAE: 42.96, RMSE: 70.38:  49% 578/1190 [5:08:13<4:33:29, 26.81s/it]\n",
            "4918.jpg: actual-predicted:      0,   67.5, error:   67.5. Current MAE: 42.96, RMSE: 70.38:  49% 579/1190 [5:08:13<4:48:02, 28.29s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([118443, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4919.jpg: actual-predicted:      0,   31.7, error:   31.7. Current MAE: 42.94, RMSE: 70.33:  49% 579/1190 [5:08:48<4:48:02, 28.29s/it]\n",
            "4919.jpg: actual-predicted:      0,   31.7, error:   31.7. Current MAE: 42.94, RMSE: 70.33:  49% 580/1190 [5:08:48<5:07:24, 30.24s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([108930, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4920.jpg: actual-predicted:      0,   16.8, error:   16.8. Current MAE: 42.90, RMSE: 70.28:  49% 580/1190 [5:09:14<5:07:24, 30.24s/it]\n",
            "4920.jpg: actual-predicted:      0,   16.8, error:   16.8. Current MAE: 42.90, RMSE: 70.28:  49% 581/1190 [5:09:14<4:54:16, 28.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([117843, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4921.jpg: actual-predicted:      0,   17.1, error:   17.1. Current MAE: 42.85, RMSE: 70.22:  49% 581/1190 [5:09:39<4:54:16, 28.99s/it]\n",
            "4921.jpg: actual-predicted:      0,   17.1, error:   17.1. Current MAE: 42.85, RMSE: 70.22:  49% 582/1190 [5:09:39<4:41:45, 27.81s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([127048, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4922.jpg: actual-predicted:      0,    8.5, error:    8.5. Current MAE: 42.80, RMSE: 70.16:  49% 582/1190 [5:10:11<4:41:45, 27.81s/it]\n",
            "4922.jpg: actual-predicted:      0,    8.5, error:    8.5. Current MAE: 42.80, RMSE: 70.16:  49% 583/1190 [5:10:11<4:56:13, 29.28s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([30183, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4923.jpg: actual-predicted:      0,   33.5, error:   33.5. Current MAE: 42.78, RMSE: 70.11:  49% 583/1190 [5:10:45<4:56:13, 29.28s/it]\n",
            "4923.jpg: actual-predicted:      0,   33.5, error:   33.5. Current MAE: 42.78, RMSE: 70.11:  49% 584/1190 [5:10:45<5:09:11, 30.61s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([3882, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4924.jpg: actual-predicted:      0,   51.5, error:   51.5. Current MAE: 42.79, RMSE: 70.09:  49% 584/1190 [5:11:21<5:09:11, 30.61s/it]\n",
            "4924.jpg: actual-predicted:      0,   51.5, error:   51.5. Current MAE: 42.79, RMSE: 70.09:  49% 585/1190 [5:11:21<5:25:35, 32.29s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([41993, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4925.jpg: actual-predicted:      0,   85.4, error:   85.4. Current MAE: 42.87, RMSE: 70.12:  49% 585/1190 [5:11:55<5:25:35, 32.29s/it]\n",
            "4926.jpg: actual-predicted:      0,   23.5, error:   23.5. Current MAE: 42.83, RMSE: 70.06:  49% 586/1190 [5:12:29<5:30:30, 32.83s/it]\n",
            "4926.jpg: actual-predicted:      0,   23.5, error:   23.5. Current MAE: 42.83, RMSE: 70.06:  49% 587/1190 [5:12:29<5:32:04, 33.04s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([15217, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4927.jpg: actual-predicted:      0,   45.8, error:   45.8. Current MAE: 42.84, RMSE: 70.03:  49% 587/1190 [5:12:57<5:32:04, 33.04s/it]\n",
            "4927.jpg: actual-predicted:      0,   45.8, error:   45.8. Current MAE: 42.84, RMSE: 70.03:  49% 588/1190 [5:12:57<5:17:06, 31.61s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([136518, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4928.jpg: actual-predicted:      0,   27.6, error:   27.6. Current MAE: 42.81, RMSE: 69.98:  49% 588/1190 [5:13:30<5:17:06, 31.61s/it]\n",
            "4928.jpg: actual-predicted:      0,   27.6, error:   27.6. Current MAE: 42.81, RMSE: 69.98:  49% 589/1190 [5:13:30<5:19:37, 31.91s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([28962, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4929.jpg: actual-predicted:      0,   20.8, error:   20.8. Current MAE: 42.78, RMSE: 69.92:  49% 589/1190 [5:14:01<5:19:37, 31.91s/it]\n",
            "4929.jpg: actual-predicted:      0,   20.8, error:   20.8. Current MAE: 42.78, RMSE: 69.92:  50% 590/1190 [5:14:01<5:17:33, 31.76s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([21659, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4930.jpg: actual-predicted:      0,   46.9, error:   46.9. Current MAE: 42.78, RMSE: 69.89:  50% 590/1190 [5:14:26<5:17:33, 31.76s/it]\n",
            "4931.jpg: actual-predicted:      0,   42.8, error:   42.8. Current MAE: 42.78, RMSE: 69.86:  50% 591/1190 [5:15:00<4:57:29, 29.80s/it]\n",
            "4931.jpg: actual-predicted:      0,   42.8, error:   42.8. Current MAE: 42.78, RMSE: 69.86:  50% 592/1190 [5:15:00<5:06:58, 30.80s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([155789, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4932.jpg: actual-predicted:      0,   27.5, error:   27.5. Current MAE: 42.76, RMSE: 69.81:  50% 592/1190 [5:15:32<5:06:58, 30.80s/it]\n",
            "4933.jpg: actual-predicted:      0,   40.6, error:   40.6. Current MAE: 42.75, RMSE: 69.77:  50% 593/1190 [5:15:57<5:11:34, 31.31s/it]\n",
            "4933.jpg: actual-predicted:      0,   40.6, error:   40.6. Current MAE: 42.75, RMSE: 69.77:  50% 594/1190 [5:15:57<4:51:08, 29.31s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([65401, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4934.jpg: actual-predicted:      0,   17.4, error:   17.4. Current MAE: 42.71, RMSE: 69.71:  50% 594/1190 [5:16:27<4:51:08, 29.31s/it]\n",
            "4934.jpg: actual-predicted:      0,   17.4, error:   17.4. Current MAE: 42.71, RMSE: 69.71:  50% 595/1190 [5:16:27<4:54:27, 29.69s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([118246, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4935.jpg: actual-predicted:      0,   14.9, error:   14.9. Current MAE: 42.66, RMSE: 69.66:  50% 595/1190 [5:16:59<4:54:27, 29.69s/it]\n",
            "4935.jpg: actual-predicted:      0,   14.9, error:   14.9. Current MAE: 42.66, RMSE: 69.66:  50% 596/1190 [5:16:59<4:59:13, 30.23s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([121089, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4937.jpg: actual-predicted:      0,   16.4, error:   16.4. Current MAE: 42.62, RMSE: 69.60:  50% 596/1190 [5:17:25<4:59:13, 30.23s/it]\n",
            "4937.jpg: actual-predicted:      0,   16.4, error:   16.4. Current MAE: 42.62, RMSE: 69.60:  50% 597/1190 [5:17:25<4:46:32, 28.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([46627, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4938.jpg: actual-predicted:      0,   43.5, error:   43.5. Current MAE: 42.62, RMSE: 69.57:  50% 597/1190 [5:17:56<4:46:32, 28.99s/it]\n",
            "4938.jpg: actual-predicted:      0,   43.5, error:   43.5. Current MAE: 42.62, RMSE: 69.57:  50% 598/1190 [5:17:56<4:51:38, 29.56s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([28298, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4939.jpg: actual-predicted:      0,   19.8, error:   19.8. Current MAE: 42.58, RMSE: 69.51:  50% 598/1190 [5:18:24<4:51:38, 29.56s/it]\n",
            "4939.jpg: actual-predicted:      0,   19.8, error:   19.8. Current MAE: 42.58, RMSE: 69.51:  50% 599/1190 [5:18:24<4:48:15, 29.26s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([7607, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4940.jpg: actual-predicted:      0,   24.9, error:   24.9. Current MAE: 42.55, RMSE: 69.46:  50% 599/1190 [5:19:02<4:48:15, 29.26s/it]\n",
            "4940.jpg: actual-predicted:      0,   24.9, error:   24.9. Current MAE: 42.55, RMSE: 69.46:  50% 600/1190 [5:19:02<5:12:33, 31.79s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([4846, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4941.jpg: actual-predicted:      0,  140.4, error:  140.4. Current MAE: 42.72, RMSE: 69.64:  50% 600/1190 [5:19:32<5:12:33, 31.79s/it]\n",
            "4942.jpg: actual-predicted:      0,   46.4, error:   46.4. Current MAE: 42.72, RMSE: 69.61:  51% 601/1190 [5:20:05<5:06:35, 31.23s/it]\n",
            "4942.jpg: actual-predicted:      0,   46.4, error:   46.4. Current MAE: 42.72, RMSE: 69.61:  51% 602/1190 [5:20:05<5:11:56, 31.83s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([15366, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4943.jpg: actual-predicted:      0,   54.0, error:   54.0. Current MAE: 42.74, RMSE: 69.58:  51% 602/1190 [5:20:38<5:11:56, 31.83s/it]\n",
            "4943.jpg: actual-predicted:      0,   54.0, error:   54.0. Current MAE: 42.74, RMSE: 69.58:  51% 603/1190 [5:20:38<5:13:39, 32.06s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([137925, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4944.jpg: actual-predicted:      0,   41.6, error:   41.6. Current MAE: 42.74, RMSE: 69.55:  51% 603/1190 [5:21:10<5:13:39, 32.06s/it]\n",
            "4944.jpg: actual-predicted:      0,   41.6, error:   41.6. Current MAE: 42.74, RMSE: 69.55:  51% 604/1190 [5:21:10<5:14:52, 32.24s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([110153, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4945.jpg: actual-predicted:      0,   61.0, error:   61.0. Current MAE: 42.77, RMSE: 69.53:  51% 604/1190 [5:21:45<5:14:52, 32.24s/it]\n",
            "4945.jpg: actual-predicted:      0,   61.0, error:   61.0. Current MAE: 42.77, RMSE: 69.53:  51% 605/1190 [5:21:45<5:21:08, 32.94s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1788, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4946.jpg: actual-predicted:      0,   60.5, error:   60.5. Current MAE: 42.80, RMSE: 69.52:  51% 605/1190 [5:22:15<5:21:08, 32.94s/it]\n",
            "4947.jpg: actual-predicted:      0,  273.9, error:  273.9. Current MAE: 43.18, RMSE: 70.35:  51% 606/1190 [5:22:54<5:12:15, 32.08s/it]\n",
            "4948.jpg: actual-predicted:      0,   14.8, error:   14.8. Current MAE: 43.13, RMSE: 70.29:  51% 607/1190 [5:23:28<5:31:13, 34.09s/it]\n",
            "4948.jpg: actual-predicted:      0,   14.8, error:   14.8. Current MAE: 43.13, RMSE: 70.29:  51% 608/1190 [5:23:28<5:30:10, 34.04s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([44276, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4949.jpg: actual-predicted:      0,   87.1, error:   87.1. Current MAE: 43.21, RMSE: 70.32:  51% 608/1190 [5:24:00<5:30:10, 34.04s/it]\n",
            "4949.jpg: actual-predicted:      0,   87.1, error:   87.1. Current MAE: 43.21, RMSE: 70.32:  51% 609/1190 [5:24:00<5:25:34, 33.62s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([72788, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4950.jpg: actual-predicted:      0,   28.0, error:   28.0. Current MAE: 43.18, RMSE: 70.27:  51% 609/1190 [5:24:33<5:25:34, 33.62s/it]\n",
            "4950.jpg: actual-predicted:      0,   28.0, error:   28.0. Current MAE: 43.18, RMSE: 70.27:  51% 610/1190 [5:24:33<5:21:26, 33.25s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([47826, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4951.jpg: actual-predicted:      0,  174.9, error:  174.9. Current MAE: 43.40, RMSE: 70.57:  51% 610/1190 [5:24:59<5:21:26, 33.25s/it]\n",
            "4951.jpg: actual-predicted:      0,  174.9, error:  174.9. Current MAE: 43.40, RMSE: 70.57:  51% 611/1190 [5:24:59<4:59:12, 31.01s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([11358, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4952.jpg: actual-predicted:      0,  209.3, error:  209.3. Current MAE: 43.67, RMSE: 71.02:  51% 611/1190 [5:25:29<4:59:12, 31.01s/it]\n",
            "4952.jpg: actual-predicted:      0,  209.3, error:  209.3. Current MAE: 43.67, RMSE: 71.02:  51% 612/1190 [5:25:29<4:55:42, 30.70s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([90465, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4953.jpg: actual-predicted:      0,   49.1, error:   49.1. Current MAE: 43.68, RMSE: 70.99:  51% 612/1190 [5:26:04<4:55:42, 30.70s/it]\n",
            "4953.jpg: actual-predicted:      0,   49.1, error:   49.1. Current MAE: 43.68, RMSE: 70.99:  52% 613/1190 [5:26:04<5:08:54, 32.12s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17275, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4954.jpg: actual-predicted:      0,   17.3, error:   17.3. Current MAE: 43.63, RMSE: 70.94:  52% 613/1190 [5:26:36<5:08:54, 32.12s/it]\n",
            "4955.jpg: actual-predicted:      0,  152.2, error:  152.2. Current MAE: 43.81, RMSE: 71.14:  52% 614/1190 [5:27:06<5:07:45, 32.06s/it]\n",
            "4955.jpg: actual-predicted:      0,  152.2, error:  152.2. Current MAE: 43.81, RMSE: 71.14:  52% 615/1190 [5:27:06<5:01:02, 31.41s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([8075, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4956.jpg: actual-predicted:      0,  100.9, error:  100.9. Current MAE: 43.90, RMSE: 71.20:  52% 615/1190 [5:27:39<5:01:02, 31.41s/it]\n",
            "4956.jpg: actual-predicted:      0,  100.9, error:  100.9. Current MAE: 43.90, RMSE: 71.20:  52% 616/1190 [5:27:39<5:06:38, 32.05s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([68142, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4957.jpg: actual-predicted:      0,   66.6, error:   66.6. Current MAE: 43.94, RMSE: 71.19:  52% 616/1190 [5:28:12<5:06:38, 32.05s/it]\n",
            "4958.jpg: actual-predicted:      0,   66.4, error:   66.4. Current MAE: 43.98, RMSE: 71.19:  52% 617/1190 [5:28:47<5:08:15, 32.28s/it]\n",
            "4958.jpg: actual-predicted:      0,   66.4, error:   66.4. Current MAE: 43.98, RMSE: 71.19:  52% 618/1190 [5:28:47<5:13:56, 32.93s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([105111, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4959.jpg: actual-predicted:      0,   28.0, error:   28.0. Current MAE: 43.95, RMSE: 71.14:  52% 618/1190 [5:29:23<5:13:56, 32.93s/it]\n",
            "4959.jpg: actual-predicted:      0,   28.0, error:   28.0. Current MAE: 43.95, RMSE: 71.14:  52% 619/1190 [5:29:23<5:22:31, 33.89s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([16782, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4960.jpg: actual-predicted:      0,   21.6, error:   21.6. Current MAE: 43.91, RMSE: 71.09:  52% 619/1190 [5:29:55<5:22:31, 33.89s/it]\n",
            "4960.jpg: actual-predicted:      0,   21.6, error:   21.6. Current MAE: 43.91, RMSE: 71.09:  52% 620/1190 [5:29:55<5:16:53, 33.36s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([82658, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4961.jpg: actual-predicted:      0,  212.6, error:  212.6. Current MAE: 44.18, RMSE: 71.54:  52% 620/1190 [5:30:30<5:16:53, 33.36s/it]\n",
            "4961.jpg: actual-predicted:      0,  212.6, error:  212.6. Current MAE: 44.18, RMSE: 71.54:  52% 621/1190 [5:30:30<5:20:02, 33.75s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([90215, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4962.jpg: actual-predicted:      0,   32.6, error:   32.6. Current MAE: 44.17, RMSE: 71.49:  52% 621/1190 [5:31:10<5:20:02, 33.75s/it]\n",
            "4962.jpg: actual-predicted:      0,   32.6, error:   32.6. Current MAE: 44.17, RMSE: 71.49:  52% 622/1190 [5:31:10<5:39:06, 35.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([26887, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4963.jpg: actual-predicted:      0,  206.8, error:  206.8. Current MAE: 44.43, RMSE: 71.91:  52% 622/1190 [5:31:46<5:39:06, 35.82s/it]\n",
            "4963.jpg: actual-predicted:      0,  206.8, error:  206.8. Current MAE: 44.43, RMSE: 71.91:  52% 623/1190 [5:31:46<5:37:10, 35.68s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([67364, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4964.jpg: actual-predicted:      0,   45.1, error:   45.1. Current MAE: 44.43, RMSE: 71.88:  52% 623/1190 [5:32:18<5:37:10, 35.68s/it]\n",
            "4964.jpg: actual-predicted:      0,   45.1, error:   45.1. Current MAE: 44.43, RMSE: 71.88:  52% 624/1190 [5:32:18<5:26:21, 34.60s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([14686, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4965.jpg: actual-predicted:      0,    9.8, error:    9.8. Current MAE: 44.37, RMSE: 71.82:  52% 624/1190 [5:32:53<5:26:21, 34.60s/it]\n",
            "4965.jpg: actual-predicted:      0,    9.8, error:    9.8. Current MAE: 44.37, RMSE: 71.82:  53% 625/1190 [5:32:53<5:28:34, 34.89s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([2244, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4966.jpg: actual-predicted:      0,   19.3, error:   19.3. Current MAE: 44.33, RMSE: 71.77:  53% 625/1190 [5:33:23<5:28:34, 34.89s/it]\n",
            "4966.jpg: actual-predicted:      0,   19.3, error:   19.3. Current MAE: 44.33, RMSE: 71.77:  53% 626/1190 [5:33:23<5:14:48, 33.49s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([22556, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4967.jpg: actual-predicted:      0,   10.8, error:   10.8. Current MAE: 44.28, RMSE: 71.71:  53% 626/1190 [5:33:59<5:14:48, 33.49s/it]\n",
            "4967.jpg: actual-predicted:      0,   10.8, error:   10.8. Current MAE: 44.28, RMSE: 71.71:  53% 627/1190 [5:33:59<5:20:09, 34.12s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([28592, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4969.jpg: actual-predicted:      0,  110.8, error:  110.8. Current MAE: 44.39, RMSE: 71.79:  53% 627/1190 [5:34:24<5:20:09, 34.12s/it]\n",
            "4969.jpg: actual-predicted:      0,  110.8, error:  110.8. Current MAE: 44.39, RMSE: 71.79:  53% 628/1190 [5:34:24<4:54:48, 31.47s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([52011, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "4970.jpg: actual-predicted:      0,   33.0, error:   33.0. Current MAE: 44.37, RMSE: 71.75:  53% 628/1190 [5:34:56<4:54:48, 31.47s/it]\n",
            "4970.jpg: actual-predicted:      0,   33.0, error:   33.0. Current MAE: 44.37, RMSE: 71.75:  53% 629/1190 [5:34:56<4:55:43, 31.63s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([84047, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5141.jpg: actual-predicted:      0,   18.0, error:   18.0. Current MAE: 44.33, RMSE: 71.69:  53% 629/1190 [5:35:22<4:55:43, 31.63s/it]\n",
            "5141.jpg: actual-predicted:      0,   18.0, error:   18.0. Current MAE: 44.33, RMSE: 71.69:  53% 630/1190 [5:35:22<4:39:50, 29.98s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([67424, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5142.jpg: actual-predicted:      0,   97.0, error:   97.0. Current MAE: 44.41, RMSE: 71.74:  53% 630/1190 [5:35:47<4:39:50, 29.98s/it]\n",
            "5142.jpg: actual-predicted:      0,   97.0, error:   97.0. Current MAE: 44.41, RMSE: 71.74:  53% 631/1190 [5:35:47<4:24:16, 28.37s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([112028, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5143.jpg: actual-predicted:      0,   32.8, error:   32.8. Current MAE: 44.39, RMSE: 71.70:  53% 631/1190 [5:36:20<4:24:16, 28.37s/it]\n",
            "5143.jpg: actual-predicted:      0,   32.8, error:   32.8. Current MAE: 44.39, RMSE: 71.70:  53% 632/1190 [5:36:20<4:35:44, 29.65s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([111980, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5144.jpg: actual-predicted:      0,   62.6, error:   62.6. Current MAE: 44.42, RMSE: 71.68:  53% 632/1190 [5:36:55<4:35:44, 29.65s/it]\n",
            "5144.jpg: actual-predicted:      0,   62.6, error:   62.6. Current MAE: 44.42, RMSE: 71.68:  53% 633/1190 [5:36:55<4:50:19, 31.27s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([122659, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5145.jpg: actual-predicted:      0,   16.2, error:   16.2. Current MAE: 44.38, RMSE: 71.63:  53% 633/1190 [5:37:21<4:50:19, 31.27s/it]\n",
            "5145.jpg: actual-predicted:      0,   16.2, error:   16.2. Current MAE: 44.38, RMSE: 71.63:  53% 634/1190 [5:37:21<4:36:56, 29.89s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([155321, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5147.jpg: actual-predicted:      0,   27.9, error:   27.9. Current MAE: 44.35, RMSE: 71.58:  53% 634/1190 [5:38:02<4:36:56, 29.89s/it]\n",
            "5147.jpg: actual-predicted:      0,   27.9, error:   27.9. Current MAE: 44.35, RMSE: 71.58:  53% 635/1190 [5:38:02<5:06:42, 33.16s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([130824, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5148.jpg: actual-predicted:      0,   28.8, error:   28.8. Current MAE: 44.32, RMSE: 71.53:  53% 635/1190 [5:38:34<5:06:42, 33.16s/it]\n",
            "5148.jpg: actual-predicted:      0,   28.8, error:   28.8. Current MAE: 44.32, RMSE: 71.53:  53% 636/1190 [5:38:34<5:03:11, 32.84s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([80716, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5149.jpg: actual-predicted:      0,  146.5, error:  146.5. Current MAE: 44.49, RMSE: 71.71:  53% 636/1190 [5:38:58<5:03:11, 32.84s/it]\n",
            "5149.jpg: actual-predicted:      0,  146.5, error:  146.5. Current MAE: 44.49, RMSE: 71.71:  54% 637/1190 [5:38:58<4:38:37, 30.23s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([150217, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5356.jpg: actual-predicted:      0,   21.9, error:   21.9. Current MAE: 44.45, RMSE: 71.66:  54% 637/1190 [5:39:31<4:38:37, 30.23s/it]\n",
            "5356.jpg: actual-predicted:      0,   21.9, error:   21.9. Current MAE: 44.45, RMSE: 71.66:  54% 638/1190 [5:39:31<4:43:22, 30.80s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([177666, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5357.jpg: actual-predicted:      0,   16.6, error:   16.6. Current MAE: 44.41, RMSE: 71.61:  54% 638/1190 [5:40:05<4:43:22, 30.80s/it]\n",
            "5357.jpg: actual-predicted:      0,   16.6, error:   16.6. Current MAE: 44.41, RMSE: 71.61:  54% 639/1190 [5:40:05<4:51:37, 31.76s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([67432, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5358.jpg: actual-predicted:      0,   26.3, error:   26.3. Current MAE: 44.38, RMSE: 71.56:  54% 639/1190 [5:40:40<4:51:37, 31.76s/it]\n",
            "5358.jpg: actual-predicted:      0,   26.3, error:   26.3. Current MAE: 44.38, RMSE: 71.56:  54% 640/1190 [5:40:40<5:00:22, 32.77s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([163595, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5359.jpg: actual-predicted:      0,   24.3, error:   24.3. Current MAE: 44.35, RMSE: 71.51:  54% 640/1190 [5:41:13<5:00:22, 32.77s/it]\n",
            "5359.jpg: actual-predicted:      0,   24.3, error:   24.3. Current MAE: 44.35, RMSE: 71.51:  54% 641/1190 [5:41:13<5:01:10, 32.91s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([101797, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5360.jpg: actual-predicted:      0,   67.4, error:   67.4. Current MAE: 44.38, RMSE: 71.51:  54% 641/1190 [5:41:44<5:01:10, 32.91s/it]\n",
            "5360.jpg: actual-predicted:      0,   67.4, error:   67.4. Current MAE: 44.38, RMSE: 71.51:  54% 642/1190 [5:41:44<4:56:02, 32.41s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([160523, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5361.jpg: actual-predicted:      0,   24.0, error:   24.0. Current MAE: 44.35, RMSE: 71.46:  54% 642/1190 [5:42:16<4:56:02, 32.41s/it]\n",
            "5361.jpg: actual-predicted:      0,   24.0, error:   24.0. Current MAE: 44.35, RMSE: 71.46:  54% 643/1190 [5:42:16<4:54:06, 32.26s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([152129, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5362.jpg: actual-predicted:      0,   26.1, error:   26.1. Current MAE: 44.32, RMSE: 71.41:  54% 643/1190 [5:42:43<4:54:06, 32.26s/it]\n",
            "5362.jpg: actual-predicted:      0,   26.1, error:   26.1. Current MAE: 44.32, RMSE: 71.41:  54% 644/1190 [5:42:43<4:39:18, 30.69s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([141706, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5363.jpg: actual-predicted:      0,   47.9, error:   47.9. Current MAE: 44.33, RMSE: 71.38:  54% 644/1190 [5:43:15<4:39:18, 30.69s/it]\n",
            "5363.jpg: actual-predicted:      0,   47.9, error:   47.9. Current MAE: 44.33, RMSE: 71.38:  54% 645/1190 [5:43:15<4:41:47, 31.02s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([93013, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5364.jpg: actual-predicted:      0,   23.8, error:   23.8. Current MAE: 44.30, RMSE: 71.33:  54% 645/1190 [5:43:45<4:41:47, 31.02s/it]\n",
            "5364.jpg: actual-predicted:      0,   23.8, error:   23.8. Current MAE: 44.30, RMSE: 71.33:  54% 646/1190 [5:43:45<4:38:24, 30.71s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([190146, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5365.jpg: actual-predicted:      0,   35.5, error:   35.5. Current MAE: 44.28, RMSE: 71.29:  54% 646/1190 [5:44:17<4:38:24, 30.71s/it]\n",
            "5365.jpg: actual-predicted:      0,   35.5, error:   35.5. Current MAE: 44.28, RMSE: 71.29:  54% 647/1190 [5:44:17<4:41:02, 31.05s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([109385, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5366.jpg: actual-predicted:      0,   53.5, error:   53.5. Current MAE: 44.30, RMSE: 71.26:  54% 647/1190 [5:44:49<4:41:02, 31.05s/it]\n",
            "5366.jpg: actual-predicted:      0,   53.5, error:   53.5. Current MAE: 44.30, RMSE: 71.26:  54% 648/1190 [5:44:49<4:44:16, 31.47s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([46686, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5367.jpg: actual-predicted:      0,  139.0, error:  139.0. Current MAE: 44.44, RMSE: 71.42:  54% 648/1190 [5:45:26<4:44:16, 31.47s/it]\n",
            "5367.jpg: actual-predicted:      0,  139.0, error:  139.0. Current MAE: 44.44, RMSE: 71.42:  55% 649/1190 [5:45:26<4:57:31, 33.00s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([33177, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5368.jpg: actual-predicted:      0,  176.8, error:  176.8. Current MAE: 44.65, RMSE: 71.70:  55% 649/1190 [5:45:51<4:57:31, 33.00s/it]\n",
            "5368.jpg: actual-predicted:      0,  176.8, error:  176.8. Current MAE: 44.65, RMSE: 71.70:  55% 650/1190 [5:45:51<4:36:27, 30.72s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([120212, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5369.jpg: actual-predicted:      0,   31.2, error:   31.2. Current MAE: 44.63, RMSE: 71.65:  55% 650/1190 [5:46:23<4:36:27, 30.72s/it]\n",
            "5369.jpg: actual-predicted:      0,   31.2, error:   31.2. Current MAE: 44.63, RMSE: 71.65:  55% 651/1190 [5:46:23<4:37:40, 30.91s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([25379, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5371.jpg: actual-predicted:      0,   47.5, error:   47.5. Current MAE: 44.63, RMSE: 71.62:  55% 651/1190 [5:46:47<4:37:40, 30.91s/it]\n",
            "5371.jpg: actual-predicted:      0,   47.5, error:   47.5. Current MAE: 44.63, RMSE: 71.62:  55% 652/1190 [5:46:47<4:19:06, 28.90s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([73136, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5372.jpg: actual-predicted:      0,   39.5, error:   39.5. Current MAE: 44.62, RMSE: 71.58:  55% 652/1190 [5:47:13<4:19:06, 28.90s/it]\n",
            "5372.jpg: actual-predicted:      0,   39.5, error:   39.5. Current MAE: 44.62, RMSE: 71.58:  55% 653/1190 [5:47:13<4:11:43, 28.13s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([70287, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5373.jpg: actual-predicted:      0,   46.7, error:   46.7. Current MAE: 44.63, RMSE: 71.55:  55% 653/1190 [5:47:44<4:11:43, 28.13s/it]\n",
            "5373.jpg: actual-predicted:      0,   46.7, error:   46.7. Current MAE: 44.63, RMSE: 71.55:  55% 654/1190 [5:47:44<4:19:20, 29.03s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([121229, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5374.jpg: actual-predicted:      0,   21.1, error:   21.1. Current MAE: 44.59, RMSE: 71.50:  55% 654/1190 [5:48:10<4:19:20, 29.03s/it]\n",
            "5374.jpg: actual-predicted:      0,   21.1, error:   21.1. Current MAE: 44.59, RMSE: 71.50:  55% 655/1190 [5:48:10<4:11:36, 28.22s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([30692, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5375.jpg: actual-predicted:      0,   16.8, error:   16.8. Current MAE: 44.55, RMSE: 71.45:  55% 655/1190 [5:48:46<4:11:36, 28.22s/it]\n",
            "5375.jpg: actual-predicted:      0,   16.8, error:   16.8. Current MAE: 44.55, RMSE: 71.45:  55% 656/1190 [5:48:46<4:30:22, 30.38s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([86391, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5376.jpg: actual-predicted:      0,   14.9, error:   14.9. Current MAE: 44.50, RMSE: 71.40:  55% 656/1190 [5:49:12<4:30:22, 30.38s/it]\n",
            "5376.jpg: actual-predicted:      0,   14.9, error:   14.9. Current MAE: 44.50, RMSE: 71.40:  55% 657/1190 [5:49:12<4:18:22, 29.09s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([131467, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5377.jpg: actual-predicted:      0,    8.8, error:    8.8. Current MAE: 44.45, RMSE: 71.35:  55% 657/1190 [5:49:42<4:18:22, 29.09s/it]\n",
            "5377.jpg: actual-predicted:      0,    8.8, error:    8.8. Current MAE: 44.45, RMSE: 71.35:  55% 658/1190 [5:49:42<4:19:21, 29.25s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([98630, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5378.jpg: actual-predicted:      0,   12.5, error:   12.5. Current MAE: 44.40, RMSE: 71.29:  55% 658/1190 [5:50:06<4:19:21, 29.25s/it]\n",
            "5378.jpg: actual-predicted:      0,   12.5, error:   12.5. Current MAE: 44.40, RMSE: 71.29:  55% 659/1190 [5:50:06<4:07:03, 27.92s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([85973, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5379.jpg: actual-predicted:      0,   11.1, error:   11.1. Current MAE: 44.35, RMSE: 71.24:  55% 659/1190 [5:50:33<4:07:03, 27.92s/it]\n",
            "5379.jpg: actual-predicted:      0,   11.1, error:   11.1. Current MAE: 44.35, RMSE: 71.24:  55% 660/1190 [5:50:33<4:02:07, 27.41s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([104333, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5380.jpg: actual-predicted:      0,   10.8, error:   10.8. Current MAE: 44.30, RMSE: 71.19:  55% 660/1190 [5:50:59<4:02:07, 27.41s/it]\n",
            "5380.jpg: actual-predicted:      0,   10.8, error:   10.8. Current MAE: 44.30, RMSE: 71.19:  56% 661/1190 [5:50:59<3:58:30, 27.05s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([154984, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5381.jpg: actual-predicted:      0,    8.5, error:    8.5. Current MAE: 44.24, RMSE: 71.14:  56% 661/1190 [5:51:28<3:58:30, 27.05s/it]\n",
            "5381.jpg: actual-predicted:      0,    8.5, error:    8.5. Current MAE: 44.24, RMSE: 71.14:  56% 662/1190 [5:51:28<4:04:04, 27.74s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([186554, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5382.jpg: actual-predicted:      0,    9.3, error:    9.3. Current MAE: 44.19, RMSE: 71.08:  56% 662/1190 [5:52:04<4:04:04, 27.74s/it]\n",
            "5382.jpg: actual-predicted:      0,    9.3, error:    9.3. Current MAE: 44.19, RMSE: 71.08:  56% 663/1190 [5:52:04<4:24:16, 30.09s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([97065, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5383.jpg: actual-predicted:      0,   10.5, error:   10.5. Current MAE: 44.14, RMSE: 71.03:  56% 663/1190 [5:52:30<4:24:16, 30.09s/it]\n",
            "5383.jpg: actual-predicted:      0,   10.5, error:   10.5. Current MAE: 44.14, RMSE: 71.03:  56% 664/1190 [5:52:30<4:14:36, 29.04s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([81133, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5385.jpg: actual-predicted:      0,   12.9, error:   12.9. Current MAE: 44.09, RMSE: 70.98:  56% 664/1190 [5:52:55<4:14:36, 29.04s/it]\n",
            "5385.jpg: actual-predicted:      0,   12.9, error:   12.9. Current MAE: 44.09, RMSE: 70.98:  56% 665/1190 [5:52:55<4:02:43, 27.74s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([133460, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5386.jpg: actual-predicted:      0,   12.6, error:   12.6. Current MAE: 44.05, RMSE: 70.93:  56% 665/1190 [5:53:29<4:02:43, 27.74s/it]\n",
            "5386.jpg: actual-predicted:      0,   12.6, error:   12.6. Current MAE: 44.05, RMSE: 70.93:  56% 666/1190 [5:53:29<4:17:47, 29.52s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([102551, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5387.jpg: actual-predicted:      0,    8.6, error:    8.6. Current MAE: 43.99, RMSE: 70.87:  56% 666/1190 [5:54:02<4:17:47, 29.52s/it]\n",
            "5387.jpg: actual-predicted:      0,    8.6, error:    8.6. Current MAE: 43.99, RMSE: 70.87:  56% 667/1190 [5:54:02<4:27:31, 30.69s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([127362, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5388.jpg: actual-predicted:      0,   20.9, error:   20.9. Current MAE: 43.96, RMSE: 70.83:  56% 667/1190 [5:54:29<4:27:31, 30.69s/it]\n",
            "5388.jpg: actual-predicted:      0,   20.9, error:   20.9. Current MAE: 43.96, RMSE: 70.83:  56% 668/1190 [5:54:29<4:16:16, 29.46s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([103201, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5390.jpg: actual-predicted:      0,   17.6, error:   17.6. Current MAE: 43.92, RMSE: 70.78:  56% 668/1190 [5:54:55<4:16:16, 29.46s/it]\n",
            "5390.jpg: actual-predicted:      0,   17.6, error:   17.6. Current MAE: 43.92, RMSE: 70.78:  56% 669/1190 [5:54:55<4:07:43, 28.53s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([142408, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5391.jpg: actual-predicted:      0,   13.3, error:   13.3. Current MAE: 43.87, RMSE: 70.73:  56% 669/1190 [5:55:30<4:07:43, 28.53s/it]\n",
            "5391.jpg: actual-predicted:      0,   13.3, error:   13.3. Current MAE: 43.87, RMSE: 70.73:  56% 670/1190 [5:55:30<4:24:46, 30.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([80912, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5458.jpg: actual-predicted:      0,   37.9, error:   37.9. Current MAE: 43.86, RMSE: 70.69:  56% 670/1190 [5:55:57<4:24:46, 30.55s/it]\n",
            "5458.jpg: actual-predicted:      0,   37.9, error:   37.9. Current MAE: 43.86, RMSE: 70.69:  56% 671/1190 [5:55:57<4:12:51, 29.23s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([152599, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5459.jpg: actual-predicted:      0,   48.4, error:   48.4. Current MAE: 43.87, RMSE: 70.66:  56% 671/1190 [5:56:37<4:12:51, 29.23s/it]\n",
            "5460.jpg: actual-predicted:      0,  127.7, error:  127.7. Current MAE: 44.00, RMSE: 70.78:  56% 672/1190 [5:57:08<4:42:40, 32.74s/it]\n",
            "5460.jpg: actual-predicted:      0,  127.7, error:  127.7. Current MAE: 44.00, RMSE: 70.78:  57% 673/1190 [5:57:08<4:35:19, 31.95s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([99398, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5461.jpg: actual-predicted:      0,   19.3, error:   19.3. Current MAE: 43.96, RMSE: 70.73:  57% 673/1190 [5:57:32<4:35:19, 31.95s/it]\n",
            "5461.jpg: actual-predicted:      0,   19.3, error:   19.3. Current MAE: 43.96, RMSE: 70.73:  57% 674/1190 [5:57:32<4:16:15, 29.80s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([129965, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5463.jpg: actual-predicted:      0,   17.2, error:   17.2. Current MAE: 43.92, RMSE: 70.68:  57% 674/1190 [5:57:59<4:16:15, 29.80s/it]\n",
            "5463.jpg: actual-predicted:      0,   17.2, error:   17.2. Current MAE: 43.92, RMSE: 70.68:  57% 675/1190 [5:57:59<4:06:47, 28.75s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([69391, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5464.jpg: actual-predicted:      0,   39.5, error:   39.5. Current MAE: 43.91, RMSE: 70.65:  57% 675/1190 [5:58:26<4:06:47, 28.75s/it]\n",
            "5503.jpg: actual-predicted:      0,  111.5, error:  111.5. Current MAE: 44.01, RMSE: 70.72:  57% 676/1190 [5:58:56<4:02:26, 28.30s/it]\n",
            "5503.jpg: actual-predicted:      0,  111.5, error:  111.5. Current MAE: 44.01, RMSE: 70.72:  57% 677/1190 [5:58:56<4:05:30, 28.72s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([96746, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5504.jpg: actual-predicted:      0,   95.0, error:   95.0. Current MAE: 44.09, RMSE: 70.77:  57% 677/1190 [5:59:20<4:05:30, 28.72s/it]\n",
            "5504.jpg: actual-predicted:      0,   95.0, error:   95.0. Current MAE: 44.09, RMSE: 70.77:  57% 678/1190 [5:59:20<3:54:04, 27.43s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([108293, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5505.jpg: actual-predicted:      0,   94.9, error:   94.9. Current MAE: 44.16, RMSE: 70.81:  57% 678/1190 [5:59:46<3:54:04, 27.43s/it]\n",
            "5505.jpg: actual-predicted:      0,   94.9, error:   94.9. Current MAE: 44.16, RMSE: 70.81:  57% 679/1190 [5:59:46<3:50:30, 27.07s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([112910, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5506.jpg: actual-predicted:      0,   47.6, error:   47.6. Current MAE: 44.17, RMSE: 70.78:  57% 679/1190 [6:00:16<3:50:30, 27.07s/it]\n",
            "5507.jpg: actual-predicted:      0,  232.5, error:  232.5. Current MAE: 44.44, RMSE: 71.28:  57% 680/1190 [6:00:39<3:55:57, 27.76s/it]\n",
            "5508.jpg: actual-predicted:      0,  113.9, error:  113.9. Current MAE: 44.55, RMSE: 71.37:  57% 681/1190 [6:01:03<3:45:19, 26.56s/it]\n",
            "5509.jpg: actual-predicted:      0,  121.2, error:  121.2. Current MAE: 44.66, RMSE: 71.46:  57% 682/1190 [6:01:41<3:36:33, 25.58s/it]\n",
            "5509.jpg: actual-predicted:      0,  121.2, error:  121.2. Current MAE: 44.66, RMSE: 71.46:  57% 683/1190 [6:01:41<4:09:11, 29.49s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([23386, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5510.jpg: actual-predicted:      0,   71.6, error:   71.6. Current MAE: 44.70, RMSE: 71.46:  57% 683/1190 [6:02:08<4:09:11, 29.49s/it]\n",
            "5510.jpg: actual-predicted:      0,   71.6, error:   71.6. Current MAE: 44.70, RMSE: 71.46:  57% 684/1190 [6:02:08<4:00:40, 28.54s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([160572, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5511.jpg: actual-predicted:      0,   29.6, error:   29.6. Current MAE: 44.68, RMSE: 71.42:  57% 684/1190 [6:02:40<4:00:40, 28.54s/it]\n",
            "5511.jpg: actual-predicted:      0,   29.6, error:   29.6. Current MAE: 44.68, RMSE: 71.42:  58% 685/1190 [6:02:40<4:09:12, 29.61s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([75920, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5512.jpg: actual-predicted:      0,   69.1, error:   69.1. Current MAE: 44.71, RMSE: 71.42:  58% 685/1190 [6:03:06<4:09:12, 29.61s/it]\n",
            "5512.jpg: actual-predicted:      0,   69.1, error:   69.1. Current MAE: 44.71, RMSE: 71.42:  58% 686/1190 [6:03:06<4:00:06, 28.59s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([166101, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5513.jpg: actual-predicted:      0,   80.5, error:   80.5. Current MAE: 44.76, RMSE: 71.43:  58% 686/1190 [6:03:47<4:00:06, 28.59s/it]\n",
            "5513.jpg: actual-predicted:      0,   80.5, error:   80.5. Current MAE: 44.76, RMSE: 71.43:  58% 687/1190 [6:03:47<4:30:59, 32.32s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([174434, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5514.jpg: actual-predicted:      0,   78.9, error:   78.9. Current MAE: 44.81, RMSE: 71.44:  58% 687/1190 [6:04:23<4:30:59, 32.32s/it]\n",
            "5514.jpg: actual-predicted:      0,   78.9, error:   78.9. Current MAE: 44.81, RMSE: 71.44:  58% 688/1190 [6:04:23<4:39:08, 33.36s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([59534, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5562.jpg: actual-predicted:      0,   15.9, error:   15.9. Current MAE: 44.77, RMSE: 71.39:  58% 688/1190 [6:04:47<4:39:08, 33.36s/it]\n",
            "5562.jpg: actual-predicted:      0,   15.9, error:   15.9. Current MAE: 44.77, RMSE: 71.39:  58% 689/1190 [6:04:47<4:16:29, 30.72s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([62953, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5563.jpg: actual-predicted:      0,  222.8, error:  222.8. Current MAE: 45.03, RMSE: 71.85:  58% 689/1190 [6:05:13<4:16:29, 30.72s/it]\n",
            "5563.jpg: actual-predicted:      0,  222.8, error:  222.8. Current MAE: 45.03, RMSE: 71.85:  58% 690/1190 [6:05:13<4:04:13, 29.31s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([95269, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5564.jpg: actual-predicted:      0,   17.1, error:   17.1. Current MAE: 44.99, RMSE: 71.80:  58% 690/1190 [6:05:48<4:04:13, 29.31s/it]\n",
            "5564.jpg: actual-predicted:      0,   17.1, error:   17.1. Current MAE: 44.99, RMSE: 71.80:  58% 691/1190 [6:05:48<4:17:37, 30.98s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([176286, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5565.jpg: actual-predicted:      0,    9.3, error:    9.3. Current MAE: 44.94, RMSE: 71.75:  58% 691/1190 [6:06:24<4:17:37, 30.98s/it]\n",
            "5565.jpg: actual-predicted:      0,    9.3, error:    9.3. Current MAE: 44.94, RMSE: 71.75:  58% 692/1190 [6:06:24<4:28:33, 32.36s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([38480, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5566.jpg: actual-predicted:      0,   26.5, error:   26.5. Current MAE: 44.91, RMSE: 71.70:  58% 692/1190 [6:06:56<4:28:33, 32.36s/it]\n",
            "5566.jpg: actual-predicted:      0,   26.5, error:   26.5. Current MAE: 44.91, RMSE: 71.70:  58% 693/1190 [6:06:56<4:26:57, 32.23s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([67837, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5567.jpg: actual-predicted:      0,   40.0, error:   40.0. Current MAE: 44.90, RMSE: 71.66:  58% 693/1190 [6:07:26<4:26:57, 32.23s/it]\n",
            "5567.jpg: actual-predicted:      0,   40.0, error:   40.0. Current MAE: 44.90, RMSE: 71.66:  58% 694/1190 [6:07:26<4:22:18, 31.73s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([129774, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5568.jpg: actual-predicted:      0,   28.9, error:   28.9. Current MAE: 44.88, RMSE: 71.62:  58% 694/1190 [6:08:11<4:22:18, 31.73s/it]\n",
            "5568.jpg: actual-predicted:      0,   28.9, error:   28.9. Current MAE: 44.88, RMSE: 71.62:  58% 695/1190 [6:08:11<4:54:35, 35.71s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([46006, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5571.jpg: actual-predicted:      0,   25.8, error:   25.8. Current MAE: 44.85, RMSE: 71.58:  58% 695/1190 [6:08:42<4:54:35, 35.71s/it]\n",
            "5571.jpg: actual-predicted:      0,   25.8, error:   25.8. Current MAE: 44.85, RMSE: 71.58:  58% 696/1190 [6:08:42<4:42:56, 34.37s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([68875, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5572.jpg: actual-predicted:      0,   10.0, error:   10.0. Current MAE: 44.80, RMSE: 71.53:  58% 696/1190 [6:09:20<4:42:56, 34.37s/it]\n",
            "5572.jpg: actual-predicted:      0,   10.0, error:   10.0. Current MAE: 44.80, RMSE: 71.53:  59% 697/1190 [6:09:20<4:49:03, 35.18s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([84731, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5573.jpg: actual-predicted:      0,   31.0, error:   31.0. Current MAE: 44.78, RMSE: 71.48:  59% 697/1190 [6:09:44<4:49:03, 35.18s/it]\n",
            "5573.jpg: actual-predicted:      0,   31.0, error:   31.0. Current MAE: 44.78, RMSE: 71.48:  59% 698/1190 [6:09:44<4:22:16, 31.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([74546, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5574.jpg: actual-predicted:      0,  101.4, error:  101.4. Current MAE: 44.86, RMSE: 71.54:  59% 698/1190 [6:10:09<4:22:16, 31.99s/it]\n",
            "5574.jpg: actual-predicted:      0,  101.4, error:  101.4. Current MAE: 44.86, RMSE: 71.54:  59% 699/1190 [6:10:09<4:03:46, 29.79s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([52233, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5575.jpg: actual-predicted:      0,   13.8, error:   13.8. Current MAE: 44.82, RMSE: 71.49:  59% 699/1190 [6:10:33<4:03:46, 29.79s/it]\n",
            "5575.jpg: actual-predicted:      0,   13.8, error:   13.8. Current MAE: 44.82, RMSE: 71.49:  59% 700/1190 [6:10:33<3:48:45, 28.01s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([19659, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5576.jpg: actual-predicted:      0,   78.0, error:   78.0. Current MAE: 44.87, RMSE: 71.50:  59% 700/1190 [6:11:03<3:48:45, 28.01s/it]\n",
            "5576.jpg: actual-predicted:      0,   78.0, error:   78.0. Current MAE: 44.87, RMSE: 71.50:  59% 701/1190 [6:11:03<3:53:54, 28.70s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([39657, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5577.jpg: actual-predicted:      0,   20.9, error:   20.9. Current MAE: 44.83, RMSE: 71.45:  59% 701/1190 [6:11:30<3:53:54, 28.70s/it]\n",
            "5577.jpg: actual-predicted:      0,   20.9, error:   20.9. Current MAE: 44.83, RMSE: 71.45:  59% 702/1190 [6:11:30<3:49:17, 28.19s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([174737, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5578.jpg: actual-predicted:      0,   30.9, error:   30.9. Current MAE: 44.81, RMSE: 71.41:  59% 702/1190 [6:12:08<3:49:17, 28.19s/it]\n",
            "5578.jpg: actual-predicted:      0,   30.9, error:   30.9. Current MAE: 44.81, RMSE: 71.41:  59% 703/1190 [6:12:08<4:12:50, 31.15s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([114016, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5579.jpg: actual-predicted:      0,   32.7, error:   32.7. Current MAE: 44.80, RMSE: 71.37:  59% 703/1190 [6:12:37<4:12:50, 31.15s/it]\n",
            "5579.jpg: actual-predicted:      0,   32.7, error:   32.7. Current MAE: 44.80, RMSE: 71.37:  59% 704/1190 [6:12:37<4:07:24, 30.54s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([41170, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5580.jpg: actual-predicted:      0,   49.7, error:   49.7. Current MAE: 44.80, RMSE: 71.34:  59% 704/1190 [6:13:03<4:07:24, 30.54s/it]\n",
            "5580.jpg: actual-predicted:      0,   49.7, error:   49.7. Current MAE: 44.80, RMSE: 71.34:  59% 705/1190 [6:13:03<3:54:49, 29.05s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([111754, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5581.jpg: actual-predicted:      0,    9.4, error:    9.4. Current MAE: 44.75, RMSE: 71.29:  59% 705/1190 [6:13:37<3:54:49, 29.05s/it]\n",
            "5581.jpg: actual-predicted:      0,    9.4, error:    9.4. Current MAE: 44.75, RMSE: 71.29:  59% 706/1190 [6:13:37<4:06:23, 30.54s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([62753, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5582.jpg: actual-predicted:      0,   59.0, error:   59.0. Current MAE: 44.77, RMSE: 71.28:  59% 706/1190 [6:14:01<4:06:23, 30.54s/it]\n",
            "5582.jpg: actual-predicted:      0,   59.0, error:   59.0. Current MAE: 44.77, RMSE: 71.28:  59% 707/1190 [6:14:01<3:50:51, 28.68s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([121816, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5583.jpg: actual-predicted:      0,   14.8, error:   14.8. Current MAE: 44.73, RMSE: 71.23:  59% 707/1190 [6:14:33<3:50:51, 28.68s/it]\n",
            "5583.jpg: actual-predicted:      0,   14.8, error:   14.8. Current MAE: 44.73, RMSE: 71.23:  59% 708/1190 [6:14:33<3:57:18, 29.54s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([91355, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5584.jpg: actual-predicted:      0,   56.1, error:   56.1. Current MAE: 44.75, RMSE: 71.21:  59% 708/1190 [6:14:59<3:57:18, 29.54s/it]\n",
            "5584.jpg: actual-predicted:      0,   56.1, error:   56.1. Current MAE: 44.75, RMSE: 71.21:  60% 709/1190 [6:14:59<3:48:22, 28.49s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([82578, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5585.jpg: actual-predicted:      0,   44.2, error:   44.2. Current MAE: 44.75, RMSE: 71.18:  60% 709/1190 [6:15:30<3:48:22, 28.49s/it]\n",
            "5585.jpg: actual-predicted:      0,   44.2, error:   44.2. Current MAE: 44.75, RMSE: 71.18:  60% 710/1190 [6:15:30<3:54:27, 29.31s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([96812, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5587.jpg: actual-predicted:      0,   20.4, error:   20.4. Current MAE: 44.71, RMSE: 71.13:  60% 710/1190 [6:16:01<3:54:27, 29.31s/it]\n",
            "5587.jpg: actual-predicted:      0,   20.4, error:   20.4. Current MAE: 44.71, RMSE: 71.13:  60% 711/1190 [6:16:01<3:58:59, 29.94s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([63803, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5588.jpg: actual-predicted:      0,   47.1, error:   47.1. Current MAE: 44.72, RMSE: 71.11:  60% 711/1190 [6:16:28<3:58:59, 29.94s/it]\n",
            "5588.jpg: actual-predicted:      0,   47.1, error:   47.1. Current MAE: 44.72, RMSE: 71.11:  60% 712/1190 [6:16:28<3:51:03, 29.00s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([51968, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5590.jpg: actual-predicted:      0,   22.0, error:   22.0. Current MAE: 44.68, RMSE: 71.06:  60% 712/1190 [6:17:09<3:51:03, 29.00s/it]\n",
            "5590.jpg: actual-predicted:      0,   22.0, error:   22.0. Current MAE: 44.68, RMSE: 71.06:  60% 713/1190 [6:17:09<4:18:20, 32.50s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([45688, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5591.jpg: actual-predicted:      0,   40.7, error:   40.7. Current MAE: 44.68, RMSE: 71.03:  60% 713/1190 [6:17:34<4:18:20, 32.50s/it]\n",
            "5591.jpg: actual-predicted:      0,   40.7, error:   40.7. Current MAE: 44.68, RMSE: 71.03:  60% 714/1190 [6:17:34<4:01:14, 30.41s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64675, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5592.jpg: actual-predicted:      0,  106.9, error:  106.9. Current MAE: 44.77, RMSE: 71.09:  60% 714/1190 [6:18:00<4:01:14, 30.41s/it]\n",
            "5592.jpg: actual-predicted:      0,  106.9, error:  106.9. Current MAE: 44.77, RMSE: 71.09:  60% 715/1190 [6:18:00<3:49:13, 28.95s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([76898, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5593.jpg: actual-predicted:      0,   27.6, error:   27.6. Current MAE: 44.74, RMSE: 71.05:  60% 715/1190 [6:18:40<3:49:13, 28.95s/it]\n",
            "5593.jpg: actual-predicted:      0,   27.6, error:   27.6. Current MAE: 44.74, RMSE: 71.05:  60% 716/1190 [6:18:40<4:15:42, 32.37s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([95305, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5594.jpg: actual-predicted:      0,   19.5, error:   19.5. Current MAE: 44.71, RMSE: 71.00:  60% 716/1190 [6:19:12<4:15:42, 32.37s/it]\n",
            "5594.jpg: actual-predicted:      0,   19.5, error:   19.5. Current MAE: 44.71, RMSE: 71.00:  60% 717/1190 [6:19:12<4:14:56, 32.34s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([68514, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5595.jpg: actual-predicted:      0,   14.9, error:   14.9. Current MAE: 44.66, RMSE: 70.95:  60% 717/1190 [6:19:45<4:14:56, 32.34s/it]\n",
            "5595.jpg: actual-predicted:      0,   14.9, error:   14.9. Current MAE: 44.66, RMSE: 70.95:  60% 718/1190 [6:19:45<4:14:25, 32.34s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([90165, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5596.jpg: actual-predicted:      0,   51.8, error:   51.8. Current MAE: 44.67, RMSE: 70.93:  60% 718/1190 [6:20:16<4:14:25, 32.34s/it]\n",
            "5596.jpg: actual-predicted:      0,   51.8, error:   51.8. Current MAE: 44.67, RMSE: 70.93:  60% 719/1190 [6:20:16<4:10:12, 31.87s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([129711, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5597.jpg: actual-predicted:      0,   57.2, error:   57.2. Current MAE: 44.69, RMSE: 70.91:  60% 719/1190 [6:20:49<4:10:12, 31.87s/it]\n",
            "5597.jpg: actual-predicted:      0,   57.2, error:   57.2. Current MAE: 44.69, RMSE: 70.91:  61% 720/1190 [6:20:49<4:13:11, 32.32s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([79535, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5598.jpg: actual-predicted:      0,   25.9, error:   25.9. Current MAE: 44.67, RMSE: 70.87:  61% 720/1190 [6:21:20<4:13:11, 32.32s/it]\n",
            "5598.jpg: actual-predicted:      0,   25.9, error:   25.9. Current MAE: 44.67, RMSE: 70.87:  61% 721/1190 [6:21:20<4:09:38, 31.94s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([108853, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5599.jpg: actual-predicted:      0,   32.8, error:   32.8. Current MAE: 44.65, RMSE: 70.83:  61% 721/1190 [6:21:45<4:09:38, 31.94s/it]\n",
            "5599.jpg: actual-predicted:      0,   32.8, error:   32.8. Current MAE: 44.65, RMSE: 70.83:  61% 722/1190 [6:21:45<3:52:40, 29.83s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([50785, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5600.jpg: actual-predicted:      0,  106.3, error:  106.3. Current MAE: 44.73, RMSE: 70.89:  61% 722/1190 [6:22:11<3:52:40, 29.83s/it]\n",
            "5600.jpg: actual-predicted:      0,  106.3, error:  106.3. Current MAE: 44.73, RMSE: 70.89:  61% 723/1190 [6:22:11<3:43:46, 28.75s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([62696, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5601.jpg: actual-predicted:      0,   29.5, error:   29.5. Current MAE: 44.71, RMSE: 70.85:  61% 723/1190 [6:22:42<3:43:46, 28.75s/it]\n",
            "5601.jpg: actual-predicted:      0,   29.5, error:   29.5. Current MAE: 44.71, RMSE: 70.85:  61% 724/1190 [6:22:42<3:48:37, 29.44s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([67463, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5602.jpg: actual-predicted:      0,   23.7, error:   23.7. Current MAE: 44.68, RMSE: 70.81:  61% 724/1190 [6:23:13<3:48:37, 29.44s/it]\n",
            "5602.jpg: actual-predicted:      0,   23.7, error:   23.7. Current MAE: 44.68, RMSE: 70.81:  61% 725/1190 [6:23:13<3:51:49, 29.91s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([58892, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5791.jpg: actual-predicted:      0,   12.0, error:   12.0. Current MAE: 44.64, RMSE: 70.76:  61% 725/1190 [6:23:40<3:51:49, 29.91s/it]\n",
            "5791.jpg: actual-predicted:      0,   12.0, error:   12.0. Current MAE: 44.64, RMSE: 70.76:  61% 726/1190 [6:23:40<3:44:08, 28.98s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([128624, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5792.jpg: actual-predicted:      0,   10.5, error:   10.5. Current MAE: 44.59, RMSE: 70.72:  61% 726/1190 [6:24:13<3:44:08, 28.98s/it]\n",
            "5792.jpg: actual-predicted:      0,   10.5, error:   10.5. Current MAE: 44.59, RMSE: 70.72:  61% 727/1190 [6:24:13<3:52:18, 30.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([92056, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5793.jpg: actual-predicted:      0,   42.1, error:   42.1. Current MAE: 44.59, RMSE: 70.68:  61% 727/1190 [6:24:53<3:52:18, 30.10s/it]\n",
            "5793.jpg: actual-predicted:      0,   42.1, error:   42.1. Current MAE: 44.59, RMSE: 70.68:  61% 728/1190 [6:24:53<4:14:42, 33.08s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([138562, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5794.jpg: actual-predicted:      0,   12.8, error:   12.8. Current MAE: 44.55, RMSE: 70.64:  61% 728/1190 [6:25:29<4:14:42, 33.08s/it]\n",
            "5794.jpg: actual-predicted:      0,   12.8, error:   12.8. Current MAE: 44.55, RMSE: 70.64:  61% 729/1190 [6:25:29<4:21:20, 34.01s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([122098, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5795.jpg: actual-predicted:      0,   84.0, error:   84.0. Current MAE: 44.60, RMSE: 70.66:  61% 729/1190 [6:26:04<4:21:20, 34.01s/it]\n",
            "5795.jpg: actual-predicted:      0,   84.0, error:   84.0. Current MAE: 44.60, RMSE: 70.66:  61% 730/1190 [6:26:04<4:23:21, 34.35s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([96789, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5796.jpg: actual-predicted:      0,   55.0, error:   55.0. Current MAE: 44.61, RMSE: 70.64:  61% 730/1190 [6:26:47<4:23:21, 34.35s/it]\n",
            "5796.jpg: actual-predicted:      0,   55.0, error:   55.0. Current MAE: 44.61, RMSE: 70.64:  61% 731/1190 [6:26:47<4:41:41, 36.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([55444, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5797.jpg: actual-predicted:      0,   49.4, error:   49.4. Current MAE: 44.62, RMSE: 70.61:  61% 731/1190 [6:27:15<4:41:41, 36.82s/it]\n",
            "5797.jpg: actual-predicted:      0,   49.4, error:   49.4. Current MAE: 44.62, RMSE: 70.61:  62% 732/1190 [6:27:15<4:21:24, 34.25s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([168568, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5798.jpg: actual-predicted:      0,   34.4, error:   34.4. Current MAE: 44.61, RMSE: 70.58:  62% 732/1190 [6:27:50<4:21:24, 34.25s/it]\n",
            "5798.jpg: actual-predicted:      0,   34.4, error:   34.4. Current MAE: 44.61, RMSE: 70.58:  62% 733/1190 [6:27:50<4:23:00, 34.53s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([115371, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5799.jpg: actual-predicted:      0,   15.8, error:   15.8. Current MAE: 44.57, RMSE: 70.53:  62% 733/1190 [6:28:33<4:23:00, 34.53s/it]\n",
            "5799.jpg: actual-predicted:      0,   15.8, error:   15.8. Current MAE: 44.57, RMSE: 70.53:  62% 734/1190 [6:28:33<4:41:13, 37.00s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([160450, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5800.jpg: actual-predicted:      0,    9.5, error:    9.5. Current MAE: 44.52, RMSE: 70.48:  62% 734/1190 [6:29:08<4:41:13, 37.00s/it]\n",
            "5800.jpg: actual-predicted:      0,    9.5, error:    9.5. Current MAE: 44.52, RMSE: 70.48:  62% 735/1190 [6:29:08<4:36:08, 36.42s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([65658, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5801.jpg: actual-predicted:      0,  142.6, error:  142.6. Current MAE: 44.65, RMSE: 70.63:  62% 735/1190 [6:29:32<4:36:08, 36.42s/it]\n",
            "5801.jpg: actual-predicted:      0,  142.6, error:  142.6. Current MAE: 44.65, RMSE: 70.63:  62% 736/1190 [6:29:32<4:07:58, 32.77s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([96233, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5802.jpg: actual-predicted:      0,   16.0, error:   16.0. Current MAE: 44.61, RMSE: 70.59:  62% 736/1190 [6:30:13<4:07:58, 32.77s/it]\n",
            "5802.jpg: actual-predicted:      0,   16.0, error:   16.0. Current MAE: 44.61, RMSE: 70.59:  62% 737/1190 [6:30:13<4:26:05, 35.24s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([128924, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5803.jpg: actual-predicted:      0,   20.7, error:   20.7. Current MAE: 44.58, RMSE: 70.54:  62% 737/1190 [6:30:45<4:26:05, 35.24s/it]\n",
            "5803.jpg: actual-predicted:      0,   20.7, error:   20.7. Current MAE: 44.58, RMSE: 70.54:  62% 738/1190 [6:30:45<4:16:52, 34.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([126882, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5804.jpg: actual-predicted:      0,   12.1, error:   12.1. Current MAE: 44.54, RMSE: 70.50:  62% 738/1190 [6:31:11<4:16:52, 34.10s/it]\n",
            "5804.jpg: actual-predicted:      0,   12.1, error:   12.1. Current MAE: 44.54, RMSE: 70.50:  62% 739/1190 [6:31:11<3:58:55, 31.79s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([56826, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5805.jpg: actual-predicted:      0,   10.9, error:   10.9. Current MAE: 44.49, RMSE: 70.45:  62% 739/1190 [6:31:40<3:58:55, 31.79s/it]\n",
            "5805.jpg: actual-predicted:      0,   10.9, error:   10.9. Current MAE: 44.49, RMSE: 70.45:  62% 740/1190 [6:31:40<3:51:43, 30.90s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([130174, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5806.jpg: actual-predicted:      0,   28.7, error:   28.7. Current MAE: 44.47, RMSE: 70.41:  62% 740/1190 [6:32:21<3:51:43, 30.90s/it]\n",
            "5806.jpg: actual-predicted:      0,   28.7, error:   28.7. Current MAE: 44.47, RMSE: 70.41:  62% 741/1190 [6:32:21<4:13:34, 33.89s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([69949, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5807.jpg: actual-predicted:      0,  120.4, error:  120.4. Current MAE: 44.57, RMSE: 70.50:  62% 741/1190 [6:32:45<4:13:34, 33.89s/it]\n",
            "5807.jpg: actual-predicted:      0,  120.4, error:  120.4. Current MAE: 44.57, RMSE: 70.50:  62% 742/1190 [6:32:45<3:51:13, 30.97s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([77321, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5808.jpg: actual-predicted:      0,   37.1, error:   37.1. Current MAE: 44.56, RMSE: 70.47:  62% 742/1190 [6:33:09<3:51:13, 30.97s/it]\n",
            "5808.jpg: actual-predicted:      0,   37.1, error:   37.1. Current MAE: 44.56, RMSE: 70.47:  62% 743/1190 [6:33:09<3:35:38, 28.94s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([58235, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5809.jpg: actual-predicted:      0,    9.7, error:    9.7. Current MAE: 44.52, RMSE: 70.42:  62% 743/1190 [6:33:33<3:35:38, 28.94s/it]\n",
            "5810.jpg: actual-predicted:      0,  110.0, error:  110.0. Current MAE: 44.60, RMSE: 70.49:  63% 744/1190 [6:34:12<3:24:00, 27.45s/it]\n",
            "5811.jpg: actual-predicted:      0,   29.5, error:   29.5. Current MAE: 44.58, RMSE: 70.45:  63% 745/1190 [6:34:46<3:49:02, 30.88s/it]\n",
            "5811.jpg: actual-predicted:      0,   29.5, error:   29.5. Current MAE: 44.58, RMSE: 70.45:  63% 746/1190 [6:34:46<3:54:40, 31.71s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([32794, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5812.jpg: actual-predicted:      0,   20.1, error:   20.1. Current MAE: 44.55, RMSE: 70.41:  63% 746/1190 [6:35:14<3:54:40, 31.71s/it]\n",
            "5812.jpg: actual-predicted:      0,   20.1, error:   20.1. Current MAE: 44.55, RMSE: 70.41:  63% 747/1190 [6:35:14<3:47:27, 30.81s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([28810, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5813.jpg: actual-predicted:      0,   14.6, error:   14.6. Current MAE: 44.51, RMSE: 70.36:  63% 747/1190 [6:35:45<3:47:27, 30.81s/it]\n",
            "5813.jpg: actual-predicted:      0,   14.6, error:   14.6. Current MAE: 44.51, RMSE: 70.36:  63% 748/1190 [6:35:45<3:46:45, 30.78s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([53171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5814.jpg: actual-predicted:      0,   32.2, error:   32.2. Current MAE: 44.49, RMSE: 70.32:  63% 748/1190 [6:36:10<3:46:45, 30.78s/it]\n",
            "5814.jpg: actual-predicted:      0,   32.2, error:   32.2. Current MAE: 44.49, RMSE: 70.32:  63% 749/1190 [6:36:10<3:34:10, 29.14s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([16214, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5815.jpg: actual-predicted:      0,   93.8, error:   93.8. Current MAE: 44.56, RMSE: 70.36:  63% 749/1190 [6:36:45<3:34:10, 29.14s/it]\n",
            "5815.jpg: actual-predicted:      0,   93.8, error:   93.8. Current MAE: 44.56, RMSE: 70.36:  63% 750/1190 [6:36:45<3:45:56, 30.81s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([73741, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5816.jpg: actual-predicted:      0,   91.9, error:   91.9. Current MAE: 44.62, RMSE: 70.39:  63% 750/1190 [6:37:16<3:45:56, 30.81s/it]\n",
            "5816.jpg: actual-predicted:      0,   91.9, error:   91.9. Current MAE: 44.62, RMSE: 70.39:  63% 751/1190 [6:37:16<3:45:21, 30.80s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([20568, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5817.jpg: actual-predicted:      0,   30.6, error:   30.6. Current MAE: 44.60, RMSE: 70.36:  63% 751/1190 [6:37:47<3:45:21, 30.80s/it]\n",
            "5817.jpg: actual-predicted:      0,   30.6, error:   30.6. Current MAE: 44.60, RMSE: 70.36:  63% 752/1190 [6:37:47<3:46:01, 30.96s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([67171, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5818.jpg: actual-predicted:      0,   56.3, error:   56.3. Current MAE: 44.62, RMSE: 70.34:  63% 752/1190 [6:38:18<3:46:01, 30.96s/it]\n",
            "5818.jpg: actual-predicted:      0,   56.3, error:   56.3. Current MAE: 44.62, RMSE: 70.34:  63% 753/1190 [6:38:18<3:44:36, 30.84s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([101917, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5819.jpg: actual-predicted:      0,   13.0, error:   13.0. Current MAE: 44.58, RMSE: 70.29:  63% 753/1190 [6:38:44<3:44:36, 30.84s/it]\n",
            "5819.jpg: actual-predicted:      0,   13.0, error:   13.0. Current MAE: 44.58, RMSE: 70.29:  63% 754/1190 [6:38:44<3:34:27, 29.51s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([83709, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5820.jpg: actual-predicted:      0,   22.3, error:   22.3. Current MAE: 44.55, RMSE: 70.25:  63% 754/1190 [6:39:24<3:34:27, 29.51s/it]\n",
            "5821.jpg: actual-predicted:      0,   91.6, error:   91.6. Current MAE: 44.61, RMSE: 70.28:  63% 755/1190 [6:39:54<3:57:25, 32.75s/it]\n",
            "5821.jpg: actual-predicted:      0,   91.6, error:   91.6. Current MAE: 44.61, RMSE: 70.28:  64% 756/1190 [6:39:54<3:50:46, 31.91s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([61452, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5822.jpg: actual-predicted:      0,  106.2, error:  106.2. Current MAE: 44.69, RMSE: 70.34:  64% 756/1190 [6:40:30<3:50:46, 31.91s/it]\n",
            "5822.jpg: actual-predicted:      0,  106.2, error:  106.2. Current MAE: 44.69, RMSE: 70.34:  64% 757/1190 [6:40:30<3:57:36, 32.93s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([100670, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5823.jpg: actual-predicted:      0,   47.4, error:   47.4. Current MAE: 44.70, RMSE: 70.32:  64% 757/1190 [6:41:10<3:57:36, 32.93s/it]\n",
            "5823.jpg: actual-predicted:      0,   47.4, error:   47.4. Current MAE: 44.70, RMSE: 70.32:  64% 758/1190 [6:41:10<4:12:59, 35.14s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([117479, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5824.jpg: actual-predicted:      0,   16.6, error:   16.6. Current MAE: 44.66, RMSE: 70.27:  64% 758/1190 [6:41:36<4:12:59, 35.14s/it]\n",
            "5824.jpg: actual-predicted:      0,   16.6, error:   16.6. Current MAE: 44.66, RMSE: 70.27:  64% 759/1190 [6:41:36<3:52:31, 32.37s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([116421, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5825.jpg: actual-predicted:      0,   18.3, error:   18.3. Current MAE: 44.62, RMSE: 70.23:  64% 759/1190 [6:42:02<3:52:31, 32.37s/it]\n",
            "5825.jpg: actual-predicted:      0,   18.3, error:   18.3. Current MAE: 44.62, RMSE: 70.23:  64% 760/1190 [6:42:02<3:38:39, 30.51s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([50657, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5826.jpg: actual-predicted:      0,   24.3, error:   24.3. Current MAE: 44.60, RMSE: 70.19:  64% 760/1190 [6:42:33<3:38:39, 30.51s/it]\n",
            "5826.jpg: actual-predicted:      0,   24.3, error:   24.3. Current MAE: 44.60, RMSE: 70.19:  64% 761/1190 [6:42:33<3:39:11, 30.66s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([5041, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5827.jpg: actual-predicted:      0,   32.4, error:   32.4. Current MAE: 44.58, RMSE: 70.15:  64% 761/1190 [6:43:05<3:39:11, 30.66s/it]\n",
            "5827.jpg: actual-predicted:      0,   32.4, error:   32.4. Current MAE: 44.58, RMSE: 70.15:  64% 762/1190 [6:43:05<3:40:40, 30.94s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([126107, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5828.jpg: actual-predicted:      0,    9.3, error:    9.3. Current MAE: 44.54, RMSE: 70.11:  64% 762/1190 [6:43:36<3:40:40, 30.94s/it]\n",
            "5829.jpg: actual-predicted:      0,  221.3, error:  221.3. Current MAE: 44.77, RMSE: 70.52:  64% 763/1190 [6:44:01<3:41:36, 31.14s/it]\n",
            "5829.jpg: actual-predicted:      0,  221.3, error:  221.3. Current MAE: 44.77, RMSE: 70.52:  64% 764/1190 [6:44:01<3:27:05, 29.17s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([83947, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5830.jpg: actual-predicted:      0,   20.0, error:   20.0. Current MAE: 44.73, RMSE: 70.48:  64% 764/1190 [6:44:32<3:27:05, 29.17s/it]\n",
            "5830.jpg: actual-predicted:      0,   20.0, error:   20.0. Current MAE: 44.73, RMSE: 70.48:  64% 765/1190 [6:44:32<3:30:16, 29.69s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([45201, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5831.jpg: actual-predicted:      0,   58.2, error:   58.2. Current MAE: 44.75, RMSE: 70.46:  64% 765/1190 [6:45:02<3:30:16, 29.69s/it]\n",
            "5831.jpg: actual-predicted:      0,   58.2, error:   58.2. Current MAE: 44.75, RMSE: 70.46:  64% 766/1190 [6:45:02<3:31:14, 29.89s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([59119, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5832.jpg: actual-predicted:      0,   57.2, error:   57.2. Current MAE: 44.77, RMSE: 70.45:  64% 766/1190 [6:45:38<3:31:14, 29.89s/it]\n",
            "5833.jpg: actual-predicted:      0,   57.2, error:   57.2. Current MAE: 44.78, RMSE: 70.43:  64% 767/1190 [6:46:12<3:42:57, 31.63s/it]\n",
            "5833.jpg: actual-predicted:      0,   57.2, error:   57.2. Current MAE: 44.78, RMSE: 70.43:  65% 768/1190 [6:46:12<3:47:48, 32.39s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([66330, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5834.jpg: actual-predicted:      0,   23.9, error:   23.9. Current MAE: 44.76, RMSE: 70.39:  65% 768/1190 [6:46:38<3:47:48, 32.39s/it]\n",
            "5834.jpg: actual-predicted:      0,   23.9, error:   23.9. Current MAE: 44.76, RMSE: 70.39:  65% 769/1190 [6:46:38<3:33:37, 30.44s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([26883, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5835.jpg: actual-predicted:      0,   38.1, error:   38.1. Current MAE: 44.75, RMSE: 70.36:  65% 769/1190 [6:47:09<3:33:37, 30.44s/it]\n",
            "5835.jpg: actual-predicted:      0,   38.1, error:   38.1. Current MAE: 44.75, RMSE: 70.36:  65% 770/1190 [6:47:09<3:35:21, 30.77s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([146589, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5836.jpg: actual-predicted:      0,   12.3, error:   12.3. Current MAE: 44.71, RMSE: 70.31:  65% 770/1190 [6:47:46<3:35:21, 30.77s/it]\n",
            "5836.jpg: actual-predicted:      0,   12.3, error:   12.3. Current MAE: 44.71, RMSE: 70.31:  65% 771/1190 [6:47:46<3:47:45, 32.61s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([96799, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5837.jpg: actual-predicted:      0,   13.6, error:   13.6. Current MAE: 44.67, RMSE: 70.27:  65% 771/1190 [6:48:21<3:47:45, 32.61s/it]\n",
            "5838.jpg: actual-predicted:      0,  108.6, error:  108.6. Current MAE: 44.75, RMSE: 70.33:  65% 772/1190 [6:48:55<3:52:26, 33.36s/it]\n",
            "5838.jpg: actual-predicted:      0,  108.6, error:  108.6. Current MAE: 44.75, RMSE: 70.33:  65% 773/1190 [6:48:55<3:51:36, 33.33s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([3373, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5839.jpg: actual-predicted:      0,   31.4, error:   31.4. Current MAE: 44.73, RMSE: 70.30:  65% 773/1190 [6:49:28<3:51:36, 33.33s/it]\n",
            "5839.jpg: actual-predicted:      0,   31.4, error:   31.4. Current MAE: 44.73, RMSE: 70.30:  65% 774/1190 [6:49:28<3:51:59, 33.46s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([40777, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5840.jpg: actual-predicted:      0,   80.6, error:   80.6. Current MAE: 44.78, RMSE: 70.31:  65% 774/1190 [6:50:04<3:51:59, 33.46s/it]\n",
            "5840.jpg: actual-predicted:      0,   80.6, error:   80.6. Current MAE: 44.78, RMSE: 70.31:  65% 775/1190 [6:50:04<3:55:11, 34.00s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([146427, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5841.jpg: actual-predicted:      0,   40.9, error:   40.9. Current MAE: 44.77, RMSE: 70.28:  65% 775/1190 [6:50:44<3:55:11, 34.00s/it]\n",
            "5842.jpg: actual-predicted:      0,   42.3, error:   42.3. Current MAE: 44.77, RMSE: 70.25:  65% 776/1190 [6:51:09<4:07:57, 35.94s/it]\n",
            "5843.jpg: actual-predicted:      0,   47.3, error:   47.3. Current MAE: 44.77, RMSE: 70.23:  65% 777/1190 [6:51:42<3:44:19, 32.59s/it]\n",
            "5843.jpg: actual-predicted:      0,   47.3, error:   47.3. Current MAE: 44.77, RMSE: 70.23:  65% 778/1190 [6:51:42<3:45:10, 32.79s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([29681, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5844.jpg: actual-predicted:      0,   43.2, error:   43.2. Current MAE: 44.77, RMSE: 70.20:  65% 778/1190 [6:52:12<3:45:10, 32.79s/it]\n",
            "5844.jpg: actual-predicted:      0,   43.2, error:   43.2. Current MAE: 44.77, RMSE: 70.20:  65% 779/1190 [6:52:12<3:39:35, 32.06s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([73277, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5845.jpg: actual-predicted:      0,   19.7, error:   19.7. Current MAE: 44.74, RMSE: 70.16:  65% 779/1190 [6:52:50<3:39:35, 32.06s/it]\n",
            "5845.jpg: actual-predicted:      0,   19.7, error:   19.7. Current MAE: 44.74, RMSE: 70.16:  66% 780/1190 [6:52:50<3:51:10, 33.83s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([53795, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5846.jpg: actual-predicted:      0,   30.0, error:   30.0. Current MAE: 44.72, RMSE: 70.12:  66% 780/1190 [6:53:14<3:51:10, 33.83s/it]\n",
            "5846.jpg: actual-predicted:      0,   30.0, error:   30.0. Current MAE: 44.72, RMSE: 70.12:  66% 781/1190 [6:53:14<3:30:22, 30.86s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([145814, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5847.jpg: actual-predicted:      0,   13.7, error:   13.7. Current MAE: 44.68, RMSE: 70.08:  66% 781/1190 [6:53:52<3:30:22, 30.86s/it]\n",
            "5848.jpg: actual-predicted:      0,   12.8, error:   12.8. Current MAE: 44.64, RMSE: 70.04:  66% 782/1190 [6:54:29<3:44:03, 32.95s/it]\n",
            "5848.jpg: actual-predicted:      0,   12.8, error:   12.8. Current MAE: 44.64, RMSE: 70.04:  66% 783/1190 [6:54:29<3:50:41, 34.01s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([160309, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5849.jpg: actual-predicted:      0,   34.5, error:   34.5. Current MAE: 44.63, RMSE: 70.00:  66% 783/1190 [6:55:00<3:50:41, 34.01s/it]\n",
            "5849.jpg: actual-predicted:      0,   34.5, error:   34.5. Current MAE: 44.63, RMSE: 70.00:  66% 784/1190 [6:55:00<3:45:16, 33.29s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([138266, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5850.jpg: actual-predicted:      0,   11.6, error:   11.6. Current MAE: 44.58, RMSE: 69.96:  66% 784/1190 [6:55:36<3:45:16, 33.29s/it]\n",
            "5850.jpg: actual-predicted:      0,   11.6, error:   11.6. Current MAE: 44.58, RMSE: 69.96:  66% 785/1190 [6:55:36<3:48:42, 33.88s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([114156, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5851.jpg: actual-predicted:      0,   38.1, error:   38.1. Current MAE: 44.58, RMSE: 69.93:  66% 785/1190 [6:56:10<3:48:42, 33.88s/it]\n",
            "5851.jpg: actual-predicted:      0,   38.1, error:   38.1. Current MAE: 44.58, RMSE: 69.93:  66% 786/1190 [6:56:10<3:49:38, 34.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([26645, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5852.jpg: actual-predicted:      0,   30.2, error:   30.2. Current MAE: 44.56, RMSE: 69.89:  66% 786/1190 [6:56:44<3:49:38, 34.10s/it]\n",
            "5852.jpg: actual-predicted:      0,   30.2, error:   30.2. Current MAE: 44.56, RMSE: 69.89:  66% 787/1190 [6:56:44<3:49:25, 34.16s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([70680, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5853.jpg: actual-predicted:      0,   60.3, error:   60.3. Current MAE: 44.58, RMSE: 69.88:  66% 787/1190 [6:57:15<3:49:25, 34.16s/it]\n",
            "5853.jpg: actual-predicted:      0,   60.3, error:   60.3. Current MAE: 44.58, RMSE: 69.88:  66% 788/1190 [6:57:15<3:42:21, 33.19s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([185742, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5854.jpg: actual-predicted:      0,   21.3, error:   21.3. Current MAE: 44.55, RMSE: 69.84:  66% 788/1190 [6:57:52<3:42:21, 33.19s/it]\n",
            "5854.jpg: actual-predicted:      0,   21.3, error:   21.3. Current MAE: 44.55, RMSE: 69.84:  66% 789/1190 [6:57:52<3:48:58, 34.26s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([37010, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5855.jpg: actual-predicted:      0,   51.4, error:   51.4. Current MAE: 44.56, RMSE: 69.82:  66% 789/1190 [6:58:24<3:48:58, 34.26s/it]\n",
            "5855.jpg: actual-predicted:      0,   51.4, error:   51.4. Current MAE: 44.56, RMSE: 69.82:  66% 790/1190 [6:58:24<3:43:25, 33.51s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([113280, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5856.jpg: actual-predicted:      0,   48.5, error:   48.5. Current MAE: 44.56, RMSE: 69.80:  66% 790/1190 [6:58:55<3:43:25, 33.51s/it]\n",
            "5856.jpg: actual-predicted:      0,   48.5, error:   48.5. Current MAE: 44.56, RMSE: 69.80:  66% 791/1190 [6:58:55<3:38:10, 32.81s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([151979, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5915.jpg: actual-predicted:      0,   17.4, error:   17.4. Current MAE: 44.53, RMSE: 69.75:  66% 791/1190 [6:59:27<3:38:10, 32.81s/it]\n",
            "5915.jpg: actual-predicted:      0,   17.4, error:   17.4. Current MAE: 44.53, RMSE: 69.75:  67% 792/1190 [6:59:27<3:36:42, 32.67s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([257431, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5916.jpg: actual-predicted:      0,   47.2, error:   47.2. Current MAE: 44.53, RMSE: 69.73:  67% 792/1190 [7:00:12<3:36:42, 32.67s/it]\n",
            "5916.jpg: actual-predicted:      0,   47.2, error:   47.2. Current MAE: 44.53, RMSE: 69.73:  67% 793/1190 [7:00:12<4:00:19, 36.32s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([129560, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5917.jpg: actual-predicted:      0,   17.3, error:   17.3. Current MAE: 44.50, RMSE: 69.69:  67% 793/1190 [7:00:44<4:00:19, 36.32s/it]\n",
            "5917.jpg: actual-predicted:      0,   17.3, error:   17.3. Current MAE: 44.50, RMSE: 69.69:  67% 794/1190 [7:00:44<3:51:30, 35.08s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([119322, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5918.jpg: actual-predicted:      0,   16.9, error:   16.9. Current MAE: 44.46, RMSE: 69.65:  67% 794/1190 [7:01:11<3:51:30, 35.08s/it]\n",
            "5918.jpg: actual-predicted:      0,   16.9, error:   16.9. Current MAE: 44.46, RMSE: 69.65:  67% 795/1190 [7:01:11<3:34:37, 32.60s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([126389, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5919.jpg: actual-predicted:      0,   29.5, error:   29.5. Current MAE: 44.44, RMSE: 69.61:  67% 795/1190 [7:01:46<3:34:37, 32.60s/it]\n",
            "5919.jpg: actual-predicted:      0,   29.5, error:   29.5. Current MAE: 44.44, RMSE: 69.61:  67% 796/1190 [7:01:46<3:38:47, 33.32s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([149566, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5920.jpg: actual-predicted:      0,   25.5, error:   25.5. Current MAE: 44.42, RMSE: 69.57:  67% 796/1190 [7:02:23<3:38:47, 33.32s/it]\n",
            "5920.jpg: actual-predicted:      0,   25.5, error:   25.5. Current MAE: 44.42, RMSE: 69.57:  67% 797/1190 [7:02:23<3:44:07, 34.22s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([49659, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5921.jpg: actual-predicted:      0,   25.6, error:   25.6. Current MAE: 44.40, RMSE: 69.54:  67% 797/1190 [7:02:54<3:44:07, 34.22s/it]\n",
            "5921.jpg: actual-predicted:      0,   25.6, error:   25.6. Current MAE: 44.40, RMSE: 69.54:  67% 798/1190 [7:02:54<3:38:33, 33.45s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([147865, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5922.jpg: actual-predicted:      0,   48.2, error:   48.2. Current MAE: 44.40, RMSE: 69.51:  67% 798/1190 [7:03:30<3:38:33, 33.45s/it]\n",
            "5922.jpg: actual-predicted:      0,   48.2, error:   48.2. Current MAE: 44.40, RMSE: 69.51:  67% 799/1190 [7:03:30<3:41:56, 34.06s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([61147, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5923.jpg: actual-predicted:      0,   17.3, error:   17.3. Current MAE: 44.37, RMSE: 69.47:  67% 799/1190 [7:03:56<3:41:56, 34.06s/it]\n",
            "5924.jpg: actual-predicted:      0,   23.6, error:   23.6. Current MAE: 44.34, RMSE: 69.44:  67% 800/1190 [7:04:20<3:26:07, 31.71s/it]\n",
            "5924.jpg: actual-predicted:      0,   23.6, error:   23.6. Current MAE: 44.34, RMSE: 69.44:  67% 801/1190 [7:04:20<3:11:37, 29.56s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([7246, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5925.jpg: actual-predicted:      0,   14.2, error:   14.2. Current MAE: 44.30, RMSE: 69.39:  67% 801/1190 [7:04:46<3:11:37, 29.56s/it]\n",
            "5925.jpg: actual-predicted:      0,   14.2, error:   14.2. Current MAE: 44.30, RMSE: 69.39:  67% 802/1190 [7:04:46<3:03:32, 28.38s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([182311, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5926.jpg: actual-predicted:      0,   13.1, error:   13.1. Current MAE: 44.26, RMSE: 69.35:  67% 802/1190 [7:05:28<3:03:32, 28.38s/it]\n",
            "5926.jpg: actual-predicted:      0,   13.1, error:   13.1. Current MAE: 44.26, RMSE: 69.35:  67% 803/1190 [7:05:28<3:28:41, 32.36s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([82803, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5927.jpg: actual-predicted:      0,   10.7, error:   10.7. Current MAE: 44.22, RMSE: 69.31:  67% 803/1190 [7:05:52<3:28:41, 32.36s/it]\n",
            "5927.jpg: actual-predicted:      0,   10.7, error:   10.7. Current MAE: 44.22, RMSE: 69.31:  68% 804/1190 [7:05:52<3:13:03, 30.01s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([135567, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5928.jpg: actual-predicted:      0,   49.9, error:   49.9. Current MAE: 44.23, RMSE: 69.29:  68% 804/1190 [7:06:24<3:13:03, 30.01s/it]\n",
            "5928.jpg: actual-predicted:      0,   49.9, error:   49.9. Current MAE: 44.23, RMSE: 69.29:  68% 805/1190 [7:06:24<3:15:28, 30.46s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([26882, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5929.jpg: actual-predicted:      0,   48.2, error:   48.2. Current MAE: 44.24, RMSE: 69.27:  68% 805/1190 [7:07:04<3:15:28, 30.46s/it]\n",
            "5929.jpg: actual-predicted:      0,   48.2, error:   48.2. Current MAE: 44.24, RMSE: 69.27:  68% 806/1190 [7:07:04<3:33:11, 33.31s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([100104, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5930.jpg: actual-predicted:      0,   14.5, error:   14.5. Current MAE: 44.20, RMSE: 69.23:  68% 806/1190 [7:07:36<3:33:11, 33.31s/it]\n",
            "5930.jpg: actual-predicted:      0,   14.5, error:   14.5. Current MAE: 44.20, RMSE: 69.23:  68% 807/1190 [7:07:36<3:31:03, 33.06s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([60380, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5931.jpg: actual-predicted:      0,    8.8, error:    8.8. Current MAE: 44.15, RMSE: 69.18:  68% 807/1190 [7:08:11<3:31:03, 33.06s/it]\n",
            "5931.jpg: actual-predicted:      0,    8.8, error:    8.8. Current MAE: 44.15, RMSE: 69.18:  68% 808/1190 [7:08:11<3:34:01, 33.62s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([20020, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5932.jpg: actual-predicted:      0,   25.9, error:   25.9. Current MAE: 44.13, RMSE: 69.15:  68% 808/1190 [7:08:37<3:34:01, 33.62s/it]\n",
            "5932.jpg: actual-predicted:      0,   25.9, error:   25.9. Current MAE: 44.13, RMSE: 69.15:  68% 809/1190 [7:08:37<3:18:16, 31.22s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([114417, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5933.jpg: actual-predicted:      0,   15.3, error:   15.3. Current MAE: 44.10, RMSE: 69.11:  68% 809/1190 [7:09:03<3:18:16, 31.22s/it]\n",
            "5933.jpg: actual-predicted:      0,   15.3, error:   15.3. Current MAE: 44.10, RMSE: 69.11:  68% 810/1190 [7:09:03<3:08:45, 29.80s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([106691, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5934.jpg: actual-predicted:      0,   17.7, error:   17.7. Current MAE: 44.06, RMSE: 69.07:  68% 810/1190 [7:09:35<3:08:45, 29.80s/it]\n",
            "5934.jpg: actual-predicted:      0,   17.7, error:   17.7. Current MAE: 44.06, RMSE: 69.07:  68% 811/1190 [7:09:35<3:11:29, 30.32s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([78744, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5935.jpg: actual-predicted:      0,    9.4, error:    9.4. Current MAE: 44.02, RMSE: 69.03:  68% 811/1190 [7:10:06<3:11:29, 30.32s/it]\n",
            "5935.jpg: actual-predicted:      0,    9.4, error:    9.4. Current MAE: 44.02, RMSE: 69.03:  68% 812/1190 [7:10:06<3:12:29, 30.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([83501, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5936.jpg: actual-predicted:      0,   21.4, error:   21.4. Current MAE: 43.99, RMSE: 68.99:  68% 812/1190 [7:10:37<3:12:29, 30.55s/it]\n",
            "5936.jpg: actual-predicted:      0,   21.4, error:   21.4. Current MAE: 43.99, RMSE: 68.99:  68% 813/1190 [7:10:37<3:13:45, 30.84s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([67159, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5937.jpg: actual-predicted:      0,   12.5, error:   12.5. Current MAE: 43.95, RMSE: 68.95:  68% 813/1190 [7:11:03<3:13:45, 30.84s/it]\n",
            "5937.jpg: actual-predicted:      0,   12.5, error:   12.5. Current MAE: 43.95, RMSE: 68.95:  68% 814/1190 [7:11:03<3:04:04, 29.37s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([12424, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5938.jpg: actual-predicted:      0,   26.2, error:   26.2. Current MAE: 43.93, RMSE: 68.91:  68% 814/1190 [7:11:39<3:04:04, 29.37s/it]\n",
            "5938.jpg: actual-predicted:      0,   26.2, error:   26.2. Current MAE: 43.93, RMSE: 68.91:  68% 815/1190 [7:11:39<3:14:37, 31.14s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([69830, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5939.jpg: actual-predicted:      0,   11.0, error:   11.0. Current MAE: 43.89, RMSE: 68.87:  68% 815/1190 [7:12:19<3:14:37, 31.14s/it]\n",
            "5939.jpg: actual-predicted:      0,   11.0, error:   11.0. Current MAE: 43.89, RMSE: 68.87:  69% 816/1190 [7:12:19<3:31:54, 34.00s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([52460, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5940.jpg: actual-predicted:      0,   12.3, error:   12.3. Current MAE: 43.85, RMSE: 68.83:  69% 816/1190 [7:12:54<3:31:54, 34.00s/it]\n",
            "5940.jpg: actual-predicted:      0,   12.3, error:   12.3. Current MAE: 43.85, RMSE: 68.83:  69% 817/1190 [7:12:54<3:32:12, 34.13s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([112672, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5941.jpg: actual-predicted:      0,   12.4, error:   12.4. Current MAE: 43.82, RMSE: 68.79:  69% 817/1190 [7:13:25<3:32:12, 34.13s/it]\n",
            "5941.jpg: actual-predicted:      0,   12.4, error:   12.4. Current MAE: 43.82, RMSE: 68.79:  69% 818/1190 [7:13:25<3:26:55, 33.37s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([143147, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5942.jpg: actual-predicted:      0,   14.6, error:   14.6. Current MAE: 43.78, RMSE: 68.75:  69% 818/1190 [7:14:10<3:26:55, 33.37s/it]\n",
            "5942.jpg: actual-predicted:      0,   14.6, error:   14.6. Current MAE: 43.78, RMSE: 68.75:  69% 819/1190 [7:14:10<3:48:05, 36.89s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([171347, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5943.jpg: actual-predicted:      0,   49.2, error:   49.2. Current MAE: 43.79, RMSE: 68.73:  69% 819/1190 [7:14:46<3:48:05, 36.89s/it]\n",
            "5943.jpg: actual-predicted:      0,   49.2, error:   49.2. Current MAE: 43.79, RMSE: 68.73:  69% 820/1190 [7:14:46<3:45:30, 36.57s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([155115, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "5944.jpg: actual-predicted:      0,   14.9, error:   14.9. Current MAE: 43.75, RMSE: 68.69:  69% 820/1190 [7:15:18<3:45:30, 36.57s/it]\n",
            "6042.jpg: actual-predicted:      0,   16.8, error:   16.8. Current MAE: 43.72, RMSE: 68.65:  69% 821/1190 [7:15:43<3:36:30, 35.20s/it]\n",
            "6042.jpg: actual-predicted:      0,   16.8, error:   16.8. Current MAE: 43.72, RMSE: 68.65:  69% 822/1190 [7:15:43<3:17:01, 32.12s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([94387, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6043.jpg: actual-predicted:      0,   94.2, error:   94.2. Current MAE: 43.78, RMSE: 68.68:  69% 822/1190 [7:16:30<3:17:01, 32.12s/it]\n",
            "6043.jpg: actual-predicted:      0,   94.2, error:   94.2. Current MAE: 43.78, RMSE: 68.68:  69% 823/1190 [7:16:30<3:43:42, 36.57s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([177002, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6044.jpg: actual-predicted:      0,   57.8, error:   57.8. Current MAE: 43.80, RMSE: 68.67:  69% 823/1190 [7:17:17<3:43:42, 36.57s/it]\n",
            "6044.jpg: actual-predicted:      0,   57.8, error:   57.8. Current MAE: 43.80, RMSE: 68.67:  69% 824/1190 [7:17:17<4:02:32, 39.76s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([63020, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6045.jpg: actual-predicted:      0,   33.0, error:   33.0. Current MAE: 43.78, RMSE: 68.64:  69% 824/1190 [7:17:47<4:02:32, 39.76s/it]\n",
            "6045.jpg: actual-predicted:      0,   33.0, error:   33.0. Current MAE: 43.78, RMSE: 68.64:  69% 825/1190 [7:17:47<3:43:27, 36.73s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([52846, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6046.jpg: actual-predicted:      0,   63.9, error:   63.9. Current MAE: 43.81, RMSE: 68.63:  69% 825/1190 [7:18:42<3:43:27, 36.73s/it]\n",
            "6046.jpg: actual-predicted:      0,   63.9, error:   63.9. Current MAE: 43.81, RMSE: 68.63:  69% 826/1190 [7:18:42<4:15:22, 42.09s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([111404, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6047.jpg: actual-predicted:      0,   89.8, error:   89.8. Current MAE: 43.86, RMSE: 68.66:  69% 826/1190 [7:19:23<4:15:22, 42.09s/it]\n",
            "6047.jpg: actual-predicted:      0,   89.8, error:   89.8. Current MAE: 43.86, RMSE: 68.66:  69% 827/1190 [7:19:23<4:13:00, 41.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([107213, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6048.jpg: actual-predicted:      0,  123.6, error:  123.6. Current MAE: 43.96, RMSE: 68.76:  69% 827/1190 [7:19:48<4:13:00, 41.82s/it]\n",
            "6048.jpg: actual-predicted:      0,  123.6, error:  123.6. Current MAE: 43.96, RMSE: 68.76:  70% 828/1190 [7:19:48<3:42:19, 36.85s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([111236, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6049.jpg: actual-predicted:      0,   91.2, error:   91.2. Current MAE: 44.02, RMSE: 68.79:  70% 828/1190 [7:20:22<3:42:19, 36.85s/it]\n",
            "6049.jpg: actual-predicted:      0,   91.2, error:   91.2. Current MAE: 44.02, RMSE: 68.79:  70% 829/1190 [7:20:22<3:35:47, 35.87s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([145801, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6050.jpg: actual-predicted:      0,  123.6, error:  123.6. Current MAE: 44.11, RMSE: 68.88:  70% 829/1190 [7:20:57<3:35:47, 35.87s/it]\n",
            "6050.jpg: actual-predicted:      0,  123.6, error:  123.6. Current MAE: 44.11, RMSE: 68.88:  70% 830/1190 [7:20:57<3:33:39, 35.61s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([117104, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6051.jpg: actual-predicted:      0,   98.2, error:   98.2. Current MAE: 44.18, RMSE: 68.92:  70% 830/1190 [7:21:32<3:33:39, 35.61s/it]\n",
            "6051.jpg: actual-predicted:      0,   98.2, error:   98.2. Current MAE: 44.18, RMSE: 68.92:  70% 831/1190 [7:21:32<3:32:28, 35.51s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([95786, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6052.jpg: actual-predicted:      0,   41.5, error:   41.5. Current MAE: 44.17, RMSE: 68.90:  70% 831/1190 [7:22:04<3:32:28, 35.51s/it]\n",
            "6052.jpg: actual-predicted:      0,   41.5, error:   41.5. Current MAE: 44.17, RMSE: 68.90:  70% 832/1190 [7:22:04<3:25:05, 34.37s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([95515, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6053.jpg: actual-predicted:      0,  108.8, error:  108.8. Current MAE: 44.25, RMSE: 68.96:  70% 832/1190 [7:22:44<3:25:05, 34.37s/it]\n",
            "6053.jpg: actual-predicted:      0,  108.8, error:  108.8. Current MAE: 44.25, RMSE: 68.96:  70% 833/1190 [7:22:44<3:35:41, 36.25s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([131105, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6054.jpg: actual-predicted:      0,  118.1, error:  118.1. Current MAE: 44.34, RMSE: 69.04:  70% 833/1190 [7:23:42<3:35:41, 36.25s/it]\n",
            "6054.jpg: actual-predicted:      0,  118.1, error:  118.1. Current MAE: 44.34, RMSE: 69.04:  70% 834/1190 [7:23:42<4:13:37, 42.75s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([89070, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6240.jpg: actual-predicted:      0,   25.7, error:   25.7. Current MAE: 44.32, RMSE: 69.00:  70% 834/1190 [7:24:23<4:13:37, 42.75s/it]\n",
            "6241.jpg: actual-predicted:      0,  234.7, error:  234.7. Current MAE: 44.55, RMSE: 69.44:  70% 835/1190 [7:24:47<4:09:24, 42.15s/it]\n",
            "6242.jpg: actual-predicted:      0,   92.8, error:   92.8. Current MAE: 44.60, RMSE: 69.47:  70% 836/1190 [7:25:12<3:37:27, 36.86s/it]\n",
            "6243.jpg: actual-predicted:      0,   22.5, error:   22.5. Current MAE: 44.58, RMSE: 69.43:  70% 837/1190 [7:25:43<3:15:37, 33.25s/it]\n",
            "6244.jpg: actual-predicted:      0,   43.7, error:   43.7. Current MAE: 44.58, RMSE: 69.41:  70% 838/1190 [7:26:16<3:09:55, 32.37s/it]\n",
            "6244.jpg: actual-predicted:      0,   43.7, error:   43.7. Current MAE: 44.58, RMSE: 69.41:  71% 839/1190 [7:26:16<3:11:27, 32.73s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([180713, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6245.jpg: actual-predicted:      0,   24.3, error:   24.3. Current MAE: 44.55, RMSE: 69.37:  71% 839/1190 [7:26:49<3:11:27, 32.73s/it]\n",
            "6245.jpg: actual-predicted:      0,   24.3, error:   24.3. Current MAE: 44.55, RMSE: 69.37:  71% 840/1190 [7:26:49<3:10:37, 32.68s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([52076, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6246.jpg: actual-predicted:      0,   18.6, error:   18.6. Current MAE: 44.52, RMSE: 69.33:  71% 840/1190 [7:27:15<3:10:37, 32.68s/it]\n",
            "6246.jpg: actual-predicted:      0,   18.6, error:   18.6. Current MAE: 44.52, RMSE: 69.33:  71% 841/1190 [7:27:15<2:58:35, 30.70s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([147390, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6247.jpg: actual-predicted:      0,   23.7, error:   23.7. Current MAE: 44.50, RMSE: 69.30:  71% 841/1190 [7:27:41<2:58:35, 30.70s/it]\n",
            "6247.jpg: actual-predicted:      0,   23.7, error:   23.7. Current MAE: 44.50, RMSE: 69.30:  71% 842/1190 [7:27:41<2:51:00, 29.48s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([163199, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6248.jpg: actual-predicted:      0,   61.3, error:   61.3. Current MAE: 44.52, RMSE: 69.29:  71% 842/1190 [7:28:14<2:51:00, 29.48s/it]\n",
            "6248.jpg: actual-predicted:      0,   61.3, error:   61.3. Current MAE: 44.52, RMSE: 69.29:  71% 843/1190 [7:28:14<2:55:05, 30.28s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([19625, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6249.jpg: actual-predicted:      0,  111.5, error:  111.5. Current MAE: 44.60, RMSE: 69.35:  71% 843/1190 [7:28:47<2:55:05, 30.28s/it]\n",
            "6249.jpg: actual-predicted:      0,  111.5, error:  111.5. Current MAE: 44.60, RMSE: 69.35:  71% 844/1190 [7:28:47<3:00:42, 31.34s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([77274, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6250.jpg: actual-predicted:      0,   37.8, error:   37.8. Current MAE: 44.59, RMSE: 69.32:  71% 844/1190 [7:29:12<3:00:42, 31.34s/it]\n",
            "6250.jpg: actual-predicted:      0,   37.8, error:   37.8. Current MAE: 44.59, RMSE: 69.32:  71% 845/1190 [7:29:12<2:48:26, 29.29s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([117065, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6251.jpg: actual-predicted:      0,   13.4, error:   13.4. Current MAE: 44.55, RMSE: 69.28:  71% 845/1190 [7:29:47<2:48:26, 29.29s/it]\n",
            "6251.jpg: actual-predicted:      0,   13.4, error:   13.4. Current MAE: 44.55, RMSE: 69.28:  71% 846/1190 [7:29:47<2:57:38, 30.98s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17545, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6252.jpg: actual-predicted:      0,   70.0, error:   70.0. Current MAE: 44.58, RMSE: 69.29:  71% 846/1190 [7:30:19<2:57:38, 30.98s/it]\n",
            "6252.jpg: actual-predicted:      0,   70.0, error:   70.0. Current MAE: 44.58, RMSE: 69.29:  71% 847/1190 [7:30:19<2:58:36, 31.24s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([85056, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6253.jpg: actual-predicted:      0,   48.0, error:   48.0. Current MAE: 44.58, RMSE: 69.26:  71% 847/1190 [7:30:45<2:58:36, 31.24s/it]\n",
            "6254.jpg: actual-predicted:      0,   27.9, error:   27.9. Current MAE: 44.56, RMSE: 69.23:  71% 848/1190 [7:31:19<2:49:35, 29.75s/it]\n",
            "6254.jpg: actual-predicted:      0,   27.9, error:   27.9. Current MAE: 44.56, RMSE: 69.23:  71% 849/1190 [7:31:19<2:55:53, 30.95s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([123442, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6255.jpg: actual-predicted:      0,   35.1, error:   35.1. Current MAE: 44.55, RMSE: 69.20:  71% 849/1190 [7:31:53<2:55:53, 30.95s/it]\n",
            "6256.jpg: actual-predicted:      0,   46.0, error:   46.0. Current MAE: 44.56, RMSE: 69.18:  71% 850/1190 [7:32:17<3:00:30, 31.86s/it]\n",
            "6256.jpg: actual-predicted:      0,   46.0, error:   46.0. Current MAE: 44.56, RMSE: 69.18:  72% 851/1190 [7:32:17<2:47:37, 29.67s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([184245, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6257.jpg: actual-predicted:      0,   16.4, error:   16.4. Current MAE: 44.52, RMSE: 69.14:  72% 851/1190 [7:32:50<2:47:37, 29.67s/it]\n",
            "6257.jpg: actual-predicted:      0,   16.4, error:   16.4. Current MAE: 44.52, RMSE: 69.14:  72% 852/1190 [7:32:50<2:52:06, 30.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([126905, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6258.jpg: actual-predicted:      0,   14.6, error:   14.6. Current MAE: 44.49, RMSE: 69.10:  72% 852/1190 [7:33:22<2:52:06, 30.55s/it]\n",
            "6259.jpg: actual-predicted:      0,   86.5, error:   86.5. Current MAE: 44.54, RMSE: 69.12:  72% 853/1190 [7:33:51<2:53:50, 30.95s/it]\n",
            "6259.jpg: actual-predicted:      0,   86.5, error:   86.5. Current MAE: 44.54, RMSE: 69.12:  72% 854/1190 [7:33:51<2:51:07, 30.56s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([134229, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6260.jpg: actual-predicted:      0,   40.1, error:   40.1. Current MAE: 44.53, RMSE: 69.10:  72% 854/1190 [7:34:23<2:51:07, 30.56s/it]\n",
            "6260.jpg: actual-predicted:      0,   40.1, error:   40.1. Current MAE: 44.53, RMSE: 69.10:  72% 855/1190 [7:34:23<2:51:58, 30.80s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([67316, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6261.jpg: actual-predicted:      0,  302.4, error:  302.4. Current MAE: 44.83, RMSE: 69.82:  72% 855/1190 [7:34:53<2:51:58, 30.80s/it]\n",
            "6262.jpg: actual-predicted:      0,   66.7, error:   66.7. Current MAE: 44.86, RMSE: 69.82:  72% 856/1190 [7:35:28<2:51:12, 30.76s/it]\n",
            "6262.jpg: actual-predicted:      0,   66.7, error:   66.7. Current MAE: 44.86, RMSE: 69.82:  72% 857/1190 [7:35:28<2:56:44, 31.85s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([99964, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6263.jpg: actual-predicted:      0,   26.1, error:   26.1. Current MAE: 44.84, RMSE: 69.79:  72% 857/1190 [7:36:02<2:56:44, 31.85s/it]\n",
            "6263.jpg: actual-predicted:      0,   26.1, error:   26.1. Current MAE: 44.84, RMSE: 69.79:  72% 858/1190 [7:36:02<3:00:30, 32.62s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([143644, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6264.jpg: actual-predicted:      0,   23.3, error:   23.3. Current MAE: 44.81, RMSE: 69.75:  72% 858/1190 [7:36:29<3:00:30, 32.62s/it]\n",
            "6265.jpg: actual-predicted:      0,   86.5, error:   86.5. Current MAE: 44.86, RMSE: 69.77:  72% 859/1190 [7:37:02<2:49:58, 30.81s/it]\n",
            "6265.jpg: actual-predicted:      0,   86.5, error:   86.5. Current MAE: 44.86, RMSE: 69.77:  72% 860/1190 [7:37:02<2:53:30, 31.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([148184, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6266.jpg: actual-predicted:      0,   32.7, error:   32.7. Current MAE: 44.85, RMSE: 69.74:  72% 860/1190 [7:37:28<2:53:30, 31.55s/it]\n",
            "6267.jpg: actual-predicted:      0,  102.1, error:  102.1. Current MAE: 44.91, RMSE: 69.79:  72% 861/1190 [7:38:04<2:44:20, 29.97s/it]\n",
            "6267.jpg: actual-predicted:      0,  102.1, error:  102.1. Current MAE: 44.91, RMSE: 69.79:  72% 862/1190 [7:38:04<2:53:09, 31.67s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([94864, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6268.jpg: actual-predicted:      0,   29.1, error:   29.1. Current MAE: 44.89, RMSE: 69.75:  72% 862/1190 [7:38:30<2:53:09, 31.67s/it]\n",
            "6268.jpg: actual-predicted:      0,   29.1, error:   29.1. Current MAE: 44.89, RMSE: 69.75:  73% 863/1190 [7:38:30<2:43:58, 30.09s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([139079, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6269.jpg: actual-predicted:      0,   47.8, error:   47.8. Current MAE: 44.90, RMSE: 69.73:  73% 863/1190 [7:39:05<2:43:58, 30.09s/it]\n",
            "6269.jpg: actual-predicted:      0,   47.8, error:   47.8. Current MAE: 44.90, RMSE: 69.73:  73% 864/1190 [7:39:05<2:51:33, 31.58s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([170132, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6270.jpg: actual-predicted:      0,   65.2, error:   65.2. Current MAE: 44.92, RMSE: 69.73:  73% 864/1190 [7:39:46<2:51:33, 31.58s/it]\n",
            "6270.jpg: actual-predicted:      0,   65.2, error:   65.2. Current MAE: 44.92, RMSE: 69.73:  73% 865/1190 [7:39:46<3:06:11, 34.37s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([107061, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6271.jpg: actual-predicted:      0,  224.8, error:  224.8. Current MAE: 45.13, RMSE: 70.10:  73% 865/1190 [7:40:17<3:06:11, 34.37s/it]\n",
            "6272.jpg: actual-predicted:      0,   98.4, error:   98.4. Current MAE: 45.19, RMSE: 70.14:  73% 866/1190 [7:40:48<3:00:22, 33.40s/it]\n",
            "6272.jpg: actual-predicted:      0,   98.4, error:   98.4. Current MAE: 45.19, RMSE: 70.14:  73% 867/1190 [7:40:48<2:54:32, 32.42s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([60545, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6273.jpg: actual-predicted:      0,   30.6, error:   30.6. Current MAE: 45.17, RMSE: 70.11:  73% 867/1190 [7:41:12<2:54:32, 32.42s/it]\n",
            "6273.jpg: actual-predicted:      0,   30.6, error:   30.6. Current MAE: 45.17, RMSE: 70.11:  73% 868/1190 [7:41:12<2:40:37, 29.93s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([43524, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6274.jpg: actual-predicted:      0,   10.7, error:   10.7. Current MAE: 45.13, RMSE: 70.07:  73% 868/1190 [7:41:43<2:40:37, 29.93s/it]\n",
            "6274.jpg: actual-predicted:      0,   10.7, error:   10.7. Current MAE: 45.13, RMSE: 70.07:  73% 869/1190 [7:41:43<2:42:12, 30.32s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([52046, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6275.jpg: actual-predicted:      0,   33.2, error:   33.2. Current MAE: 45.12, RMSE: 70.04:  73% 869/1190 [7:42:14<2:42:12, 30.32s/it]\n",
            "6276.jpg: actual-predicted:      0,   32.2, error:   32.2. Current MAE: 45.10, RMSE: 70.01:  73% 870/1190 [7:42:47<2:42:30, 30.47s/it]\n",
            "6276.jpg: actual-predicted:      0,   32.2, error:   32.2. Current MAE: 45.10, RMSE: 70.01:  73% 871/1190 [7:42:47<2:46:23, 31.30s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([100042, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6277.jpg: actual-predicted:      0,   31.7, error:   31.7. Current MAE: 45.09, RMSE: 69.98:  73% 871/1190 [7:43:24<2:46:23, 31.30s/it]\n",
            "6278.jpg: actual-predicted:      0,   47.7, error:   47.7. Current MAE: 45.09, RMSE: 69.95:  73% 872/1190 [7:43:56<2:55:07, 33.04s/it]\n",
            "6278.jpg: actual-predicted:      0,   47.7, error:   47.7. Current MAE: 45.09, RMSE: 69.95:  73% 873/1190 [7:43:56<2:53:23, 32.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([120170, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6279.jpg: actual-predicted:      0,    9.5, error:    9.5. Current MAE: 45.05, RMSE: 69.92:  73% 873/1190 [7:44:33<2:53:23, 32.82s/it]\n",
            "6279.jpg: actual-predicted:      0,    9.5, error:    9.5. Current MAE: 45.05, RMSE: 69.92:  73% 874/1190 [7:44:33<2:58:42, 33.93s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([44553, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6280.jpg: actual-predicted:      0,   35.2, error:   35.2. Current MAE: 45.04, RMSE: 69.89:  73% 874/1190 [7:45:11<2:58:42, 33.93s/it]\n",
            "6281.jpg: actual-predicted:      0,  590.0, error:  590.0. Current MAE: 45.66, RMSE: 72.63:  74% 875/1190 [7:45:44<3:04:30, 35.14s/it]\n",
            "6281.jpg: actual-predicted:      0,  590.0, error:  590.0. Current MAE: 45.66, RMSE: 72.63:  74% 876/1190 [7:45:44<3:00:12, 34.43s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([76411, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6282.jpg: actual-predicted:      0,   45.4, error:   45.4. Current MAE: 45.66, RMSE: 72.61:  74% 876/1190 [7:46:09<3:00:12, 34.43s/it]\n",
            "6283.jpg: actual-predicted:      0,   13.8, error:   13.8. Current MAE: 45.63, RMSE: 72.57:  74% 877/1190 [7:46:43<2:44:53, 31.61s/it]\n",
            "6283.jpg: actual-predicted:      0,   13.8, error:   13.8. Current MAE: 45.63, RMSE: 72.57:  74% 878/1190 [7:46:43<2:47:49, 32.27s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([20753, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6284.jpg: actual-predicted:      0,   56.0, error:   56.0. Current MAE: 45.64, RMSE: 72.55:  74% 878/1190 [7:47:16<2:47:49, 32.27s/it]\n",
            "6285.jpg: actual-predicted:      0,   86.9, error:   86.9. Current MAE: 45.68, RMSE: 72.57:  74% 879/1190 [7:47:52<2:49:43, 32.74s/it]\n",
            "6547.jpg: actual-predicted:      0,   93.8, error:   93.8. Current MAE: 45.74, RMSE: 72.60:  74% 880/1190 [7:48:31<2:53:35, 33.60s/it]\n",
            "6547.jpg: actual-predicted:      0,   93.8, error:   93.8. Current MAE: 45.74, RMSE: 72.60:  74% 881/1190 [7:48:31<3:01:58, 35.34s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([85840, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6548.jpg: actual-predicted:      0,   18.4, error:   18.4. Current MAE: 45.71, RMSE: 72.56:  74% 881/1190 [7:48:56<3:01:58, 35.34s/it]\n",
            "6548.jpg: actual-predicted:      0,   18.4, error:   18.4. Current MAE: 45.71, RMSE: 72.56:  74% 882/1190 [7:48:56<2:44:35, 32.06s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([117647, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6549.jpg: actual-predicted:      0,   26.3, error:   26.3. Current MAE: 45.69, RMSE: 72.52:  74% 882/1190 [7:49:22<2:44:35, 32.06s/it]\n",
            "6549.jpg: actual-predicted:      0,   26.3, error:   26.3. Current MAE: 45.69, RMSE: 72.52:  74% 883/1190 [7:49:22<2:35:16, 30.35s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([68159, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6550.jpg: actual-predicted:      0,   12.2, error:   12.2. Current MAE: 45.65, RMSE: 72.48:  74% 883/1190 [7:49:48<2:35:16, 30.35s/it]\n",
            "6550.jpg: actual-predicted:      0,   12.2, error:   12.2. Current MAE: 45.65, RMSE: 72.48:  74% 884/1190 [7:49:48<2:28:12, 29.06s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([44469, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6643.jpg: actual-predicted:      0,   29.8, error:   29.8. Current MAE: 45.63, RMSE: 72.45:  74% 884/1190 [7:50:12<2:28:12, 29.06s/it]\n",
            "6643.jpg: actual-predicted:      0,   29.8, error:   29.8. Current MAE: 45.63, RMSE: 72.45:  74% 885/1190 [7:50:12<2:20:16, 27.60s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([90923, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6644.jpg: actual-predicted:      0,  413.7, error:  413.7. Current MAE: 46.05, RMSE: 73.73:  74% 885/1190 [7:51:03<2:20:16, 27.60s/it]\n",
            "6644.jpg: actual-predicted:      0,  413.7, error:  413.7. Current MAE: 46.05, RMSE: 73.73:  74% 886/1190 [7:51:03<2:54:21, 34.41s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([97816, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6645.jpg: actual-predicted:      0,   30.9, error:   30.9. Current MAE: 46.03, RMSE: 73.70:  74% 886/1190 [7:51:30<2:54:21, 34.41s/it]\n",
            "6645.jpg: actual-predicted:      0,   30.9, error:   30.9. Current MAE: 46.03, RMSE: 73.70:  75% 887/1190 [7:51:30<2:42:22, 32.15s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([102528, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6646.jpg: actual-predicted:      0,   10.9, error:   10.9. Current MAE: 45.99, RMSE: 73.66:  75% 887/1190 [7:51:55<2:42:22, 32.15s/it]\n",
            "6646.jpg: actual-predicted:      0,   10.9, error:   10.9. Current MAE: 45.99, RMSE: 73.66:  75% 888/1190 [7:51:55<2:30:58, 29.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([47802, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6647.jpg: actual-predicted:      0,  150.3, error:  150.3. Current MAE: 46.11, RMSE: 73.79:  75% 888/1190 [7:52:20<2:30:58, 29.99s/it]\n",
            "6647.jpg: actual-predicted:      0,  150.3, error:  150.3. Current MAE: 46.11, RMSE: 73.79:  75% 889/1190 [7:52:20<2:24:00, 28.71s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([141805, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6648.jpg: actual-predicted:      0,   72.1, error:   72.1. Current MAE: 46.14, RMSE: 73.79:  75% 889/1190 [7:52:52<2:24:00, 28.71s/it]\n",
            "6648.jpg: actual-predicted:      0,   72.1, error:   72.1. Current MAE: 46.14, RMSE: 73.79:  75% 890/1190 [7:52:52<2:27:54, 29.58s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([84252, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6649.jpg: actual-predicted:      0,   48.6, error:   48.6. Current MAE: 46.14, RMSE: 73.76:  75% 890/1190 [7:53:18<2:27:54, 29.58s/it]\n",
            "6650.jpg: actual-predicted:      0,   30.2, error:   30.2. Current MAE: 46.12, RMSE: 73.73:  75% 891/1190 [7:53:46<2:22:09, 28.53s/it]\n",
            "6650.jpg: actual-predicted:      0,   30.2, error:   30.2. Current MAE: 46.12, RMSE: 73.73:  75% 892/1190 [7:53:46<2:20:25, 28.27s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([51967, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6651.jpg: actual-predicted:      0,   20.2, error:   20.2. Current MAE: 46.09, RMSE: 73.69:  75% 892/1190 [7:54:11<2:20:25, 28.27s/it]\n",
            "6651.jpg: actual-predicted:      0,   20.2, error:   20.2. Current MAE: 46.09, RMSE: 73.69:  75% 893/1190 [7:54:11<2:16:21, 27.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([42185, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6652.jpg: actual-predicted:      0,   31.0, error:   31.0. Current MAE: 46.07, RMSE: 73.66:  75% 893/1190 [7:55:03<2:16:21, 27.55s/it]\n",
            "6652.jpg: actual-predicted:      0,   31.0, error:   31.0. Current MAE: 46.07, RMSE: 73.66:  75% 894/1190 [7:55:03<2:51:39, 34.80s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([38765, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6653.jpg: actual-predicted:      0,  169.3, error:  169.3. Current MAE: 46.21, RMSE: 73.83:  75% 894/1190 [7:55:39<2:51:39, 34.80s/it]\n",
            "6653.jpg: actual-predicted:      0,  169.3, error:  169.3. Current MAE: 46.21, RMSE: 73.83:  75% 895/1190 [7:55:39<2:52:40, 35.12s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([124490, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6654.jpg: actual-predicted:      0,   49.0, error:   49.0. Current MAE: 46.22, RMSE: 73.81:  75% 895/1190 [7:56:05<2:52:40, 35.12s/it]\n",
            "6654.jpg: actual-predicted:      0,   49.0, error:   49.0. Current MAE: 46.22, RMSE: 73.81:  75% 896/1190 [7:56:05<2:38:38, 32.37s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([16371, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6655.jpg: actual-predicted:      0,  138.7, error:  138.7. Current MAE: 46.32, RMSE: 73.91:  75% 896/1190 [7:56:29<2:38:38, 32.37s/it]\n",
            "6655.jpg: actual-predicted:      0,  138.7, error:  138.7. Current MAE: 46.32, RMSE: 73.91:  75% 897/1190 [7:56:29<2:25:40, 29.83s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([18494, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6656.jpg: actual-predicted:      0,   87.4, error:   87.4. Current MAE: 46.36, RMSE: 73.93:  75% 897/1190 [7:57:00<2:25:40, 29.83s/it]\n",
            "6656.jpg: actual-predicted:      0,   87.4, error:   87.4. Current MAE: 46.36, RMSE: 73.93:  75% 898/1190 [7:57:00<2:26:48, 30.17s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([12265, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6657.jpg: actual-predicted:      0,  108.7, error:  108.7. Current MAE: 46.43, RMSE: 73.98:  75% 898/1190 [7:57:25<2:26:48, 30.17s/it]\n",
            "6657.jpg: actual-predicted:      0,  108.7, error:  108.7. Current MAE: 46.43, RMSE: 73.98:  76% 899/1190 [7:57:25<2:18:34, 28.57s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([74362, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6658.jpg: actual-predicted:      0,  345.6, error:  345.6. Current MAE: 46.77, RMSE: 74.83:  76% 899/1190 [7:57:51<2:18:34, 28.57s/it]\n",
            "6658.jpg: actual-predicted:      0,  345.6, error:  345.6. Current MAE: 46.77, RMSE: 74.83:  76% 900/1190 [7:57:51<2:14:26, 27.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([19758, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6659.jpg: actual-predicted:      0,    8.3, error:    8.3. Current MAE: 46.72, RMSE: 74.79:  76% 900/1190 [7:58:15<2:14:26, 27.82s/it]\n",
            "6659.jpg: actual-predicted:      0,    8.3, error:    8.3. Current MAE: 46.72, RMSE: 74.79:  76% 901/1190 [7:58:15<2:09:10, 26.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([43140, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6660.jpg: actual-predicted:      0,   10.9, error:   10.9. Current MAE: 46.68, RMSE: 74.75:  76% 901/1190 [7:58:39<2:09:10, 26.82s/it]\n",
            "6660.jpg: actual-predicted:      0,   10.9, error:   10.9. Current MAE: 46.68, RMSE: 74.75:  76% 902/1190 [7:58:39<2:04:52, 26.02s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([111054, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6661.jpg: actual-predicted:      0,  307.1, error:  307.1. Current MAE: 46.97, RMSE: 75.40:  76% 902/1190 [7:59:11<2:04:52, 26.02s/it]\n",
            "6661.jpg: actual-predicted:      0,  307.1, error:  307.1. Current MAE: 46.97, RMSE: 75.40:  76% 903/1190 [7:59:11<2:12:05, 27.61s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([115763, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7627.jpg: actual-predicted:      0,   17.6, error:   17.6. Current MAE: 46.94, RMSE: 75.36:  76% 903/1190 [7:59:43<2:12:05, 27.61s/it]\n",
            "7627.jpg: actual-predicted:      0,   17.6, error:   17.6. Current MAE: 46.94, RMSE: 75.36:  76% 904/1190 [7:59:43<2:18:47, 29.12s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([111410, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7625.jpg: actual-predicted:      0,   25.6, error:   25.6. Current MAE: 46.92, RMSE: 75.32:  76% 904/1190 [8:00:16<2:18:47, 29.12s/it]\n",
            "7625.jpg: actual-predicted:      0,   25.6, error:   25.6. Current MAE: 46.92, RMSE: 75.32:  76% 905/1190 [8:00:16<2:23:44, 30.26s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([29725, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6971.jpg: actual-predicted:      0,   83.1, error:   83.1. Current MAE: 46.96, RMSE: 75.33:  76% 905/1190 [8:01:18<2:23:44, 30.26s/it]\n",
            "7643.jpg: actual-predicted:      0,   40.6, error:   40.6. Current MAE: 46.95, RMSE: 75.30:  76% 906/1190 [8:01:43<3:07:59, 39.72s/it]\n",
            "7643.jpg: actual-predicted:      0,   40.6, error:   40.6. Current MAE: 46.95, RMSE: 75.30:  76% 907/1190 [8:01:43<2:45:48, 35.15s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([85593, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7635.jpg: actual-predicted:      0,   19.7, error:   19.7. Current MAE: 46.92, RMSE: 75.26:  76% 907/1190 [8:02:09<2:45:48, 35.15s/it]\n",
            "7635.jpg: actual-predicted:      0,   19.7, error:   19.7. Current MAE: 46.92, RMSE: 75.26:  76% 908/1190 [8:02:09<2:32:46, 32.50s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([104291, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7662.jpg: actual-predicted:      0,   28.8, error:   28.8. Current MAE: 46.90, RMSE: 75.23:  76% 908/1190 [8:02:34<2:32:46, 32.50s/it]\n",
            "7665.jpg: actual-predicted:      0,   37.8, error:   37.8. Current MAE: 46.89, RMSE: 75.20:  76% 909/1190 [8:03:09<2:22:28, 30.42s/it]\n",
            "7665.jpg: actual-predicted:      0,   37.8, error:   37.8. Current MAE: 46.89, RMSE: 75.20:  76% 910/1190 [8:03:09<2:27:42, 31.65s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([125232, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7661.jpg: actual-predicted:      0,   31.3, error:   31.3. Current MAE: 46.87, RMSE: 75.16:  76% 910/1190 [8:03:42<2:27:42, 31.65s/it]\n",
            "7661.jpg: actual-predicted:      0,   31.3, error:   31.3. Current MAE: 46.87, RMSE: 75.16:  77% 911/1190 [8:03:42<2:28:52, 32.02s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([9452, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6829.jpg: actual-predicted:      0,   86.7, error:   86.7. Current MAE: 46.92, RMSE: 75.18:  77% 911/1190 [8:04:23<2:28:52, 32.02s/it]\n",
            "6829.jpg: actual-predicted:      0,   86.7, error:   86.7. Current MAE: 46.92, RMSE: 75.18:  77% 912/1190 [8:04:23<2:41:02, 34.76s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([20885, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7650.jpg: actual-predicted:      0,   32.4, error:   32.4. Current MAE: 46.90, RMSE: 75.14:  77% 912/1190 [8:05:08<2:41:02, 34.76s/it]\n",
            "7650.jpg: actual-predicted:      0,   32.4, error:   32.4. Current MAE: 46.90, RMSE: 75.14:  77% 913/1190 [8:05:08<2:54:59, 37.90s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([71436, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7596.jpg: actual-predicted:      0,  190.7, error:  190.7. Current MAE: 47.06, RMSE: 75.37:  77% 913/1190 [8:05:52<2:54:59, 37.90s/it]\n",
            "7596.jpg: actual-predicted:      0,  190.7, error:  190.7. Current MAE: 47.06, RMSE: 75.37:  77% 914/1190 [8:05:52<3:02:30, 39.68s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([113564, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7262.jpg: actual-predicted:      0,   19.3, error:   19.3. Current MAE: 47.03, RMSE: 75.33:  77% 914/1190 [8:06:33<3:02:30, 39.68s/it]\n",
            "7262.jpg: actual-predicted:      0,   19.3, error:   19.3. Current MAE: 47.03, RMSE: 75.33:  77% 915/1190 [8:06:33<3:03:04, 39.95s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([176848, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7614.jpg: actual-predicted:      0,   26.0, error:   26.0. Current MAE: 47.00, RMSE: 75.29:  77% 915/1190 [8:07:10<3:03:04, 39.95s/it]\n",
            "7640.jpg: actual-predicted:      0,   42.7, error:   42.7. Current MAE: 47.00, RMSE: 75.26:  77% 916/1190 [8:07:44<2:58:27, 39.08s/it]\n",
            "7640.jpg: actual-predicted:      0,   42.7, error:   42.7. Current MAE: 47.00, RMSE: 75.26:  77% 917/1190 [8:07:44<2:51:55, 37.79s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([37036, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6936.jpg: actual-predicted:      0,   65.3, error:   65.3. Current MAE: 47.02, RMSE: 75.25:  77% 917/1190 [8:08:10<2:51:55, 37.79s/it]\n",
            "6936.jpg: actual-predicted:      0,   65.3, error:   65.3. Current MAE: 47.02, RMSE: 75.25:  77% 918/1190 [8:08:10<2:34:54, 34.17s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([63365, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7114.jpg: actual-predicted:      0,  155.9, error:  155.9. Current MAE: 47.14, RMSE: 75.39:  77% 918/1190 [8:08:57<2:34:54, 34.17s/it]\n",
            "7114.jpg: actual-predicted:      0,  155.9, error:  155.9. Current MAE: 47.14, RMSE: 75.39:  77% 919/1190 [8:08:57<2:51:48, 38.04s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([45509, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7493.jpg: actual-predicted:      0,   41.8, error:   41.8. Current MAE: 47.13, RMSE: 75.36:  77% 919/1190 [8:09:32<2:51:48, 38.04s/it]\n",
            "7493.jpg: actual-predicted:      0,   41.8, error:   41.8. Current MAE: 47.13, RMSE: 75.36:  77% 920/1190 [8:09:32<2:47:06, 37.14s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([129475, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7298.jpg: actual-predicted:      0,   29.3, error:   29.3. Current MAE: 47.11, RMSE: 75.33:  77% 920/1190 [8:10:04<2:47:06, 37.14s/it]\n",
            "7298.jpg: actual-predicted:      0,   29.3, error:   29.3. Current MAE: 47.11, RMSE: 75.33:  77% 921/1190 [8:10:04<2:39:46, 35.64s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([54641, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7283.jpg: actual-predicted:      0,   24.1, error:   24.1. Current MAE: 47.09, RMSE: 75.29:  77% 921/1190 [8:10:36<2:39:46, 35.64s/it]\n",
            "7283.jpg: actual-predicted:      0,   24.1, error:   24.1. Current MAE: 47.09, RMSE: 75.29:  77% 922/1190 [8:10:36<2:33:40, 34.40s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([3648, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6965.jpg: actual-predicted:      0,   53.6, error:   53.6. Current MAE: 47.09, RMSE: 75.27:  77% 922/1190 [8:11:16<2:33:40, 34.40s/it]\n",
            "7027.jpg: actual-predicted:      0,  109.6, error:  109.6. Current MAE: 47.16, RMSE: 75.32:  78% 923/1190 [8:12:01<2:40:24, 36.05s/it]\n",
            "7027.jpg: actual-predicted:      0,  109.6, error:  109.6. Current MAE: 47.16, RMSE: 75.32:  78% 924/1190 [8:12:01<2:52:29, 38.91s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([89894, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7693.jpg: actual-predicted:      0,   61.7, error:   61.7. Current MAE: 47.18, RMSE: 75.30:  78% 924/1190 [8:12:33<2:52:29, 38.91s/it]\n",
            "7693.jpg: actual-predicted:      0,   61.7, error:   61.7. Current MAE: 47.18, RMSE: 75.30:  78% 925/1190 [8:12:33<2:42:15, 36.74s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([99098, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7483.jpg: actual-predicted:      0,  193.9, error:  193.9. Current MAE: 47.34, RMSE: 75.53:  78% 925/1190 [8:13:04<2:42:15, 36.74s/it]\n",
            "7483.jpg: actual-predicted:      0,  193.9, error:  193.9. Current MAE: 47.34, RMSE: 75.53:  78% 926/1190 [8:13:04<2:34:20, 35.08s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([41053, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7341.jpg: actual-predicted:      0,   15.5, error:   15.5. Current MAE: 47.30, RMSE: 75.49:  78% 926/1190 [8:13:40<2:34:20, 35.08s/it]\n",
            "7341.jpg: actual-predicted:      0,   15.5, error:   15.5. Current MAE: 47.30, RMSE: 75.49:  78% 927/1190 [8:13:40<2:34:30, 35.25s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([18483, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7095.jpg: actual-predicted:      0,   39.8, error:   39.8. Current MAE: 47.29, RMSE: 75.46:  78% 927/1190 [8:14:04<2:34:30, 35.25s/it]\n",
            "7095.jpg: actual-predicted:      0,   39.8, error:   39.8. Current MAE: 47.29, RMSE: 75.46:  78% 928/1190 [8:14:04<2:18:55, 31.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([47330, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7438.jpg: actual-predicted:      0,   38.5, error:   38.5. Current MAE: 47.28, RMSE: 75.43:  78% 928/1190 [8:14:35<2:18:55, 31.82s/it]\n",
            "7438.jpg: actual-predicted:      0,   38.5, error:   38.5. Current MAE: 47.28, RMSE: 75.43:  78% 929/1190 [8:14:35<2:17:19, 31.57s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([31516, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6771.jpg: actual-predicted:      0,   18.4, error:   18.4. Current MAE: 47.25, RMSE: 75.39:  78% 929/1190 [8:15:06<2:17:19, 31.57s/it]\n",
            "6771.jpg: actual-predicted:      0,   18.4, error:   18.4. Current MAE: 47.25, RMSE: 75.39:  78% 930/1190 [8:15:06<2:15:49, 31.34s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([39561, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7586.jpg: actual-predicted:      0,   38.1, error:   38.1. Current MAE: 47.24, RMSE: 75.36:  78% 930/1190 [8:15:38<2:15:49, 31.34s/it]\n",
            "7586.jpg: actual-predicted:      0,   38.1, error:   38.1. Current MAE: 47.24, RMSE: 75.36:  78% 931/1190 [8:15:38<2:16:26, 31.61s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([106001, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7645.jpg: actual-predicted:      0,   13.4, error:   13.4. Current MAE: 47.21, RMSE: 75.32:  78% 931/1190 [8:16:18<2:16:26, 31.61s/it]\n",
            "7645.jpg: actual-predicted:      0,   13.4, error:   13.4. Current MAE: 47.21, RMSE: 75.32:  78% 932/1190 [8:16:18<2:27:40, 34.34s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([8738, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6938.jpg: actual-predicted:      0,   47.1, error:   47.1. Current MAE: 47.21, RMSE: 75.30:  78% 932/1190 [8:16:52<2:27:40, 34.34s/it]\n",
            "6938.jpg: actual-predicted:      0,   47.1, error:   47.1. Current MAE: 47.21, RMSE: 75.30:  78% 933/1190 [8:16:52<2:26:13, 34.14s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([53431, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7076.jpg: actual-predicted:      0,   30.4, error:   30.4. Current MAE: 47.19, RMSE: 75.27:  78% 933/1190 [8:17:23<2:26:13, 34.14s/it]\n",
            "7076.jpg: actual-predicted:      0,   30.4, error:   30.4. Current MAE: 47.19, RMSE: 75.27:  78% 934/1190 [8:17:23<2:21:56, 33.27s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([113184, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6943.jpg: actual-predicted:      0,   33.2, error:   33.2. Current MAE: 47.17, RMSE: 75.23:  78% 934/1190 [8:18:00<2:21:56, 33.27s/it]\n",
            "6943.jpg: actual-predicted:      0,   33.2, error:   33.2. Current MAE: 47.17, RMSE: 75.23:  79% 935/1190 [8:18:00<2:25:22, 34.20s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17742, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6823.jpg: actual-predicted:      0,   25.2, error:   25.2. Current MAE: 47.15, RMSE: 75.20:  79% 935/1190 [8:18:34<2:25:22, 34.20s/it]\n",
            "6823.jpg: actual-predicted:      0,   25.2, error:   25.2. Current MAE: 47.15, RMSE: 75.20:  79% 936/1190 [8:18:34<2:24:53, 34.23s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([61704, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7567.jpg: actual-predicted:      0,   54.1, error:   54.1. Current MAE: 47.16, RMSE: 75.18:  79% 936/1190 [8:19:05<2:24:53, 34.23s/it]\n",
            "7567.jpg: actual-predicted:      0,   54.1, error:   54.1. Current MAE: 47.16, RMSE: 75.18:  79% 937/1190 [8:19:05<2:20:24, 33.30s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([77989, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7542.jpg: actual-predicted:      0,   37.1, error:   37.1. Current MAE: 47.15, RMSE: 75.15:  79% 937/1190 [8:19:41<2:20:24, 33.30s/it]\n",
            "7542.jpg: actual-predicted:      0,   37.1, error:   37.1. Current MAE: 47.15, RMSE: 75.15:  79% 938/1190 [8:19:41<2:23:21, 34.13s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([127662, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7398.jpg: actual-predicted:      0,   34.1, error:   34.1. Current MAE: 47.13, RMSE: 75.12:  79% 938/1190 [8:20:20<2:23:21, 34.13s/it]\n",
            "7398.jpg: actual-predicted:      0,   34.1, error:   34.1. Current MAE: 47.13, RMSE: 75.12:  79% 939/1190 [8:20:20<2:28:41, 35.54s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([33714, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7071.jpg: actual-predicted:      0,   41.8, error:   41.8. Current MAE: 47.13, RMSE: 75.09:  79% 939/1190 [8:20:51<2:28:41, 35.54s/it]\n",
            "7071.jpg: actual-predicted:      0,   41.8, error:   41.8. Current MAE: 47.13, RMSE: 75.09:  79% 940/1190 [8:20:51<2:22:12, 34.13s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([63667, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7240.jpg: actual-predicted:      0,   43.0, error:   43.0. Current MAE: 47.12, RMSE: 75.06:  79% 940/1190 [8:21:17<2:22:12, 34.13s/it]\n",
            "7240.jpg: actual-predicted:      0,   43.0, error:   43.0. Current MAE: 47.12, RMSE: 75.06:  79% 941/1190 [8:21:17<2:11:46, 31.75s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64625, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6859.jpg: actual-predicted:      0,   29.3, error:   29.3. Current MAE: 47.10, RMSE: 75.03:  79% 941/1190 [8:21:48<2:11:46, 31.75s/it]\n",
            "6859.jpg: actual-predicted:      0,   29.3, error:   29.3. Current MAE: 47.10, RMSE: 75.03:  79% 942/1190 [8:21:48<2:10:32, 31.58s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([193863, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7617.jpg: actual-predicted:      0,   15.9, error:   15.9. Current MAE: 47.07, RMSE: 74.99:  79% 942/1190 [8:22:32<2:10:32, 31.58s/it]\n",
            "7617.jpg: actual-predicted:      0,   15.9, error:   15.9. Current MAE: 47.07, RMSE: 74.99:  79% 943/1190 [8:22:32<2:24:33, 35.12s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([93725, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6879.jpg: actual-predicted:      0,   17.8, error:   17.8. Current MAE: 47.04, RMSE: 74.95:  79% 943/1190 [8:23:03<2:24:33, 35.12s/it]\n",
            "6879.jpg: actual-predicted:      0,   17.8, error:   17.8. Current MAE: 47.04, RMSE: 74.95:  79% 944/1190 [8:23:03<2:19:51, 34.11s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([78260, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7580.jpg: actual-predicted:      0,   15.7, error:   15.7. Current MAE: 47.01, RMSE: 74.91:  79% 944/1190 [8:23:42<2:19:51, 34.11s/it]\n",
            "7580.jpg: actual-predicted:      0,   15.7, error:   15.7. Current MAE: 47.01, RMSE: 74.91:  79% 945/1190 [8:23:42<2:25:18, 35.58s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([121594, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7668.jpg: actual-predicted:      0,   25.8, error:   25.8. Current MAE: 46.98, RMSE: 74.88:  79% 945/1190 [8:24:09<2:25:18, 35.58s/it]\n",
            "7668.jpg: actual-predicted:      0,   25.8, error:   25.8. Current MAE: 46.98, RMSE: 74.88:  79% 946/1190 [8:24:09<2:13:54, 32.93s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([74480, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6996.jpg: actual-predicted:      0,   55.0, error:   55.0. Current MAE: 46.99, RMSE: 74.86:  79% 946/1190 [8:24:50<2:13:54, 32.93s/it]\n",
            "6996.jpg: actual-predicted:      0,   55.0, error:   55.0. Current MAE: 46.99, RMSE: 74.86:  80% 947/1190 [8:24:50<2:23:10, 35.35s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([147228, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7595.jpg: actual-predicted:      0,   25.0, error:   25.0. Current MAE: 46.97, RMSE: 74.83:  80% 947/1190 [8:25:32<2:23:10, 35.35s/it]\n",
            "7595.jpg: actual-predicted:      0,   25.0, error:   25.0. Current MAE: 46.97, RMSE: 74.83:  80% 948/1190 [8:25:32<2:29:50, 37.15s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([108403, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6876.jpg: actual-predicted:      0,   58.4, error:   58.4. Current MAE: 46.98, RMSE: 74.81:  80% 948/1190 [8:25:58<2:29:50, 37.15s/it]\n",
            "6876.jpg: actual-predicted:      0,   58.4, error:   58.4. Current MAE: 46.98, RMSE: 74.81:  80% 949/1190 [8:25:58<2:16:22, 33.95s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([105930, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7605.jpg: actual-predicted:      0,   19.2, error:   19.2. Current MAE: 46.95, RMSE: 74.77:  80% 949/1190 [8:26:35<2:16:22, 33.95s/it]\n",
            "7605.jpg: actual-predicted:      0,   19.2, error:   19.2. Current MAE: 46.95, RMSE: 74.77:  80% 950/1190 [8:26:35<2:18:55, 34.73s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([135994, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6733.jpg: actual-predicted:      0,   20.7, error:   20.7. Current MAE: 46.92, RMSE: 74.74:  80% 950/1190 [8:27:14<2:18:55, 34.73s/it]\n",
            "6733.jpg: actual-predicted:      0,   20.7, error:   20.7. Current MAE: 46.92, RMSE: 74.74:  80% 951/1190 [8:27:14<2:23:50, 36.11s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([183820, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7689.jpg: actual-predicted:      0,   13.0, error:   13.0. Current MAE: 46.89, RMSE: 74.70:  80% 951/1190 [8:27:50<2:23:50, 36.11s/it]\n",
            "7689.jpg: actual-predicted:      0,   13.0, error:   13.0. Current MAE: 46.89, RMSE: 74.70:  80% 952/1190 [8:27:50<2:22:47, 36.00s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([183427, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7370.jpg: actual-predicted:      0,   12.4, error:   12.4. Current MAE: 46.85, RMSE: 74.66:  80% 952/1190 [8:28:26<2:22:47, 36.00s/it]\n",
            "7370.jpg: actual-predicted:      0,   12.4, error:   12.4. Current MAE: 46.85, RMSE: 74.66:  80% 953/1190 [8:28:26<2:22:30, 36.08s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([167702, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7424.jpg: actual-predicted:      0,   64.6, error:   64.6. Current MAE: 46.87, RMSE: 74.65:  80% 953/1190 [8:29:14<2:22:30, 36.08s/it]\n",
            "7424.jpg: actual-predicted:      0,   64.6, error:   64.6. Current MAE: 46.87, RMSE: 74.65:  80% 954/1190 [8:29:14<2:36:33, 39.80s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([157111, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6804.jpg: actual-predicted:      0,   12.4, error:   12.4. Current MAE: 46.84, RMSE: 74.61:  80% 954/1190 [8:29:49<2:36:33, 39.80s/it]\n",
            "6804.jpg: actual-predicted:      0,   12.4, error:   12.4. Current MAE: 46.84, RMSE: 74.61:  80% 955/1190 [8:29:49<2:30:03, 38.31s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([23907, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7145.jpg: actual-predicted:      0,   24.6, error:   24.6. Current MAE: 46.81, RMSE: 74.58:  80% 955/1190 [8:30:20<2:30:03, 38.31s/it]\n",
            "7145.jpg: actual-predicted:      0,   24.6, error:   24.6. Current MAE: 46.81, RMSE: 74.58:  80% 956/1190 [8:30:20<2:20:48, 36.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([35011, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7205.jpg: actual-predicted:      0,   63.2, error:   63.2. Current MAE: 46.83, RMSE: 74.57:  80% 956/1190 [8:30:51<2:20:48, 36.10s/it]\n",
            "7205.jpg: actual-predicted:      0,   63.2, error:   63.2. Current MAE: 46.83, RMSE: 74.57:  80% 957/1190 [8:30:51<2:13:59, 34.50s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([52781, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6732.jpg: actual-predicted:      0,   37.7, error:   37.7. Current MAE: 46.82, RMSE: 74.54:  80% 957/1190 [8:31:31<2:13:59, 34.50s/it]\n",
            "6732.jpg: actual-predicted:      0,   37.7, error:   37.7. Current MAE: 46.82, RMSE: 74.54:  81% 958/1190 [8:31:31<2:20:10, 36.25s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([34395, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6852.jpg: actual-predicted:      0,   51.3, error:   51.3. Current MAE: 46.82, RMSE: 74.52:  81% 958/1190 [8:32:11<2:20:10, 36.25s/it]\n",
            "6852.jpg: actual-predicted:      0,   51.3, error:   51.3. Current MAE: 46.82, RMSE: 74.52:  81% 959/1190 [8:32:11<2:23:58, 37.40s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([103967, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7277.jpg: actual-predicted:      0,   18.3, error:   18.3. Current MAE: 46.79, RMSE: 74.48:  81% 959/1190 [8:32:44<2:23:58, 37.40s/it]\n",
            "7277.jpg: actual-predicted:      0,   18.3, error:   18.3. Current MAE: 46.79, RMSE: 74.48:  81% 960/1190 [8:32:44<2:17:48, 35.95s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([85943, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6928.jpg: actual-predicted:      0,   32.7, error:   32.7. Current MAE: 46.78, RMSE: 74.45:  81% 960/1190 [8:33:09<2:17:48, 35.95s/it]\n",
            "7128.jpg: actual-predicted:      0,   43.7, error:   43.7. Current MAE: 46.78, RMSE: 74.43:  81% 961/1190 [8:33:48<2:04:34, 32.64s/it]\n",
            "7128.jpg: actual-predicted:      0,   43.7, error:   43.7. Current MAE: 46.78, RMSE: 74.43:  81% 962/1190 [8:33:48<2:11:39, 34.65s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([164148, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7146.jpg: actual-predicted:      0,   19.8, error:   19.8. Current MAE: 46.75, RMSE: 74.39:  81% 962/1190 [8:34:24<2:11:39, 34.65s/it]\n",
            "7146.jpg: actual-predicted:      0,   19.8, error:   19.8. Current MAE: 46.75, RMSE: 74.39:  81% 963/1190 [8:34:24<2:12:25, 35.00s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([47830, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7222.jpg: actual-predicted:      0,   59.1, error:   59.1. Current MAE: 46.76, RMSE: 74.38:  81% 963/1190 [8:34:50<2:12:25, 35.00s/it]\n",
            "6986.jpg: actual-predicted:      0,   46.6, error:   46.6. Current MAE: 46.76, RMSE: 74.35:  81% 964/1190 [8:35:21<2:01:28, 32.25s/it]\n",
            "6986.jpg: actual-predicted:      0,   46.6, error:   46.6. Current MAE: 46.76, RMSE: 74.35:  81% 965/1190 [8:35:21<1:59:46, 31.94s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([26107, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7417.jpg: actual-predicted:      0,   38.2, error:   38.2. Current MAE: 46.75, RMSE: 74.32:  81% 965/1190 [8:35:53<1:59:46, 31.94s/it]\n",
            "7417.jpg: actual-predicted:      0,   38.2, error:   38.2. Current MAE: 46.75, RMSE: 74.32:  81% 966/1190 [8:35:53<1:59:26, 31.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([24303, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7449.jpg: actual-predicted:      0,   54.1, error:   54.1. Current MAE: 46.76, RMSE: 74.31:  81% 966/1190 [8:36:18<1:59:26, 31.99s/it]\n",
            "7449.jpg: actual-predicted:      0,   54.1, error:   54.1. Current MAE: 46.76, RMSE: 74.31:  81% 967/1190 [8:36:18<1:50:28, 29.73s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([61409, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7687.jpg: actual-predicted:      0,   21.5, error:   21.5. Current MAE: 46.73, RMSE: 74.27:  81% 967/1190 [8:36:43<1:50:28, 29.73s/it]\n",
            "7687.jpg: actual-predicted:      0,   21.5, error:   21.5. Current MAE: 46.73, RMSE: 74.27:  81% 968/1190 [8:36:43<1:45:35, 28.54s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([16864, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6892.jpg: actual-predicted:      0,   52.1, error:   52.1. Current MAE: 46.74, RMSE: 74.25:  81% 968/1190 [8:37:17<1:45:35, 28.54s/it]\n",
            "6892.jpg: actual-predicted:      0,   52.1, error:   52.1. Current MAE: 46.74, RMSE: 74.25:  81% 969/1190 [8:37:17<1:50:57, 30.12s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([38525, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7273.jpg: actual-predicted:      0,   37.5, error:   37.5. Current MAE: 46.73, RMSE: 74.22:  81% 969/1190 [8:37:43<1:50:57, 30.12s/it]\n",
            "7273.jpg: actual-predicted:      0,   37.5, error:   37.5. Current MAE: 46.73, RMSE: 74.22:  82% 970/1190 [8:37:43<1:45:17, 28.72s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([68827, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7263.jpg: actual-predicted:      0,   49.3, error:   49.3. Current MAE: 46.73, RMSE: 74.20:  82% 970/1190 [8:38:09<1:45:17, 28.72s/it]\n",
            "6923.jpg: actual-predicted:      0,   38.0, error:   38.0. Current MAE: 46.72, RMSE: 74.17:  82% 971/1190 [8:38:44<1:42:16, 28.02s/it]\n",
            "6715.jpg: actual-predicted:      0,   45.5, error:   45.5. Current MAE: 46.72, RMSE: 74.15:  82% 972/1190 [8:39:09<1:49:33, 30.15s/it]\n",
            "6715.jpg: actual-predicted:      0,   45.5, error:   45.5. Current MAE: 46.72, RMSE: 74.15:  82% 973/1190 [8:39:09<1:43:29, 28.62s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([58419, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7555.jpg: actual-predicted:      0,   37.4, error:   37.4. Current MAE: 46.71, RMSE: 74.12:  82% 973/1190 [8:39:35<1:43:29, 28.62s/it]\n",
            "7555.jpg: actual-predicted:      0,   37.4, error:   37.4. Current MAE: 46.71, RMSE: 74.12:  82% 974/1190 [8:39:35<1:39:53, 27.75s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([31490, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7342.jpg: actual-predicted:      0,   53.8, error:   53.8. Current MAE: 46.72, RMSE: 74.10:  82% 974/1190 [8:40:09<1:39:53, 27.75s/it]\n",
            "7365.jpg: actual-predicted:      0,   59.4, error:   59.4. Current MAE: 46.73, RMSE: 74.09:  82% 975/1190 [8:40:34<1:46:23, 29.69s/it]\n",
            "7365.jpg: actual-predicted:      0,   59.4, error:   59.4. Current MAE: 46.73, RMSE: 74.09:  82% 976/1190 [8:40:34<1:41:12, 28.38s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([40512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7161.jpg: actual-predicted:      0,   30.9, error:   30.9. Current MAE: 46.72, RMSE: 74.06:  82% 976/1190 [8:41:07<1:41:12, 28.38s/it]\n",
            "7161.jpg: actual-predicted:      0,   30.9, error:   30.9. Current MAE: 46.72, RMSE: 74.06:  82% 977/1190 [8:41:07<1:44:52, 29.54s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([57243, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7564.jpg: actual-predicted:      0,   50.4, error:   50.4. Current MAE: 46.72, RMSE: 74.04:  82% 977/1190 [8:41:41<1:44:52, 29.54s/it]\n",
            "7216.jpg: actual-predicted:      0,   34.1, error:   34.1. Current MAE: 46.71, RMSE: 74.01:  82% 978/1190 [8:42:07<1:49:40, 31.04s/it]\n",
            "7216.jpg: actual-predicted:      0,   34.1, error:   34.1. Current MAE: 46.71, RMSE: 74.01:  82% 979/1190 [8:42:07<1:43:19, 29.38s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([91663, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7554.jpg: actual-predicted:      0,   82.1, error:   82.1. Current MAE: 46.74, RMSE: 74.02:  82% 979/1190 [8:42:39<1:43:19, 29.38s/it]\n",
            "7554.jpg: actual-predicted:      0,   82.1, error:   82.1. Current MAE: 46.74, RMSE: 74.02:  82% 980/1190 [8:42:39<1:45:38, 30.18s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([65576, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6735.jpg: actual-predicted:      0,   67.1, error:   67.1. Current MAE: 46.77, RMSE: 74.01:  82% 980/1190 [8:43:05<1:45:38, 30.18s/it]\n",
            "6735.jpg: actual-predicted:      0,   67.1, error:   67.1. Current MAE: 46.77, RMSE: 74.01:  82% 981/1190 [8:43:05<1:40:54, 28.97s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([93406, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6711.jpg: actual-predicted:      0,   52.8, error:   52.8. Current MAE: 46.77, RMSE: 73.99:  82% 981/1190 [8:43:39<1:40:54, 28.97s/it]\n",
            "6711.jpg: actual-predicted:      0,   52.8, error:   52.8. Current MAE: 46.77, RMSE: 73.99:  83% 982/1190 [8:43:39<1:45:15, 30.36s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([41806, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7443.jpg: actual-predicted:      0,  328.0, error:  328.0. Current MAE: 47.06, RMSE: 74.69:  83% 982/1190 [8:44:09<1:45:15, 30.36s/it]\n",
            "7443.jpg: actual-predicted:      0,  328.0, error:  328.0. Current MAE: 47.06, RMSE: 74.69:  83% 983/1190 [8:44:09<1:45:06, 30.47s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([69516, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6822.jpg: actual-predicted:      0,  189.7, error:  189.7. Current MAE: 47.20, RMSE: 74.90:  83% 983/1190 [8:44:50<1:45:06, 30.47s/it]\n",
            "6822.jpg: actual-predicted:      0,  189.7, error:  189.7. Current MAE: 47.20, RMSE: 74.90:  83% 984/1190 [8:44:50<1:55:21, 33.60s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([38290, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7707.jpg: actual-predicted:      0,  309.1, error:  309.1. Current MAE: 47.47, RMSE: 75.50:  83% 984/1190 [8:45:24<1:55:21, 33.60s/it]\n",
            "7707.jpg: actual-predicted:      0,  309.1, error:  309.1. Current MAE: 47.47, RMSE: 75.50:  83% 985/1190 [8:45:24<1:55:19, 33.76s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([79143, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6803.jpg: actual-predicted:      0,   48.9, error:   48.9. Current MAE: 47.47, RMSE: 75.48:  83% 985/1190 [8:46:02<1:55:19, 33.76s/it]\n",
            "6922.jpg: actual-predicted:      0,  118.5, error:  118.5. Current MAE: 47.54, RMSE: 75.54:  83% 986/1190 [8:46:37<1:58:33, 34.87s/it]\n",
            "6922.jpg: actual-predicted:      0,  118.5, error:  118.5. Current MAE: 47.54, RMSE: 75.54:  83% 987/1190 [8:46:37<1:58:26, 35.01s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([32035, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6950.jpg: actual-predicted:      0,   23.5, error:   23.5. Current MAE: 47.52, RMSE: 75.50:  83% 987/1190 [8:47:14<1:58:26, 35.01s/it]\n",
            "6950.jpg: actual-predicted:      0,   23.5, error:   23.5. Current MAE: 47.52, RMSE: 75.50:  83% 988/1190 [8:47:14<1:59:33, 35.51s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([66684, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7484.jpg: actual-predicted:      0,   23.3, error:   23.3. Current MAE: 47.49, RMSE: 75.47:  83% 988/1190 [8:47:54<1:59:33, 35.51s/it]\n",
            "7484.jpg: actual-predicted:      0,   23.3, error:   23.3. Current MAE: 47.49, RMSE: 75.47:  83% 989/1190 [8:47:54<2:03:56, 37.00s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([41839, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7384.jpg: actual-predicted:      0,   22.6, error:   22.6. Current MAE: 47.47, RMSE: 75.43:  83% 989/1190 [8:48:20<2:03:56, 37.00s/it]\n",
            "7384.jpg: actual-predicted:      0,   22.6, error:   22.6. Current MAE: 47.47, RMSE: 75.43:  83% 990/1190 [8:48:20<1:52:07, 33.64s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([40076, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7583.jpg: actual-predicted:      0,   29.9, error:   29.9. Current MAE: 47.45, RMSE: 75.40:  83% 990/1190 [8:48:51<1:52:07, 33.64s/it]\n",
            "7557.jpg: actual-predicted:      0,   19.0, error:   19.0. Current MAE: 47.42, RMSE: 75.37:  83% 991/1190 [8:49:30<1:48:50, 32.82s/it]\n",
            "7557.jpg: actual-predicted:      0,   19.0, error:   19.0. Current MAE: 47.42, RMSE: 75.37:  83% 992/1190 [8:49:30<1:54:55, 34.83s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([100652, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7709.jpg: actual-predicted:      0,   28.9, error:   28.9. Current MAE: 47.40, RMSE: 75.33:  83% 992/1190 [8:50:02<1:54:55, 34.83s/it]\n",
            "7709.jpg: actual-predicted:      0,   28.9, error:   28.9. Current MAE: 47.40, RMSE: 75.33:  83% 993/1190 [8:50:02<1:51:25, 33.93s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([28406, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7080.jpg: actual-predicted:      0,   28.7, error:   28.7. Current MAE: 47.38, RMSE: 75.30:  83% 993/1190 [8:50:28<1:51:25, 33.93s/it]\n",
            "7080.jpg: actual-predicted:      0,   28.7, error:   28.7. Current MAE: 47.38, RMSE: 75.30:  84% 994/1190 [8:50:28<1:42:32, 31.39s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([98471, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7126.jpg: actual-predicted:      0,   38.1, error:   38.1. Current MAE: 47.37, RMSE: 75.27:  84% 994/1190 [8:50:59<1:42:32, 31.39s/it]\n",
            "7126.jpg: actual-predicted:      0,   38.1, error:   38.1. Current MAE: 47.37, RMSE: 75.27:  84% 995/1190 [8:50:59<1:42:05, 31.41s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([5702, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6838.jpg: actual-predicted:      0,   14.1, error:   14.1. Current MAE: 47.34, RMSE: 75.24:  84% 995/1190 [8:51:34<1:42:05, 31.41s/it]\n",
            "6838.jpg: actual-predicted:      0,   14.1, error:   14.1. Current MAE: 47.34, RMSE: 75.24:  84% 996/1190 [8:51:34<1:45:08, 32.52s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([100642, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7000.jpg: actual-predicted:      0,   75.9, error:   75.9. Current MAE: 47.37, RMSE: 75.24:  84% 996/1190 [8:52:20<1:45:08, 32.52s/it]\n",
            "7000.jpg: actual-predicted:      0,   75.9, error:   75.9. Current MAE: 47.37, RMSE: 75.24:  84% 997/1190 [8:52:20<1:57:41, 36.59s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([39476, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6736.jpg: actual-predicted:      0,   72.7, error:   72.7. Current MAE: 47.39, RMSE: 75.23:  84% 997/1190 [8:53:03<1:57:41, 36.59s/it]\n",
            "6736.jpg: actual-predicted:      0,   72.7, error:   72.7. Current MAE: 47.39, RMSE: 75.23:  84% 998/1190 [8:53:03<2:02:49, 38.38s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([82983, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7694.jpg: actual-predicted:      0,   63.3, error:   63.3. Current MAE: 47.41, RMSE: 75.22:  84% 998/1190 [8:53:35<2:02:49, 38.38s/it]\n",
            "7694.jpg: actual-predicted:      0,   63.3, error:   63.3. Current MAE: 47.41, RMSE: 75.22:  84% 999/1190 [8:53:35<1:55:44, 36.36s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([58061, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6742.jpg: actual-predicted:      0,   20.8, error:   20.8. Current MAE: 47.38, RMSE: 75.19:  84% 999/1190 [8:54:11<1:55:44, 36.36s/it]\n",
            "6742.jpg: actual-predicted:      0,   20.8, error:   20.8. Current MAE: 47.38, RMSE: 75.19:  84% 1000/1190 [8:54:11<1:54:52, 36.28s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([51392, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7683.jpg: actual-predicted:      0,   35.7, error:   35.7. Current MAE: 47.37, RMSE: 75.16:  84% 1000/1190 [8:54:42<1:54:52, 36.28s/it]\n",
            "7683.jpg: actual-predicted:      0,   35.7, error:   35.7. Current MAE: 47.37, RMSE: 75.16:  84% 1001/1190 [8:54:42<1:49:48, 34.86s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([60723, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7581.jpg: actual-predicted:      0,   34.4, error:   34.4. Current MAE: 47.36, RMSE: 75.13:  84% 1001/1190 [8:55:08<1:49:48, 34.86s/it]\n",
            "7581.jpg: actual-predicted:      0,   34.4, error:   34.4. Current MAE: 47.36, RMSE: 75.13:  84% 1002/1190 [8:55:08<1:40:49, 32.18s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([26846, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7695.jpg: actual-predicted:      0,   28.8, error:   28.8. Current MAE: 47.34, RMSE: 75.10:  84% 1002/1190 [8:55:54<1:40:49, 32.18s/it]\n",
            "7695.jpg: actual-predicted:      0,   28.8, error:   28.8. Current MAE: 47.34, RMSE: 75.10:  84% 1003/1190 [8:55:54<1:53:02, 36.27s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([69794, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7442.jpg: actual-predicted:      0,   67.0, error:   67.0. Current MAE: 47.36, RMSE: 75.09:  84% 1003/1190 [8:56:34<1:53:02, 36.27s/it]\n",
            "7442.jpg: actual-predicted:      0,   67.0, error:   67.0. Current MAE: 47.36, RMSE: 75.09:  84% 1004/1190 [8:56:34<1:56:12, 37.49s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([90070, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6906.jpg: actual-predicted:      0,   28.7, error:   28.7. Current MAE: 47.34, RMSE: 75.06:  84% 1004/1190 [8:57:07<1:56:12, 37.49s/it]\n",
            "6906.jpg: actual-predicted:      0,   28.7, error:   28.7. Current MAE: 47.34, RMSE: 75.06:  84% 1005/1190 [8:57:07<1:51:12, 36.07s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([60961, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7098.jpg: actual-predicted:      0,   67.6, error:   67.6. Current MAE: 47.36, RMSE: 75.05:  84% 1005/1190 [8:57:44<1:51:12, 36.07s/it]\n",
            "7098.jpg: actual-predicted:      0,   67.6, error:   67.6. Current MAE: 47.36, RMSE: 75.05:  85% 1006/1190 [8:57:44<1:51:18, 36.30s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([58182, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7565.jpg: actual-predicted:      0,   73.5, error:   73.5. Current MAE: 47.39, RMSE: 75.05:  85% 1006/1190 [8:58:26<1:51:18, 36.30s/it]\n",
            "7565.jpg: actual-predicted:      0,   73.5, error:   73.5. Current MAE: 47.39, RMSE: 75.05:  85% 1007/1190 [8:58:26<1:56:27, 38.18s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([105516, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7200.jpg: actual-predicted:      0,   52.0, error:   52.0. Current MAE: 47.39, RMSE: 75.03:  85% 1007/1190 [8:59:08<1:56:27, 38.18s/it]\n",
            "7200.jpg: actual-predicted:      0,   52.0, error:   52.0. Current MAE: 47.39, RMSE: 75.03:  85% 1008/1190 [8:59:08<1:58:35, 39.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([61475, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7120.jpg: actual-predicted:      0,   43.3, error:   43.3. Current MAE: 47.39, RMSE: 75.01:  85% 1008/1190 [8:59:53<1:58:35, 39.10s/it]\n",
            "7120.jpg: actual-predicted:      0,   43.3, error:   43.3. Current MAE: 47.39, RMSE: 75.01:  85% 1009/1190 [8:59:53<2:03:23, 40.90s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([67362, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7097.jpg: actual-predicted:      0,   50.2, error:   50.2. Current MAE: 47.39, RMSE: 74.99:  85% 1009/1190 [9:00:19<2:03:23, 40.90s/it]\n",
            "7097.jpg: actual-predicted:      0,   50.2, error:   50.2. Current MAE: 47.39, RMSE: 74.99:  85% 1010/1190 [9:00:19<1:49:03, 36.35s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([219840, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7039.jpg: actual-predicted:      0,   32.8, error:   32.8. Current MAE: 47.38, RMSE: 74.96:  85% 1010/1190 [9:01:08<1:49:03, 36.35s/it]\n",
            "7039.jpg: actual-predicted:      0,   32.8, error:   32.8. Current MAE: 47.38, RMSE: 74.96:  85% 1011/1190 [9:01:08<1:59:57, 40.21s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([98208, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7123.jpg: actual-predicted:      0,   33.5, error:   33.5. Current MAE: 47.36, RMSE: 74.93:  85% 1011/1190 [9:01:39<1:59:57, 40.21s/it]\n",
            "7123.jpg: actual-predicted:      0,   33.5, error:   33.5. Current MAE: 47.36, RMSE: 74.93:  85% 1012/1190 [9:01:39<1:51:41, 37.65s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([65822, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6710.jpg: actual-predicted:      0,   54.9, error:   54.9. Current MAE: 47.37, RMSE: 74.91:  85% 1012/1190 [9:02:36<1:51:41, 37.65s/it]\n",
            "6710.jpg: actual-predicted:      0,   54.9, error:   54.9. Current MAE: 47.37, RMSE: 74.91:  85% 1013/1190 [9:02:36<2:07:28, 43.21s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([60334, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6857.jpg: actual-predicted:      0,   76.1, error:   76.1. Current MAE: 47.40, RMSE: 74.91:  85% 1013/1190 [9:03:18<2:07:28, 43.21s/it]\n",
            "6857.jpg: actual-predicted:      0,   76.1, error:   76.1. Current MAE: 47.40, RMSE: 74.91:  85% 1014/1190 [9:03:18<2:06:21, 43.08s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([72819, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6964.jpg: actual-predicted:      0,   63.7, error:   63.7. Current MAE: 47.42, RMSE: 74.90:  85% 1014/1190 [9:03:59<2:06:21, 43.08s/it]\n",
            "6964.jpg: actual-predicted:      0,   63.7, error:   63.7. Current MAE: 47.42, RMSE: 74.90:  85% 1015/1190 [9:03:59<2:03:15, 42.26s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([165122, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7067.jpg: actual-predicted:      0,   57.8, error:   57.8. Current MAE: 47.43, RMSE: 74.88:  85% 1015/1190 [9:04:52<2:03:15, 42.26s/it]\n",
            "7067.jpg: actual-predicted:      0,   57.8, error:   57.8. Current MAE: 47.43, RMSE: 74.88:  85% 1016/1190 [9:04:52<2:11:50, 45.46s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([87073, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7523.jpg: actual-predicted:      0,   43.7, error:   43.7. Current MAE: 47.42, RMSE: 74.86:  85% 1016/1190 [9:05:39<2:11:50, 45.46s/it]\n",
            "7523.jpg: actual-predicted:      0,   43.7, error:   43.7. Current MAE: 47.42, RMSE: 74.86:  85% 1017/1190 [9:05:39<2:12:37, 46.00s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([81415, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6810.jpg: actual-predicted:      0,   33.0, error:   33.0. Current MAE: 47.41, RMSE: 74.83:  85% 1017/1190 [9:06:04<2:12:37, 46.00s/it]\n",
            "6810.jpg: actual-predicted:      0,   33.0, error:   33.0. Current MAE: 47.41, RMSE: 74.83:  86% 1018/1190 [9:06:04<1:53:39, 39.65s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([22302, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7536.jpg: actual-predicted:      0,   21.7, error:   21.7. Current MAE: 47.38, RMSE: 74.80:  86% 1018/1190 [9:06:33<1:53:39, 39.65s/it]\n",
            "7536.jpg: actual-predicted:      0,   21.7, error:   21.7. Current MAE: 47.38, RMSE: 74.80:  86% 1019/1190 [9:06:33<1:43:50, 36.44s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([48801, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6760.jpg: actual-predicted:      0,  118.7, error:  118.7. Current MAE: 47.45, RMSE: 74.85:  86% 1019/1190 [9:06:58<1:43:50, 36.44s/it]\n",
            "6760.jpg: actual-predicted:      0,  118.7, error:  118.7. Current MAE: 47.45, RMSE: 74.85:  86% 1020/1190 [9:06:58<1:34:01, 33.18s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([96146, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6994.jpg: actual-predicted:      0,  129.6, error:  129.6. Current MAE: 47.53, RMSE: 74.93:  86% 1020/1190 [9:07:40<1:34:01, 33.18s/it]\n",
            "7043.jpg: actual-predicted:      0,  117.5, error:  117.5. Current MAE: 47.60, RMSE: 74.98:  86% 1021/1190 [9:08:14<1:40:39, 35.74s/it]\n",
            "7043.jpg: actual-predicted:      0,  117.5, error:  117.5. Current MAE: 47.60, RMSE: 74.98:  86% 1022/1190 [9:08:14<1:38:52, 35.31s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([22609, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7410.jpg: actual-predicted:      0,   39.3, error:   39.3. Current MAE: 47.59, RMSE: 74.95:  86% 1022/1190 [9:08:50<1:38:52, 35.31s/it]\n",
            "7410.jpg: actual-predicted:      0,   39.3, error:   39.3. Current MAE: 47.59, RMSE: 74.95:  86% 1023/1190 [9:08:50<1:38:49, 35.51s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([86448, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7711.jpg: actual-predicted:      0,  142.6, error:  142.6. Current MAE: 47.69, RMSE: 75.05:  86% 1023/1190 [9:09:24<1:38:49, 35.51s/it]\n",
            "7711.jpg: actual-predicted:      0,  142.6, error:  142.6. Current MAE: 47.69, RMSE: 75.05:  86% 1024/1190 [9:09:24<1:37:06, 35.10s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([21161, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6973.jpg: actual-predicted:      0,  133.9, error:  133.9. Current MAE: 47.77, RMSE: 75.13:  86% 1024/1190 [9:09:59<1:37:06, 35.10s/it]\n",
            "6973.jpg: actual-predicted:      0,  133.9, error:  133.9. Current MAE: 47.77, RMSE: 75.13:  86% 1025/1190 [9:09:59<1:36:09, 34.97s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([85278, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7201.jpg: actual-predicted:      0,  135.4, error:  135.4. Current MAE: 47.86, RMSE: 75.21:  86% 1025/1190 [9:10:40<1:36:09, 34.97s/it]\n",
            "7201.jpg: actual-predicted:      0,  135.4, error:  135.4. Current MAE: 47.86, RMSE: 75.21:  86% 1026/1190 [9:10:40<1:40:03, 36.61s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([42894, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6828.jpg: actual-predicted:      0,   23.5, error:   23.5. Current MAE: 47.83, RMSE: 75.18:  86% 1026/1190 [9:11:04<1:40:03, 36.61s/it]\n",
            "6828.jpg: actual-predicted:      0,   23.5, error:   23.5. Current MAE: 47.83, RMSE: 75.18:  86% 1027/1190 [9:11:04<1:29:44, 33.03s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([44387, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7319.jpg: actual-predicted:      0,  538.7, error:  538.7. Current MAE: 48.31, RMSE: 77.00:  86% 1027/1190 [9:11:49<1:29:44, 33.03s/it]\n",
            "7319.jpg: actual-predicted:      0,  538.7, error:  538.7. Current MAE: 48.31, RMSE: 77.00:  86% 1028/1190 [9:11:49<1:38:53, 36.63s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([23590, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6935.jpg: actual-predicted:      0,   86.7, error:   86.7. Current MAE: 48.35, RMSE: 77.01:  86% 1028/1190 [9:12:23<1:38:53, 36.63s/it]\n",
            "7079.jpg: actual-predicted:      0,   80.0, error:   80.0. Current MAE: 48.38, RMSE: 77.01:  86% 1029/1190 [9:12:57<1:36:07, 35.82s/it]\n",
            "7079.jpg: actual-predicted:      0,   80.0, error:   80.0. Current MAE: 48.38, RMSE: 77.01:  87% 1030/1190 [9:12:57<1:33:40, 35.13s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([61646, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7462.jpg: actual-predicted:      0,   95.3, error:   95.3. Current MAE: 48.42, RMSE: 77.03:  87% 1030/1190 [9:13:42<1:33:40, 35.13s/it]\n",
            "7462.jpg: actual-predicted:      0,   95.3, error:   95.3. Current MAE: 48.42, RMSE: 77.03:  87% 1031/1190 [9:13:42<1:40:48, 38.04s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([909, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7034.jpg: actual-predicted:      0,   50.9, error:   50.9. Current MAE: 48.43, RMSE: 77.01:  87% 1031/1190 [9:14:05<1:40:48, 38.04s/it]\n",
            "7034.jpg: actual-predicted:      0,   50.9, error:   50.9. Current MAE: 48.43, RMSE: 77.01:  87% 1032/1190 [9:14:05<1:28:50, 33.73s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([107004, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7526.jpg: actual-predicted:      0,   18.8, error:   18.8. Current MAE: 48.40, RMSE: 76.97:  87% 1032/1190 [9:14:30<1:28:50, 33.73s/it]\n",
            "7526.jpg: actual-predicted:      0,   18.8, error:   18.8. Current MAE: 48.40, RMSE: 76.97:  87% 1033/1190 [9:14:30<1:21:00, 30.96s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([50040, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6898.jpg: actual-predicted:      0,  140.8, error:  140.8. Current MAE: 48.49, RMSE: 77.06:  87% 1033/1190 [9:14:58<1:21:00, 30.96s/it]\n",
            "6898.jpg: actual-predicted:      0,  140.8, error:  140.8. Current MAE: 48.49, RMSE: 77.06:  87% 1034/1190 [9:14:58<1:18:32, 30.21s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64186, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7198.jpg: actual-predicted:      0,   34.7, error:   34.7. Current MAE: 48.47, RMSE: 77.03:  87% 1034/1190 [9:15:24<1:18:32, 30.21s/it]\n",
            "7198.jpg: actual-predicted:      0,   34.7, error:   34.7. Current MAE: 48.47, RMSE: 77.03:  87% 1035/1190 [9:15:24<1:14:22, 28.79s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([18695, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6815.jpg: actual-predicted:      0,   90.1, error:   90.1. Current MAE: 48.51, RMSE: 77.05:  87% 1035/1190 [9:15:49<1:14:22, 28.79s/it]\n",
            "6815.jpg: actual-predicted:      0,   90.1, error:   90.1. Current MAE: 48.51, RMSE: 77.05:  87% 1036/1190 [9:15:49<1:11:29, 27.85s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([18959, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7473.jpg: actual-predicted:      0,  278.8, error:  278.8. Current MAE: 48.73, RMSE: 77.49:  87% 1036/1190 [9:16:29<1:11:29, 27.85s/it]\n",
            "7473.jpg: actual-predicted:      0,  278.8, error:  278.8. Current MAE: 48.73, RMSE: 77.49:  87% 1037/1190 [9:16:29<1:20:01, 31.38s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64668, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7219.jpg: actual-predicted:      0,   51.1, error:   51.1. Current MAE: 48.74, RMSE: 77.47:  87% 1037/1190 [9:16:56<1:20:01, 31.38s/it]\n",
            "7219.jpg: actual-predicted:      0,   51.1, error:   51.1. Current MAE: 48.74, RMSE: 77.47:  87% 1038/1190 [9:16:56<1:16:00, 30.00s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([16282, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7015.jpg: actual-predicted:      0,   38.9, error:   38.9. Current MAE: 48.73, RMSE: 77.44:  87% 1038/1190 [9:17:31<1:16:00, 30.00s/it]\n",
            "7329.jpg: actual-predicted:      0,  156.7, error:  156.7. Current MAE: 48.83, RMSE: 77.56:  87% 1039/1190 [9:18:10<1:19:31, 31.60s/it]\n",
            "7329.jpg: actual-predicted:      0,  156.7, error:  156.7. Current MAE: 48.83, RMSE: 77.56:  87% 1040/1190 [9:18:10<1:24:45, 33.90s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([18102, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7401.jpg: actual-predicted:      0,   83.6, error:   83.6. Current MAE: 48.86, RMSE: 77.57:  87% 1040/1190 [9:18:50<1:24:45, 33.90s/it]\n",
            "7426.jpg: actual-predicted:      0,  283.8, error:  283.8. Current MAE: 49.09, RMSE: 78.02:  87% 1041/1190 [9:19:32<1:28:35, 35.67s/it]\n",
            "7426.jpg: actual-predicted:      0,  283.8, error:  283.8. Current MAE: 49.09, RMSE: 78.02:  88% 1042/1190 [9:19:32<1:32:19, 37.43s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([26012, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6993.jpg: actual-predicted:      0,   50.9, error:   50.9. Current MAE: 49.09, RMSE: 78.00:  88% 1042/1190 [9:20:04<1:32:19, 37.43s/it]\n",
            "7491.jpg: actual-predicted:      0,  228.0, error:  228.0. Current MAE: 49.26, RMSE: 78.28:  88% 1043/1190 [9:20:45<1:27:37, 35.77s/it]\n",
            "7491.jpg: actual-predicted:      0,  228.0, error:  228.0. Current MAE: 49.26, RMSE: 78.28:  88% 1044/1190 [9:20:45<1:31:23, 37.56s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([33727, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7511.jpg: actual-predicted:      0,   42.0, error:   42.0. Current MAE: 49.26, RMSE: 78.26:  88% 1044/1190 [9:21:11<1:31:23, 37.56s/it]\n",
            "7511.jpg: actual-predicted:      0,   42.0, error:   42.0. Current MAE: 49.26, RMSE: 78.26:  88% 1045/1190 [9:21:11<1:22:13, 34.02s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([39143, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6785.jpg: actual-predicted:      0,   73.5, error:   73.5. Current MAE: 49.28, RMSE: 78.25:  88% 1045/1190 [9:21:36<1:22:13, 34.02s/it]\n",
            "6785.jpg: actual-predicted:      0,   73.5, error:   73.5. Current MAE: 49.28, RMSE: 78.25:  88% 1046/1190 [9:21:36<1:15:26, 31.43s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([25319, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7455.jpg: actual-predicted:      0,   64.4, error:   64.4. Current MAE: 49.29, RMSE: 78.24:  88% 1046/1190 [9:22:01<1:15:26, 31.43s/it]\n",
            "7455.jpg: actual-predicted:      0,   64.4, error:   64.4. Current MAE: 49.29, RMSE: 78.24:  88% 1047/1190 [9:22:01<1:09:51, 29.31s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([9637, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7221.jpg: actual-predicted:      0,   49.3, error:   49.3. Current MAE: 49.29, RMSE: 78.22:  88% 1047/1190 [9:22:37<1:09:51, 29.31s/it]\n",
            "7221.jpg: actual-predicted:      0,   49.3, error:   49.3. Current MAE: 49.29, RMSE: 78.22:  88% 1048/1190 [9:22:37<1:14:13, 31.37s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([34139, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7637.jpg: actual-predicted:      0,   63.8, error:   63.8. Current MAE: 49.31, RMSE: 78.21:  88% 1048/1190 [9:23:09<1:14:13, 31.37s/it]\n",
            "7637.jpg: actual-predicted:      0,   63.8, error:   63.8. Current MAE: 49.31, RMSE: 78.21:  88% 1049/1190 [9:23:09<1:13:58, 31.48s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([6557, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7676.jpg: actual-predicted:      0,   86.0, error:   86.0. Current MAE: 49.34, RMSE: 78.21:  88% 1049/1190 [9:23:43<1:13:58, 31.48s/it]\n",
            "7676.jpg: actual-predicted:      0,   86.0, error:   86.0. Current MAE: 49.34, RMSE: 78.21:  88% 1050/1190 [9:23:43<1:15:39, 32.42s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([85535, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7666.jpg: actual-predicted:      0,   30.2, error:   30.2. Current MAE: 49.32, RMSE: 78.18:  88% 1050/1190 [9:24:16<1:15:39, 32.42s/it]\n",
            "7666.jpg: actual-predicted:      0,   30.2, error:   30.2. Current MAE: 49.32, RMSE: 78.18:  88% 1051/1190 [9:24:16<1:14:57, 32.36s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([64367, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7633.jpg: actual-predicted:      0,   29.3, error:   29.3. Current MAE: 49.31, RMSE: 78.15:  88% 1051/1190 [9:24:48<1:14:57, 32.36s/it]\n",
            "7633.jpg: actual-predicted:      0,   29.3, error:   29.3. Current MAE: 49.31, RMSE: 78.15:  88% 1052/1190 [9:24:48<1:14:30, 32.39s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([87646, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7688.jpg: actual-predicted:      0,   29.0, error:   29.0. Current MAE: 49.29, RMSE: 78.12:  88% 1052/1190 [9:25:24<1:14:30, 32.39s/it]\n",
            "6839.jpg: actual-predicted:      0,   82.2, error:   82.2. Current MAE: 49.32, RMSE: 78.12:  88% 1053/1190 [9:26:39<1:16:32, 33.52s/it]\n",
            "6839.jpg: actual-predicted:      0,   82.2, error:   82.2. Current MAE: 49.32, RMSE: 78.12:  89% 1054/1190 [9:26:39<1:44:00, 45.88s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([153333, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7366.jpg: actual-predicted:      0,   33.5, error:   33.5. Current MAE: 49.30, RMSE: 78.09:  89% 1054/1190 [9:27:20<1:44:00, 45.88s/it]\n",
            "7366.jpg: actual-predicted:      0,   33.5, error:   33.5. Current MAE: 49.30, RMSE: 78.09:  89% 1055/1190 [9:27:20<1:39:56, 44.42s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([144551, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7251.jpg: actual-predicted:      0,   25.1, error:   25.1. Current MAE: 49.28, RMSE: 78.06:  89% 1055/1190 [9:27:53<1:39:56, 44.42s/it]\n",
            "7251.jpg: actual-predicted:      0,   25.1, error:   25.1. Current MAE: 49.28, RMSE: 78.06:  89% 1056/1190 [9:27:53<1:31:35, 41.01s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([70856, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7082.jpg: actual-predicted:      0,   45.2, error:   45.2. Current MAE: 49.28, RMSE: 78.03:  89% 1056/1190 [9:28:28<1:31:35, 41.01s/it]\n",
            "7082.jpg: actual-predicted:      0,   45.2, error:   45.2. Current MAE: 49.28, RMSE: 78.03:  89% 1057/1190 [9:28:28<1:26:41, 39.11s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([244479, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7042.jpg: actual-predicted:      0,   74.5, error:   74.5. Current MAE: 49.30, RMSE: 78.03:  89% 1057/1190 [9:29:10<1:26:41, 39.11s/it]\n",
            "7042.jpg: actual-predicted:      0,   74.5, error:   74.5. Current MAE: 49.30, RMSE: 78.03:  89% 1058/1190 [9:29:10<1:27:53, 39.95s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([131155, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7598.jpg: actual-predicted:      0,   26.2, error:   26.2. Current MAE: 49.28, RMSE: 78.00:  89% 1058/1190 [9:29:52<1:27:53, 39.95s/it]\n",
            "7598.jpg: actual-predicted:      0,   26.2, error:   26.2. Current MAE: 49.28, RMSE: 78.00:  89% 1059/1190 [9:29:52<1:28:51, 40.70s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([214858, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7075.jpg: actual-predicted:      0,   37.6, error:   37.6. Current MAE: 49.27, RMSE: 77.97:  89% 1059/1190 [9:30:34<1:28:51, 40.70s/it]\n",
            "7075.jpg: actual-predicted:      0,   37.6, error:   37.6. Current MAE: 49.27, RMSE: 77.97:  89% 1060/1190 [9:30:34<1:28:48, 40.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([181972, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7475.jpg: actual-predicted:      0,   74.3, error:   74.3. Current MAE: 49.29, RMSE: 77.97:  89% 1060/1190 [9:31:18<1:28:48, 40.99s/it]\n",
            "7475.jpg: actual-predicted:      0,   74.3, error:   74.3. Current MAE: 49.29, RMSE: 77.97:  89% 1061/1190 [9:31:18<1:30:10, 41.94s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([127209, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6750.jpg: actual-predicted:      0,   41.7, error:   41.7. Current MAE: 49.28, RMSE: 77.94:  89% 1061/1190 [9:31:46<1:30:10, 41.94s/it]\n",
            "6750.jpg: actual-predicted:      0,   41.7, error:   41.7. Current MAE: 49.28, RMSE: 77.94:  89% 1062/1190 [9:31:46<1:20:23, 37.69s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([54721, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7239.jpg: actual-predicted:      0,   39.4, error:   39.4. Current MAE: 49.27, RMSE: 77.91:  89% 1062/1190 [9:32:33<1:20:23, 37.69s/it]\n",
            "7239.jpg: actual-predicted:      0,   39.4, error:   39.4. Current MAE: 49.27, RMSE: 77.91:  89% 1063/1190 [9:32:33<1:25:44, 40.51s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([107241, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6847.jpg: actual-predicted:      0,   42.7, error:   42.7. Current MAE: 49.27, RMSE: 77.89:  89% 1063/1190 [9:33:20<1:25:44, 40.51s/it]\n",
            "6847.jpg: actual-predicted:      0,   42.7, error:   42.7. Current MAE: 49.27, RMSE: 77.89:  89% 1064/1190 [9:33:20<1:29:25, 42.58s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([63649, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6893.jpg: actual-predicted:      0,   30.7, error:   30.7. Current MAE: 49.25, RMSE: 77.86:  89% 1064/1190 [9:33:51<1:29:25, 42.58s/it]\n",
            "6893.jpg: actual-predicted:      0,   30.7, error:   30.7. Current MAE: 49.25, RMSE: 77.86:  89% 1065/1190 [9:33:51<1:21:35, 39.16s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([148875, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7622.jpg: actual-predicted:      0,   38.2, error:   38.2. Current MAE: 49.24, RMSE: 77.83:  89% 1065/1190 [9:34:32<1:21:35, 39.16s/it]\n",
            "7622.jpg: actual-predicted:      0,   38.2, error:   38.2. Current MAE: 49.24, RMSE: 77.83:  90% 1066/1190 [9:34:32<1:22:05, 39.72s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([94215, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7328.jpg: actual-predicted:      0,   62.1, error:   62.1. Current MAE: 49.25, RMSE: 77.82:  90% 1066/1190 [9:35:07<1:22:05, 39.72s/it]\n",
            "7328.jpg: actual-predicted:      0,   62.1, error:   62.1. Current MAE: 49.25, RMSE: 77.82:  90% 1067/1190 [9:35:07<1:18:15, 38.18s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([126173, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6713.jpg: actual-predicted:      0,  108.7, error:  108.7. Current MAE: 49.31, RMSE: 77.85:  90% 1067/1190 [9:35:48<1:18:15, 38.18s/it]\n",
            "6713.jpg: actual-predicted:      0,  108.7, error:  108.7. Current MAE: 49.31, RMSE: 77.85:  90% 1068/1190 [9:35:48<1:19:40, 39.19s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([42021, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6811.jpg: actual-predicted:      0,   59.8, error:   59.8. Current MAE: 49.32, RMSE: 77.84:  90% 1068/1190 [9:36:14<1:19:40, 39.19s/it]\n",
            "6811.jpg: actual-predicted:      0,   59.8, error:   59.8. Current MAE: 49.32, RMSE: 77.84:  90% 1069/1190 [9:36:14<1:10:56, 35.18s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([247322, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7639.jpg: actual-predicted:      0,   22.4, error:   22.4. Current MAE: 49.29, RMSE: 77.80:  90% 1069/1190 [9:36:56<1:10:56, 35.18s/it]\n",
            "7639.jpg: actual-predicted:      0,   22.4, error:   22.4. Current MAE: 49.29, RMSE: 77.80:  90% 1070/1190 [9:36:56<1:14:29, 37.24s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([53867, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7281.jpg: actual-predicted:      0,   49.8, error:   49.8. Current MAE: 49.29, RMSE: 77.78:  90% 1070/1190 [9:37:27<1:14:29, 37.24s/it]\n",
            "7281.jpg: actual-predicted:      0,   49.8, error:   49.8. Current MAE: 49.29, RMSE: 77.78:  90% 1071/1190 [9:37:27<1:10:14, 35.41s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([174762, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7248.jpg: actual-predicted:      0,   32.0, error:   32.0. Current MAE: 49.28, RMSE: 77.75:  90% 1071/1190 [9:38:05<1:10:14, 35.41s/it]\n",
            "7248.jpg: actual-predicted:      0,   32.0, error:   32.0. Current MAE: 49.28, RMSE: 77.75:  90% 1072/1190 [9:38:05<1:11:02, 36.12s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([154434, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7153.jpg: actual-predicted:      0,   28.0, error:   28.0. Current MAE: 49.26, RMSE: 77.72:  90% 1072/1190 [9:38:39<1:11:02, 36.12s/it]\n",
            "7153.jpg: actual-predicted:      0,   28.0, error:   28.0. Current MAE: 49.26, RMSE: 77.72:  90% 1073/1190 [9:38:39<1:09:20, 35.56s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([83825, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7312.jpg: actual-predicted:      0,   21.1, error:   21.1. Current MAE: 49.23, RMSE: 77.69:  90% 1073/1190 [9:39:11<1:09:20, 35.56s/it]\n",
            "7312.jpg: actual-predicted:      0,   21.1, error:   21.1. Current MAE: 49.23, RMSE: 77.69:  90% 1074/1190 [9:39:11<1:06:11, 34.24s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([120703, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7530.jpg: actual-predicted:      0,    9.2, error:    9.2. Current MAE: 49.19, RMSE: 77.65:  90% 1074/1190 [9:39:43<1:06:11, 34.24s/it]\n",
            "7530.jpg: actual-predicted:      0,    9.2, error:    9.2. Current MAE: 49.19, RMSE: 77.65:  90% 1075/1190 [9:39:43<1:04:19, 33.56s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([66545, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7679.jpg: actual-predicted:      0,    9.7, error:    9.7. Current MAE: 49.16, RMSE: 77.61:  90% 1075/1190 [9:40:18<1:04:19, 33.56s/it]\n",
            "7679.jpg: actual-predicted:      0,    9.7, error:    9.7. Current MAE: 49.16, RMSE: 77.61:  90% 1076/1190 [9:40:18<1:04:40, 34.04s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([110760, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7472.jpg: actual-predicted:      0,   11.0, error:   11.0. Current MAE: 49.12, RMSE: 77.58:  90% 1076/1190 [9:40:49<1:04:40, 34.04s/it]\n",
            "7472.jpg: actual-predicted:      0,   11.0, error:   11.0. Current MAE: 49.12, RMSE: 77.58:  91% 1077/1190 [9:40:49<1:02:30, 33.19s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([173013, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7090.jpg: actual-predicted:      0,   12.1, error:   12.1. Current MAE: 49.09, RMSE: 77.54:  91% 1077/1190 [9:41:24<1:02:30, 33.19s/it]\n",
            "7090.jpg: actual-predicted:      0,   12.1, error:   12.1. Current MAE: 49.09, RMSE: 77.54:  91% 1078/1190 [9:41:24<1:03:03, 33.78s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([154357, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7056.jpg: actual-predicted:      0,   18.2, error:   18.2. Current MAE: 49.06, RMSE: 77.51:  91% 1078/1190 [9:42:00<1:03:03, 33.78s/it]\n",
            "7056.jpg: actual-predicted:      0,   18.2, error:   18.2. Current MAE: 49.06, RMSE: 77.51:  91% 1079/1190 [9:42:00<1:03:28, 34.31s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([153814, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6833.jpg: actual-predicted:      0,   12.7, error:   12.7. Current MAE: 49.02, RMSE: 77.48:  91% 1079/1190 [9:42:37<1:03:28, 34.31s/it]\n",
            "6833.jpg: actual-predicted:      0,   12.7, error:   12.7. Current MAE: 49.02, RMSE: 77.48:  91% 1080/1190 [9:42:37<1:04:17, 35.07s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([108356, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7420.jpg: actual-predicted:      0,   11.7, error:   11.7. Current MAE: 48.99, RMSE: 77.44:  91% 1080/1190 [9:43:11<1:04:17, 35.07s/it]\n",
            "7420.jpg: actual-predicted:      0,   11.7, error:   11.7. Current MAE: 48.99, RMSE: 77.44:  91% 1081/1190 [9:43:11<1:03:14, 34.81s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([192012, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7588.jpg: actual-predicted:      0,   45.3, error:   45.3. Current MAE: 48.99, RMSE: 77.42:  91% 1081/1190 [9:43:54<1:03:14, 34.81s/it]\n",
            "7588.jpg: actual-predicted:      0,   45.3, error:   45.3. Current MAE: 48.99, RMSE: 77.42:  91% 1082/1190 [9:43:54<1:07:02, 37.25s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([162558, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7550.jpg: actual-predicted:      0,   12.9, error:   12.9. Current MAE: 48.95, RMSE: 77.38:  91% 1082/1190 [9:44:30<1:07:02, 37.25s/it]\n",
            "7550.jpg: actual-predicted:      0,   12.9, error:   12.9. Current MAE: 48.95, RMSE: 77.38:  91% 1083/1190 [9:44:30<1:05:57, 36.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([172979, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7525.jpg: actual-predicted:      0,   33.1, error:   33.1. Current MAE: 48.94, RMSE: 77.35:  91% 1083/1190 [9:45:06<1:05:57, 36.99s/it]\n",
            "7525.jpg: actual-predicted:      0,   33.1, error:   33.1. Current MAE: 48.94, RMSE: 77.35:  91% 1084/1190 [9:45:06<1:04:34, 36.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([139678, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6956.jpg: actual-predicted:      0,   16.3, error:   16.3. Current MAE: 48.91, RMSE: 77.32:  91% 1084/1190 [9:45:41<1:04:34, 36.55s/it]\n",
            "6956.jpg: actual-predicted:      0,   16.3, error:   16.3. Current MAE: 48.91, RMSE: 77.32:  91% 1085/1190 [9:45:41<1:03:20, 36.19s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([92694, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7295.jpg: actual-predicted:      0,   41.1, error:   41.1. Current MAE: 48.90, RMSE: 77.29:  91% 1085/1190 [9:46:34<1:03:20, 36.19s/it]\n",
            "7295.jpg: actual-predicted:      0,   41.1, error:   41.1. Current MAE: 48.90, RMSE: 77.29:  91% 1086/1190 [9:46:34<1:11:20, 41.16s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([155447, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7106.jpg: actual-predicted:      0,   13.3, error:   13.3. Current MAE: 48.87, RMSE: 77.26:  91% 1086/1190 [9:47:14<1:11:20, 41.16s/it]\n",
            "7106.jpg: actual-predicted:      0,   13.3, error:   13.3. Current MAE: 48.87, RMSE: 77.26:  91% 1087/1190 [9:47:14<1:10:17, 40.95s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([96999, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7065.jpg: actual-predicted:      0,   22.1, error:   22.1. Current MAE: 48.84, RMSE: 77.23:  91% 1087/1190 [9:47:40<1:10:17, 40.95s/it]\n",
            "7065.jpg: actual-predicted:      0,   22.1, error:   22.1. Current MAE: 48.84, RMSE: 77.23:  91% 1088/1190 [9:47:40<1:01:53, 36.41s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([180048, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6869.jpg: actual-predicted:      0,   19.8, error:   19.8. Current MAE: 48.82, RMSE: 77.19:  91% 1088/1190 [9:48:17<1:01:53, 36.41s/it]\n",
            "6869.jpg: actual-predicted:      0,   19.8, error:   19.8. Current MAE: 48.82, RMSE: 77.19:  92% 1089/1190 [9:48:17<1:01:32, 36.56s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([207414, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7480.jpg: actual-predicted:      0,   18.5, error:   18.5. Current MAE: 48.79, RMSE: 77.16:  92% 1089/1190 [9:48:58<1:01:32, 36.56s/it]\n",
            "7480.jpg: actual-predicted:      0,   18.5, error:   18.5. Current MAE: 48.79, RMSE: 77.16:  92% 1090/1190 [9:48:58<1:03:16, 37.97s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([122166, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7547.jpg: actual-predicted:      0,   11.8, error:   11.8. Current MAE: 48.76, RMSE: 77.13:  92% 1090/1190 [9:49:33<1:03:16, 37.97s/it]\n",
            "7547.jpg: actual-predicted:      0,   11.8, error:   11.8. Current MAE: 48.76, RMSE: 77.13:  92% 1091/1190 [9:49:33<1:01:09, 37.07s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([128667, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7134.jpg: actual-predicted:      0,   19.5, error:   19.5. Current MAE: 48.73, RMSE: 77.09:  92% 1091/1190 [9:50:08<1:01:09, 37.07s/it]\n",
            "7134.jpg: actual-predicted:      0,   19.5, error:   19.5. Current MAE: 48.73, RMSE: 77.09:  92% 1092/1190 [9:50:08<59:30, 36.43s/it]  /content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([99569, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7282.jpg: actual-predicted:      0,   17.8, error:   17.8. Current MAE: 48.70, RMSE: 77.06:  92% 1092/1190 [9:50:34<59:30, 36.43s/it]\n",
            "7282.jpg: actual-predicted:      0,   17.8, error:   17.8. Current MAE: 48.70, RMSE: 77.06:  92% 1093/1190 [9:50:34<53:40, 33.20s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([113996, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7474.jpg: actual-predicted:      0,   45.8, error:   45.8. Current MAE: 48.70, RMSE: 77.04:  92% 1093/1190 [9:51:08<53:40, 33.20s/it]\n",
            "7474.jpg: actual-predicted:      0,   45.8, error:   45.8. Current MAE: 48.70, RMSE: 77.04:  92% 1094/1190 [9:51:08<53:45, 33.60s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([148067, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6980.jpg: actual-predicted:      0,   26.1, error:   26.1. Current MAE: 48.68, RMSE: 77.00:  92% 1094/1190 [9:51:44<53:45, 33.60s/it]\n",
            "6980.jpg: actual-predicted:      0,   26.1, error:   26.1. Current MAE: 48.68, RMSE: 77.00:  92% 1095/1190 [9:51:44<54:11, 34.22s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([144425, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7140.jpg: actual-predicted:      0,   20.2, error:   20.2. Current MAE: 48.65, RMSE: 76.97:  92% 1095/1190 [9:52:19<54:11, 34.22s/it]\n",
            "7140.jpg: actual-predicted:      0,   20.2, error:   20.2. Current MAE: 48.65, RMSE: 76.97:  92% 1096/1190 [9:52:19<54:01, 34.49s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([191284, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7459.jpg: actual-predicted:      0,   15.5, error:   15.5. Current MAE: 48.62, RMSE: 76.94:  92% 1096/1190 [9:52:55<54:01, 34.49s/it]\n",
            "7459.jpg: actual-predicted:      0,   15.5, error:   15.5. Current MAE: 48.62, RMSE: 76.94:  92% 1097/1190 [9:52:55<54:01, 34.86s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([116220, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7535.jpg: actual-predicted:      0,   46.8, error:   46.8. Current MAE: 48.62, RMSE: 76.92:  92% 1097/1190 [9:53:38<54:01, 34.86s/it]\n",
            "7535.jpg: actual-predicted:      0,   46.8, error:   46.8. Current MAE: 48.62, RMSE: 76.92:  92% 1098/1190 [9:53:38<57:20, 37.39s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([171590, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7463.jpg: actual-predicted:      0,   24.9, error:   24.9. Current MAE: 48.60, RMSE: 76.89:  92% 1098/1190 [9:54:15<57:20, 37.39s/it]\n",
            "7463.jpg: actual-predicted:      0,   24.9, error:   24.9. Current MAE: 48.60, RMSE: 76.89:  92% 1099/1190 [9:54:15<56:18, 37.13s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([87388, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7701.jpg: actual-predicted:      0,   30.4, error:   30.4. Current MAE: 48.58, RMSE: 76.86:  92% 1099/1190 [9:54:40<56:18, 37.13s/it]\n",
            "7701.jpg: actual-predicted:      0,   30.4, error:   30.4. Current MAE: 48.58, RMSE: 76.86:  92% 1100/1190 [9:54:40<50:36, 33.74s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([36697, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7195.jpg: actual-predicted:      0,  299.6, error:  299.6. Current MAE: 48.81, RMSE: 77.35:  92% 1100/1190 [9:55:15<50:36, 33.74s/it]\n",
            "7195.jpg: actual-predicted:      0,  299.6, error:  299.6. Current MAE: 48.81, RMSE: 77.35:  93% 1101/1190 [9:55:15<50:17, 33.90s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([34907, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7700.jpg: actual-predicted:      0,   42.8, error:   42.8. Current MAE: 48.80, RMSE: 77.33:  93% 1101/1190 [9:55:48<50:17, 33.90s/it]\n",
            "7700.jpg: actual-predicted:      0,   42.8, error:   42.8. Current MAE: 48.80, RMSE: 77.33:  93% 1102/1190 [9:55:48<49:38, 33.85s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([109678, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6860.jpg: actual-predicted:      0,  245.9, error:  245.9. Current MAE: 48.98, RMSE: 77.64:  93% 1102/1190 [9:56:13<49:38, 33.85s/it]\n",
            "6860.jpg: actual-predicted:      0,  245.9, error:  245.9. Current MAE: 48.98, RMSE: 77.64:  93% 1103/1190 [9:56:13<45:16, 31.22s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([27578, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6856.jpg: actual-predicted:      0,   14.4, error:   14.4. Current MAE: 48.95, RMSE: 77.61:  93% 1103/1190 [9:56:39<45:16, 31.22s/it]\n",
            "6856.jpg: actual-predicted:      0,   14.4, error:   14.4. Current MAE: 48.95, RMSE: 77.61:  93% 1104/1190 [9:56:39<42:13, 29.46s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([132143, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7174.jpg: actual-predicted:      0,   93.2, error:   93.2. Current MAE: 48.99, RMSE: 77.63:  93% 1104/1190 [9:57:14<42:13, 29.46s/it]\n",
            "7174.jpg: actual-predicted:      0,   93.2, error:   93.2. Current MAE: 48.99, RMSE: 77.63:  93% 1105/1190 [9:57:14<44:13, 31.22s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([75713, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7486.jpg: actual-predicted:      0,   52.0, error:   52.0. Current MAE: 48.99, RMSE: 77.61:  93% 1105/1190 [9:57:47<44:13, 31.22s/it]\n",
            "7486.jpg: actual-predicted:      0,   52.0, error:   52.0. Current MAE: 48.99, RMSE: 77.61:  93% 1106/1190 [9:57:47<44:16, 31.62s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([33802, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7440.jpg: actual-predicted:      0,   23.0, error:   23.0. Current MAE: 48.97, RMSE: 77.57:  93% 1106/1190 [9:58:17<44:16, 31.62s/it]\n",
            "7440.jpg: actual-predicted:      0,   23.0, error:   23.0. Current MAE: 48.97, RMSE: 77.57:  93% 1107/1190 [9:58:17<43:19, 31.32s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([48179, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7378.jpg: actual-predicted:      0,  161.8, error:  161.8. Current MAE: 49.07, RMSE: 77.69:  93% 1107/1190 [9:58:48<43:19, 31.32s/it]\n",
            "7378.jpg: actual-predicted:      0,  161.8, error:  161.8. Current MAE: 49.07, RMSE: 77.69:  93% 1108/1190 [9:58:48<42:42, 31.25s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([32271, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7590.jpg: actual-predicted:      0,   74.9, error:   74.9. Current MAE: 49.10, RMSE: 77.69:  93% 1108/1190 [9:59:13<42:42, 31.25s/it]\n",
            "7590.jpg: actual-predicted:      0,   74.9, error:   74.9. Current MAE: 49.10, RMSE: 77.69:  93% 1109/1190 [9:59:13<39:25, 29.21s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([159392, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7713.jpg: actual-predicted:      0,   28.5, error:   28.5. Current MAE: 49.08, RMSE: 77.66:  93% 1109/1190 [9:59:45<39:25, 29.21s/it]\n",
            "7713.jpg: actual-predicted:      0,   28.5, error:   28.5. Current MAE: 49.08, RMSE: 77.66:  93% 1110/1190 [9:59:45<40:16, 30.20s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([111658, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6743.jpg: actual-predicted:      0,   26.2, error:   26.2. Current MAE: 49.06, RMSE: 77.63:  93% 1110/1190 [10:00:11<40:16, 30.20s/it]\n",
            "6743.jpg: actual-predicted:      0,   26.2, error:   26.2. Current MAE: 49.06, RMSE: 77.63:  93% 1111/1190 [10:00:11<37:51, 28.75s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([222797, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7488.jpg: actual-predicted:      0,   19.4, error:   19.4. Current MAE: 49.03, RMSE: 77.59:  93% 1111/1190 [10:00:52<37:51, 28.75s/it]\n",
            "7488.jpg: actual-predicted:      0,   19.4, error:   19.4. Current MAE: 49.03, RMSE: 77.59:  93% 1112/1190 [10:00:52<42:20, 32.57s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([169071, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7573.jpg: actual-predicted:      0,   22.6, error:   22.6. Current MAE: 49.01, RMSE: 77.56:  93% 1112/1190 [10:01:34<42:20, 32.57s/it]\n",
            "7573.jpg: actual-predicted:      0,   22.6, error:   22.6. Current MAE: 49.01, RMSE: 77.56:  94% 1113/1190 [10:01:34<45:27, 35.42s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([109875, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7520.jpg: actual-predicted:      0,   21.8, error:   21.8. Current MAE: 48.98, RMSE: 77.53:  94% 1113/1190 [10:02:18<45:27, 35.42s/it]\n",
            "7520.jpg: actual-predicted:      0,   21.8, error:   21.8. Current MAE: 48.98, RMSE: 77.53:  94% 1114/1190 [10:02:18<47:59, 37.89s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([63477, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6813.jpg: actual-predicted:      0,   16.4, error:   16.4. Current MAE: 48.95, RMSE: 77.50:  94% 1114/1190 [10:02:44<47:59, 37.89s/it]\n",
            "6813.jpg: actual-predicted:      0,   16.4, error:   16.4. Current MAE: 48.95, RMSE: 77.50:  94% 1115/1190 [10:02:44<42:59, 34.40s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([77719, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6960.jpg: actual-predicted:      0,   24.2, error:   24.2. Current MAE: 48.93, RMSE: 77.47:  94% 1115/1190 [10:03:09<42:59, 34.40s/it]\n",
            "6960.jpg: actual-predicted:      0,   24.2, error:   24.2. Current MAE: 48.93, RMSE: 77.47:  94% 1116/1190 [10:03:09<39:02, 31.65s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([144943, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7192.jpg: actual-predicted:      0,   20.2, error:   20.2. Current MAE: 48.90, RMSE: 77.43:  94% 1116/1190 [10:03:43<39:02, 31.65s/it]\n",
            "7192.jpg: actual-predicted:      0,   20.2, error:   20.2. Current MAE: 48.90, RMSE: 77.43:  94% 1117/1190 [10:03:43<39:16, 32.27s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([145068, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6904.jpg: actual-predicted:      0,   14.5, error:   14.5. Current MAE: 48.87, RMSE: 77.40:  94% 1117/1190 [10:04:18<39:16, 32.27s/it]\n",
            "6904.jpg: actual-predicted:      0,   14.5, error:   14.5. Current MAE: 48.87, RMSE: 77.40:  94% 1118/1190 [10:04:18<39:47, 33.16s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([57523, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7671.jpg: actual-predicted:      0,   84.9, error:   84.9. Current MAE: 48.91, RMSE: 77.41:  94% 1118/1190 [10:05:08<39:47, 33.16s/it]\n",
            "7671.jpg: actual-predicted:      0,   84.9, error:   84.9. Current MAE: 48.91, RMSE: 77.41:  94% 1119/1190 [10:05:08<44:54, 37.95s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([89715, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7539.jpg: actual-predicted:      0,   85.0, error:   85.0. Current MAE: 48.94, RMSE: 77.41:  94% 1119/1190 [10:05:47<44:54, 37.95s/it]\n",
            "7539.jpg: actual-predicted:      0,   85.0, error:   85.0. Current MAE: 48.94, RMSE: 77.41:  94% 1120/1190 [10:05:47<44:46, 38.38s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([50807, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7522.jpg: actual-predicted:      0,   91.0, error:   91.0. Current MAE: 48.98, RMSE: 77.43:  94% 1120/1190 [10:06:39<44:46, 38.38s/it]\n",
            "7522.jpg: actual-predicted:      0,   91.0, error:   91.0. Current MAE: 48.98, RMSE: 77.43:  94% 1121/1190 [10:06:39<49:00, 42.62s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([68809, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7023.jpg: actual-predicted:      0,   76.1, error:   76.1. Current MAE: 49.00, RMSE: 77.43:  94% 1121/1190 [10:07:31<49:00, 42.62s/it]\n",
            "7023.jpg: actual-predicted:      0,   76.1, error:   76.1. Current MAE: 49.00, RMSE: 77.43:  94% 1122/1190 [10:07:31<51:18, 45.27s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([128574, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7592.jpg: actual-predicted:      0,  117.0, error:  117.0. Current MAE: 49.06, RMSE: 77.47:  94% 1122/1190 [10:08:03<51:18, 45.27s/it]\n",
            "7592.jpg: actual-predicted:      0,  117.0, error:  117.0. Current MAE: 49.06, RMSE: 77.47:  94% 1123/1190 [10:08:03<46:00, 41.20s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([66253, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7345.jpg: actual-predicted:      0,   82.7, error:   82.7. Current MAE: 49.09, RMSE: 77.48:  94% 1123/1190 [10:08:51<46:00, 41.20s/it]\n",
            "7345.jpg: actual-predicted:      0,   82.7, error:   82.7. Current MAE: 49.09, RMSE: 77.48:  94% 1124/1190 [10:08:51<47:36, 43.28s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([26918, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6855.jpg: actual-predicted:      0,   86.9, error:   86.9. Current MAE: 49.12, RMSE: 77.48:  94% 1124/1190 [10:09:50<47:36, 43.28s/it]\n",
            "6855.jpg: actual-predicted:      0,   86.9, error:   86.9. Current MAE: 49.12, RMSE: 77.48:  95% 1125/1190 [10:09:50<52:00, 48.02s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17527, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7206.jpg: actual-predicted:      0,   69.7, error:   69.7. Current MAE: 49.14, RMSE: 77.48:  95% 1125/1190 [10:10:47<52:00, 48.02s/it]\n",
            "7206.jpg: actual-predicted:      0,   69.7, error:   69.7. Current MAE: 49.14, RMSE: 77.48:  95% 1126/1190 [10:10:47<54:02, 50.67s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([143960, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7129.jpg: actual-predicted:      0,   84.7, error:   84.7. Current MAE: 49.17, RMSE: 77.48:  95% 1126/1190 [10:11:39<54:02, 50.67s/it]\n",
            "7030.jpg: actual-predicted:      0,  114.1, error:  114.1. Current MAE: 49.23, RMSE: 77.53:  95% 1127/1190 [10:12:04<53:48, 51.25s/it]\n",
            "7030.jpg: actual-predicted:      0,  114.1, error:  114.1. Current MAE: 49.23, RMSE: 77.53:  95% 1128/1190 [10:12:04<44:50, 43.39s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([42777, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7284.jpg: actual-predicted:      0,   39.3, error:   39.3. Current MAE: 49.22, RMSE: 77.50:  95% 1128/1190 [10:12:40<44:50, 43.39s/it]\n",
            "7284.jpg: actual-predicted:      0,   39.3, error:   39.3. Current MAE: 49.22, RMSE: 77.50:  95% 1129/1190 [10:12:40<41:45, 41.08s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([16699, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7386.jpg: actual-predicted:      0,   67.2, error:   67.2. Current MAE: 49.24, RMSE: 77.49:  95% 1129/1190 [10:13:06<41:45, 41.08s/it]\n",
            "7386.jpg: actual-predicted:      0,   67.2, error:   67.2. Current MAE: 49.24, RMSE: 77.49:  95% 1130/1190 [10:13:06<36:25, 36.43s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([46897, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7108.jpg: actual-predicted:      0,   57.0, error:   57.0. Current MAE: 49.25, RMSE: 77.48:  95% 1130/1190 [10:13:32<36:25, 36.43s/it]\n",
            "7108.jpg: actual-predicted:      0,   57.0, error:   57.0. Current MAE: 49.25, RMSE: 77.48:  95% 1131/1190 [10:13:32<32:46, 33.33s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([34861, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6920.jpg: actual-predicted:      0,   40.9, error:   40.9. Current MAE: 49.24, RMSE: 77.45:  95% 1131/1190 [10:14:12<32:46, 33.33s/it]\n",
            "6920.jpg: actual-predicted:      0,   40.9, error:   40.9. Current MAE: 49.24, RMSE: 77.45:  95% 1132/1190 [10:14:12<34:20, 35.52s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([29835, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7253.jpg: actual-predicted:      0,   44.3, error:   44.3. Current MAE: 49.23, RMSE: 77.43:  95% 1132/1190 [10:14:43<34:20, 35.52s/it]\n",
            "7253.jpg: actual-predicted:      0,   44.3, error:   44.3. Current MAE: 49.23, RMSE: 77.43:  95% 1133/1190 [10:14:43<32:24, 34.11s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([43318, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7359.jpg: actual-predicted:      0,   28.4, error:   28.4. Current MAE: 49.22, RMSE: 77.40:  95% 1133/1190 [10:15:29<32:24, 34.11s/it]\n",
            "7411.jpg: actual-predicted:      0,  226.1, error:  226.1. Current MAE: 49.37, RMSE: 77.65:  95% 1134/1190 [10:15:53<35:13, 37.73s/it]\n",
            "7411.jpg: actual-predicted:      0,  226.1, error:  226.1. Current MAE: 49.37, RMSE: 77.65:  95% 1135/1190 [10:15:53<30:45, 33.55s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([30531, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7339.jpg: actual-predicted:      0,   96.2, error:   96.2. Current MAE: 49.41, RMSE: 77.67:  95% 1135/1190 [10:16:24<30:45, 33.55s/it]\n",
            "7339.jpg: actual-predicted:      0,   96.2, error:   96.2. Current MAE: 49.41, RMSE: 77.67:  95% 1136/1190 [10:16:24<29:32, 32.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([40621, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7167.jpg: actual-predicted:      0,  219.0, error:  219.0. Current MAE: 49.56, RMSE: 77.91:  95% 1136/1190 [10:16:59<29:32, 32.82s/it]\n",
            "7167.jpg: actual-predicted:      0,  219.0, error:  219.0. Current MAE: 49.56, RMSE: 77.91:  96% 1137/1190 [10:16:59<29:27, 33.35s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([116820, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7381.jpg: actual-predicted:      0,   68.3, error:   68.3. Current MAE: 49.58, RMSE: 77.90:  96% 1137/1190 [10:17:35<29:27, 33.35s/it]\n",
            "7381.jpg: actual-predicted:      0,   68.3, error:   68.3. Current MAE: 49.58, RMSE: 77.90:  96% 1138/1190 [10:17:35<29:42, 34.28s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([17485, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7609.jpg: actual-predicted:      0,  129.4, error:  129.4. Current MAE: 49.65, RMSE: 77.96:  96% 1138/1190 [10:18:12<29:42, 34.28s/it]\n",
            "7609.jpg: actual-predicted:      0,  129.4, error:  129.4. Current MAE: 49.65, RMSE: 77.96:  96% 1139/1190 [10:18:12<29:43, 34.97s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([46106, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6959.jpg: actual-predicted:      0,  151.9, error:  151.9. Current MAE: 49.74, RMSE: 78.06:  96% 1139/1190 [10:18:38<29:43, 34.97s/it]\n",
            "6959.jpg: actual-predicted:      0,  151.9, error:  151.9. Current MAE: 49.74, RMSE: 78.06:  96% 1140/1190 [10:18:38<26:55, 32.31s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([117277, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7506.jpg: actual-predicted:      0,   26.6, error:   26.6. Current MAE: 49.72, RMSE: 78.03:  96% 1140/1190 [10:19:03<26:55, 32.31s/it]\n",
            "7506.jpg: actual-predicted:      0,   26.6, error:   26.6. Current MAE: 49.72, RMSE: 78.03:  96% 1141/1190 [10:19:03<24:42, 30.25s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([71057, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6962.jpg: actual-predicted:      0,   30.0, error:   30.0. Current MAE: 49.70, RMSE: 78.00:  96% 1141/1190 [10:19:28<24:42, 30.25s/it]\n",
            "6962.jpg: actual-predicted:      0,   30.0, error:   30.0. Current MAE: 49.70, RMSE: 78.00:  96% 1142/1190 [10:19:28<22:53, 28.61s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([126149, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7117.jpg: actual-predicted:      0,   44.2, error:   44.2. Current MAE: 49.70, RMSE: 77.98:  96% 1142/1190 [10:20:00<22:53, 28.61s/it]\n",
            "7117.jpg: actual-predicted:      0,   44.2, error:   44.2. Current MAE: 49.70, RMSE: 77.98:  96% 1143/1190 [10:20:00<23:04, 29.46s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([62172, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6827.jpg: actual-predicted:      0,   19.4, error:   19.4. Current MAE: 49.67, RMSE: 77.94:  96% 1143/1190 [10:20:31<23:04, 29.46s/it]\n",
            "6827.jpg: actual-predicted:      0,   19.4, error:   19.4. Current MAE: 49.67, RMSE: 77.94:  96% 1144/1190 [10:20:31<23:02, 30.04s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([50578, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7538.jpg: actual-predicted:      0,   37.8, error:   37.8. Current MAE: 49.66, RMSE: 77.92:  96% 1144/1190 [10:21:09<23:02, 30.04s/it]\n",
            "7521.jpg: actual-predicted:      0,   27.8, error:   27.8. Current MAE: 49.64, RMSE: 77.89:  96% 1145/1190 [10:21:43<24:24, 32.55s/it]\n",
            "7521.jpg: actual-predicted:      0,   27.8, error:   27.8. Current MAE: 49.64, RMSE: 77.89:  96% 1146/1190 [10:21:43<24:06, 32.88s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1645, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7678.jpg: actual-predicted:      0,  122.6, error:  122.6. Current MAE: 49.70, RMSE: 77.94:  96% 1146/1190 [10:22:15<24:06, 32.88s/it]\n",
            "7678.jpg: actual-predicted:      0,  122.6, error:  122.6. Current MAE: 49.70, RMSE: 77.94:  96% 1147/1190 [10:22:15<23:17, 32.49s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([30380, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7062.jpg: actual-predicted:      0,   63.2, error:   63.2. Current MAE: 49.72, RMSE: 77.93:  96% 1147/1190 [10:22:45<23:17, 32.49s/it]\n",
            "6842.jpg: actual-predicted:      0,  177.3, error:  177.3. Current MAE: 49.83, RMSE: 78.07:  96% 1148/1190 [10:23:10<22:21, 31.94s/it]\n",
            "6842.jpg: actual-predicted:      0,  177.3, error:  177.3. Current MAE: 49.83, RMSE: 78.07:  97% 1149/1190 [10:23:10<20:25, 29.90s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([33820, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7171.jpg: actual-predicted:      0,  640.2, error:  640.2. Current MAE: 50.34, RMSE: 80.28:  97% 1149/1190 [10:23:45<20:25, 29.90s/it]\n",
            "7611.jpg: actual-predicted:      0, 2777.9, error: 2777.9. Current MAE: 52.71, RMSE: 114.65:  97% 1150/1190 [10:24:21<20:49, 31.23s/it]\n",
            "7611.jpg: actual-predicted:      0, 2777.9, error: 2777.9. Current MAE: 52.71, RMSE: 114.65:  97% 1151/1190 [10:24:21<21:12, 32.62s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([3273, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6908.jpg: actual-predicted:      0,   70.9, error:   70.9. Current MAE: 52.73, RMSE: 114.62:  97% 1151/1190 [10:24:47<21:12, 32.62s/it]\n",
            "6908.jpg: actual-predicted:      0,   70.9, error:   70.9. Current MAE: 52.73, RMSE: 114.62:  97% 1152/1190 [10:24:47<19:32, 30.86s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([37478, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6739.jpg: actual-predicted:      0,  134.1, error:  134.1. Current MAE: 52.80, RMSE: 114.64:  97% 1152/1190 [10:25:51<19:32, 30.86s/it]\n",
            "6739.jpg: actual-predicted:      0,  134.1, error:  134.1. Current MAE: 52.80, RMSE: 114.64:  97% 1153/1190 [10:25:51<25:06, 40.70s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([94273, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7131.jpg: actual-predicted:      0,  109.4, error:  109.4. Current MAE: 52.84, RMSE: 114.63:  97% 1153/1190 [10:26:28<25:06, 40.70s/it]\n",
            "7131.jpg: actual-predicted:      0,  109.4, error:  109.4. Current MAE: 52.84, RMSE: 114.63:  97% 1154/1190 [10:26:28<23:41, 39.49s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([124306, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7529.jpg: actual-predicted:      0,   63.1, error:   63.1. Current MAE: 52.85, RMSE: 114.60:  97% 1154/1190 [10:27:06<23:41, 39.49s/it]\n",
            "7529.jpg: actual-predicted:      0,   63.1, error:   63.1. Current MAE: 52.85, RMSE: 114.60:  97% 1155/1190 [10:27:06<22:44, 38.99s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([125282, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7109.jpg: actual-predicted:      0,   45.6, error:   45.6. Current MAE: 52.85, RMSE: 114.56:  97% 1155/1190 [10:27:37<22:44, 38.99s/it]\n",
            "7109.jpg: actual-predicted:      0,   45.6, error:   45.6. Current MAE: 52.85, RMSE: 114.56:  97% 1156/1190 [10:27:37<20:50, 36.77s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([86245, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7144.jpg: actual-predicted:      0,  122.5, error:  122.5. Current MAE: 52.91, RMSE: 114.56:  97% 1156/1190 [10:28:09<20:50, 36.77s/it]\n",
            "7144.jpg: actual-predicted:      0,  122.5, error:  122.5. Current MAE: 52.91, RMSE: 114.56:  97% 1157/1190 [10:28:09<19:20, 35.18s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([68911, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7176.jpg: actual-predicted:      0,   30.1, error:   30.1. Current MAE: 52.89, RMSE: 114.52:  97% 1157/1190 [10:28:41<19:20, 35.18s/it]\n",
            "7176.jpg: actual-predicted:      0,   30.1, error:   30.1. Current MAE: 52.89, RMSE: 114.52:  97% 1158/1190 [10:28:41<18:20, 34.40s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([57747, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7096.jpg: actual-predicted:      0,   16.6, error:   16.6. Current MAE: 52.86, RMSE: 114.47:  97% 1158/1190 [10:29:10<18:20, 34.40s/it]\n",
            "6809.jpg: actual-predicted:      0,  147.0, error:  147.0. Current MAE: 52.94, RMSE: 114.50:  97% 1159/1190 [10:29:45<16:58, 32.87s/it]\n",
            "6809.jpg: actual-predicted:      0,  147.0, error:  147.0. Current MAE: 52.94, RMSE: 114.50:  97% 1160/1190 [10:29:45<16:38, 33.28s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([133629, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6849.jpg: actual-predicted:      0,   30.3, error:   30.3. Current MAE: 52.92, RMSE: 114.45:  97% 1160/1190 [10:30:17<16:38, 33.28s/it]\n",
            "6849.jpg: actual-predicted:      0,   30.3, error:   30.3. Current MAE: 52.92, RMSE: 114.45:  98% 1161/1190 [10:30:17<15:53, 32.89s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([79127, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6954.jpg: actual-predicted:      0,   74.0, error:   74.0. Current MAE: 52.94, RMSE: 114.43:  98% 1161/1190 [10:30:51<15:53, 32.89s/it]\n",
            "6954.jpg: actual-predicted:      0,   74.0, error:   74.0. Current MAE: 52.94, RMSE: 114.43:  98% 1162/1190 [10:30:51<15:34, 33.36s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([69880, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7714.jpg: actual-predicted:      0,   47.4, error:   47.4. Current MAE: 52.93, RMSE: 114.38:  98% 1162/1190 [10:31:26<15:34, 33.36s/it]\n",
            "7714.jpg: actual-predicted:      0,   47.4, error:   47.4. Current MAE: 52.93, RMSE: 114.38:  98% 1163/1190 [10:31:26<15:13, 33.82s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([26565, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7188.jpg: actual-predicted:      0,   56.8, error:   56.8. Current MAE: 52.93, RMSE: 114.35:  98% 1163/1190 [10:31:52<15:13, 33.82s/it]\n",
            "7188.jpg: actual-predicted:      0,   56.8, error:   56.8. Current MAE: 52.93, RMSE: 114.35:  98% 1164/1190 [10:31:52<13:35, 31.35s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([73386, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7527.jpg: actual-predicted:      0,   39.1, error:   39.1. Current MAE: 52.92, RMSE: 114.30:  98% 1164/1190 [10:32:30<13:35, 31.35s/it]\n",
            "7527.jpg: actual-predicted:      0,   39.1, error:   39.1. Current MAE: 52.92, RMSE: 114.30:  98% 1165/1190 [10:32:30<13:56, 33.46s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([48621, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7173.jpg: actual-predicted:      0,   48.9, error:   48.9. Current MAE: 52.92, RMSE: 114.26:  98% 1165/1190 [10:33:02<13:56, 33.46s/it]\n",
            "7173.jpg: actual-predicted:      0,   48.9, error:   48.9. Current MAE: 52.92, RMSE: 114.26:  98% 1166/1190 [10:33:02<13:10, 32.92s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([78475, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7514.jpg: actual-predicted:      0,   32.1, error:   32.1. Current MAE: 52.90, RMSE: 114.22:  98% 1166/1190 [10:33:27<13:10, 32.92s/it]\n",
            "7514.jpg: actual-predicted:      0,   32.1, error:   32.1. Current MAE: 52.90, RMSE: 114.22:  98% 1167/1190 [10:33:27<11:42, 30.54s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([71478, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7682.jpg: actual-predicted:      0,   18.0, error:   18.0. Current MAE: 52.87, RMSE: 114.17:  98% 1167/1190 [10:33:58<11:42, 30.54s/it]\n",
            "7682.jpg: actual-predicted:      0,   18.0, error:   18.0. Current MAE: 52.87, RMSE: 114.17:  98% 1168/1190 [10:33:58<11:19, 30.88s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([23618, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6756.jpg: actual-predicted:      0,   26.5, error:   26.5. Current MAE: 52.85, RMSE: 114.13:  98% 1168/1190 [10:34:31<11:19, 30.88s/it]\n",
            "6756.jpg: actual-predicted:      0,   26.5, error:   26.5. Current MAE: 52.85, RMSE: 114.13:  98% 1169/1190 [10:34:31<10:56, 31.29s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([19000, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7452.jpg: actual-predicted:      0,   58.5, error:   58.5. Current MAE: 52.85, RMSE: 114.09:  98% 1169/1190 [10:35:01<10:56, 31.29s/it]\n",
            "7452.jpg: actual-predicted:      0,   58.5, error:   58.5. Current MAE: 52.85, RMSE: 114.09:  98% 1170/1190 [10:35:01<10:23, 31.19s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([99139, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7175.jpg: actual-predicted:      0,   28.1, error:   28.1. Current MAE: 52.83, RMSE: 114.04:  98% 1170/1190 [10:35:34<10:23, 31.19s/it]\n",
            "7175.jpg: actual-predicted:      0,   28.1, error:   28.1. Current MAE: 52.83, RMSE: 114.04:  98% 1171/1190 [10:35:34<10:01, 31.68s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([66511, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7361.jpg: actual-predicted:      0,   19.3, error:   19.3. Current MAE: 52.80, RMSE: 114.00:  98% 1171/1190 [10:36:05<10:01, 31.68s/it]\n",
            "7361.jpg: actual-predicted:      0,   19.3, error:   19.3. Current MAE: 52.80, RMSE: 114.00:  98% 1172/1190 [10:36:05<09:27, 31.51s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([29426, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7389.jpg: actual-predicted:      0,   32.7, error:   32.7. Current MAE: 52.79, RMSE: 113.95:  98% 1172/1190 [10:36:31<09:27, 31.51s/it]\n",
            "7389.jpg: actual-predicted:      0,   32.7, error:   32.7. Current MAE: 52.79, RMSE: 113.95:  99% 1173/1190 [10:36:31<08:24, 29.71s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([34525, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7710.jpg: actual-predicted:      0,   17.4, error:   17.4. Current MAE: 52.76, RMSE: 113.90:  99% 1173/1190 [10:37:02<08:24, 29.71s/it]\n",
            "7710.jpg: actual-predicted:      0,   17.4, error:   17.4. Current MAE: 52.76, RMSE: 113.90:  99% 1174/1190 [10:37:02<08:01, 30.11s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([33546, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7050.jpg: actual-predicted:      0,   31.2, error:   31.2. Current MAE: 52.74, RMSE: 113.86:  99% 1174/1190 [10:37:33<08:01, 30.11s/it]\n",
            "6990.jpg: actual-predicted:      0,   29.4, error:   29.4. Current MAE: 52.72, RMSE: 113.81:  99% 1175/1190 [10:38:12<07:34, 30.33s/it]\n",
            "6990.jpg: actual-predicted:      0,   29.4, error:   29.4. Current MAE: 52.72, RMSE: 113.81:  99% 1176/1190 [10:38:12<07:40, 32.90s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([61960, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6985.jpg: actual-predicted:      0,  112.2, error:  112.2. Current MAE: 52.77, RMSE: 113.81:  99% 1176/1190 [10:38:55<07:40, 32.90s/it]\n",
            "6985.jpg: actual-predicted:      0,  112.2, error:  112.2. Current MAE: 52.77, RMSE: 113.81:  99% 1177/1190 [10:38:55<07:46, 35.89s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([55877, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7387.jpg: actual-predicted:      0,   68.6, error:   68.6. Current MAE: 52.78, RMSE: 113.78:  99% 1177/1190 [10:39:21<07:46, 35.89s/it]\n",
            "7387.jpg: actual-predicted:      0,   68.6, error:   68.6. Current MAE: 52.78, RMSE: 113.78:  99% 1178/1190 [10:39:21<06:35, 32.95s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([84943, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7347.jpg: actual-predicted:      0,   75.9, error:   75.9. Current MAE: 52.80, RMSE: 113.76:  99% 1178/1190 [10:39:56<06:35, 32.95s/it]\n",
            "7347.jpg: actual-predicted:      0,   75.9, error:   75.9. Current MAE: 52.80, RMSE: 113.76:  99% 1179/1190 [10:39:56<06:08, 33.51s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([62846, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7278.jpg: actual-predicted:      0,   67.5, error:   67.5. Current MAE: 52.81, RMSE: 113.72:  99% 1179/1190 [10:40:20<06:08, 33.51s/it]\n",
            "7278.jpg: actual-predicted:      0,   67.5, error:   67.5. Current MAE: 52.81, RMSE: 113.72:  99% 1180/1190 [10:40:20<05:08, 30.84s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([46019, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6788.jpg: actual-predicted:      0,  179.6, error:  179.6. Current MAE: 52.92, RMSE: 113.80:  99% 1180/1190 [10:40:54<05:08, 30.84s/it]\n",
            "6788.jpg: actual-predicted:      0,  179.6, error:  179.6. Current MAE: 52.92, RMSE: 113.80:  99% 1181/1190 [10:40:54<04:46, 31.87s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([22002, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7490.jpg: actual-predicted:      0,  124.7, error:  124.7. Current MAE: 52.98, RMSE: 113.81:  99% 1181/1190 [10:41:18<04:46, 31.87s/it]\n",
            "7490.jpg: actual-predicted:      0,  124.7, error:  124.7. Current MAE: 52.98, RMSE: 113.81:  99% 1182/1190 [10:41:18<03:55, 29.39s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([62102, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7118.jpg: actual-predicted:      0,   32.1, error:   32.1. Current MAE: 52.97, RMSE: 113.76:  99% 1182/1190 [10:41:42<03:55, 29.39s/it]\n",
            "7118.jpg: actual-predicted:      0,   32.1, error:   32.1. Current MAE: 52.97, RMSE: 113.76:  99% 1183/1190 [10:41:42<03:15, 27.92s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([81066, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7136.jpg: actual-predicted:      0,   76.3, error:   76.3. Current MAE: 52.99, RMSE: 113.73:  99% 1183/1190 [10:42:09<03:15, 27.92s/it]\n",
            "7136.jpg: actual-predicted:      0,   76.3, error:   76.3. Current MAE: 52.99, RMSE: 113.73:  99% 1184/1190 [10:42:09<02:44, 27.42s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([54775, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7512.jpg: actual-predicted:      0,  106.8, error:  106.8. Current MAE: 53.03, RMSE: 113.73:  99% 1184/1190 [10:42:41<02:44, 27.42s/it]\n",
            "7512.jpg: actual-predicted:      0,  106.8, error:  106.8. Current MAE: 53.03, RMSE: 113.73: 100% 1185/1190 [10:42:41<02:24, 28.90s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([79181, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6918.jpg: actual-predicted:      0,   78.1, error:   78.1. Current MAE: 53.05, RMSE: 113.70: 100% 1185/1190 [10:43:06<02:24, 28.90s/it]\n",
            "6918.jpg: actual-predicted:      0,   78.1, error:   78.1. Current MAE: 53.05, RMSE: 113.70: 100% 1186/1190 [10:43:06<01:50, 27.73s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([181532, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7500.jpg: actual-predicted:      0,   49.7, error:   49.7. Current MAE: 53.05, RMSE: 113.67: 100% 1186/1190 [10:43:55<01:50, 27.73s/it]\n",
            "7500.jpg: actual-predicted:      0,   49.7, error:   49.7. Current MAE: 53.05, RMSE: 113.67: 100% 1187/1190 [10:43:55<01:41, 33.95s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([123650, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7047.jpg: actual-predicted:      0,   70.4, error:   70.4. Current MAE: 53.06, RMSE: 113.64: 100% 1187/1190 [10:44:30<01:41, 33.95s/it]\n",
            "7047.jpg: actual-predicted:      0,   70.4, error:   70.4. Current MAE: 53.06, RMSE: 113.64: 100% 1188/1190 [10:44:30<01:08, 34.25s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([167152, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "7412.jpg: actual-predicted:      0,   16.5, error:   16.5. Current MAE: 53.03, RMSE: 113.59: 100% 1188/1190 [10:45:02<01:08, 34.25s/it]\n",
            "7412.jpg: actual-predicted:      0,   16.5, error:   16.5. Current MAE: 53.03, RMSE: 113.59: 100% 1189/1190 [10:45:02<00:33, 33.85s/it]/content/LearningToCountEverything/utils.py:126: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([130203, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  Loss = F.mse_loss(output1, zeros, reduction='mean')\n",
            "6901.jpg: actual-predicted:      0,   26.1, error:   26.1. Current MAE: 53.01, RMSE: 113.54: 100% 1189/1190 [10:45:43<00:33, 33.85s/it]\n",
            "6901.jpg: actual-predicted:      0,   26.1, error:   26.1. Current MAE: 53.01, RMSE: 113.54: 100% 1190/1190 [10:45:43<00:00, 32.56s/it]\n",
            "On test data, MAE:  53.01, RMSE: 113.54\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}